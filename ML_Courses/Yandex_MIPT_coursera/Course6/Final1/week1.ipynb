{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEIpp7nqCh97"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_TUNO8acCh-A"
   },
   "source": [
    "# <center> Capstone проект №1. Идентификация пользователей по посещенным веб-страницам\n",
    "\n",
    "В этом проекте мы будем решать задачу идентификации пользователя по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в [статье](https://habrahabr.ru/company/yandex/blog/230583/) на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\".\n",
    "\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "Мы будем решать похожую задачу: по последовательности из нескольких веб-сайтов, посещенных подряд один и тем же человеком, мы будем идентифицировать этого человека. Идея такая: пользователи Интернета по-разному переходят по ссылкам, и это может помогать их идентифицировать (кто-то сначала в почту, потом про футбол почитать, затем новости, контакт, потом наконец – работать, кто-то – сразу работать).\n",
    "\n",
    "Будем использовать данные из [статьи](http://ceur-ws.org/Vol-1703/paper12.pdf) \"A Tool for Classification of Sequential Data\". И хотя мы не можем рекомендовать эту статью (описанные методы далеки от state-of-the-art, лучше обращаться к [книге](http://www.charuaggarwal.net/freqbook.pdf) \"Frequent Pattern Mining\" и последним статьям с ICDM), но данные там собраны аккуратно и представляют интерес.\n",
    "\n",
    "Данные пришли с прокси-серверов Университета Блеза Паскаля и имеют очень простой вид. Для каждого пользователя заведен csv-файл с названием user\\*\\*\\*\\*.csv (где вместо звездочек – 4 цифры, соответствующие ID пользователя), а в нем посещения сайтов записаны в следующем формате: <br>\n",
    "\n",
    "<center>*timestamp, посещенный веб-сайт*</center>\n",
    "\n",
    "Скачать исходные данные можно по [ссылке](http://fc.isima.fr/~kahngi/cez13.zip) в статье, там же описание.\n",
    "Для этого задания хватит данных не по всем 3000 пользователям, а по 10 и 150. [Ссылка](https://yadi.sk/d/3gscKIdN3BCASG) на архив *capstone_user_identification* (~7 Mb, в развернутом виде ~ 60 Mb). \n",
    "\n",
    "В финальном проекте уже придется столкнуться с тем, что не все операции можно выполнить за разумное время (скажем, перебрать с кросс-валидацией 100 комбинаций параметров случайного леса на этих данных вы вряд ли сможете), поэтому мы будем использовать параллельно 2 выборки: по 10 пользователям и по 150. Для 10 пользователей будем писать и отлаживать код, для 150 – будет рабочая версия. \n",
    "\n",
    "Данные устроены следующем образом:\n",
    "\n",
    " - В каталоге `10users` лежат 10 csv-файлов с названием вида \"user[USER_ID].csv\", где [USER_ID] – ID пользователя;\n",
    " - Аналогично для каталога `150users` – там 150 файлов;\n",
    " - В `3users` – игрушечный пример из 3 файлов, это для отладки кода предобработки, который вы далее напишете.\n",
    "\n",
    "На 5 неделе будет задание по [соревнованию](https://inclass.kaggle.com/c/identify-me-if-you-can4) Kaggle Inclass, которое организовано специально под Capstone проект нашей специализации. Соревнование уже открыто и, конечно, желающие могут начать уже сейчас.\n",
    "\n",
    "# <center>Неделя 1. Подготовка данных к анализу и построению моделей\n",
    "\n",
    "Первая часть проекта посвящена подготовке данных для дальнейшего описательного анализа и построения прогнозных моделей. Надо будет написать код для предобработки данных (исходно посещенные веб-сайты указаны для каждого пользователя в отдельном файле) и формирования единой обучающей выборки. Также в этой части мы познакомимся с разреженным форматом данных (матрицы Scipy.sparse), который хорошо подходит для данной задачи. \n",
    "\n",
    "**План 1 недели:**\n",
    " - Часть 1. Подготовка обучающей выборки\n",
    " - Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnrNypafCh-G"
   },
   "source": [
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций 1 и 2 недели курса \"Математика и Python для анализа данных\":**\n",
    "   - [Циклы, функции, генераторы, list comprehension](https://www.coursera.org/learn/mathematics-and-python/lecture/Kd7dL/tsikly-funktsii-ghienieratory-list-comprehension)\n",
    "   - [Чтение данных из файлов](https://www.coursera.org/learn/mathematics-and-python/lecture/8Xvwp/chtieniie-dannykh-iz-failov)\n",
    "   - [Запись файлов, изменение файлов](https://www.coursera.org/learn/mathematics-and-python/lecture/vde7k/zapis-failov-izmienieniie-failov)\n",
    "   - [Pandas.DataFrame](https://www.coursera.org/learn/mathematics-and-python/lecture/rcjAW/pandas-data-frame)\n",
    "   - [Pandas. Индексация и селекция](https://www.coursera.org/learn/mathematics-and-python/lecture/lsXAR/pandas-indieksatsiia-i-sieliektsiia)\n",
    "   \n",
    "**Кроме того, в задании будут использоваться библиотеки Python [glob](https://docs.python.org/3/library/glob.html), [pickle](https://docs.python.org/2/library/pickle.html) и класс [csr_matrix](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html) из scipy.sparse.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "walxALYRCh-H"
   },
   "source": [
    "Наконец, для лучшей воспроизводимости результатов приведем список версий основных используемых в проекте библиотек: NumPy, SciPy, Pandas, Matplotlib, Statsmodels и Scikit-learn. Для этого воспользуемся расширением [watermark](https://github.com/rasbt/watermark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1212,
     "status": "ok",
     "timestamp": 1598943650718,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "KIdlT4AFCh-n"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S57ePGVUCh-y"
   },
   "source": [
    "**Посмотрим на один из файлов с данными о посещенных пользователем (номер 31) веб-страницах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1598943690084,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "1cjttrEnCh-0"
   },
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PATH_TO_DATA = '/content/drive/My Drive/ML\\DS/Yandex_MIPT_coursera/Course6/Final1/capstone_user_identification/'\n",
    "else:\n",
    "    PATH_TO_DATA = 'capstone_user_identification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4467,
     "status": "ok",
     "timestamp": 1598943695421,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "X3idT6dkCh-_"
   },
   "outputs": [],
   "source": [
    "user31_data = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       '10users/user0031.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2796,
     "status": "ok",
     "timestamp": 1598943695430,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "YQZPqbMwCh_M",
    "outputId": "37355f0f-de45-452c-f121-caff541dea71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-15 08:12:07</td>\n",
       "      <td>fpdownload2.macromedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15 08:12:18</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-11-15 08:12:07  fpdownload2.macromedia.com\n",
       "1  2013-11-15 08:12:17                 laposte.net\n",
       "2  2013-11-15 08:12:17             www.laposte.net\n",
       "3  2013-11-15 08:12:17              www.google.com\n",
       "4  2013-11-15 08:12:18             www.laposte.net"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user31_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywYLRo4sCh_Y"
   },
   "source": [
    "**Поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов (чуть позже здесь появится \"мешок\" сайтов, подход Bag of Words). Целевым классом будет id пользователя.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nuwLrLAzCh_Z"
   },
   "source": [
    "### <center>Пример для иллюстрации</center>\n",
    "**Пусть пользователя всего 2, длина сессии – 2 сайта.**\n",
    "\n",
    "<center>user0001.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:01</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:11</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:16</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:20</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<center>user0002.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:02</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:14</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:17</td>\n",
    "    <td class=\"tg-031e\">facebook.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:25</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Идем по 1 файлу, нумеруем сайты подряд: vk.com – 1, google.com – 2 и т.д. Далее по второму файлу. \n",
    "\n",
    "Отображение сайтов в их индесы должно получиться таким:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "    <th class=\"tg-yw4l\">site_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">vk.com</td>\n",
    "    <td class=\"tg-yw4l\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "    <td class=\"tg-yw4l\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">yandex.ru</td>\n",
    "    <td class=\"tg-yw4l\">3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">facebook.com</td>\n",
    "    <td class=\"tg-yw4l\">4</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Тогда обучающая выборка будет такой (целевой признак – user_id):\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">session_id</th>\n",
    "    <th class=\"tg-hgcj\">site1</th>\n",
    "    <th class=\"tg-hgcj\">site2</th>\n",
    "    <th class=\"tg-amwm\">user_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">4</td>\n",
    "    <td class=\"tg-s6z2\">4</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Здесь 1 объект – это сессия из 2 посещенных сайтов 1-ым пользователем (target=1). Это сайты vk.com и google.com (номер 1 и 2). И так далее, всего 4 сессии. Пока сессии у нас не пересекаются по сайтам, то есть посещение каждого отдельного сайта относится только к одной сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ab6gT9SECh_b"
   },
   "source": [
    "## Часть 1. Подготовка обучающей выборки\n",
    "Реализуйте функцию *prepare_train_set*, которая принимает на вход путь к каталогу с csv-файлами *path_to_csv_files* и параметр *session_length* – длину сессии, а возвращает 2 объекта:\n",
    "- DataFrame, в котором строки соответствуют уникальным сессиям из *session_length* сайтов, *session_length* столбцов – индексам этих *session_length* сайтов и последний столбец – ID пользователя\n",
    "- частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n",
    "\n",
    "Детали:\n",
    "- Смотрите чуть ниже пример вывода, что должна возвращать функция\n",
    "- Используйте glob (или аналоги) для обхода файлов в каталоге. Для определенности, отсортируйте список файлов лексикографически. Удобно использовать `tqdm` для отслеживания числа выполненных итераций цикла\n",
    "- Создайте частотный словарь уникальных сайтов (вида {'site_string': (site_id, site_freq)}) и заполняйте его по ходу чтения файлов. Начните с 1\n",
    "- Рекомендуется меньшие индексы давать более часто попадающимся сайтам (приницип наименьшего описания)\n",
    "- Не делайте entity recognition, считайте *google.com*, *http://www.google.com* и *www.google.com* разными сайтами (подключить entity recognition можно уже в рамках индивидуальной работы над проектом)\n",
    "- Скорее всего в файле число записей не кратно числу *session_length*. Тогда последняя сессия будет короче. Остаток заполняйте нулями. То есть если в файле 24 записи и сессии длины 10, то 3 сессия будет состоять из 4 сайтов, и ей мы сопоставим вектор [*site1_id*, *site2_id*, *site3_id*, *site4_id*, 0, 0, 0, 0, 0, 0, *user_id*] \n",
    "- В итоге некоторые сессии могут повторяться – оставьте как есть, не удаляйте дубликаты. Если в двух сессиях все сайты одинаковы, но сессии принадлежат разным пользователям, то тоже оставляйте как есть, это естественная неопределенность в данных\n",
    "- Не оставляйте в частотном словаре сайт 0 (уже в конце, когда функция возвращает этот словарь)\n",
    "- 150 файлов из *capstone_websites_data/150users/* у меня обработались за 1.7 секунды, но многое, конечно, зависит от реализации функции и от используемого железа. И вообще, первая реализация скорее всего будет не самой эффективной, дальше можно заняться профилированием (особенно если планируете запускать этот код для 3000 пользователей). Также эффективная реализация этой функции поможет нам на следующей неделе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1460,
     "status": "ok",
     "timestamp": 1598943747250,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "RCje4_sMZCGz"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1598943934073,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "IVDfDxkVCh_d"
   },
   "outputs": [],
   "source": [
    "def prepare_train_set(path_to_csv_files, session_length=10):\n",
    "    files = sorted(glob(os.path.join(path_to_csv_files, '*.csv')))\n",
    "    file_names = [name for name in sorted(os.listdir(path_to_csv_files)) if not name.startswith('.')]\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    user_ids = [int(re.search(pattern, n).group(0)) for n in file_names]\n",
    "    # Initialize counter\n",
    "    c = Counter()\n",
    "    ids = []\n",
    "    col_names = ['site%i' % i for i in range(1, session_length+1)]\n",
    "    # Create empty DataFrame \n",
    "    df = pd.DataFrame()\n",
    "    for ind, file in tqdm(enumerate(files)):\n",
    "        f = pd.read_csv(file)\n",
    "        # Split file into pieces of size \"session_length\"\n",
    "        row = np.array_split(f.site.values, range(session_length, len(f), session_length))\n",
    "        # Gradually fill DataFrame\n",
    "        df = pd.concat([df, pd.DataFrame(row)], ignore_index=True)\n",
    "        # Create values for user_id column\n",
    "        ids.extend([user_ids[ind]] * len(row))\n",
    "        # Count sites frequencies\n",
    "        c.update(f.site)\n",
    "\n",
    "    # Replace sites names with their ids in order of descending frequencies and add user_id column\n",
    "    df = df.applymap(dict(zip(sorted(c, key=c.get, reverse=True), range(1, len(c)+1))).get) \\\n",
    "        .fillna(0).astype(int)\n",
    "    df.columns = col_names\n",
    "    df['user_id'] = ids\n",
    "\n",
    "    # Create frequencies dictionary\n",
    "    freq_dict = {}\n",
    "    for i, k in enumerate(c.most_common(), start=1):\n",
    "        freq_dict[k[0]] = (i, c[k[0]])\n",
    "\n",
    "    return df, freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eBI3vPyCh_q"
   },
   "source": [
    "**Примените полученную функцию к игрушечному примеру, убедитесь, что все работает как надо.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1598875410191,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "Ro8Sn-1RCh_s",
    "outputId": "1a67af43-315b-4f07-eb80-bdaf947b3449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\n",
      "2013-11-15 09:28:17,vk.com\n",
      "2013-11-15 09:33:04,oracle.com\n",
      "2013-11-15 09:52:48,oracle.com\n",
      "2013-11-15 11:37:26,geo.mozilla.org\n",
      "2013-11-15 11:40:32,oracle.com\n",
      "2013-11-15 11:40:34,google.com\n",
      "2013-11-15 11:40:35,accounts.google.com\n",
      "2013-11-15 11:40:37,mail.google.com\n",
      "2013-11-15 11:40:40,apis.google.com\n",
      "2013-11-15 11:41:35,plus.google.com\n",
      "2013-11-15 12:40:35,vk.com\n",
      "2013-11-15 12:40:37,google.com\n",
      "2013-11-15 12:40:40,google.com\n",
      "2013-11-15 12:41:35,google.com\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0001.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1598875418909,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "xw9-d68OCh_2",
    "outputId": "96be0900-3fbd-4145-d8c2-9e59b1028b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\n",
      "2013-11-15 09:28:17,vk.com\n",
      "2013-11-15 09:33:04,oracle.com\n",
      "2013-11-15 09:52:48,football.kulichki.ru\n",
      "2013-11-15 11:37:26,football.kulichki.ru\n",
      "2013-11-15 11:40:32,oracle.com\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0002.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1598875426165,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "vdRskJeZCh__",
    "outputId": "227d2876-2efc-482d-b97e-cc1d82489f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\n",
      "2013-11-15 09:28:17,meduza.io\n",
      "2013-11-15 09:33:04,google.com\n",
      "2013-11-15 09:52:48,oracle.com\n",
      "2013-11-15 11:37:26,google.com\n",
      "2013-11-15 11:40:32,oracle.com\n",
      "2013-11-15 11:40:34,google.com\n",
      "2013-11-15 11:40:35,google.com\n",
      "2013-11-15 11:40:37,mail.google.com\n",
      "2013-11-15 11:40:40,yandex.ru\n",
      "2013-11-15 11:41:35,meduza.io\n",
      "2013-11-15 12:28:17,meduza.io\n",
      "2013-11-15 12:33:04,google.com\n",
      "2013-11-15 12:52:48,oracle.com\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0003.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4121,
     "status": "ok",
     "timestamp": 1598943761921,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "X20VStqwCiAH",
    "outputId": "de507e09-6b0e-46f2-af17-4e9b78415301"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 33.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_toy, site_freq_3users = prepare_train_set(os.path.join(PATH_TO_DATA, '3users'), \n",
    "                                                     session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 977,
     "status": "ok",
     "timestamp": 1598943767956,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "LZubsBDWCiAS",
    "outputId": "988f20d4-1eb0-4914-bb14-1bc047c132d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  \\\n",
       "0      3      2      2      7      2      1      8      5      9      10   \n",
       "1      3      1      1      1      0      0      0      0      0       0   \n",
       "2      3      2      6      6      2      0      0      0      0       0   \n",
       "3      4      1      2      1      2      1      1      5     11       4   \n",
       "4      4      1      2      0      0      0      0      0      0       0   \n",
       "\n",
       "   user_id  \n",
       "0        1  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAurZQ1fCiAg"
   },
   "source": [
    "Частоты сайтов (второй элемент кортежа) точно должны быть такими, нумерация может быть любой (первые элементы кортежей могут отличаться)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1598943771878,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "_oAvo2zICiAk",
    "outputId": "b2421e8d-9134-4fc9-a01c-962f2402d00c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'google.com': (1, 9),\n",
       " 'oracle.com': (2, 8),\n",
       " 'vk.com': (3, 3),\n",
       " 'meduza.io': (4, 3),\n",
       " 'mail.google.com': (5, 2),\n",
       " 'football.kulichki.ru': (6, 2),\n",
       " 'geo.mozilla.org': (7, 1),\n",
       " 'accounts.google.com': (8, 1),\n",
       " 'apis.google.com': (9, 1),\n",
       " 'plus.google.com': (10, 1),\n",
       " 'yandex.ru': (11, 1)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_freq_3users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VR2r73V3CiAw"
   },
   "source": [
    "**1. Примените полученную функцию к данным по 10 пользователям, посмотрите, сколько уникальных сессий из 10 сайтов получится, запишите ответ в файл с помощью функции *write_answer_to_file* – это будет ответом к первому вопросу теста. Если ответ получился неправильный, значит где-то ошибка в функции *prepare_train_set*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7607,
     "status": "ok",
     "timestamp": 1598943781964,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "OXiqZOcGCiAy",
    "outputId": "2979b961-c9f8-49fa-a393-85ab0280261d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 24.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_10users, site_freq_10users = prepare_train_set(os.path.join(PATH_TO_DATA, '10users'), \n",
    "                                                     session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1598943797926,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "mDCE4KWpCiA7"
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1598943800211,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "H9v1fFubdE8G",
    "outputId": "9ec068fa-fa27-4c0a-875c-a65c37842126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 10 sites sessions for 10 users: 14061\n"
     ]
    }
   ],
   "source": [
    "print('Unique 10 sites sessions for 10 users: %i' % len(train_data_10users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUwQ3JSBCiBH"
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(len(train_data_10users), \n",
    "                     'answer1_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_MilMftCiBW"
   },
   "source": [
    "**2. Сколько всего уникальных сайтов в выборке из 10 пользователей?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1598943804614,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "yqqGL8wHeUTG",
    "outputId": "d340641f-94f5-4ecb-a99a-e10022c27339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sites for 10 users: 4913\n"
     ]
    }
   ],
   "source": [
    "print('Unique sites for 10 users: %i' % len(site_freq_10users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xyAo1dgCiBX"
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(len(site_freq_10users), \n",
    "                     'answer1_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RwsjTz8CiBg"
   },
   "source": [
    "**3. Примените полученную функцию к данным по 150 пользователям, посмотрите, сколько уникальных сессий из 10 сайтов получится, запишите ответ в файл с помощью функции *write_answer_to_file* – это будет ответом к третьему вопросу. Если ответ получился неправильный, значит где-то ошибка в функции *prepare_train_set*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsoADMYPCiBi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:04, 35.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 367 ms, total: 3.25 s\n",
      "Wall time: 4.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_150users, site_freq_150users = prepare_train_set(os.path.join(PATH_TO_DATA, '150users'), \n",
    "                                                     session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1598944015491,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "JiI638O0iszY",
    "outputId": "20e3a1de-17a6-4494-e53e-25317969c163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 10 sites sessions for 150 users: 137019\n"
     ]
    }
   ],
   "source": [
    "print('Unique 10 sites sessions for 150 users: %i' % len(train_data_150users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1598944017866,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "yGR760qzCiBt"
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(len(train_data_150users), \n",
    "                     'answer1_3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyEM8c1MCiB5"
   },
   "source": [
    "**4. Сколько всего уникальных сайтов в выборке из 150 пользователей?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1598944021113,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "ZZDX1mWZi5c9",
    "outputId": "579253b4-1582-4458-9dc9-1d8cca3b8852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sites for 150 users: 27797\n"
     ]
    }
   ],
   "source": [
    "print('Unique sites for 150 users: %i' % len(site_freq_150users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Zolr02ZCiB7"
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(len(site_freq_150users), \n",
    "                     'answer1_4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuIGBjuYCiCF"
   },
   "source": [
    "**5. Выведите топ-10 самых популярных сайтов среди посещенных 150 пользователями. Запишите ответ в файл *answer1_5.txt* через пробел – все 10 сайтов на одной строке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1598944026000,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "_m0QodOyCiCH"
   },
   "outputs": [],
   "source": [
    "top10_popular = sorted(site_freq_150users, key=lambda x: site_freq_150users.get(x)[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1598944027405,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "CRsGkU9hCiCW",
    "outputId": "d2fbd4e6-e1db-491c-eea2-27a07dd03b00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.google.fr',\n",
       " 'www.google.com',\n",
       " 'www.facebook.com',\n",
       " 'apis.google.com',\n",
       " 's.youtube.com',\n",
       " 'clients1.google.com',\n",
       " 'mail.google.com',\n",
       " 'plus.google.com',\n",
       " 'safebrowsing-cache.google.com',\n",
       " 'www.youtube.com']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbsdOp8MCiCh"
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(' '.join(top10_popular), \n",
    "                     'answer1_5.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNAgmca3CiCs"
   },
   "source": [
    "**Для дальнейшего анализа запишем полученные объекты DataFrame в csv-файлы.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AkLLkoNvCiCu"
   },
   "outputs": [],
   "source": [
    "train_data_10users.to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_10users.csv'), \n",
    "                        index_label='session_id', float_format='%d')\n",
    "train_data_150users.to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_data_150users.csv'), \n",
    "                         index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25cVmx-iCiC2"
   },
   "source": [
    "## Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cC4XjO6eCiC3"
   },
   "source": [
    "**Если так подумать, то полученные признаки *site1*, ..., *site10* смысла не имеют как признаки в задаче классификации. А вот если воспользоваться идеей мешка слов из анализа текстов – это другое дело. Создадим новые матрицы, в которых строкам будут соответствовать сессии из 10 сайтов, а столбцам – индексы сайтов. На пересечении строки $i$ и столбца $j$ будет стоять число $n_{ij}$ – cколько раз сайт $j$ встретился в сессии номер $i$. Делать это будем с помощью разреженных матриц Scipy – [csr_matrix](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html). Прочитайте документацию, разберитесь, как использовать разреженные матрицы и создайте такие матрицы для наших данных. Сначала проверьте на игрушечном примере, затем примените для 10 и 150 пользователей. **\n",
    "\n",
    "**Обратите внимание, что в коротких сессиях, меньше 10 сайтов, у нас остались нули, так что первый признак (сколько раз попался 0) по смыслу отличен от остальных (сколько раз попался сайт с индексом $i$). Поэтому первый столбец разреженной матрицы надо будет удалить.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1598944103853,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "CM27algmCiC4"
   },
   "outputs": [],
   "source": [
    "X_toy, y_toy = train_data_toy.iloc[:, :-1].values, train_data_toy.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1598944106291,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "bAIwDxsYCiDB",
    "outputId": "bc1a5d55-ca35-4878-c627-b948bff1a3d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2,  2,  7,  2,  1,  8,  5,  9, 10],\n",
       "       [ 3,  1,  1,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  2,  6,  6,  2,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  2,  1,  2,  1,  1,  5, 11,  4],\n",
       "       [ 4,  1,  2,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1347,
     "status": "ok",
     "timestamp": 1598946962626,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "6tpyQsU2nwri"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_sparse_matrix(X):\n",
    "    '''\n",
    "    Converts session matrix X to sparse of specified shape\n",
    "    '''\n",
    "    rows, cols, vals = np.asarray(list(itertools.chain.from_iterable([zip([i]*len(row), \\\n",
    "               *np.unique(row, return_counts=True)) for i, row in enumerate(X)]))).T\n",
    "\n",
    "    return csr_matrix((vals, (rows, cols)), shape=(len(X), np.max(X)+1))[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1598947032626,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "3Ud86_Q3CiDQ"
   },
   "outputs": [],
   "source": [
    "X_sparse_toy = get_sparse_matrix(X_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pi0gQgACiDW"
   },
   "source": [
    "**Размерность разреженной матрицы должна получиться равной 11, поскольку в игрушечном примере 3 пользователя посетили 11 уникальных сайтов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1598947034666,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "3POUoFsoCiDY",
    "outputId": "8552190a-24df-4b58-c8ca-f2195dd770b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 3, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
       "        [3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "        [4, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse_toy.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1433,
     "status": "ok",
     "timestamp": 1598946031591,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "OkUVD5e1CiDf"
   },
   "outputs": [],
   "source": [
    "X_10users, y_10users = train_data_10users.iloc[:, :-1].values, \\\n",
    "                       train_data_10users.iloc[:, -1].values\n",
    "X_150users, y_150users = train_data_150users.iloc[:, :-1].values, \\\n",
    "                         train_data_150users.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4926,
     "status": "ok",
     "timestamp": 1598947071161,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "L6oeeAI_CiDr"
   },
   "outputs": [],
   "source": [
    "X_sparse_10users = get_sparse_matrix(X_10users)\n",
    "X_sparse_150users = get_sparse_matrix(X_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQJ85aLwCiDz"
   },
   "source": [
    "**Сохраним эти разреженные матрицы с помощью [pickle](https://docs.python.org/2/library/pickle.html) (сериализация в Python), также сохраним вектора *y_10users, y_150users* – целевые значения (id пользователя)  в выборках из 10 и 150 пользователей. То что названия этих матриц начинаются с X и y, намекает на то, что на этих данных мы будем проверять первые модели классификации.\n",
    "Наконец, сохраним также и частотные словари сайтов для 3, 10 и 150 пользователей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1598948503250,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "9NBOG7hWCiD4"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'X_sparse_10users.pkl'), 'wb') as X10_pkl:\n",
    "    pickle.dump(X_sparse_10users, X10_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'y_10users.pkl'), 'wb') as y10_pkl:\n",
    "    pickle.dump(y_10users, y10_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'X_sparse_150users.pkl'), 'wb') as X150_pkl:\n",
    "    pickle.dump(X_sparse_150users, X150_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'y_150users.pkl'), 'wb') as y150_pkl:\n",
    "    pickle.dump(y_150users, y150_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'site_freq_3users.pkl'), 'wb') as site_freq_3users_pkl:\n",
    "    pickle.dump(site_freq_3users, site_freq_3users_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'site_freq_10users.pkl'), 'wb') as site_freq_10users_pkl:\n",
    "    pickle.dump(site_freq_10users, site_freq_10users_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'site_freq_150users.pkl'), 'wb') as site_freq_150users_pkl:\n",
    "    pickle.dump(site_freq_150users, site_freq_150users_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0L-FtfUaCiEA"
   },
   "source": [
    "**Чисто для подстраховки проверим, что число столбцов в разреженных матрицах `X_sparse_10users` и `X_sparse_150users` равно ранее посчитанным числам уникальных сайтов для 10 и 150 пользователей соответственно.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1598948540151,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "J9Ft88bPCiEC"
   },
   "outputs": [],
   "source": [
    "assert X_sparse_10users.shape[1] == len(site_freq_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1598948541607,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": 0
    },
    "id": "o2d2coaSCiEM"
   },
   "outputs": [],
   "source": [
    "assert X_sparse_150users.shape[1] == len(site_freq_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VH81O01_CiES"
   },
   "source": [
    "## Пути улучшения\n",
    "В этом проекте свобода творчества на каждом шаге, а 7 неделя проекта посвящена общему описанию (`html`, `ipynb` или `pdf`) и взаимному оцениванию проектов. Что еще можно добавить по первой части проекта:\n",
    "-  можно обработать исходные данные по 3000 пользователей; обучать на такой выборке модели лучше при наличии доступа к хорошим мощностям (можно арендовать инстанс Amazon EC2, как именно, описано [тут](https://habrahabr.ru/post/280562/)). Хотя далее в курсе мы познакомимся с алгоритмами, способными обучаться на больших выборках при малых вычислительных потребностях;\n",
    "- Помимо явного создания разреженного формата можно еще составить выборки с помощью `CountVectorizer`, `TfidfVectorizer` и т.п. Поскольку данные по сути могут быть описаны как последовательности, то можно вычислять n-граммы сайтов. Работает все это или нет, мы будем проверять в [соревновании](https://inclass.kaggle.com/c/identify-me-if-you-can4) Kaggle Inclass (желающие могут начать уже сейчас).\n",
    "\n",
    "На следующей неделе мы еще немного поготовим данные и потестируем первые гипотезы, связанные с нашими наблюдениями. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "25cVmx-iCiC2",
    "VH81O01_CiES"
   ],
   "name": "week1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
