{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-13 18:41:37--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Распознаётся ufldl.stanford.edu (ufldl.stanford.edu)… 171.64.68.10\n",
      "Подключение к ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 182040794 (174M) [text/plain]\n",
      "Сохранение в: «train_32x32.mat»\n",
      "\n",
      "train_32x32.mat     100%[===================>] 173,61M   742KB/s    за 9m 17s  \n",
      "\n",
      "2020-07-13 18:50:55 (319 KB/s) - «train_32x32.mat» сохранён [182040794/182040794]\n",
      "\n",
      "--2020-07-13 18:50:55--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Повторное использование соединения с ufldl.stanford.edu:80.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 64275384 (61M) [text/plain]\n",
      "Сохранение в: «test_32x32.mat»\n",
      "\n",
      "test_32x32.mat      100%[===================>]  61,30M   570KB/s    за 3m 23s  \n",
      "\n",
      "2020-07-13 18:54:18 (309 KB/s) - «test_32x32.mat» сохранён [64275384/64275384]\n",
      "\n",
      "ЗАВЕРШЕНО --2020-07-13 18:54:18--\n",
      "Общее время: 12m 41s\n",
      "Загружено: 2 файлов, 235M за 12m 40s (317 KB/s)\n"
     ]
    }
   ],
   "source": [
    "! ./download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20603191 0.20603191 0.56005279 0.02788339]\n",
      " [0.29692274 0.29692274 0.29692274 0.10923177]\n",
      " [0.1024912  0.0377044  0.1024912  0.7573132 ]] 2.690661964381937 [[3]\n",
      " [1]\n",
      " [1]]\n",
      "[[ 0.0686773   0.0686773   0.18668426 -0.32403887]\n",
      " [ 0.09897425 -0.23435909  0.09897425  0.03641059]\n",
      " [ 0.03416373 -0.3207652   0.03416373  0.25243773]]\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "preds = predictions - np.max(predictions, axis=1).reshape(-1, 1)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "#print(predictions, target_index)\n",
    "probs = linear_classifer.softmax(predictions)\n",
    "loss = linear_classifer.cross_entropy_loss(probs, target_index)\n",
    "print(probs, loss, target_index)\n",
    "np.take_along_axis(probs, target_index, axis=1)\n",
    "np.log(np.take_along_axis(probs, target_index, axis=1))\n",
    "a = np.zeros_like(probs)\n",
    "np.put_along_axis(a, target_index, 1, axis=1)\n",
    "print((probs - a) / len(probs))\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(2, dtype=np.int)\n",
    "b = np.ones([2, 1], dtype=np.int)\n",
    "b.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0877576813083574\n",
      "(2, 2) (2, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones([batch_size], dtype=np.int)\n",
    "predictions = np.dot(X, W)\n",
    "probs = linear_classifer.softmax(predictions)\n",
    "loss = linear_classifer.cross_entropy_loss(probs, target_index)\n",
    "print(loss)\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "print(dW.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0, -1],\n",
       "        [ 0,  2]]),\n",
       " array([[0, 1],\n",
       "        [0, 4]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(-1, 3, size=(2,2))\n",
    "a, a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = 1000\n",
    "batch_size = 5\n",
    "shuffled_indices = np.arange(num_train)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "sections = np.arange(batch_size, num_train, batch_size)\n",
    "batches_indices = np.array_split(shuffled_indices, sections)\n",
    "batches_indices\n",
    "a = np.array([i for i in range(1000)])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.484073\n",
      "Epoch 1, loss: 2.356060\n",
      "Epoch 2, loss: 2.317992\n",
      "Epoch 3, loss: 2.306667\n",
      "Epoch 4, loss: 2.303295\n",
      "Epoch 5, loss: 2.302299\n",
      "Epoch 6, loss: 2.301977\n",
      "Epoch 7, loss: 2.301886\n",
      "Epoch 8, loss: 2.301880\n",
      "Epoch 9, loss: 2.301861\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd8a8f12510>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXRc9X3n8fdXT5Ys27JGlm0hP2hsCLbLgx9k2Sk53RCWbELSYANJSLeGNN2aboDCHnYbSnf35GzaHsg2hJzTBNY87JKUwKZgB7bJhmQpKSUtNrLsYBuZALYB27It/CDZWLL18N0/5gqPxyNpRh7pzuh+Xufo6M7v/n53vneOrc/M/d2519wdERGJnqKwCxARkXAoAEREIkoBICISUQoAEZGIUgCIiERUSdgFZGPatGne0NAQdhkiIgVl8+bN77t7bWp7QQVAQ0MDzc3NYZchIlJQzOyddO06BCQiElEKABGRiFIAiIhElAJARCSiFAAiIhGlABARiSgFgIhIREUiAF584xDf++VbYZchIpJXIhEA//L2YR74xZt09/SFXYqISN6IRAA0NcQ43dfP1veOhV2KiEjeiEQALG+IYQabdh8JuxQRkbwRiQComljKgplTFAAiIkkiEQAAK+IxNr9zlJ6+/rBLERHJC5EJgKZ4jK6ePrbt6wi7FBGRvBCpAADNA4iIDBg2AMxstpm9aGatZrbDzO4You9yM+szsxuCxxeb2dakn04zuzNY93Uz25e07prc7da5pk2awPzaSjbuOjyaTyMiUjAyuSFML3CXu7eY2WRgs5n9wt1fT+5kZsXAfcDzA23u/gawOGn9PmBD0rBvu/tfn+c+ZKwpXsPf/3o/ff1OcZGN1dOKiOSlYT8BuHubu7cEy8eBVqA+TdfbgWeAQ4Ns6irgbXdPe2easbByXozjp3ppbesMqwQRkbyR1RyAmTUAS4CNKe31wGrgoSGG3wg8mdJ2m5m9ZmaPmVn1IM+51syazay5vb09m3LPsbwhMQ+wUfMAIiKZB4CZTSLxDv9Od099C/0A8DV3T3utBTMrAz4H/F1S84PAfBKHiNqAb6Ub6+7r3L3R3Rtra8+5p3FWLphawexYBZt2ax5ARCSjm8KbWSmJP/5PuPv6NF0agafMDGAacI2Z9br7j4P1nwZa3P3gwIDkZTN7GPj7ke1CdlbEa3ih9SDuTlCviEgkZXIWkAGPAq3ufn+6Pu4ed/cGd28Anga+mvTHH+BLpBz+MbO6pIerge1Z1j4iTfEYR0/28OahE2PxdCIieSuTTwBXAGuAbWa2NWi7B5gD4O5DHffHzCYCVwO3pKz6ppktBhzYk2b9qFgRPzMP8JEZk8fiKUVE8tKwAeDuLwMZHytx9y+nPD4J1KTptybTbebSnNhEZk4pZ9PuI6xZOTeMEkRE8kJkvgk8wMxoisfYuOsw7h52OSIioYlcAACsmBfj0PFTvHP4ZNiliIiEJpoBoOsCiYhEMwDm106iprKMV/R9ABGJsEgGwMA8gD4BiEiURTIAIPF9gL1Hu9h3rCvsUkREQhHpAAB0WQgRiazIBsCCmVOYUl6iw0AiElmRDYDiImN5Q0xXBhWRyIpsAEDiMNCu9g84dLw77FJERMZcpANgxbzEFSpe3X005EpERMZepAPgty6YwsSyYk0Ei0gkRToASouLWDa3WvMAIhJJkQ4ASFwWYueB4xw7eTrsUkRExlTkA6ApHswD7NE8gIhES+QD4LJZVZSVFLFxl+YBRCRaIh8A5aXFLJk9lU17NA8gItES+QCAxDzA9n0dHO/uCbsUEZExk8lN4Web2Ytm1mpmO8zsjiH6LjezPjO7Ialtj5ltM7OtZtac1B4zs1+Y2ZvB7+rz352RaYrX0O+w+R3NA4hIdGTyCaAXuMvdFwIrgVvNbFFqJzMrBu4Dnk+zjSvdfbG7Nya13Q284O4XAS8Ej0OxdO5USopM1wUSkUgZNgDcvc3dW4Ll40ArUJ+m6+3AM8ChDJ/7WuDxYPlxYFWG43JuYlkJl86q0vcBRCRSspoDMLMGYAmwMaW9HlgNPJRmmAM/N7PNZrY2qX2Gu7dBImSA6YM851ozazaz5vb29mzKzUpTPMZre4/Rdbpv1J5DRCSfZBwAZjaJxDv8O929M2X1A8DX3D3dX88r3H0p8GkSh49+J5sC3X2duze6e2NtbW02Q7OyMl5DT5+z5T3NA4hINGQUAGZWSuKP/xPuvj5Nl0bgKTPbA9wAfM/MVgG4+/7g9yFgA9AUjDloZnXB9uvI/NDRqFjWUI0ZbNylw0AiEg2ZnAVkwKNAq7vfn66Pu8fdvcHdG4Cnga+6+4/NrNLMJgfbqQQ+CWwPhj0H3Bws3ww8e157cp6mlJeyqG6KJoJFJDJKMuhzBbAG2GZmW4O2e4A5AO6e7rj/gBnAhkSGUAL80N1/Fqy7F/iRmf0h8C7w+ezLz60V8Rqe2PgOp3v7KSvRVyREZHwbNgDc/WXAMt2gu385aXkXcPkg/Q4DV2W63bHQFI/x2K9289reYzQ2xMIuR0RkVOltbpKBG8XrdFARiQIFQJJYZRkfmTFJ8wAiEgkKgBRN8RjNe47Q29cfdikiIqNKAZCiKV7DB6f7eL0t9asOIiLjiwIgxYpgHkCHgURkvFMApJgxpZyGmom8oi+Eicg4pwBIoyke49U9R+jv97BLEREZNQqANFbEa+jo6uE3h46HXYqIyKhRAKTx4fcBdBhIRMYxBUAas6oruKCqXBPBIjKuKQDSMDNWzKth4+4juGseQETGJwXAIJriMd4/cYpd738QdikiIqNCATCIJn0fQETGOQXAIOZNq2TapAkKABEZtxQAgzAzVsRjbNx1WPMAIjIuKQCG0BSPsb+jm71Hu8IuRUQk5xQAQ1gxT/MAIjJ+KQCG8JHpk6mqKGXj7sNhlyIiknOZ3BR+tpm9aGatZrbDzO4You9yM+szsxuGG2tmXzezfWa2Nfi5Jje7lDtFRcbyhpg+AYjIuJTJJ4Be4C53XwisBG41s0WpncysGLgPeD6Lsd9298XBz09HvBejaOW8GHsOn+RgZ3fYpYiI5NSwAeDube7eEiwfB1qB+jRdbweeAQ6NYGze0n2CRWS8ymoOwMwagCXAxpT2emA18FCWY28zs9fM7DEzqx5k3Fozazaz5vb29mzKzYlFdVOYNKGETZoHEJFxJuMAMLNJJN7h3+nuqfdLfAD4mrv3ZTH2QWA+sBhoA76Vbqy7r3P3RndvrK2tzbTcnCkpLmLZ3GrNA4jIuJNRAJhZKYk/4E+4+/o0XRqBp8xsD3AD8D0zWzXUWHc/6O597t4PPAw0ndeejKKmeIzfHDzBkQ9Oh12KiEjOZHIWkAGPAq3ufn+6Pu4ed/cGd28Anga+6u4/HmqsmdUlPVwNbB/hPoy6lfo+gIiMQyUZ9LkCWANsM7OtQds9wBwAdx/0uP9gY4Mzfr5pZosBB/YAt2Rf/ti4tH4qE0qK2LT7CJ+6ZGbY5YiI5MSwAeDuLwOW6Qbd/cuZjHX3NZluM2xlJUUsnVOtL4SJyLiibwJnaMW8GK+3ddLZ3RN2KSIiOaEAyFBTPIY7bN5zNOxSRERyQgGQoSWzqyktNl7RYSARGScUABmqKCvm8llTdSaQiIwbCoAsNMVjbNvbwcnTvWGXIiJy3hQAWWiKx+jtd1reORZ2KSIi500BkIXGhhhFhq4LJCLjggIgC5MmlHBJfRWvaB5ARMYBBUCWmhpibH3vGN09aa97JyJSMBQAWVoxr4bTvf28trcj7FJERM6LAiBLyxsSty3YuEvzACJS2BQAWZo6sYwFMyezaY/mAUSksCkARmBFPMbmd47S09cfdikiIiOmABiBpngNJ0/3sX2f5gFEpHApAEZgeTwxD6DLQohIIVMAjMD0yeXMq61UAIhIQVMAjNCKeIxNe47Q1+9hlyIiMiIKgBFqisc43t3LzgOdYZciIjIimdwUfraZvWhmrWa2w8zuGKLvcjPrM7Mbkto+ZWZvmNlbZnZ3UnvMzH5hZm8Gv6vPf3fGzop4DaB5ABEpXJl8AugF7nL3hcBK4FYzW5TaycyKgfuA51Pavgt8GlgEfClp7N3AC+5+EfBC8LhgXDC1glnVFWzcpQAQkcI0bAC4e5u7twTLx4FWoD5N19uBZ4BDSW1NwFvuvsvdTwNPAdcG664FHg+WHwdWjWgPQtQUzAO4ax5ARApPVnMAZtYALAE2prTXA6uBh1KG1APvJT3ey5nwmOHubZAIGWD6IM+51syazay5vb09m3JH3cp4DUc+OM3b7SfCLkVEJGsZB4CZTSLxDv9Od0+d+XwA+Jq7p14i09JsKqu3y+6+zt0b3b2xtrY2m6GjrikeA+AVHQYSkQKUUQCYWSmJP/5PuPv6NF0agafMbA9wA/A9M1tF4h3/7KR+s4D9wfJBM6sLtl/H2YeOCsLcmolMnzxBE8EiUpAyOQvIgEeBVne/P10fd4+7e4O7NwBPA1919x8DrwIXmVnczMqAG4HngmHPATcHyzcDz57XnoTAzFgxr4ZNuzUPICKFJ5NPAFcAa4BPmNnW4OcaM/tjM/vjoQa6ey9wG4kzg1qBH7n7jmD1vcDVZvYmcHXwuOA0xWMc6Ozm3SMnwy5FRCQrJcN1cPeXSX8sf7D+X055/FPgp2n6HQauynS7+WpFMA+wcfcR5tZUhlyNiEjm9E3g83TR9EnEKss0DyAiBUcBcJ7MjOUN1WzcrTuEiUhhUQDkQFO8hveOdLH/WFfYpYiIZEwBkAMD8wCv6jaRIlJAFAA5sLBuCpMnlOgLYSJSUBQAOVBcZDQ2VLNJ8wAiUkAUADmyYl4Nb7d/wPsnToVdiohIRhQAOTJwXSCdDioihUIBkCOX1ldRUVqsABCRgqEAyJHS4iKWza1mowJARAqEAiCHmuIxdh7opONkT9iliIgMSwGQQ03xGO76PoCIFAYFQA4tnj2VsuIiNikARKQAKAByqLy0mMWzp7Jxl74PICL5TwGQY03xGNv3d3LiVG/YpYiIDEkBkGMr5sXo63da3jkadikiIkNSAOTY0jnVFBeZLg8tInlPAZBjlRNKuKS+Sl8IE5G8l8lN4Web2Ytm1mpmO8zsjjR9rjWz14L7BTeb2ceC9ouT7iO81cw6zezOYN3XzWxf8n2Gc7974VgZj/Hr9zro7ukLuxQRkUFl8gmgF7jL3RcCK4FbzWxRSp8XgMvdfTHwFeARAHd/w90XB+3LgJPAhqRx3x5YH9w7eFxoisc43dfPlnePhV2KiMighg0Ad29z95Zg+TjQCtSn9Dnh7h48rAScc10FvO3u75xfyfmvsSGGmS4MJyL5Las5ADNrAJYAG9OsW21mO4GfkPgUkOpG4MmUttuCQ0ePmVl1NrXks6qKUhbOnKKJYBHJaxkHgJlNAp4B7nT3ztT17r7B3RcAq4BvpIwtAz4H/F1S84PAfGAx0AZ8a5DnXRvMKzS3t7dnWm7omuIxWt49yune/rBLERFJK6MAMLNSEn/8n3D39UP1dfeXgPlmNi2p+dNAi7sfTOp30N373L0feBhoGmR769y90d0ba2trMyk3L6ycF6O7p59t+zrCLkVEJK1MzgIy4FGg1d3vH6TPhUE/zGwpUAYkH//4EimHf8ysLunhamB7dqXnt+UNiRvE6DCQiOSrkgz6XAGsAbaZ2dag7R5gDoC7PwRcD9xkZj1AF/DFgUlhM5sIXA3ckrLdb5rZYhITxnvSrC9oNZMmcOH0SWzafYSvfjzsakREzjVsALj7y4AN0+c+4L5B1p0EatK0r8mwxoK1Ih7j2a376et3iouGfAlFRMacvgk8ipriMU6c6uX1/efMmYuIhE4BMIpWxBMffDQPICL5SAEwimZWlTO3ZqK+ECYieUkBMMqaGmJs2nOE/v50X44WEQmPAmCUNcVjHDvZw5uHToRdiojIWRQAo2zlvMQ8wCbNA4hInlEAjLJZ1RXUVZXziuYBRCTPKABGmZnRFI+xafcRzlwwVUQkfAqAMbAiXkP78VPsOXwy7FJERD6kABgDTfHgukC7NA8gIvlDATAG5tdWMm1Smb4PICJ5RQEwBgbmATYqAEQkjygAxkhTQ4x9x7rYe1TzACKSHxQAY6QpPvB9AH0KEJH8oAAYIwtmTmZKeQm/eksTwSKSHxQAY6SoyLjm0jo2bNnLL984FHY5IiIKgLH0X393ERfPnMLtT27h7XZdG0hEwqUAGEMTy0p4+KZllBUX8Uffb6ajqyfskkQkwhQAY2xW9UQe/P1lvHv4JH/y5Bb6dJloEQnJsAFgZrPN7EUzazWzHWZ2R5o+15rZa2a21cyazexjSev2mNm2gXVJ7TEz+4WZvRn8rs7dbuW3pniM/3btJfzjb9q572c7wy5HRCIqk08AvcBd7r4QWAncamaLUvq8AFzu7ouBrwCPpKy/0t0Xu3tjUtvdwAvuflEw/u4R7UGB+r0Vc7jpo3NZ99Iu1rfsDbscEYmgYQPA3dvcvSVYPg60AvUpfU74mUtdVgKZHNe4Fng8WH4cWJVp0ePFf/nsIj46r4a7129jy7tHwy5HRCImqzkAM2sAlgAb06xbbWY7gZ+Q+BQwwIGfm9lmM1ub1D7D3dsgETLA9EGec21wWKm5vb09m3LzXmlxEd/9t0uZMWUCt/xgMwc7u8MuSUQiJOMAMLNJwDPAne7embre3Te4+wIS7+S/kbTqCndfCnyaxOGj38mmQHdf5+6N7t5YW1ubzdCCEKss45GblvPBqV7Wfr+Z7p6+sEsSkYjIKADMrJTEH/8n3H39UH3d/SVgvplNCx7vD34fAjYATUHXg2ZWF2y/Dojst6MunjmZb39xMb/e28Gfrd+mG8eIyJjI5CwgAx4FWt39/kH6XBj0w8yWAmXAYTOrNLPJQXsl8ElgezDsOeDmYPlm4Nnz2ZFC98nfmsldV3+EDVv2se6lXWGXIyIRUJJBnyuANcA2M9satN0DzAFw94eA64GbzKwH6AK+6O5uZjOADUE2lAA/dPefBdu4F/iRmf0h8C7w+RztU8G67RMXsvPAce792U4+MmMyVy5IOy0iIpITVkiHGxobG725uXn4jgXs5OlebnjwX3jvyEk23HoFF06fFHZJIlLgzGxzymn4gL4JnHcmlpXw8M2NlJUUsfb7zXSc1OUiRGR0KADyUP3UCh5as4z3jp7k9qe20NvXH3ZJIjIOKQDy1PKGGN+49hJe+k079/5fXS5CRHIvk0lgCcmNTXPYeeA4j7y8mwV1U7hh2aywSxKRcUSfAPLcn39mIb89v4Z71m+jRZeLEJEcUgDkudLiIr77e0uZWVXOLT/YzIEOXS5CRHJDAVAAqivLeOTmRk6e6mXtD3S5CBHJDQVAgfjIjMk8cOMStu3r4GvPvKbLRYjIeVMAFJCrF83gP37yYp7dup+H/lGXixCR86MAKDBf/fh8PntZHd98fif/sPNg2OWISAFTABQYM+O/33A5i+qm8CdPbuWtQ8fDLklECpQCoABVlBXz8E2NlJcW8e8e1+UiRGRkFAAF6oKpFTz0+8vYd6yL255s0eUiRCRrCoAC1tgQ4y9XXco/vfk+f/VTXS5CRLKjS0EUuC8sn03rgU4e+9VuFtRN5guNs8MuSUQKhD4BjAN/fs1CPnbhNP7zhu1sfudI2OWISIFQAIwDJcVF/M3vLaFuajm3/KCF/ce6wi5JRAqAAmCcmDqxjEduaqS7p49bfrCZrtO6XISIDC2Tm8LPNrMXzazVzHaY2R1p+lxrZq+Z2VYzazazjw031sy+bmb7gjFbzeya3O5a9Fw0YzLfuXEx2/d38Ke6XISIDCOTTwC9wF3uvhBYCdxqZotS+rwAXO7ui4GvAI9kOPbb7r44+Pnpee2JAHDVwhn8p39zMf/n1/v53i/fDrscEcljwwaAu7e5e0uwfBxoBepT+pzwM283KwHPdKzk3r//V/P53OUX8Nc/f4P/97ouFyEi6WU1B2BmDcASYGOadavNbCfwExKfAjIZe1tw6OgxM6se5DnXBoeVmtvb27MpN7LMjPuuv4xLLqjijqe28JuDulyEiJwr4wAws0nAM8Cd7t6Zut7dN7j7AmAV8I0Mxj4IzAcWA23At9I9r7uvc/dGd2+sra3NtNzIqygrZt1Ny6goK+GPvt/MsZOnwy5JRPJMRgFgZqUk/oA/4e7rh+rr7i8B881s2lBj3f2gu/e5ez/wMNA0wn2QQdRVVfA/1iyj7Vg3t/5Ql4sQkbNlchaQAY8Cre5+/yB9Lgz6YWZLgTLg8FBjzawu6eFqYPvIdkGGsmxuNX+x+hJ+9dZh/uInrWGXIyJ5JJNLQVwBrAG2mdnWoO0eYA6Auz8EXA/cZGY9QBfwRXf34HTQc8YGZ/x808wWk5gw3gPckqN9khRfaJzNGweO8+jLu1lYN5kvLp8TdkkikgeskM4Vb2xs9Obm5rDLKEi9ff38wf96lVd2HebJP1pJY0Ms7JJEZIyY2WZ3b0xt1zeBI6KkuIi/+dJS6qdW8Md/u5k3dWaQSOQpACKkamIpj9zcyKnefq7+9ktc/+A/87evvKMzhEQiSoeAIuhARzfrt+xlQ8s+3jx0grLiIq5cUMvqJbO4ckEtE0qKwy5RRHJosENACoAIc3d27O9kfcs+nvv1ft4/cYqqilI+e1kd1y2tZ+mcaoKTu0SkgCkAZEi9ff3801vvs6FlHz9//QDdPf3MrZnIqsX1rF5ST8O0yrBLFJERUgBIxo539/Cz7QfYsGUf/7LrMO6wdM5UVi+dxe9eVsfUiWVhlygiWVAAyIi0dXTx4y372bBlL785eILSYuPKi6dz3dJ6rlwwXfMFIgVAASDnZWC+YMOWfTy79cx8wWcuq+O6JfUsm6v5ApF8pQCQnOnt6+flt95nw5Z9PL8jMV8wJzaRVUvquU7zBSJ5RwEgo+LEqd5gvmAv//x2Yr5gyZypXLekns9edgHVlZovEAmbAkBGXVtHF89u3c+Gln28cfA4pcXGxy+eznVL6vnEQs0XiIRFASBjxt15va2TDS37ePbX+2k/foop5SV85rILuG5pPY2aLxAZUwoACUVvXz+/evswG1r28vyOg3T19DE7VsHqxfWsWlJPfFqlwkBklCkAJHQffDhfsI9fvf0+7lBeWkRdVQUzpkygrqqCmVXl1FWVM2NK4vfMqnKmVU6gqEghITJSgwVAJvcDEMmJygklXL9sFtcvm8WBjm5+/voB3j18krbObg50dLNp9xEOdnbT23/2m5KSImPGlEQYzKwqZ2ZSOMwM2qdPLqesRNc2FMmGAkBCMbOqnJs+2nBOe3+/8/4HpzjYcYq2ji4OBOFwoKObto5uWvd38kLrQbp7zr69pRlMmzThw0BI/RRRV1XBzCnlVJRpIlpkgAJA8kpRkTF9cuId/aWzqtL2cXc6u3pp6+w6KxwOdiZ+v3v4JJt2H6Gjq+ecsVUVpeeEw/TJ5UwsK2ZCSRETSouYUJJYLi8N2kqKg/Yz63RISsYDBYAUHDOjamIpVRNLWTBzyqD9Tp7uTQRE57khcaCjm9fbOnn/xClGMg1WVlx0TmBM+DAwzl4eLEjKzxpbRGlxEcVmFBcZRUVGkUGxDSwbxUWJfR/oYwbFRYnHFrQllhPtRWYUFQXbCLZTHGy3yAa2mXisifhoGjYAzGw28H1gJtAPrHP376T0uRb4RrC+F7jT3V8O1n0K+A5QDDzi7vcG7THgfwMNJO4J/AV3P5qTvRIBJpaVMK92EvNqJw3a53RvP4c/OEV3Tz+nevs41dPPqd7E8pBtvf1Be2K5uydo6+3nVE8fnV09dPf0cbr3zNiB7Zzu6x+0nrBYUthY8Niw4PdAn8S6gQYbaEt9HIwfaD17G2e2mzyGpDGpfcI2WBmDhWba1kE2ks22/2r1pTTFc3sr10w+AfQCd7l7i5lNBjab2S/c/fWkPi8AzwU3gr8M+BGwwMyKge8CVwN7gVfN7Llg7N3AC+5+r5ndHTz+Wg73TWRYZSWJs5DGUl+/B8FwJki6exNh0e9OX7/T7yQtO/390OcDy4n1H65L08/d6TtrOfHjnmhLLCf6nL2NxCE2J/gdfDpKPIbEGs60BwvJ61PHkDQmdRup2+XDtvw4O3GwKgYrL13zYPsy6B4OsqJyQu7nr4YNAHdvA9qC5eNm1grUA68n9TmRNKSSM7vQBLzl7rsAzOwp4Npg7LXAx4N+jwO/RAEgEVBcZFSUFWtCWkKX1XlzZtYALAE2plm32sx2Aj8BvhI01wPvJXXbG7QBzAjCZSBkpg/ynGvNrNnMmtvb27MpV0REhpBxAJjZJOAZEsf3O1PXu/sGd18ArCIxHwDpD3Fl9dnO3de5e6O7N9bW1mYzVEREhpBRAJhZKYk//k+4+/qh+rr7S8B8M5tG4h3/7KTVs4D9wfJBM6sLtl8HHMqydhEROQ/DBoAlpqMfBVrd/f5B+lwY9MPMlgJlwGHgVeAiM4ubWRlwI/BcMOw54OZg+Wbg2fPZERERyU4mZwFdAawBtpnZ1qDtHmAOgLs/BFwP3GRmPUAX8EVPTH33mtltwPMkTgN9zN13BNu4F/iRmf0h8C7w+Rztk4iIZEAXgxMRGecGuxicrp4lIhJRCgARkYgqqENAZtYOvDPC4dOA93NYTqHT63GGXouz6fU423h4Pea6+znn0RdUAJwPM2tOdwwsqvR6nKHX4mx6Pc42nl8PHQISEYkoBYCISERFKQDWhV1AntHrcYZei7Pp9TjbuH09IjMHICIiZ4vSJwAREUmiABARiahIBICZfcrM3jCzt4K7j0WSmc02sxfNrNXMdpjZHWHXlA/MrNjMtpjZ34ddS9jMbKqZPW1mO4N/Jx8Nu6awmNl/CP6fbDezJ82sPOyacm3cB0DSbSk/DSwCvmRmi8KtKjQDt/dcCKwEbo3wa5HsDqA17CLyxHeAnwX39riciL4uZlYP/AnQ6O6XkLiY5Y3hVpV74z4ASLotpbufBgZuSxk57t7m7i3B8nES/7nrhx41vpnZLOAzwCNh1xI2M5sC/A6Jy7/j7qfd/Vi4VYWqBKgwsxJgImfuZTJuRCEAhrotZWQNdXvPiHkA+FOgPxbIOaAAAAFASURBVOxC8sA8oB34n8EhsUfMrDLsosLg7vuAvyZxqfo2oMPdfx5uVbkXhQA479tSjjfD3d4zKszss8Ahd98cdi15ogRYCjzo7kuAD4BIzpmZWTWJIwVx4AKg0sx+P9yqci8KATDUbSkjJ5vbe0bAFcDnzGwPiUODnzCzvw23pFDtBfa6+8CnwqdJBEIU/Wtgt7u3u3sPsB747ZBryrkoBMBQt6WMlExu7xkl7v5n7j7L3RtI/Lv4B3cfd+/yMuXuB4D3zOzioOkq4PUQSwrTu8BKM5sY/L+5inE4IZ7JLSELmrsPdVvKqEl7e093/2mINUl+uR14IniztAv4g5DrCYW7bzSzp4EWEmfPbWEcXhJCl4IQEYmoKBwCEhGRNBQAIiIRpQAQEYkoBYCISEQpAEREIkoBICISUQoAEZGI+v9z03Eln98oqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.127\n",
      "Epoch 0, loss: 2.301850\n",
      "Epoch 1, loss: 2.301872\n",
      "Epoch 2, loss: 2.301873\n",
      "Epoch 3, loss: 2.301878\n",
      "Epoch 4, loss: 2.301869\n",
      "Epoch 5, loss: 2.301875\n",
      "Epoch 6, loss: 2.301854\n",
      "Epoch 7, loss: 2.301874\n",
      "Epoch 8, loss: 2.301863\n",
      "Epoch 9, loss: 2.301861\n",
      "Epoch 10, loss: 2.301871\n",
      "Epoch 11, loss: 2.301877\n",
      "Epoch 12, loss: 2.301863\n",
      "Epoch 13, loss: 2.301870\n",
      "Epoch 14, loss: 2.301866\n",
      "Epoch 15, loss: 2.301859\n",
      "Epoch 16, loss: 2.301870\n",
      "Epoch 17, loss: 2.301867\n",
      "Epoch 18, loss: 2.301845\n",
      "Epoch 19, loss: 2.301867\n",
      "Epoch 20, loss: 2.301857\n",
      "Epoch 21, loss: 2.301849\n",
      "Epoch 22, loss: 2.301871\n",
      "Epoch 23, loss: 2.301877\n",
      "Epoch 24, loss: 2.301849\n",
      "Epoch 25, loss: 2.301871\n",
      "Epoch 26, loss: 2.301847\n",
      "Epoch 27, loss: 2.301873\n",
      "Epoch 28, loss: 2.301855\n",
      "Epoch 29, loss: 2.301888\n",
      "Epoch 30, loss: 2.301867\n",
      "Epoch 31, loss: 2.301876\n",
      "Epoch 32, loss: 2.301868\n",
      "Epoch 33, loss: 2.301868\n",
      "Epoch 34, loss: 2.301848\n",
      "Epoch 35, loss: 2.301874\n",
      "Epoch 36, loss: 2.301866\n",
      "Epoch 37, loss: 2.301855\n",
      "Epoch 38, loss: 2.301875\n",
      "Epoch 39, loss: 2.301862\n",
      "Epoch 40, loss: 2.301875\n",
      "Epoch 41, loss: 2.301865\n",
      "Epoch 42, loss: 2.301867\n",
      "Epoch 43, loss: 2.301860\n",
      "Epoch 44, loss: 2.301853\n",
      "Epoch 45, loss: 2.301855\n",
      "Epoch 46, loss: 2.301862\n",
      "Epoch 47, loss: 2.301852\n",
      "Epoch 48, loss: 2.301885\n",
      "Epoch 49, loss: 2.301857\n",
      "Epoch 50, loss: 2.301865\n",
      "Epoch 51, loss: 2.301870\n",
      "Epoch 52, loss: 2.301871\n",
      "Epoch 53, loss: 2.301869\n",
      "Epoch 54, loss: 2.301854\n",
      "Epoch 55, loss: 2.301872\n",
      "Epoch 56, loss: 2.301873\n",
      "Epoch 57, loss: 2.301877\n",
      "Epoch 58, loss: 2.301866\n",
      "Epoch 59, loss: 2.301881\n",
      "Epoch 60, loss: 2.301880\n",
      "Epoch 61, loss: 2.301869\n",
      "Epoch 62, loss: 2.301875\n",
      "Epoch 63, loss: 2.301858\n",
      "Epoch 64, loss: 2.301854\n",
      "Epoch 65, loss: 2.301860\n",
      "Epoch 66, loss: 2.301870\n",
      "Epoch 67, loss: 2.301859\n",
      "Epoch 68, loss: 2.301863\n",
      "Epoch 69, loss: 2.301858\n",
      "Epoch 70, loss: 2.301870\n",
      "Epoch 71, loss: 2.301860\n",
      "Epoch 72, loss: 2.301870\n",
      "Epoch 73, loss: 2.301860\n",
      "Epoch 74, loss: 2.301864\n",
      "Epoch 75, loss: 2.301861\n",
      "Epoch 76, loss: 2.301876\n",
      "Epoch 77, loss: 2.301862\n",
      "Epoch 78, loss: 2.301868\n",
      "Epoch 79, loss: 2.301873\n",
      "Epoch 80, loss: 2.301862\n",
      "Epoch 81, loss: 2.301868\n",
      "Epoch 82, loss: 2.301854\n",
      "Epoch 83, loss: 2.301868\n",
      "Epoch 84, loss: 2.301860\n",
      "Epoch 85, loss: 2.301892\n",
      "Epoch 86, loss: 2.301878\n",
      "Epoch 87, loss: 2.301860\n",
      "Epoch 88, loss: 2.301873\n",
      "Epoch 89, loss: 2.301871\n",
      "Epoch 90, loss: 2.301861\n",
      "Epoch 91, loss: 2.301893\n",
      "Epoch 92, loss: 2.301871\n",
      "Epoch 93, loss: 2.301866\n",
      "Epoch 94, loss: 2.301869\n",
      "Epoch 95, loss: 2.301869\n",
      "Epoch 96, loss: 2.301873\n",
      "Epoch 97, loss: 2.301872\n",
      "Epoch 98, loss: 2.301859\n",
      "Epoch 99, loss: 2.301891\n",
      "Accuracy after training for 100 epochs:  0.124\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(1, 2), (2, 1)]\n",
    "max(a, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 11.876133\n",
      "Epoch 1, loss: 12.369356\n",
      "Epoch 2, loss: 12.685861\n",
      "Epoch 3, loss: 12.934821\n",
      "Epoch 4, loss: 12.541002\n",
      "Epoch 5, loss: 12.199670\n",
      "Epoch 6, loss: 12.452821\n",
      "Epoch 7, loss: 12.540202\n",
      "Epoch 8, loss: 12.330654\n",
      "Epoch 9, loss: 12.445086\n",
      "Epoch 10, loss: 12.202762\n",
      "Epoch 11, loss: 12.509721\n",
      "Epoch 12, loss: 11.935391\n",
      "Epoch 13, loss: 12.350139\n",
      "Epoch 14, loss: 12.581724\n",
      "Epoch 15, loss: 12.534200\n",
      "Epoch 16, loss: 12.510275\n",
      "Epoch 17, loss: 12.452661\n",
      "Epoch 18, loss: 12.617073\n",
      "Epoch 19, loss: 12.453518\n",
      "Epoch 20, loss: 12.768525\n",
      "Epoch 21, loss: 12.396209\n",
      "Epoch 22, loss: 12.414434\n",
      "Epoch 23, loss: 12.302052\n",
      "Epoch 24, loss: 12.621265\n",
      "Epoch 25, loss: 12.676791\n",
      "Epoch 26, loss: 12.785100\n",
      "Epoch 27, loss: 12.381435\n",
      "Epoch 28, loss: 12.335047\n",
      "Epoch 29, loss: 12.645493\n",
      "Epoch 30, loss: 12.568997\n",
      "Epoch 31, loss: 12.349958\n",
      "Epoch 32, loss: 12.609018\n",
      "Epoch 33, loss: 12.496231\n",
      "Epoch 34, loss: 12.304923\n",
      "Epoch 35, loss: 12.264045\n",
      "Epoch 36, loss: 12.805181\n",
      "Epoch 37, loss: 12.502968\n",
      "Epoch 38, loss: 12.423241\n",
      "Epoch 39, loss: 12.538596\n",
      "Epoch 40, loss: 12.747457\n",
      "Epoch 41, loss: 12.383971\n",
      "Epoch 42, loss: 12.364849\n",
      "Epoch 43, loss: 12.465628\n",
      "Epoch 44, loss: 12.525316\n",
      "Epoch 45, loss: 12.575945\n",
      "Epoch 46, loss: 12.457880\n",
      "Epoch 47, loss: 12.730053\n",
      "Epoch 48, loss: 12.728022\n",
      "Epoch 49, loss: 12.560458\n",
      "Epoch 50, loss: 12.872458\n",
      "Epoch 51, loss: 12.905386\n",
      "Epoch 52, loss: 13.019871\n",
      "Epoch 53, loss: 12.776815\n",
      "Epoch 54, loss: 12.600022\n",
      "Epoch 55, loss: 12.673492\n",
      "Epoch 56, loss: 12.592384\n",
      "Epoch 57, loss: 12.530850\n",
      "Epoch 58, loss: 12.796955\n",
      "Epoch 59, loss: 13.164205\n",
      "Epoch 60, loss: 12.590844\n",
      "Epoch 61, loss: 12.717676\n",
      "Epoch 62, loss: 12.348429\n",
      "Epoch 63, loss: 12.458823\n",
      "Epoch 64, loss: 12.844836\n",
      "Epoch 65, loss: 13.448277\n",
      "Epoch 66, loss: 12.610351\n",
      "Epoch 67, loss: 12.547104\n",
      "Epoch 68, loss: 12.484296\n",
      "Epoch 69, loss: 12.846489\n",
      "Epoch 70, loss: 12.394026\n",
      "Epoch 71, loss: 12.718598\n",
      "Epoch 72, loss: 12.876178\n",
      "Epoch 73, loss: 12.825346\n",
      "Epoch 74, loss: 12.422732\n",
      "Epoch 75, loss: 12.619661\n",
      "Epoch 76, loss: 12.434031\n",
      "Epoch 77, loss: 12.628645\n",
      "Epoch 78, loss: 12.848800\n",
      "Epoch 79, loss: 12.885726\n",
      "Epoch 80, loss: 12.621793\n",
      "Epoch 81, loss: 12.824492\n",
      "Epoch 82, loss: 12.644232\n",
      "Epoch 83, loss: 12.691300\n",
      "Epoch 84, loss: 12.922804\n",
      "Epoch 85, loss: 13.022769\n",
      "Epoch 86, loss: 12.556028\n",
      "Epoch 87, loss: 13.175928\n",
      "Epoch 88, loss: 12.639506\n",
      "Epoch 89, loss: 13.089987\n",
      "Epoch 90, loss: 12.730853\n",
      "Epoch 91, loss: 12.945910\n",
      "Epoch 92, loss: 12.598342\n",
      "Epoch 93, loss: 12.730555\n",
      "Epoch 94, loss: 12.589483\n",
      "Epoch 95, loss: 12.616688\n",
      "Epoch 96, loss: 12.744876\n",
      "Epoch 97, loss: 13.087545\n",
      "Epoch 98, loss: 12.590013\n",
      "Epoch 99, loss: 12.709580\n",
      "Epoch 100, loss: 12.906976\n",
      "Epoch 101, loss: 12.896011\n",
      "Epoch 102, loss: 12.822395\n",
      "Epoch 103, loss: 12.748388\n",
      "Epoch 104, loss: 12.350357\n",
      "Epoch 105, loss: 12.750514\n",
      "Epoch 106, loss: 12.801039\n",
      "Epoch 107, loss: 12.653061\n",
      "Epoch 108, loss: 12.306240\n",
      "Epoch 109, loss: 12.310374\n",
      "Epoch 110, loss: 12.904173\n",
      "Epoch 111, loss: 12.527464\n",
      "Epoch 112, loss: 12.535106\n",
      "Epoch 113, loss: 12.525757\n",
      "Epoch 114, loss: 12.587578\n",
      "Epoch 115, loss: 12.312898\n",
      "Epoch 116, loss: 12.262706\n",
      "Epoch 117, loss: 12.318920\n",
      "Epoch 118, loss: 12.490674\n",
      "Epoch 119, loss: 12.381625\n",
      "Epoch 120, loss: 12.433709\n",
      "Epoch 121, loss: 12.205984\n",
      "Epoch 122, loss: 12.574292\n",
      "Epoch 123, loss: 12.471447\n",
      "Epoch 124, loss: 12.524763\n",
      "Epoch 125, loss: 12.634239\n",
      "Epoch 126, loss: 12.260217\n",
      "Epoch 127, loss: 12.143998\n",
      "Epoch 128, loss: 12.413341\n",
      "Epoch 129, loss: 12.236599\n",
      "Epoch 130, loss: 12.267544\n",
      "Epoch 131, loss: 12.191611\n",
      "Epoch 132, loss: 12.729540\n",
      "Epoch 133, loss: 12.563374\n",
      "Epoch 134, loss: 12.166768\n",
      "Epoch 135, loss: 12.453430\n",
      "Epoch 136, loss: 12.326847\n",
      "Epoch 137, loss: 12.309484\n",
      "Epoch 138, loss: 12.483688\n",
      "Epoch 139, loss: 12.600334\n",
      "Epoch 140, loss: 12.205264\n",
      "Epoch 141, loss: 12.227227\n",
      "Epoch 142, loss: 12.193651\n",
      "Epoch 143, loss: 12.434630\n",
      "Epoch 144, loss: 12.434974\n",
      "Epoch 145, loss: 12.342320\n",
      "Epoch 146, loss: 12.505521\n",
      "Epoch 147, loss: 12.475332\n",
      "Epoch 148, loss: 12.468527\n",
      "Epoch 149, loss: 12.450734\n",
      "Epoch 150, loss: 12.511675\n",
      "Epoch 151, loss: 12.421934\n",
      "Epoch 152, loss: 12.330076\n",
      "Epoch 153, loss: 12.524986\n",
      "Epoch 154, loss: 12.531337\n",
      "Epoch 155, loss: 12.337426\n",
      "Epoch 156, loss: 12.831169\n",
      "Epoch 157, loss: 12.599456\n",
      "Epoch 158, loss: 12.599872\n",
      "Epoch 159, loss: 12.565634\n",
      "Epoch 160, loss: 12.543376\n",
      "Epoch 161, loss: 12.185071\n",
      "Epoch 162, loss: 12.363847\n",
      "Epoch 163, loss: 12.625196\n",
      "Epoch 164, loss: 12.501778\n",
      "Epoch 165, loss: 12.255238\n",
      "Epoch 166, loss: 12.379536\n",
      "Epoch 167, loss: 12.223534\n",
      "Epoch 168, loss: 12.672656\n",
      "Epoch 169, loss: 12.610088\n",
      "Epoch 170, loss: 12.491988\n",
      "Epoch 171, loss: 12.601766\n",
      "Epoch 172, loss: 12.233652\n",
      "Epoch 173, loss: 12.355739\n",
      "Epoch 174, loss: 12.655470\n",
      "Epoch 175, loss: 12.828011\n",
      "Epoch 176, loss: 12.484291\n",
      "Epoch 177, loss: 13.008803\n",
      "Epoch 178, loss: 12.498207\n",
      "Epoch 179, loss: 12.642996\n",
      "Epoch 180, loss: 12.896966\n",
      "Epoch 181, loss: 12.753427\n",
      "Epoch 182, loss: 13.047947\n",
      "Epoch 183, loss: 12.726624\n",
      "Epoch 184, loss: 12.802129\n",
      "Epoch 185, loss: 12.627917\n",
      "Epoch 186, loss: 12.632098\n",
      "Epoch 187, loss: 12.859010\n",
      "Epoch 188, loss: 12.582717\n",
      "Epoch 189, loss: 12.939176\n",
      "Epoch 190, loss: 12.390999\n",
      "Epoch 191, loss: 13.251096\n",
      "Epoch 192, loss: 12.641867\n",
      "Epoch 193, loss: 12.864456\n",
      "Epoch 194, loss: 12.372487\n",
      "Epoch 195, loss: 12.816622\n",
      "Epoch 196, loss: 12.926830\n",
      "Epoch 197, loss: 12.921442\n",
      "Epoch 198, loss: 12.752276\n",
      "Epoch 199, loss: 12.890182\n",
      "lr: 1, rs: 0.1, accuracy 200 epochs: 0.176\n",
      "Epoch 0, loss: 9.065470\n",
      "Epoch 1, loss: 10.060284\n",
      "Epoch 2, loss: 9.262444\n",
      "Epoch 3, loss: 9.531463\n",
      "Epoch 4, loss: 10.268802\n",
      "Epoch 5, loss: 10.509184\n",
      "Epoch 6, loss: 9.807313\n",
      "Epoch 7, loss: 9.193260\n",
      "Epoch 8, loss: 9.995977\n",
      "Epoch 9, loss: 9.347601\n",
      "Epoch 10, loss: 8.935802\n",
      "Epoch 11, loss: 10.363671\n",
      "Epoch 12, loss: 9.729974\n",
      "Epoch 13, loss: 9.292295\n",
      "Epoch 14, loss: 8.735177\n",
      "Epoch 15, loss: 9.556956\n",
      "Epoch 16, loss: 10.494019\n",
      "Epoch 17, loss: 9.120358\n",
      "Epoch 18, loss: 9.806578\n",
      "Epoch 19, loss: 10.245149\n",
      "Epoch 20, loss: 9.402589\n",
      "Epoch 21, loss: 9.474114\n",
      "Epoch 22, loss: 10.486842\n",
      "Epoch 23, loss: 9.046629\n",
      "Epoch 24, loss: 9.519195\n",
      "Epoch 25, loss: 10.100124\n",
      "Epoch 26, loss: 9.628394\n",
      "Epoch 27, loss: 9.011752\n",
      "Epoch 28, loss: 10.318046\n",
      "Epoch 29, loss: 10.415158\n",
      "Epoch 30, loss: 9.508456\n",
      "Epoch 31, loss: 9.617247\n",
      "Epoch 32, loss: 10.580690\n",
      "Epoch 33, loss: 9.407547\n",
      "Epoch 34, loss: 8.686843\n",
      "Epoch 35, loss: 9.665962\n",
      "Epoch 36, loss: 9.625801\n",
      "Epoch 37, loss: 10.032423\n",
      "Epoch 38, loss: 9.995151\n",
      "Epoch 39, loss: 9.403826\n",
      "Epoch 40, loss: 9.094456\n",
      "Epoch 41, loss: 10.174248\n",
      "Epoch 42, loss: 9.657027\n",
      "Epoch 43, loss: 10.394279\n",
      "Epoch 44, loss: 9.807405\n",
      "Epoch 45, loss: 9.203087\n",
      "Epoch 46, loss: 9.543401\n",
      "Epoch 47, loss: 9.620562\n",
      "Epoch 48, loss: 9.807232\n",
      "Epoch 49, loss: 9.513459\n",
      "Epoch 50, loss: 9.704741\n",
      "Epoch 51, loss: 8.754054\n",
      "Epoch 52, loss: 9.938992\n",
      "Epoch 53, loss: 9.699000\n",
      "Epoch 54, loss: 9.839563\n",
      "Epoch 55, loss: 9.467020\n",
      "Epoch 56, loss: 8.904461\n",
      "Epoch 57, loss: 9.811414\n",
      "Epoch 58, loss: 10.001731\n",
      "Epoch 59, loss: 9.555016\n",
      "Epoch 60, loss: 10.251197\n",
      "Epoch 61, loss: 9.988851\n",
      "Epoch 62, loss: 9.564491\n",
      "Epoch 63, loss: 9.203831\n",
      "Epoch 64, loss: 10.284725\n",
      "Epoch 65, loss: 9.144366\n",
      "Epoch 66, loss: 9.964052\n",
      "Epoch 67, loss: 9.891668\n",
      "Epoch 68, loss: 9.725920\n",
      "Epoch 69, loss: 9.573072\n",
      "Epoch 70, loss: 9.774240\n",
      "Epoch 71, loss: 9.832873\n",
      "Epoch 72, loss: 10.327549\n",
      "Epoch 73, loss: 9.537091\n",
      "Epoch 74, loss: 9.982052\n",
      "Epoch 75, loss: 9.160227\n",
      "Epoch 76, loss: 9.248846\n",
      "Epoch 77, loss: 10.354184\n",
      "Epoch 78, loss: 9.348248\n",
      "Epoch 79, loss: 9.702456\n",
      "Epoch 80, loss: 10.082484\n",
      "Epoch 81, loss: 9.727583\n",
      "Epoch 82, loss: 9.785642\n",
      "Epoch 83, loss: 9.601205\n",
      "Epoch 84, loss: 10.147563\n",
      "Epoch 85, loss: 9.333152\n",
      "Epoch 86, loss: 9.583001\n",
      "Epoch 87, loss: 10.120149\n",
      "Epoch 88, loss: 9.748860\n",
      "Epoch 89, loss: 9.079476\n",
      "Epoch 90, loss: 10.097122\n",
      "Epoch 91, loss: 9.176990\n",
      "Epoch 92, loss: 9.986523\n",
      "Epoch 93, loss: 9.363925\n",
      "Epoch 94, loss: 9.452256\n",
      "Epoch 95, loss: 10.778610\n",
      "Epoch 96, loss: 10.654304\n",
      "Epoch 97, loss: 9.298649\n",
      "Epoch 98, loss: 8.615678\n",
      "Epoch 99, loss: 10.386060\n",
      "Epoch 100, loss: 10.314988\n",
      "Epoch 101, loss: 10.228873\n",
      "Epoch 102, loss: 9.756621\n",
      "Epoch 103, loss: 9.504058\n",
      "Epoch 104, loss: 9.266490\n",
      "Epoch 105, loss: 9.893105\n",
      "Epoch 106, loss: 9.559648\n",
      "Epoch 107, loss: 10.113967\n",
      "Epoch 108, loss: 9.677540\n",
      "Epoch 109, loss: 10.011023\n",
      "Epoch 110, loss: 9.938055\n",
      "Epoch 111, loss: 9.290303\n",
      "Epoch 112, loss: 9.623443\n",
      "Epoch 113, loss: 10.228712\n",
      "Epoch 114, loss: 9.551134\n",
      "Epoch 115, loss: 9.901436\n",
      "Epoch 116, loss: 9.909113\n",
      "Epoch 117, loss: 8.962437\n",
      "Epoch 118, loss: 9.816423\n",
      "Epoch 119, loss: 10.294923\n",
      "Epoch 120, loss: 9.512143\n",
      "Epoch 121, loss: 9.996603\n",
      "Epoch 122, loss: 9.204146\n",
      "Epoch 123, loss: 10.227776\n",
      "Epoch 124, loss: 9.341540\n",
      "Epoch 125, loss: 9.520158\n",
      "Epoch 126, loss: 10.440906\n",
      "Epoch 127, loss: 9.166164\n",
      "Epoch 128, loss: 10.283110\n",
      "Epoch 129, loss: 9.526639\n",
      "Epoch 130, loss: 10.160320\n",
      "Epoch 131, loss: 9.348901\n",
      "Epoch 132, loss: 9.943174\n",
      "Epoch 133, loss: 10.115689\n",
      "Epoch 134, loss: 10.133722\n",
      "Epoch 135, loss: 9.560235\n",
      "Epoch 136, loss: 9.785865\n",
      "Epoch 137, loss: 8.690125\n",
      "Epoch 138, loss: 9.142908\n",
      "Epoch 139, loss: 10.163584\n",
      "Epoch 140, loss: 9.834139\n",
      "Epoch 141, loss: 9.974510\n",
      "Epoch 142, loss: 10.095244\n",
      "Epoch 143, loss: 9.603475\n",
      "Epoch 144, loss: 10.382246\n",
      "Epoch 145, loss: 9.602961\n",
      "Epoch 146, loss: 10.134084\n",
      "Epoch 147, loss: 10.177619\n",
      "Epoch 148, loss: 9.239450\n",
      "Epoch 149, loss: 9.798655\n",
      "Epoch 150, loss: 9.417802\n",
      "Epoch 151, loss: 10.039088\n",
      "Epoch 152, loss: 9.249304\n",
      "Epoch 153, loss: 9.923113\n",
      "Epoch 154, loss: 9.337942\n",
      "Epoch 155, loss: 10.181365\n",
      "Epoch 156, loss: 9.317849\n",
      "Epoch 157, loss: 10.441009\n",
      "Epoch 158, loss: 10.199271\n",
      "Epoch 159, loss: 9.587021\n",
      "Epoch 160, loss: 8.912463\n",
      "Epoch 161, loss: 9.446150\n",
      "Epoch 162, loss: 9.917040\n",
      "Epoch 163, loss: 9.333846\n",
      "Epoch 164, loss: 9.102579\n",
      "Epoch 165, loss: 9.956552\n",
      "Epoch 166, loss: 9.629789\n",
      "Epoch 167, loss: 10.063529\n",
      "Epoch 168, loss: 10.098881\n",
      "Epoch 169, loss: 9.845545\n",
      "Epoch 170, loss: 9.809431\n",
      "Epoch 171, loss: 9.108644\n",
      "Epoch 172, loss: 10.453512\n",
      "Epoch 173, loss: 9.354935\n",
      "Epoch 174, loss: 9.782409\n",
      "Epoch 175, loss: 9.413778\n",
      "Epoch 176, loss: 9.614866\n",
      "Epoch 177, loss: 9.652273\n",
      "Epoch 178, loss: 8.961909\n",
      "Epoch 179, loss: 9.449456\n",
      "Epoch 180, loss: 10.485958\n",
      "Epoch 181, loss: 9.310969\n",
      "Epoch 182, loss: 9.870772\n",
      "Epoch 183, loss: 8.855132\n",
      "Epoch 184, loss: 10.027412\n",
      "Epoch 185, loss: 10.058273\n",
      "Epoch 186, loss: 9.539928\n",
      "Epoch 187, loss: 9.092803\n",
      "Epoch 188, loss: 10.379564\n",
      "Epoch 189, loss: 9.576902\n",
      "Epoch 190, loss: 8.748046\n",
      "Epoch 191, loss: 9.846786\n",
      "Epoch 192, loss: 10.066393\n",
      "Epoch 193, loss: 9.732447\n",
      "Epoch 194, loss: 9.852948\n",
      "Epoch 195, loss: 9.460506\n",
      "Epoch 196, loss: 9.339449\n",
      "Epoch 197, loss: 10.309473\n",
      "Epoch 198, loss: 9.467137\n",
      "Epoch 199, loss: 9.560016\n",
      "lr: 1, rs: 0.01, accuracy 200 epochs: 0.158\n",
      "Epoch 0, loss: 9.883466\n",
      "Epoch 1, loss: 9.690871\n",
      "Epoch 2, loss: 9.764209\n",
      "Epoch 3, loss: 10.016889\n",
      "Epoch 4, loss: 8.948916\n",
      "Epoch 5, loss: 9.853603\n",
      "Epoch 6, loss: 8.833146\n",
      "Epoch 7, loss: 9.618916\n",
      "Epoch 8, loss: 9.318007\n",
      "Epoch 9, loss: 9.220708\n",
      "Epoch 10, loss: 9.586087\n",
      "Epoch 11, loss: 9.134876\n",
      "Epoch 12, loss: 9.723227\n",
      "Epoch 13, loss: 9.311973\n",
      "Epoch 14, loss: 9.767739\n",
      "Epoch 15, loss: 8.104488\n",
      "Epoch 16, loss: 9.816059\n",
      "Epoch 17, loss: 9.783949\n",
      "Epoch 18, loss: 9.297964\n",
      "Epoch 19, loss: 9.346626\n",
      "Epoch 20, loss: 9.292999\n",
      "Epoch 21, loss: 9.280699\n",
      "Epoch 22, loss: 9.723470\n",
      "Epoch 23, loss: 9.108278\n",
      "Epoch 24, loss: 9.275664\n",
      "Epoch 25, loss: 9.793671\n",
      "Epoch 26, loss: 8.831928\n",
      "Epoch 27, loss: 9.464560\n",
      "Epoch 28, loss: 9.310224\n",
      "Epoch 29, loss: 8.824170\n",
      "Epoch 30, loss: 9.312889\n",
      "Epoch 31, loss: 9.687067\n",
      "Epoch 32, loss: 8.939659\n",
      "Epoch 33, loss: 9.192420\n",
      "Epoch 34, loss: 10.182652\n",
      "Epoch 35, loss: 9.393887\n",
      "Epoch 36, loss: 8.712041\n",
      "Epoch 37, loss: 9.666876\n",
      "Epoch 38, loss: 9.061536\n",
      "Epoch 39, loss: 9.644448\n",
      "Epoch 40, loss: 10.113754\n",
      "Epoch 41, loss: 9.747854\n",
      "Epoch 42, loss: 8.753090\n",
      "Epoch 43, loss: 9.444150\n",
      "Epoch 44, loss: 9.292802\n",
      "Epoch 45, loss: 9.218060\n",
      "Epoch 46, loss: 9.609789\n",
      "Epoch 47, loss: 9.466379\n",
      "Epoch 48, loss: 9.424783\n",
      "Epoch 49, loss: 9.064641\n",
      "Epoch 50, loss: 9.547529\n",
      "Epoch 51, loss: 8.587768\n",
      "Epoch 52, loss: 9.791060\n",
      "Epoch 53, loss: 9.766649\n",
      "Epoch 54, loss: 9.318774\n",
      "Epoch 55, loss: 9.258433\n",
      "Epoch 56, loss: 9.265789\n",
      "Epoch 57, loss: 9.702639\n",
      "Epoch 58, loss: 8.617414\n",
      "Epoch 59, loss: 9.148987\n",
      "Epoch 60, loss: 9.836881\n",
      "Epoch 61, loss: 9.547536\n",
      "Epoch 62, loss: 9.086360\n",
      "Epoch 63, loss: 9.471401\n",
      "Epoch 64, loss: 9.151189\n",
      "Epoch 65, loss: 9.806462\n",
      "Epoch 66, loss: 9.215611\n",
      "Epoch 67, loss: 8.922382\n",
      "Epoch 68, loss: 9.737331\n",
      "Epoch 69, loss: 9.846278\n",
      "Epoch 70, loss: 9.572805\n",
      "Epoch 71, loss: 9.721043\n",
      "Epoch 72, loss: 9.298190\n",
      "Epoch 73, loss: 9.761590\n",
      "Epoch 74, loss: 8.782923\n",
      "Epoch 75, loss: 9.195453\n",
      "Epoch 76, loss: 8.797597\n",
      "Epoch 77, loss: 10.101234\n",
      "Epoch 78, loss: 9.261249\n",
      "Epoch 79, loss: 9.133950\n",
      "Epoch 80, loss: 9.909855\n",
      "Epoch 81, loss: 8.456455\n",
      "Epoch 82, loss: 9.875060\n",
      "Epoch 83, loss: 9.387710\n",
      "Epoch 84, loss: 9.474958\n",
      "Epoch 85, loss: 8.911051\n",
      "Epoch 86, loss: 9.550122\n",
      "Epoch 87, loss: 9.501729\n",
      "Epoch 88, loss: 9.466483\n",
      "Epoch 89, loss: 9.856637\n",
      "Epoch 90, loss: 9.119725\n",
      "Epoch 91, loss: 9.446965\n",
      "Epoch 92, loss: 9.857329\n",
      "Epoch 93, loss: 9.361065\n",
      "Epoch 94, loss: 9.374200\n",
      "Epoch 95, loss: 9.244193\n",
      "Epoch 96, loss: 9.333657\n",
      "Epoch 97, loss: 9.763228\n",
      "Epoch 98, loss: 8.937586\n",
      "Epoch 99, loss: 9.143846\n",
      "Epoch 100, loss: 9.783437\n",
      "Epoch 101, loss: 9.458397\n",
      "Epoch 102, loss: 9.439111\n",
      "Epoch 103, loss: 9.455162\n",
      "Epoch 104, loss: 8.324766\n",
      "Epoch 105, loss: 9.583204\n",
      "Epoch 106, loss: 8.839448\n",
      "Epoch 107, loss: 9.701165\n",
      "Epoch 108, loss: 8.791125\n",
      "Epoch 109, loss: 10.170786\n",
      "Epoch 110, loss: 9.457867\n",
      "Epoch 111, loss: 9.003985\n",
      "Epoch 112, loss: 9.238851\n",
      "Epoch 113, loss: 9.300318\n",
      "Epoch 114, loss: 9.328710\n",
      "Epoch 115, loss: 9.375399\n",
      "Epoch 116, loss: 9.179173\n",
      "Epoch 117, loss: 9.247068\n",
      "Epoch 118, loss: 9.506001\n",
      "Epoch 119, loss: 9.280263\n",
      "Epoch 120, loss: 8.890274\n",
      "Epoch 121, loss: 9.424203\n",
      "Epoch 122, loss: 9.471728\n",
      "Epoch 123, loss: 9.132756\n",
      "Epoch 124, loss: 9.477547\n",
      "Epoch 125, loss: 9.479867\n",
      "Epoch 126, loss: 9.209738\n",
      "Epoch 127, loss: 9.566442\n",
      "Epoch 128, loss: 9.574849\n",
      "Epoch 129, loss: 9.153033\n",
      "Epoch 130, loss: 9.411523\n",
      "Epoch 131, loss: 10.316170\n",
      "Epoch 132, loss: 9.036934\n",
      "Epoch 133, loss: 10.565286\n",
      "Epoch 134, loss: 8.724823\n",
      "Epoch 135, loss: 9.387942\n",
      "Epoch 136, loss: 9.631887\n",
      "Epoch 137, loss: 9.350206\n",
      "Epoch 138, loss: 9.959201\n",
      "Epoch 139, loss: 9.112214\n",
      "Epoch 140, loss: 9.039858\n",
      "Epoch 141, loss: 9.445236\n",
      "Epoch 142, loss: 10.074279\n",
      "Epoch 143, loss: 9.415351\n",
      "Epoch 144, loss: 9.781827\n",
      "Epoch 145, loss: 9.509942\n",
      "Epoch 146, loss: 9.573010\n",
      "Epoch 147, loss: 9.284867\n",
      "Epoch 148, loss: 8.569757\n",
      "Epoch 149, loss: 9.851622\n",
      "Epoch 150, loss: 9.433890\n",
      "Epoch 151, loss: 9.545252\n",
      "Epoch 152, loss: 9.332991\n",
      "Epoch 153, loss: 9.417956\n",
      "Epoch 154, loss: 8.698908\n",
      "Epoch 155, loss: 9.373150\n",
      "Epoch 156, loss: 9.729252\n",
      "Epoch 157, loss: 9.380838\n",
      "Epoch 158, loss: 9.546008\n",
      "Epoch 159, loss: 9.179277\n",
      "Epoch 160, loss: 10.477972\n",
      "Epoch 161, loss: 9.419767\n",
      "Epoch 162, loss: 9.790433\n",
      "Epoch 163, loss: 9.810602\n",
      "Epoch 164, loss: 10.197545\n",
      "Epoch 165, loss: 9.084545\n",
      "Epoch 166, loss: 8.746612\n",
      "Epoch 167, loss: 9.409218\n",
      "Epoch 168, loss: 9.315278\n",
      "Epoch 169, loss: 9.741342\n",
      "Epoch 170, loss: 9.736860\n",
      "Epoch 171, loss: 9.586438\n",
      "Epoch 172, loss: 9.141821\n",
      "Epoch 173, loss: 9.364940\n",
      "Epoch 174, loss: 9.299965\n",
      "Epoch 175, loss: 8.529783\n",
      "Epoch 176, loss: 9.892365\n",
      "Epoch 177, loss: 9.468848\n",
      "Epoch 178, loss: 9.574034\n",
      "Epoch 179, loss: 10.194042\n",
      "Epoch 180, loss: 9.221662\n",
      "Epoch 181, loss: 8.664418\n",
      "Epoch 182, loss: 9.535613\n",
      "Epoch 183, loss: 9.902222\n",
      "Epoch 184, loss: 9.498280\n",
      "Epoch 185, loss: 8.757533\n",
      "Epoch 186, loss: 9.708821\n",
      "Epoch 187, loss: 9.838335\n",
      "Epoch 188, loss: 9.749243\n",
      "Epoch 189, loss: 8.705273\n",
      "Epoch 190, loss: 9.021057\n",
      "Epoch 191, loss: 9.142080\n",
      "Epoch 192, loss: 10.392026\n",
      "Epoch 193, loss: 9.267187\n",
      "Epoch 194, loss: 9.205735\n",
      "Epoch 195, loss: 9.511684\n",
      "Epoch 196, loss: 9.408985\n",
      "Epoch 197, loss: 9.005103\n",
      "Epoch 198, loss: 9.809171\n",
      "Epoch 199, loss: 9.114912\n",
      "lr: 1, rs: 0.001, accuracy 200 epochs: 0.145\n",
      "Epoch 0, loss: 8.256930\n",
      "Epoch 1, loss: 9.077343\n",
      "Epoch 2, loss: 9.627266\n",
      "Epoch 3, loss: 9.358571\n",
      "Epoch 4, loss: 10.008335\n",
      "Epoch 5, loss: 10.147324\n",
      "Epoch 6, loss: 9.847523\n",
      "Epoch 7, loss: 9.244488\n",
      "Epoch 8, loss: 9.115549\n",
      "Epoch 9, loss: 9.705165\n",
      "Epoch 10, loss: 9.694348\n",
      "Epoch 11, loss: 8.977222\n",
      "Epoch 12, loss: 8.716015\n",
      "Epoch 13, loss: 9.530121\n",
      "Epoch 14, loss: 9.387598\n",
      "Epoch 15, loss: 8.663576\n",
      "Epoch 16, loss: 9.420958\n",
      "Epoch 17, loss: 9.511767\n",
      "Epoch 18, loss: 9.018188\n",
      "Epoch 19, loss: 9.077256\n",
      "Epoch 20, loss: 9.500779\n",
      "Epoch 21, loss: 9.843302\n",
      "Epoch 22, loss: 9.376105\n",
      "Epoch 23, loss: 8.708779\n",
      "Epoch 24, loss: 8.692033\n",
      "Epoch 25, loss: 9.275011\n",
      "Epoch 26, loss: 9.187429\n",
      "Epoch 27, loss: 8.886082\n",
      "Epoch 28, loss: 9.539037\n",
      "Epoch 29, loss: 9.510731\n",
      "Epoch 30, loss: 8.903017\n",
      "Epoch 31, loss: 9.122247\n",
      "Epoch 32, loss: 8.501117\n",
      "Epoch 33, loss: 8.951566\n",
      "Epoch 34, loss: 9.303815\n",
      "Epoch 35, loss: 9.165995\n",
      "Epoch 36, loss: 8.603383\n",
      "Epoch 37, loss: 9.241709\n",
      "Epoch 38, loss: 8.196178\n",
      "Epoch 39, loss: 8.658258\n",
      "Epoch 40, loss: 9.235365\n",
      "Epoch 41, loss: 8.453723\n",
      "Epoch 42, loss: 9.014561\n",
      "Epoch 43, loss: 9.336303\n",
      "Epoch 44, loss: 9.430226\n",
      "Epoch 45, loss: 8.706365\n",
      "Epoch 46, loss: 8.465801\n",
      "Epoch 47, loss: 9.507565\n",
      "Epoch 48, loss: 8.845156\n",
      "Epoch 49, loss: 9.171537\n",
      "Epoch 50, loss: 8.786037\n",
      "Epoch 51, loss: 8.870661\n",
      "Epoch 52, loss: 8.944901\n",
      "Epoch 53, loss: 8.788278\n",
      "Epoch 54, loss: 9.088557\n",
      "Epoch 55, loss: 8.763519\n",
      "Epoch 56, loss: 8.757428\n",
      "Epoch 57, loss: 8.798558\n",
      "Epoch 58, loss: 8.338875\n",
      "Epoch 59, loss: 9.451490\n",
      "Epoch 60, loss: 8.074684\n",
      "Epoch 61, loss: 8.948961\n",
      "Epoch 62, loss: 8.432414\n",
      "Epoch 63, loss: 9.238294\n",
      "Epoch 64, loss: 8.655334\n",
      "Epoch 65, loss: 8.464888\n",
      "Epoch 66, loss: 8.936675\n",
      "Epoch 67, loss: 8.776868\n",
      "Epoch 68, loss: 9.019341\n",
      "Epoch 69, loss: 8.795856\n",
      "Epoch 70, loss: 9.116611\n",
      "Epoch 71, loss: 8.732906\n",
      "Epoch 72, loss: 9.308277\n",
      "Epoch 73, loss: 9.083097\n",
      "Epoch 74, loss: 9.007265\n",
      "Epoch 75, loss: 9.176773\n",
      "Epoch 76, loss: 8.932838\n",
      "Epoch 77, loss: 8.132014\n",
      "Epoch 78, loss: 8.902496\n",
      "Epoch 79, loss: 8.414272\n",
      "Epoch 80, loss: 9.456739\n",
      "Epoch 81, loss: 8.755822\n",
      "Epoch 82, loss: 8.360461\n",
      "Epoch 83, loss: 8.646889\n",
      "Epoch 84, loss: 8.537382\n",
      "Epoch 85, loss: 8.587065\n",
      "Epoch 86, loss: 8.953076\n",
      "Epoch 87, loss: 9.096349\n",
      "Epoch 88, loss: 8.433650\n",
      "Epoch 89, loss: 8.934513\n",
      "Epoch 90, loss: 8.622355\n",
      "Epoch 91, loss: 9.293237\n",
      "Epoch 92, loss: 8.668802\n",
      "Epoch 93, loss: 8.757315\n",
      "Epoch 94, loss: 8.410113\n",
      "Epoch 95, loss: 9.493174\n",
      "Epoch 96, loss: 8.553037\n",
      "Epoch 97, loss: 9.179554\n",
      "Epoch 98, loss: 8.420811\n",
      "Epoch 99, loss: 9.013188\n",
      "Epoch 100, loss: 8.888369\n",
      "Epoch 101, loss: 8.263220\n",
      "Epoch 102, loss: 8.967483\n",
      "Epoch 103, loss: 9.141957\n",
      "Epoch 104, loss: 8.456262\n",
      "Epoch 105, loss: 8.975450\n",
      "Epoch 106, loss: 8.468424\n",
      "Epoch 107, loss: 9.186094\n",
      "Epoch 108, loss: 8.302136\n",
      "Epoch 109, loss: 9.515536\n",
      "Epoch 110, loss: 8.587956\n",
      "Epoch 111, loss: 9.256536\n",
      "Epoch 112, loss: 8.699195\n",
      "Epoch 113, loss: 8.840613\n",
      "Epoch 114, loss: 8.921144\n",
      "Epoch 115, loss: 8.723546\n",
      "Epoch 116, loss: 8.900494\n",
      "Epoch 117, loss: 8.815036\n",
      "Epoch 118, loss: 8.393127\n",
      "Epoch 119, loss: 8.827975\n",
      "Epoch 120, loss: 8.349708\n",
      "Epoch 121, loss: 8.239016\n",
      "Epoch 122, loss: 8.928500\n",
      "Epoch 123, loss: 8.488419\n",
      "Epoch 124, loss: 8.970432\n",
      "Epoch 125, loss: 8.509816\n",
      "Epoch 126, loss: 8.679188\n",
      "Epoch 127, loss: 8.320713\n",
      "Epoch 128, loss: 8.341255\n",
      "Epoch 129, loss: 9.288467\n",
      "Epoch 130, loss: 8.580707\n",
      "Epoch 131, loss: 8.771507\n",
      "Epoch 132, loss: 8.680273\n",
      "Epoch 133, loss: 8.845850\n",
      "Epoch 134, loss: 8.684492\n",
      "Epoch 135, loss: 9.770966\n",
      "Epoch 136, loss: 7.900341\n",
      "Epoch 137, loss: 8.438958\n",
      "Epoch 138, loss: 9.086396\n",
      "Epoch 139, loss: 8.709154\n",
      "Epoch 140, loss: 9.155548\n",
      "Epoch 141, loss: 8.523227\n",
      "Epoch 142, loss: 7.945524\n",
      "Epoch 143, loss: 9.291210\n",
      "Epoch 144, loss: 8.490851\n",
      "Epoch 145, loss: 8.216979\n",
      "Epoch 146, loss: 8.725777\n",
      "Epoch 147, loss: 8.446727\n",
      "Epoch 148, loss: 8.420445\n",
      "Epoch 149, loss: 8.914856\n",
      "Epoch 150, loss: 8.389230\n",
      "Epoch 151, loss: 8.735107\n",
      "Epoch 152, loss: 8.770668\n",
      "Epoch 153, loss: 8.801157\n",
      "Epoch 154, loss: 8.150606\n",
      "Epoch 155, loss: 8.421354\n",
      "Epoch 156, loss: 8.710994\n",
      "Epoch 157, loss: 8.419419\n",
      "Epoch 158, loss: 8.919329\n",
      "Epoch 159, loss: 8.563373\n",
      "Epoch 160, loss: 8.300735\n",
      "Epoch 161, loss: 9.101778\n",
      "Epoch 162, loss: 8.526894\n",
      "Epoch 163, loss: 9.152662\n",
      "Epoch 164, loss: 8.516645\n",
      "Epoch 165, loss: 8.851021\n",
      "Epoch 166, loss: 8.564995\n",
      "Epoch 167, loss: 8.286182\n",
      "Epoch 168, loss: 9.002909\n",
      "Epoch 169, loss: 8.641273\n",
      "Epoch 170, loss: 8.616681\n",
      "Epoch 171, loss: 9.109204\n",
      "Epoch 172, loss: 8.396237\n",
      "Epoch 173, loss: 8.818735\n",
      "Epoch 174, loss: 8.444480\n",
      "Epoch 175, loss: 9.613046\n",
      "Epoch 176, loss: 8.787316\n",
      "Epoch 177, loss: 8.463299\n",
      "Epoch 178, loss: 8.381512\n",
      "Epoch 179, loss: 8.557653\n",
      "Epoch 180, loss: 9.094268\n",
      "Epoch 181, loss: 9.043603\n",
      "Epoch 182, loss: 8.338136\n",
      "Epoch 183, loss: 8.851846\n",
      "Epoch 184, loss: 9.220686\n",
      "Epoch 185, loss: 8.785734\n",
      "Epoch 186, loss: 8.338020\n",
      "Epoch 187, loss: 9.099696\n",
      "Epoch 188, loss: 8.436041\n",
      "Epoch 189, loss: 8.721205\n",
      "Epoch 190, loss: 8.754085\n",
      "Epoch 191, loss: 8.637471\n",
      "Epoch 192, loss: 8.364500\n",
      "Epoch 193, loss: 9.285771\n",
      "Epoch 194, loss: 8.092057\n",
      "Epoch 195, loss: 9.003986\n",
      "Epoch 196, loss: 8.982967\n",
      "Epoch 197, loss: 8.710702\n",
      "Epoch 198, loss: 8.546082\n",
      "Epoch 199, loss: 8.564430\n",
      "lr: 1, rs: 0.0001, accuracy 200 epochs: 0.163\n",
      "Epoch 0, loss: 9.218208\n",
      "Epoch 1, loss: 9.602887\n",
      "Epoch 2, loss: 9.229404\n",
      "Epoch 3, loss: 9.512840\n",
      "Epoch 4, loss: 9.917768\n",
      "Epoch 5, loss: 9.392129\n",
      "Epoch 6, loss: 9.483833\n",
      "Epoch 7, loss: 9.964516\n",
      "Epoch 8, loss: 8.880554\n",
      "Epoch 9, loss: 9.988232\n",
      "Epoch 10, loss: 9.366738\n",
      "Epoch 11, loss: 9.585562\n",
      "Epoch 12, loss: 9.171945\n",
      "Epoch 13, loss: 9.113740\n",
      "Epoch 14, loss: 8.879828\n",
      "Epoch 15, loss: 9.058083\n",
      "Epoch 16, loss: 9.227940\n",
      "Epoch 17, loss: 8.927628\n",
      "Epoch 18, loss: 7.798655\n",
      "Epoch 19, loss: 9.690025\n",
      "Epoch 20, loss: 9.413016\n",
      "Epoch 21, loss: 7.588015\n",
      "Epoch 22, loss: 8.967712\n",
      "Epoch 23, loss: 9.007607\n",
      "Epoch 24, loss: 8.813017\n",
      "Epoch 25, loss: 9.355784\n",
      "Epoch 26, loss: 8.142495\n",
      "Epoch 27, loss: 8.476675\n",
      "Epoch 28, loss: 9.235198\n",
      "Epoch 29, loss: 8.922955\n",
      "Epoch 30, loss: 8.666222\n",
      "Epoch 31, loss: 8.709892\n",
      "Epoch 32, loss: 8.679668\n",
      "Epoch 33, loss: 8.734843\n",
      "Epoch 34, loss: 8.970014\n",
      "Epoch 35, loss: 8.329975\n",
      "Epoch 36, loss: 9.299756\n",
      "Epoch 37, loss: 8.756776\n",
      "Epoch 38, loss: 9.524732\n",
      "Epoch 39, loss: 8.761931\n",
      "Epoch 40, loss: 8.829229\n",
      "Epoch 41, loss: 8.755187\n",
      "Epoch 42, loss: 8.940368\n",
      "Epoch 43, loss: 8.748146\n",
      "Epoch 44, loss: 8.466541\n",
      "Epoch 45, loss: 8.551314\n",
      "Epoch 46, loss: 8.946710\n",
      "Epoch 47, loss: 8.180636\n",
      "Epoch 48, loss: 8.704724\n",
      "Epoch 49, loss: 8.432447\n",
      "Epoch 50, loss: 9.442395\n",
      "Epoch 51, loss: 7.919223\n",
      "Epoch 52, loss: 8.925104\n",
      "Epoch 53, loss: 8.606173\n",
      "Epoch 54, loss: 9.115948\n",
      "Epoch 55, loss: 8.575083\n",
      "Epoch 56, loss: 8.990554\n",
      "Epoch 57, loss: 9.252043\n",
      "Epoch 58, loss: 8.995726\n",
      "Epoch 59, loss: 8.599612\n",
      "Epoch 60, loss: 8.744199\n",
      "Epoch 61, loss: 8.259972\n",
      "Epoch 62, loss: 8.651929\n",
      "Epoch 63, loss: 8.676742\n",
      "Epoch 64, loss: 9.014771\n",
      "Epoch 65, loss: 8.880886\n",
      "Epoch 66, loss: 9.113751\n",
      "Epoch 67, loss: 8.922713\n",
      "Epoch 68, loss: 8.929628\n",
      "Epoch 69, loss: 8.166122\n",
      "Epoch 70, loss: 8.385218\n",
      "Epoch 71, loss: 8.863922\n",
      "Epoch 72, loss: 8.258083\n",
      "Epoch 73, loss: 8.633549\n",
      "Epoch 74, loss: 9.141315\n",
      "Epoch 75, loss: 7.934834\n",
      "Epoch 76, loss: 8.171662\n",
      "Epoch 77, loss: 8.534278\n",
      "Epoch 78, loss: 9.217853\n",
      "Epoch 79, loss: 8.100700\n",
      "Epoch 80, loss: 8.865340\n",
      "Epoch 81, loss: 8.390267\n",
      "Epoch 82, loss: 8.331632\n",
      "Epoch 83, loss: 8.708990\n",
      "Epoch 84, loss: 8.159383\n",
      "Epoch 85, loss: 8.602776\n",
      "Epoch 86, loss: 8.310604\n",
      "Epoch 87, loss: 8.877662\n",
      "Epoch 88, loss: 8.048740\n",
      "Epoch 89, loss: 9.148161\n",
      "Epoch 90, loss: 9.010947\n",
      "Epoch 91, loss: 8.579921\n",
      "Epoch 92, loss: 8.415066\n",
      "Epoch 93, loss: 8.920463\n",
      "Epoch 94, loss: 8.785813\n",
      "Epoch 95, loss: 8.727395\n",
      "Epoch 96, loss: 7.845137\n",
      "Epoch 97, loss: 8.948436\n",
      "Epoch 98, loss: 8.775817\n",
      "Epoch 99, loss: 8.228330\n",
      "Epoch 100, loss: 8.793350\n",
      "Epoch 101, loss: 8.164617\n",
      "Epoch 102, loss: 8.719431\n",
      "Epoch 103, loss: 8.575825\n",
      "Epoch 104, loss: 8.385711\n",
      "Epoch 105, loss: 8.762473\n",
      "Epoch 106, loss: 8.131299\n",
      "Epoch 107, loss: 8.938011\n",
      "Epoch 108, loss: 7.911348\n",
      "Epoch 109, loss: 8.127279\n",
      "Epoch 110, loss: 8.223050\n",
      "Epoch 111, loss: 8.039126\n",
      "Epoch 112, loss: 8.743288\n",
      "Epoch 113, loss: 9.159538\n",
      "Epoch 114, loss: 8.507291\n",
      "Epoch 115, loss: 8.629767\n",
      "Epoch 116, loss: 8.249127\n",
      "Epoch 117, loss: 8.269865\n",
      "Epoch 118, loss: 8.368463\n",
      "Epoch 119, loss: 8.335004\n",
      "Epoch 120, loss: 8.425430\n",
      "Epoch 121, loss: 8.481786\n",
      "Epoch 122, loss: 8.866999\n",
      "Epoch 123, loss: 8.318738\n",
      "Epoch 124, loss: 7.774413\n",
      "Epoch 125, loss: 8.031330\n",
      "Epoch 126, loss: 8.985732\n",
      "Epoch 127, loss: 8.687460\n",
      "Epoch 128, loss: 8.704616\n",
      "Epoch 129, loss: 8.341076\n",
      "Epoch 130, loss: 8.657254\n",
      "Epoch 131, loss: 8.747665\n",
      "Epoch 132, loss: 8.114665\n",
      "Epoch 133, loss: 8.332969\n",
      "Epoch 134, loss: 8.375919\n",
      "Epoch 135, loss: 8.353785\n",
      "Epoch 136, loss: 8.265215\n",
      "Epoch 137, loss: 8.196269\n",
      "Epoch 138, loss: 8.295068\n",
      "Epoch 139, loss: 7.817029\n",
      "Epoch 140, loss: 8.160831\n",
      "Epoch 141, loss: 8.489206\n",
      "Epoch 142, loss: 8.179011\n",
      "Epoch 143, loss: 8.924949\n",
      "Epoch 144, loss: 9.017073\n",
      "Epoch 145, loss: 8.675011\n",
      "Epoch 146, loss: 8.412702\n",
      "Epoch 147, loss: 8.005681\n",
      "Epoch 148, loss: 8.252866\n",
      "Epoch 149, loss: 8.052641\n",
      "Epoch 150, loss: 8.275658\n",
      "Epoch 151, loss: 8.702805\n",
      "Epoch 152, loss: 8.044257\n",
      "Epoch 153, loss: 8.572198\n",
      "Epoch 154, loss: 8.504195\n",
      "Epoch 155, loss: 7.968983\n",
      "Epoch 156, loss: 8.271603\n",
      "Epoch 157, loss: 8.543904\n",
      "Epoch 158, loss: 7.325754\n",
      "Epoch 159, loss: 8.176729\n",
      "Epoch 160, loss: 8.468573\n",
      "Epoch 161, loss: 8.805017\n",
      "Epoch 162, loss: 8.314489\n",
      "Epoch 163, loss: 7.936286\n",
      "Epoch 164, loss: 8.530647\n",
      "Epoch 165, loss: 8.544584\n",
      "Epoch 166, loss: 7.866394\n",
      "Epoch 167, loss: 9.291477\n",
      "Epoch 168, loss: 8.286601\n",
      "Epoch 169, loss: 8.371571\n",
      "Epoch 170, loss: 7.527778\n",
      "Epoch 171, loss: 8.239004\n",
      "Epoch 172, loss: 9.165592\n",
      "Epoch 173, loss: 8.571181\n",
      "Epoch 174, loss: 8.271706\n",
      "Epoch 175, loss: 8.628394\n",
      "Epoch 176, loss: 7.943600\n",
      "Epoch 177, loss: 8.324878\n",
      "Epoch 178, loss: 8.226050\n",
      "Epoch 179, loss: 8.067104\n",
      "Epoch 180, loss: 8.780670\n",
      "Epoch 181, loss: 8.890339\n",
      "Epoch 182, loss: 8.045111\n",
      "Epoch 183, loss: 7.840760\n",
      "Epoch 184, loss: 7.948582\n",
      "Epoch 185, loss: 8.551192\n",
      "Epoch 186, loss: 7.950290\n",
      "Epoch 187, loss: 9.122015\n",
      "Epoch 188, loss: 8.056375\n",
      "Epoch 189, loss: 8.365213\n",
      "Epoch 190, loss: 8.686748\n",
      "Epoch 191, loss: 8.427685\n",
      "Epoch 192, loss: 8.586886\n",
      "Epoch 193, loss: 7.778999\n",
      "Epoch 194, loss: 9.012002\n",
      "Epoch 195, loss: 8.147999\n",
      "Epoch 196, loss: 8.257202\n",
      "Epoch 197, loss: 7.950396\n",
      "Epoch 198, loss: 8.710176\n",
      "Epoch 199, loss: 8.671850\n",
      "lr: 1, rs: 1e-05, accuracy 200 epochs: 0.203\n",
      "Epoch 0, loss: 8.660248\n",
      "Epoch 1, loss: 10.204857\n",
      "Epoch 2, loss: 9.115276\n",
      "Epoch 3, loss: 9.903297\n",
      "Epoch 4, loss: 9.727228\n",
      "Epoch 5, loss: 9.460718\n",
      "Epoch 6, loss: 9.372663\n",
      "Epoch 7, loss: 8.707992\n",
      "Epoch 8, loss: 9.168329\n",
      "Epoch 9, loss: 8.510983\n",
      "Epoch 10, loss: 9.635363\n",
      "Epoch 11, loss: 9.194756\n",
      "Epoch 12, loss: 9.613063\n",
      "Epoch 13, loss: 8.617842\n",
      "Epoch 14, loss: 10.067657\n",
      "Epoch 15, loss: 9.224530\n",
      "Epoch 16, loss: 8.813230\n",
      "Epoch 17, loss: 8.621516\n",
      "Epoch 18, loss: 9.558821\n",
      "Epoch 19, loss: 8.772964\n",
      "Epoch 20, loss: 8.823661\n",
      "Epoch 21, loss: 8.475742\n",
      "Epoch 22, loss: 8.673864\n",
      "Epoch 23, loss: 9.410273\n",
      "Epoch 24, loss: 9.132601\n",
      "Epoch 25, loss: 9.059667\n",
      "Epoch 26, loss: 8.941946\n",
      "Epoch 27, loss: 9.045826\n",
      "Epoch 28, loss: 8.994368\n",
      "Epoch 29, loss: 9.166573\n",
      "Epoch 30, loss: 8.632993\n",
      "Epoch 31, loss: 8.875534\n",
      "Epoch 32, loss: 8.988700\n",
      "Epoch 33, loss: 9.131078\n",
      "Epoch 34, loss: 9.612261\n",
      "Epoch 35, loss: 8.544679\n",
      "Epoch 36, loss: 8.938482\n",
      "Epoch 37, loss: 8.686765\n",
      "Epoch 38, loss: 8.716336\n",
      "Epoch 39, loss: 8.307596\n",
      "Epoch 40, loss: 8.834446\n",
      "Epoch 41, loss: 9.211825\n",
      "Epoch 42, loss: 9.224133\n",
      "Epoch 43, loss: 8.305442\n",
      "Epoch 44, loss: 9.666146\n",
      "Epoch 45, loss: 9.190137\n",
      "Epoch 46, loss: 8.566476\n",
      "Epoch 47, loss: 8.913938\n",
      "Epoch 48, loss: 8.522931\n",
      "Epoch 49, loss: 9.287198\n",
      "Epoch 50, loss: 7.983890\n",
      "Epoch 51, loss: 8.873152\n",
      "Epoch 52, loss: 8.771356\n",
      "Epoch 53, loss: 8.685887\n",
      "Epoch 54, loss: 8.571836\n",
      "Epoch 55, loss: 8.998633\n",
      "Epoch 56, loss: 7.942331\n",
      "Epoch 57, loss: 8.662243\n",
      "Epoch 58, loss: 8.995014\n",
      "Epoch 59, loss: 8.779644\n",
      "Epoch 60, loss: 8.195796\n",
      "Epoch 61, loss: 8.499554\n",
      "Epoch 62, loss: 8.737511\n",
      "Epoch 63, loss: 8.548470\n",
      "Epoch 64, loss: 9.165575\n",
      "Epoch 65, loss: 8.974649\n",
      "Epoch 66, loss: 9.091236\n",
      "Epoch 67, loss: 8.709655\n",
      "Epoch 68, loss: 8.673977\n",
      "Epoch 69, loss: 9.170690\n",
      "Epoch 70, loss: 7.484349\n",
      "Epoch 71, loss: 8.556309\n",
      "Epoch 72, loss: 8.730407\n",
      "Epoch 73, loss: 9.266544\n",
      "Epoch 74, loss: 7.983555\n",
      "Epoch 75, loss: 8.698242\n",
      "Epoch 76, loss: 8.403502\n",
      "Epoch 77, loss: 8.489769\n",
      "Epoch 78, loss: 8.689804\n",
      "Epoch 79, loss: 8.624013\n",
      "Epoch 80, loss: 8.720109\n",
      "Epoch 81, loss: 8.713989\n",
      "Epoch 82, loss: 8.449979\n",
      "Epoch 83, loss: 8.860351\n",
      "Epoch 84, loss: 7.965544\n",
      "Epoch 85, loss: 8.370699\n",
      "Epoch 86, loss: 8.721289\n",
      "Epoch 87, loss: 8.346442\n",
      "Epoch 88, loss: 8.575384\n",
      "Epoch 89, loss: 8.366514\n",
      "Epoch 90, loss: 9.158576\n",
      "Epoch 91, loss: 8.221615\n",
      "Epoch 92, loss: 8.605199\n",
      "Epoch 93, loss: 9.003674\n",
      "Epoch 94, loss: 8.338314\n",
      "Epoch 95, loss: 8.262665\n",
      "Epoch 96, loss: 8.456489\n",
      "Epoch 97, loss: 8.665751\n",
      "Epoch 98, loss: 8.616009\n",
      "Epoch 99, loss: 8.747500\n",
      "Epoch 100, loss: 8.525936\n",
      "Epoch 101, loss: 8.544640\n",
      "Epoch 102, loss: 8.852697\n",
      "Epoch 103, loss: 8.024772\n",
      "Epoch 104, loss: 8.797673\n",
      "Epoch 105, loss: 8.387853\n",
      "Epoch 106, loss: 8.701175\n",
      "Epoch 107, loss: 8.267993\n",
      "Epoch 108, loss: 8.909628\n",
      "Epoch 109, loss: 8.338304\n",
      "Epoch 110, loss: 8.167191\n",
      "Epoch 111, loss: 8.924374\n",
      "Epoch 112, loss: 9.192820\n",
      "Epoch 113, loss: 8.532106\n",
      "Epoch 114, loss: 8.400796\n",
      "Epoch 115, loss: 8.626450\n",
      "Epoch 116, loss: 8.803268\n",
      "Epoch 117, loss: 8.506408\n",
      "Epoch 118, loss: 8.358376\n",
      "Epoch 119, loss: 8.640304\n",
      "Epoch 120, loss: 8.295791\n",
      "Epoch 121, loss: 8.126104\n",
      "Epoch 122, loss: 8.354117\n",
      "Epoch 123, loss: 8.540632\n",
      "Epoch 124, loss: 8.771225\n",
      "Epoch 125, loss: 8.860033\n",
      "Epoch 126, loss: 8.052861\n",
      "Epoch 127, loss: 8.382830\n",
      "Epoch 128, loss: 8.623587\n",
      "Epoch 129, loss: 8.211565\n",
      "Epoch 130, loss: 8.705948\n",
      "Epoch 131, loss: 7.549718\n",
      "Epoch 132, loss: 8.395096\n",
      "Epoch 133, loss: 8.910343\n",
      "Epoch 134, loss: 8.350676\n",
      "Epoch 135, loss: 8.427302\n",
      "Epoch 136, loss: 7.992719\n",
      "Epoch 137, loss: 7.926568\n",
      "Epoch 138, loss: 8.163821\n",
      "Epoch 139, loss: 7.707629\n",
      "Epoch 140, loss: 8.543255\n",
      "Epoch 141, loss: 8.091241\n",
      "Epoch 142, loss: 8.725984\n",
      "Epoch 143, loss: 7.887036\n",
      "Epoch 144, loss: 8.822241\n",
      "Epoch 145, loss: 8.318500\n",
      "Epoch 146, loss: 8.198840\n",
      "Epoch 147, loss: 8.401843\n",
      "Epoch 148, loss: 7.858095\n",
      "Epoch 149, loss: 8.030749\n",
      "Epoch 150, loss: 8.747366\n",
      "Epoch 151, loss: 8.139375\n",
      "Epoch 152, loss: 8.831156\n",
      "Epoch 153, loss: 8.624427\n",
      "Epoch 154, loss: 8.652138\n",
      "Epoch 155, loss: 8.356504\n",
      "Epoch 156, loss: 8.548832\n",
      "Epoch 157, loss: 7.926412\n",
      "Epoch 158, loss: 8.742091\n",
      "Epoch 159, loss: 8.204512\n",
      "Epoch 160, loss: 8.527205\n",
      "Epoch 161, loss: 8.563994\n",
      "Epoch 162, loss: 7.988385\n",
      "Epoch 163, loss: 8.299611\n",
      "Epoch 164, loss: 8.343567\n",
      "Epoch 165, loss: 8.040426\n",
      "Epoch 166, loss: 8.571864\n",
      "Epoch 167, loss: 8.631621\n",
      "Epoch 168, loss: 8.013089\n",
      "Epoch 169, loss: 8.079160\n",
      "Epoch 170, loss: 8.008587\n",
      "Epoch 171, loss: 8.164891\n",
      "Epoch 172, loss: 8.416387\n",
      "Epoch 173, loss: 8.306542\n",
      "Epoch 174, loss: 8.723620\n",
      "Epoch 175, loss: 7.955511\n",
      "Epoch 176, loss: 8.137264\n",
      "Epoch 177, loss: 8.533922\n",
      "Epoch 178, loss: 8.217986\n",
      "Epoch 179, loss: 8.310104\n",
      "Epoch 180, loss: 8.270537\n",
      "Epoch 181, loss: 8.877397\n",
      "Epoch 182, loss: 7.623278\n",
      "Epoch 183, loss: 8.140556\n",
      "Epoch 184, loss: 8.352285\n",
      "Epoch 185, loss: 8.484977\n",
      "Epoch 186, loss: 8.350524\n",
      "Epoch 187, loss: 7.600061\n",
      "Epoch 188, loss: 8.650632\n",
      "Epoch 189, loss: 7.763003\n",
      "Epoch 190, loss: 8.455748\n",
      "Epoch 191, loss: 8.165865\n",
      "Epoch 192, loss: 7.839269\n",
      "Epoch 193, loss: 8.538396\n",
      "Epoch 194, loss: 8.630095\n",
      "Epoch 195, loss: 8.162973\n",
      "Epoch 196, loss: 8.445575\n",
      "Epoch 197, loss: 7.966557\n",
      "Epoch 198, loss: 8.199107\n",
      "Epoch 199, loss: 8.721584\n",
      "lr: 1, rs: 1e-06, accuracy 200 epochs: 0.149\n",
      "Epoch 0, loss: 2.296907\n",
      "Epoch 1, loss: 2.272062\n",
      "Epoch 2, loss: 2.269448\n",
      "Epoch 3, loss: 2.270987\n",
      "Epoch 4, loss: 2.269466\n",
      "Epoch 5, loss: 2.269347\n",
      "Epoch 6, loss: 2.266881\n",
      "Epoch 7, loss: 2.268346\n",
      "Epoch 8, loss: 2.268461\n",
      "Epoch 9, loss: 2.268764\n",
      "Epoch 10, loss: 2.269069\n",
      "Epoch 11, loss: 2.268881\n",
      "Epoch 12, loss: 2.265680\n",
      "Epoch 13, loss: 2.271000\n",
      "Epoch 14, loss: 2.267557\n",
      "Epoch 15, loss: 2.267795\n",
      "Epoch 16, loss: 2.267365\n",
      "Epoch 17, loss: 2.269052\n",
      "Epoch 18, loss: 2.268940\n",
      "Epoch 19, loss: 2.268369\n",
      "Epoch 20, loss: 2.266787\n",
      "Epoch 21, loss: 2.269240\n",
      "Epoch 22, loss: 2.270596\n",
      "Epoch 23, loss: 2.268779\n",
      "Epoch 24, loss: 2.271483\n",
      "Epoch 25, loss: 2.267099\n",
      "Epoch 26, loss: 2.271217\n",
      "Epoch 27, loss: 2.271837\n",
      "Epoch 28, loss: 2.269707\n",
      "Epoch 29, loss: 2.272269\n",
      "Epoch 30, loss: 2.268518\n",
      "Epoch 31, loss: 2.268352\n",
      "Epoch 32, loss: 2.267995\n",
      "Epoch 33, loss: 2.270036\n",
      "Epoch 34, loss: 2.269570\n",
      "Epoch 35, loss: 2.267253\n",
      "Epoch 36, loss: 2.271578\n",
      "Epoch 37, loss: 2.269756\n",
      "Epoch 38, loss: 2.266359\n",
      "Epoch 39, loss: 2.271068\n",
      "Epoch 40, loss: 2.271283\n",
      "Epoch 41, loss: 2.267568\n",
      "Epoch 42, loss: 2.269390\n",
      "Epoch 43, loss: 2.268833\n",
      "Epoch 44, loss: 2.267666\n",
      "Epoch 45, loss: 2.269232\n",
      "Epoch 46, loss: 2.270297\n",
      "Epoch 47, loss: 2.270628\n",
      "Epoch 48, loss: 2.266947\n",
      "Epoch 49, loss: 2.271002\n",
      "Epoch 50, loss: 2.267833\n",
      "Epoch 51, loss: 2.269894\n",
      "Epoch 52, loss: 2.269981\n",
      "Epoch 53, loss: 2.269054\n",
      "Epoch 54, loss: 2.269874\n",
      "Epoch 55, loss: 2.266645\n",
      "Epoch 56, loss: 2.270851\n",
      "Epoch 57, loss: 2.269632\n",
      "Epoch 58, loss: 2.269370\n",
      "Epoch 59, loss: 2.267770\n",
      "Epoch 60, loss: 2.268865\n",
      "Epoch 61, loss: 2.268255\n",
      "Epoch 62, loss: 2.266461\n",
      "Epoch 63, loss: 2.269581\n",
      "Epoch 64, loss: 2.267923\n",
      "Epoch 65, loss: 2.268546\n",
      "Epoch 66, loss: 2.269620\n",
      "Epoch 67, loss: 2.270232\n",
      "Epoch 68, loss: 2.268011\n",
      "Epoch 69, loss: 2.268441\n",
      "Epoch 70, loss: 2.268059\n",
      "Epoch 71, loss: 2.270850\n",
      "Epoch 72, loss: 2.270002\n",
      "Epoch 73, loss: 2.268821\n",
      "Epoch 74, loss: 2.268831\n",
      "Epoch 75, loss: 2.268375\n",
      "Epoch 76, loss: 2.269955\n",
      "Epoch 77, loss: 2.267565\n",
      "Epoch 78, loss: 2.267920\n",
      "Epoch 79, loss: 2.270304\n",
      "Epoch 80, loss: 2.269098\n",
      "Epoch 81, loss: 2.268157\n",
      "Epoch 82, loss: 2.269064\n",
      "Epoch 83, loss: 2.269071\n",
      "Epoch 84, loss: 2.269079\n",
      "Epoch 85, loss: 2.271845\n",
      "Epoch 86, loss: 2.268220\n",
      "Epoch 87, loss: 2.268904\n",
      "Epoch 88, loss: 2.269300\n",
      "Epoch 89, loss: 2.268840\n",
      "Epoch 90, loss: 2.269981\n",
      "Epoch 91, loss: 2.268892\n",
      "Epoch 92, loss: 2.269299\n",
      "Epoch 93, loss: 2.267307\n",
      "Epoch 94, loss: 2.266805\n",
      "Epoch 95, loss: 2.271411\n",
      "Epoch 96, loss: 2.266432\n",
      "Epoch 97, loss: 2.267496\n",
      "Epoch 98, loss: 2.271427\n",
      "Epoch 99, loss: 2.267318\n",
      "Epoch 100, loss: 2.268069\n",
      "Epoch 101, loss: 2.269296\n",
      "Epoch 102, loss: 2.267882\n",
      "Epoch 103, loss: 2.268790\n",
      "Epoch 104, loss: 2.268067\n",
      "Epoch 105, loss: 2.269765\n",
      "Epoch 106, loss: 2.268271\n",
      "Epoch 107, loss: 2.270721\n",
      "Epoch 108, loss: 2.268942\n",
      "Epoch 109, loss: 2.271908\n",
      "Epoch 110, loss: 2.265986\n",
      "Epoch 111, loss: 2.266947\n",
      "Epoch 112, loss: 2.268176\n",
      "Epoch 113, loss: 2.268822\n",
      "Epoch 114, loss: 2.270424\n",
      "Epoch 115, loss: 2.268826\n",
      "Epoch 116, loss: 2.270674\n",
      "Epoch 117, loss: 2.266913\n",
      "Epoch 118, loss: 2.270138\n",
      "Epoch 119, loss: 2.268224\n",
      "Epoch 120, loss: 2.269445\n",
      "Epoch 121, loss: 2.267507\n",
      "Epoch 122, loss: 2.270758\n",
      "Epoch 123, loss: 2.268199\n",
      "Epoch 124, loss: 2.267488\n",
      "Epoch 125, loss: 2.268008\n",
      "Epoch 126, loss: 2.268473\n",
      "Epoch 127, loss: 2.266627\n",
      "Epoch 128, loss: 2.268025\n",
      "Epoch 129, loss: 2.268776\n",
      "Epoch 130, loss: 2.267838\n",
      "Epoch 131, loss: 2.267519\n",
      "Epoch 132, loss: 2.272249\n",
      "Epoch 133, loss: 2.268932\n",
      "Epoch 134, loss: 2.268207\n",
      "Epoch 135, loss: 2.270742\n",
      "Epoch 136, loss: 2.271918\n",
      "Epoch 137, loss: 2.268499\n",
      "Epoch 138, loss: 2.271748\n",
      "Epoch 139, loss: 2.268431\n",
      "Epoch 140, loss: 2.267741\n",
      "Epoch 141, loss: 2.269751\n",
      "Epoch 142, loss: 2.267272\n",
      "Epoch 143, loss: 2.267859\n",
      "Epoch 144, loss: 2.272001\n",
      "Epoch 145, loss: 2.269813\n",
      "Epoch 146, loss: 2.269383\n",
      "Epoch 147, loss: 2.270692\n",
      "Epoch 148, loss: 2.270831\n",
      "Epoch 149, loss: 2.270227\n",
      "Epoch 150, loss: 2.267541\n",
      "Epoch 151, loss: 2.266589\n",
      "Epoch 152, loss: 2.268793\n",
      "Epoch 153, loss: 2.267847\n",
      "Epoch 154, loss: 2.268480\n",
      "Epoch 155, loss: 2.268944\n",
      "Epoch 156, loss: 2.269556\n",
      "Epoch 157, loss: 2.271035\n",
      "Epoch 158, loss: 2.268574\n",
      "Epoch 159, loss: 2.270127\n",
      "Epoch 160, loss: 2.268782\n",
      "Epoch 161, loss: 2.272019\n",
      "Epoch 162, loss: 2.269474\n",
      "Epoch 163, loss: 2.268866\n",
      "Epoch 164, loss: 2.268590\n",
      "Epoch 165, loss: 2.269690\n",
      "Epoch 166, loss: 2.266714\n",
      "Epoch 167, loss: 2.268455\n",
      "Epoch 168, loss: 2.267943\n",
      "Epoch 169, loss: 2.270310\n",
      "Epoch 170, loss: 2.266834\n",
      "Epoch 171, loss: 2.270158\n",
      "Epoch 172, loss: 2.268099\n",
      "Epoch 173, loss: 2.267910\n",
      "Epoch 174, loss: 2.268382\n",
      "Epoch 175, loss: 2.270776\n",
      "Epoch 176, loss: 2.268307\n",
      "Epoch 177, loss: 2.268346\n",
      "Epoch 178, loss: 2.270991\n",
      "Epoch 179, loss: 2.268916\n",
      "Epoch 180, loss: 2.271106\n",
      "Epoch 181, loss: 2.268184\n",
      "Epoch 182, loss: 2.266287\n",
      "Epoch 183, loss: 2.268729\n",
      "Epoch 184, loss: 2.269499\n",
      "Epoch 185, loss: 2.269468\n",
      "Epoch 186, loss: 2.268352\n",
      "Epoch 187, loss: 2.269664\n",
      "Epoch 188, loss: 2.269246\n",
      "Epoch 189, loss: 2.266261\n",
      "Epoch 190, loss: 2.270060\n",
      "Epoch 191, loss: 2.269076\n",
      "Epoch 192, loss: 2.270018\n",
      "Epoch 193, loss: 2.271424\n",
      "Epoch 194, loss: 2.269180\n",
      "Epoch 195, loss: 2.270031\n",
      "Epoch 196, loss: 2.268115\n",
      "Epoch 197, loss: 2.269859\n",
      "Epoch 198, loss: 2.268279\n",
      "Epoch 199, loss: 2.269001\n",
      "lr: 0.1, rs: 0.1, accuracy 200 epochs: 0.2\n",
      "Epoch 0, loss: 2.281459\n",
      "Epoch 1, loss: 2.240671\n",
      "Epoch 2, loss: 2.219400\n",
      "Epoch 3, loss: 2.205995\n",
      "Epoch 4, loss: 2.199335\n",
      "Epoch 5, loss: 2.193246\n",
      "Epoch 6, loss: 2.186760\n",
      "Epoch 7, loss: 2.185199\n",
      "Epoch 8, loss: 2.185679\n",
      "Epoch 9, loss: 2.182660\n",
      "Epoch 10, loss: 2.181800\n",
      "Epoch 11, loss: 2.182648\n",
      "Epoch 12, loss: 2.177870\n",
      "Epoch 13, loss: 2.177020\n",
      "Epoch 14, loss: 2.178857\n",
      "Epoch 15, loss: 2.179829\n",
      "Epoch 16, loss: 2.177042\n",
      "Epoch 17, loss: 2.174847\n",
      "Epoch 18, loss: 2.177527\n",
      "Epoch 19, loss: 2.174989\n",
      "Epoch 20, loss: 2.179685\n",
      "Epoch 21, loss: 2.176153\n",
      "Epoch 22, loss: 2.176029\n",
      "Epoch 23, loss: 2.174773\n",
      "Epoch 24, loss: 2.175700\n",
      "Epoch 25, loss: 2.175368\n",
      "Epoch 26, loss: 2.174473\n",
      "Epoch 27, loss: 2.176508\n",
      "Epoch 28, loss: 2.174420\n",
      "Epoch 29, loss: 2.176020\n",
      "Epoch 30, loss: 2.175312\n",
      "Epoch 31, loss: 2.175644\n",
      "Epoch 32, loss: 2.175716\n",
      "Epoch 33, loss: 2.174760\n",
      "Epoch 34, loss: 2.176806\n",
      "Epoch 35, loss: 2.177012\n",
      "Epoch 36, loss: 2.175866\n",
      "Epoch 37, loss: 2.174485\n",
      "Epoch 38, loss: 2.177587\n",
      "Epoch 39, loss: 2.176685\n",
      "Epoch 40, loss: 2.178906\n",
      "Epoch 41, loss: 2.176000\n",
      "Epoch 42, loss: 2.175019\n",
      "Epoch 43, loss: 2.173190\n",
      "Epoch 44, loss: 2.174683\n",
      "Epoch 45, loss: 2.174772\n",
      "Epoch 46, loss: 2.175615\n",
      "Epoch 47, loss: 2.175740\n",
      "Epoch 48, loss: 2.175332\n",
      "Epoch 49, loss: 2.175391\n",
      "Epoch 50, loss: 2.176697\n",
      "Epoch 51, loss: 2.174553\n",
      "Epoch 52, loss: 2.176781\n",
      "Epoch 53, loss: 2.175340\n",
      "Epoch 54, loss: 2.175892\n",
      "Epoch 55, loss: 2.176069\n",
      "Epoch 56, loss: 2.174241\n",
      "Epoch 57, loss: 2.173944\n",
      "Epoch 58, loss: 2.173774\n",
      "Epoch 59, loss: 2.175365\n",
      "Epoch 60, loss: 2.175609\n",
      "Epoch 61, loss: 2.174361\n",
      "Epoch 62, loss: 2.175629\n",
      "Epoch 63, loss: 2.174512\n",
      "Epoch 64, loss: 2.178586\n",
      "Epoch 65, loss: 2.175013\n",
      "Epoch 66, loss: 2.180248\n",
      "Epoch 67, loss: 2.175088\n",
      "Epoch 68, loss: 2.175264\n",
      "Epoch 69, loss: 2.173796\n",
      "Epoch 70, loss: 2.175699\n",
      "Epoch 71, loss: 2.176379\n",
      "Epoch 72, loss: 2.177084\n",
      "Epoch 73, loss: 2.174012\n",
      "Epoch 74, loss: 2.174910\n",
      "Epoch 75, loss: 2.176938\n",
      "Epoch 76, loss: 2.175710\n",
      "Epoch 77, loss: 2.176649\n",
      "Epoch 78, loss: 2.175542\n",
      "Epoch 79, loss: 2.176978\n",
      "Epoch 80, loss: 2.174875\n",
      "Epoch 81, loss: 2.174450\n",
      "Epoch 82, loss: 2.173818\n",
      "Epoch 83, loss: 2.176742\n",
      "Epoch 84, loss: 2.175430\n",
      "Epoch 85, loss: 2.175605\n",
      "Epoch 86, loss: 2.176452\n",
      "Epoch 87, loss: 2.175176\n",
      "Epoch 88, loss: 2.175434\n",
      "Epoch 89, loss: 2.175438\n",
      "Epoch 90, loss: 2.175524\n",
      "Epoch 91, loss: 2.177082\n",
      "Epoch 92, loss: 2.175730\n",
      "Epoch 93, loss: 2.176076\n",
      "Epoch 94, loss: 2.175976\n",
      "Epoch 95, loss: 2.175136\n",
      "Epoch 96, loss: 2.174514\n",
      "Epoch 97, loss: 2.176507\n",
      "Epoch 98, loss: 2.176182\n",
      "Epoch 99, loss: 2.176725\n",
      "Epoch 100, loss: 2.177905\n",
      "Epoch 101, loss: 2.175785\n",
      "Epoch 102, loss: 2.174213\n",
      "Epoch 103, loss: 2.177235\n",
      "Epoch 104, loss: 2.174012\n",
      "Epoch 105, loss: 2.176504\n",
      "Epoch 106, loss: 2.173810\n",
      "Epoch 107, loss: 2.173969\n",
      "Epoch 108, loss: 2.175308\n",
      "Epoch 109, loss: 2.175641\n",
      "Epoch 110, loss: 2.176381\n",
      "Epoch 111, loss: 2.175553\n",
      "Epoch 112, loss: 2.177351\n",
      "Epoch 113, loss: 2.175156\n",
      "Epoch 114, loss: 2.176067\n",
      "Epoch 115, loss: 2.176563\n",
      "Epoch 116, loss: 2.175717\n",
      "Epoch 117, loss: 2.176300\n",
      "Epoch 118, loss: 2.176171\n",
      "Epoch 119, loss: 2.175541\n",
      "Epoch 120, loss: 2.173806\n",
      "Epoch 121, loss: 2.174363\n",
      "Epoch 122, loss: 2.175086\n",
      "Epoch 123, loss: 2.175068\n",
      "Epoch 124, loss: 2.175784\n",
      "Epoch 125, loss: 2.175509\n",
      "Epoch 126, loss: 2.175311\n",
      "Epoch 127, loss: 2.179798\n",
      "Epoch 128, loss: 2.174148\n",
      "Epoch 129, loss: 2.176466\n",
      "Epoch 130, loss: 2.176177\n",
      "Epoch 131, loss: 2.177372\n",
      "Epoch 132, loss: 2.174263\n",
      "Epoch 133, loss: 2.176595\n",
      "Epoch 134, loss: 2.179343\n",
      "Epoch 135, loss: 2.174543\n",
      "Epoch 136, loss: 2.175365\n",
      "Epoch 137, loss: 2.174421\n",
      "Epoch 138, loss: 2.177505\n",
      "Epoch 139, loss: 2.174194\n",
      "Epoch 140, loss: 2.175391\n",
      "Epoch 141, loss: 2.177504\n",
      "Epoch 142, loss: 2.176969\n",
      "Epoch 143, loss: 2.177836\n",
      "Epoch 144, loss: 2.176447\n",
      "Epoch 145, loss: 2.175960\n",
      "Epoch 146, loss: 2.176728\n",
      "Epoch 147, loss: 2.174475\n",
      "Epoch 148, loss: 2.174300\n",
      "Epoch 149, loss: 2.174719\n",
      "Epoch 150, loss: 2.174880\n",
      "Epoch 151, loss: 2.175450\n",
      "Epoch 152, loss: 2.177796\n",
      "Epoch 153, loss: 2.176806\n",
      "Epoch 154, loss: 2.173364\n",
      "Epoch 155, loss: 2.175659\n",
      "Epoch 156, loss: 2.174305\n",
      "Epoch 157, loss: 2.178168\n",
      "Epoch 158, loss: 2.175177\n",
      "Epoch 159, loss: 2.175620\n",
      "Epoch 160, loss: 2.178754\n",
      "Epoch 161, loss: 2.175532\n",
      "Epoch 162, loss: 2.176093\n",
      "Epoch 163, loss: 2.175290\n",
      "Epoch 164, loss: 2.175185\n",
      "Epoch 165, loss: 2.172287\n",
      "Epoch 166, loss: 2.177827\n",
      "Epoch 167, loss: 2.176643\n",
      "Epoch 168, loss: 2.174196\n",
      "Epoch 169, loss: 2.176656\n",
      "Epoch 170, loss: 2.174431\n",
      "Epoch 171, loss: 2.174392\n",
      "Epoch 172, loss: 2.177143\n",
      "Epoch 173, loss: 2.176405\n",
      "Epoch 174, loss: 2.174074\n",
      "Epoch 175, loss: 2.174654\n",
      "Epoch 176, loss: 2.176481\n",
      "Epoch 177, loss: 2.173568\n",
      "Epoch 178, loss: 2.175131\n",
      "Epoch 179, loss: 2.177521\n",
      "Epoch 180, loss: 2.177509\n",
      "Epoch 181, loss: 2.174189\n",
      "Epoch 182, loss: 2.175776\n",
      "Epoch 183, loss: 2.177696\n",
      "Epoch 184, loss: 2.176365\n",
      "Epoch 185, loss: 2.174844\n",
      "Epoch 186, loss: 2.175702\n",
      "Epoch 187, loss: 2.173589\n",
      "Epoch 188, loss: 2.172926\n",
      "Epoch 189, loss: 2.174255\n",
      "Epoch 190, loss: 2.174597\n",
      "Epoch 191, loss: 2.173633\n",
      "Epoch 192, loss: 2.176896\n",
      "Epoch 193, loss: 2.176706\n",
      "Epoch 194, loss: 2.176482\n",
      "Epoch 195, loss: 2.175304\n",
      "Epoch 196, loss: 2.176405\n",
      "Epoch 197, loss: 2.174494\n",
      "Epoch 198, loss: 2.176337\n",
      "Epoch 199, loss: 2.174579\n",
      "lr: 0.1, rs: 0.01, accuracy 200 epochs: 0.228\n",
      "Epoch 0, loss: 2.282404\n",
      "Epoch 1, loss: 2.233671\n",
      "Epoch 2, loss: 2.209753\n",
      "Epoch 3, loss: 2.190965\n",
      "Epoch 4, loss: 2.178746\n",
      "Epoch 5, loss: 2.173550\n",
      "Epoch 6, loss: 2.162726\n",
      "Epoch 7, loss: 2.167061\n",
      "Epoch 8, loss: 2.151398\n",
      "Epoch 9, loss: 2.149269\n",
      "Epoch 10, loss: 2.145785\n",
      "Epoch 11, loss: 2.142893\n",
      "Epoch 12, loss: 2.140832\n",
      "Epoch 13, loss: 2.138088\n",
      "Epoch 14, loss: 2.133599\n",
      "Epoch 15, loss: 2.131347\n",
      "Epoch 16, loss: 2.129908\n",
      "Epoch 17, loss: 2.128218\n",
      "Epoch 18, loss: 2.126077\n",
      "Epoch 19, loss: 2.123287\n",
      "Epoch 20, loss: 2.121450\n",
      "Epoch 21, loss: 2.118851\n",
      "Epoch 22, loss: 2.120814\n",
      "Epoch 23, loss: 2.119095\n",
      "Epoch 24, loss: 2.119009\n",
      "Epoch 25, loss: 2.117737\n",
      "Epoch 26, loss: 2.114714\n",
      "Epoch 27, loss: 2.116240\n",
      "Epoch 28, loss: 2.111315\n",
      "Epoch 29, loss: 2.112425\n",
      "Epoch 30, loss: 2.108214\n",
      "Epoch 31, loss: 2.107975\n",
      "Epoch 32, loss: 2.108950\n",
      "Epoch 33, loss: 2.108289\n",
      "Epoch 34, loss: 2.106407\n",
      "Epoch 35, loss: 2.109453\n",
      "Epoch 36, loss: 2.107194\n",
      "Epoch 37, loss: 2.105644\n",
      "Epoch 38, loss: 2.102893\n",
      "Epoch 39, loss: 2.106156\n",
      "Epoch 40, loss: 2.101515\n",
      "Epoch 41, loss: 2.102440\n",
      "Epoch 42, loss: 2.101856\n",
      "Epoch 43, loss: 2.102617\n",
      "Epoch 44, loss: 2.102188\n",
      "Epoch 45, loss: 2.101638\n",
      "Epoch 46, loss: 2.098398\n",
      "Epoch 47, loss: 2.096182\n",
      "Epoch 48, loss: 2.099050\n",
      "Epoch 49, loss: 2.098301\n",
      "Epoch 50, loss: 2.098365\n",
      "Epoch 51, loss: 2.098237\n",
      "Epoch 52, loss: 2.098952\n",
      "Epoch 53, loss: 2.096217\n",
      "Epoch 54, loss: 2.095800\n",
      "Epoch 55, loss: 2.097181\n",
      "Epoch 56, loss: 2.095770\n",
      "Epoch 57, loss: 2.094800\n",
      "Epoch 58, loss: 2.094253\n",
      "Epoch 59, loss: 2.094036\n",
      "Epoch 60, loss: 2.092828\n",
      "Epoch 61, loss: 2.094305\n",
      "Epoch 62, loss: 2.096309\n",
      "Epoch 63, loss: 2.092548\n",
      "Epoch 64, loss: 2.095251\n",
      "Epoch 65, loss: 2.093071\n",
      "Epoch 66, loss: 2.094358\n",
      "Epoch 67, loss: 2.091399\n",
      "Epoch 68, loss: 2.089907\n",
      "Epoch 69, loss: 2.090854\n",
      "Epoch 70, loss: 2.090396\n",
      "Epoch 71, loss: 2.094107\n",
      "Epoch 72, loss: 2.088920\n",
      "Epoch 73, loss: 2.088956\n",
      "Epoch 74, loss: 2.095069\n",
      "Epoch 75, loss: 2.088678\n",
      "Epoch 76, loss: 2.088694\n",
      "Epoch 77, loss: 2.089063\n",
      "Epoch 78, loss: 2.090073\n",
      "Epoch 79, loss: 2.088211\n",
      "Epoch 80, loss: 2.089925\n",
      "Epoch 81, loss: 2.088783\n",
      "Epoch 82, loss: 2.087092\n",
      "Epoch 83, loss: 2.087985\n",
      "Epoch 84, loss: 2.087168\n",
      "Epoch 85, loss: 2.085376\n",
      "Epoch 86, loss: 2.084711\n",
      "Epoch 87, loss: 2.087294\n",
      "Epoch 88, loss: 2.083782\n",
      "Epoch 89, loss: 2.087096\n",
      "Epoch 90, loss: 2.087615\n",
      "Epoch 91, loss: 2.085773\n",
      "Epoch 92, loss: 2.088448\n",
      "Epoch 93, loss: 2.084071\n",
      "Epoch 94, loss: 2.084662\n",
      "Epoch 95, loss: 2.086829\n",
      "Epoch 96, loss: 2.083115\n",
      "Epoch 97, loss: 2.083881\n",
      "Epoch 98, loss: 2.083932\n",
      "Epoch 99, loss: 2.085963\n",
      "Epoch 100, loss: 2.083924\n",
      "Epoch 101, loss: 2.084112\n",
      "Epoch 102, loss: 2.083958\n",
      "Epoch 103, loss: 2.087223\n",
      "Epoch 104, loss: 2.083537\n",
      "Epoch 105, loss: 2.084642\n",
      "Epoch 106, loss: 2.085727\n",
      "Epoch 107, loss: 2.081348\n",
      "Epoch 108, loss: 2.083020\n",
      "Epoch 109, loss: 2.082692\n",
      "Epoch 110, loss: 2.081187\n",
      "Epoch 111, loss: 2.080495\n",
      "Epoch 112, loss: 2.081032\n",
      "Epoch 113, loss: 2.082833\n",
      "Epoch 114, loss: 2.079512\n",
      "Epoch 115, loss: 2.083457\n",
      "Epoch 116, loss: 2.082637\n",
      "Epoch 117, loss: 2.081526\n",
      "Epoch 118, loss: 2.082782\n",
      "Epoch 119, loss: 2.083864\n",
      "Epoch 120, loss: 2.081590\n",
      "Epoch 121, loss: 2.080860\n",
      "Epoch 122, loss: 2.080957\n",
      "Epoch 123, loss: 2.082319\n",
      "Epoch 124, loss: 2.081725\n",
      "Epoch 125, loss: 2.082053\n",
      "Epoch 126, loss: 2.077762\n",
      "Epoch 127, loss: 2.084914\n",
      "Epoch 128, loss: 2.083105\n",
      "Epoch 129, loss: 2.081863\n",
      "Epoch 130, loss: 2.080166\n",
      "Epoch 131, loss: 2.082732\n",
      "Epoch 132, loss: 2.079484\n",
      "Epoch 133, loss: 2.079857\n",
      "Epoch 134, loss: 2.080922\n",
      "Epoch 135, loss: 2.082836\n",
      "Epoch 136, loss: 2.080976\n",
      "Epoch 137, loss: 2.077514\n",
      "Epoch 138, loss: 2.080205\n",
      "Epoch 139, loss: 2.086594\n",
      "Epoch 140, loss: 2.081825\n",
      "Epoch 141, loss: 2.080077\n",
      "Epoch 142, loss: 2.079537\n",
      "Epoch 143, loss: 2.081501\n",
      "Epoch 144, loss: 2.077767\n",
      "Epoch 145, loss: 2.078312\n",
      "Epoch 146, loss: 2.077822\n",
      "Epoch 147, loss: 2.079146\n",
      "Epoch 148, loss: 2.078903\n",
      "Epoch 149, loss: 2.076793\n",
      "Epoch 150, loss: 2.079441\n",
      "Epoch 151, loss: 2.078024\n",
      "Epoch 152, loss: 2.079753\n",
      "Epoch 153, loss: 2.080849\n",
      "Epoch 154, loss: 2.078861\n",
      "Epoch 155, loss: 2.083278\n",
      "Epoch 156, loss: 2.078323\n",
      "Epoch 157, loss: 2.079641\n",
      "Epoch 158, loss: 2.079107\n",
      "Epoch 159, loss: 2.081612\n",
      "Epoch 160, loss: 2.077246\n",
      "Epoch 161, loss: 2.080653\n",
      "Epoch 162, loss: 2.078570\n",
      "Epoch 163, loss: 2.079342\n",
      "Epoch 164, loss: 2.075478\n",
      "Epoch 165, loss: 2.078178\n",
      "Epoch 166, loss: 2.077148\n",
      "Epoch 167, loss: 2.078472\n",
      "Epoch 168, loss: 2.077041\n",
      "Epoch 169, loss: 2.078173\n",
      "Epoch 170, loss: 2.078467\n",
      "Epoch 171, loss: 2.077498\n",
      "Epoch 172, loss: 2.079242\n",
      "Epoch 173, loss: 2.077959\n",
      "Epoch 174, loss: 2.078244\n",
      "Epoch 175, loss: 2.081635\n",
      "Epoch 176, loss: 2.076146\n",
      "Epoch 177, loss: 2.078052\n",
      "Epoch 178, loss: 2.076232\n",
      "Epoch 179, loss: 2.077047\n",
      "Epoch 180, loss: 2.076875\n",
      "Epoch 181, loss: 2.078957\n",
      "Epoch 182, loss: 2.075905\n",
      "Epoch 183, loss: 2.076339\n",
      "Epoch 184, loss: 2.078178\n",
      "Epoch 185, loss: 2.076506\n",
      "Epoch 186, loss: 2.079364\n",
      "Epoch 187, loss: 2.082476\n",
      "Epoch 188, loss: 2.081234\n",
      "Epoch 189, loss: 2.077322\n",
      "Epoch 190, loss: 2.076631\n",
      "Epoch 191, loss: 2.076451\n",
      "Epoch 192, loss: 2.077474\n",
      "Epoch 193, loss: 2.078583\n",
      "Epoch 194, loss: 2.075854\n",
      "Epoch 195, loss: 2.080697\n",
      "Epoch 196, loss: 2.076867\n",
      "Epoch 197, loss: 2.077580\n",
      "Epoch 198, loss: 2.077338\n",
      "Epoch 199, loss: 2.077400\n",
      "lr: 0.1, rs: 0.001, accuracy 200 epochs: 0.239\n",
      "Epoch 0, loss: 2.285365\n",
      "Epoch 1, loss: 2.237070\n",
      "Epoch 2, loss: 2.208510\n",
      "Epoch 3, loss: 2.188551\n",
      "Epoch 4, loss: 2.174711\n",
      "Epoch 5, loss: 2.168320\n",
      "Epoch 6, loss: 2.158960\n",
      "Epoch 7, loss: 2.151107\n",
      "Epoch 8, loss: 2.151266\n",
      "Epoch 9, loss: 2.144553\n",
      "Epoch 10, loss: 2.138273\n",
      "Epoch 11, loss: 2.136190\n",
      "Epoch 12, loss: 2.135898\n",
      "Epoch 13, loss: 2.129771\n",
      "Epoch 14, loss: 2.126101\n",
      "Epoch 15, loss: 2.124423\n",
      "Epoch 16, loss: 2.124689\n",
      "Epoch 17, loss: 2.121383\n",
      "Epoch 18, loss: 2.115982\n",
      "Epoch 19, loss: 2.116469\n",
      "Epoch 20, loss: 2.114893\n",
      "Epoch 21, loss: 2.110029\n",
      "Epoch 22, loss: 2.109078\n",
      "Epoch 23, loss: 2.111938\n",
      "Epoch 24, loss: 2.108919\n",
      "Epoch 25, loss: 2.103850\n",
      "Epoch 26, loss: 2.103344\n",
      "Epoch 27, loss: 2.104362\n",
      "Epoch 28, loss: 2.103490\n",
      "Epoch 29, loss: 2.102118\n",
      "Epoch 30, loss: 2.102940\n",
      "Epoch 31, loss: 2.098011\n",
      "Epoch 32, loss: 2.094393\n",
      "Epoch 33, loss: 2.096730\n",
      "Epoch 34, loss: 2.092740\n",
      "Epoch 35, loss: 2.092639\n",
      "Epoch 36, loss: 2.092842\n",
      "Epoch 37, loss: 2.089673\n",
      "Epoch 38, loss: 2.092636\n",
      "Epoch 39, loss: 2.085932\n",
      "Epoch 40, loss: 2.089604\n",
      "Epoch 41, loss: 2.084163\n",
      "Epoch 42, loss: 2.086402\n",
      "Epoch 43, loss: 2.085196\n",
      "Epoch 44, loss: 2.081989\n",
      "Epoch 45, loss: 2.084155\n",
      "Epoch 46, loss: 2.079696\n",
      "Epoch 47, loss: 2.081986\n",
      "Epoch 48, loss: 2.083406\n",
      "Epoch 49, loss: 2.078848\n",
      "Epoch 50, loss: 2.077505\n",
      "Epoch 51, loss: 2.077831\n",
      "Epoch 52, loss: 2.076570\n",
      "Epoch 53, loss: 2.076172\n",
      "Epoch 54, loss: 2.075704\n",
      "Epoch 55, loss: 2.074411\n",
      "Epoch 56, loss: 2.074958\n",
      "Epoch 57, loss: 2.072054\n",
      "Epoch 58, loss: 2.073474\n",
      "Epoch 59, loss: 2.070140\n",
      "Epoch 60, loss: 2.069521\n",
      "Epoch 61, loss: 2.070169\n",
      "Epoch 62, loss: 2.071721\n",
      "Epoch 63, loss: 2.068775\n",
      "Epoch 64, loss: 2.068095\n",
      "Epoch 65, loss: 2.068986\n",
      "Epoch 66, loss: 2.065114\n",
      "Epoch 67, loss: 2.066697\n",
      "Epoch 68, loss: 2.065428\n",
      "Epoch 69, loss: 2.066935\n",
      "Epoch 70, loss: 2.066645\n",
      "Epoch 71, loss: 2.064769\n",
      "Epoch 72, loss: 2.064752\n",
      "Epoch 73, loss: 2.062043\n",
      "Epoch 74, loss: 2.064251\n",
      "Epoch 75, loss: 2.060863\n",
      "Epoch 76, loss: 2.060079\n",
      "Epoch 77, loss: 2.058645\n",
      "Epoch 78, loss: 2.060248\n",
      "Epoch 79, loss: 2.059494\n",
      "Epoch 80, loss: 2.060779\n",
      "Epoch 81, loss: 2.058066\n",
      "Epoch 82, loss: 2.056135\n",
      "Epoch 83, loss: 2.057443\n",
      "Epoch 84, loss: 2.056031\n",
      "Epoch 85, loss: 2.057056\n",
      "Epoch 86, loss: 2.055971\n",
      "Epoch 87, loss: 2.057158\n",
      "Epoch 88, loss: 2.058216\n",
      "Epoch 89, loss: 2.054341\n",
      "Epoch 90, loss: 2.054465\n",
      "Epoch 91, loss: 2.054100\n",
      "Epoch 92, loss: 2.053242\n",
      "Epoch 93, loss: 2.051277\n",
      "Epoch 94, loss: 2.052154\n",
      "Epoch 95, loss: 2.048438\n",
      "Epoch 96, loss: 2.050880\n",
      "Epoch 97, loss: 2.051193\n",
      "Epoch 98, loss: 2.050345\n",
      "Epoch 99, loss: 2.047753\n",
      "Epoch 100, loss: 2.051104\n",
      "Epoch 101, loss: 2.049987\n",
      "Epoch 102, loss: 2.049230\n",
      "Epoch 103, loss: 2.049403\n",
      "Epoch 104, loss: 2.046588\n",
      "Epoch 105, loss: 2.046079\n",
      "Epoch 106, loss: 2.044217\n",
      "Epoch 107, loss: 2.047397\n",
      "Epoch 108, loss: 2.046785\n",
      "Epoch 109, loss: 2.043996\n",
      "Epoch 110, loss: 2.046074\n",
      "Epoch 111, loss: 2.042826\n",
      "Epoch 112, loss: 2.045738\n",
      "Epoch 113, loss: 2.043459\n",
      "Epoch 114, loss: 2.040993\n",
      "Epoch 115, loss: 2.042730\n",
      "Epoch 116, loss: 2.043113\n",
      "Epoch 117, loss: 2.040845\n",
      "Epoch 118, loss: 2.042289\n",
      "Epoch 119, loss: 2.040498\n",
      "Epoch 120, loss: 2.042215\n",
      "Epoch 121, loss: 2.038130\n",
      "Epoch 122, loss: 2.037348\n",
      "Epoch 123, loss: 2.038015\n",
      "Epoch 124, loss: 2.040946\n",
      "Epoch 125, loss: 2.037987\n",
      "Epoch 126, loss: 2.039151\n",
      "Epoch 127, loss: 2.039397\n",
      "Epoch 128, loss: 2.038022\n",
      "Epoch 129, loss: 2.036594\n",
      "Epoch 130, loss: 2.036564\n",
      "Epoch 131, loss: 2.034880\n",
      "Epoch 132, loss: 2.036936\n",
      "Epoch 133, loss: 2.035902\n",
      "Epoch 134, loss: 2.036570\n",
      "Epoch 135, loss: 2.034935\n",
      "Epoch 136, loss: 2.035647\n",
      "Epoch 137, loss: 2.037179\n",
      "Epoch 138, loss: 2.038837\n",
      "Epoch 139, loss: 2.037731\n",
      "Epoch 140, loss: 2.032864\n",
      "Epoch 141, loss: 2.033020\n",
      "Epoch 142, loss: 2.034170\n",
      "Epoch 143, loss: 2.033309\n",
      "Epoch 144, loss: 2.033346\n",
      "Epoch 145, loss: 2.033840\n",
      "Epoch 146, loss: 2.031038\n",
      "Epoch 147, loss: 2.032098\n",
      "Epoch 148, loss: 2.029663\n",
      "Epoch 149, loss: 2.030964\n",
      "Epoch 150, loss: 2.030487\n",
      "Epoch 151, loss: 2.030837\n",
      "Epoch 152, loss: 2.029280\n",
      "Epoch 153, loss: 2.029751\n",
      "Epoch 154, loss: 2.029900\n",
      "Epoch 155, loss: 2.030793\n",
      "Epoch 156, loss: 2.031014\n",
      "Epoch 157, loss: 2.027874\n",
      "Epoch 158, loss: 2.026213\n",
      "Epoch 159, loss: 2.030822\n",
      "Epoch 160, loss: 2.029870\n",
      "Epoch 161, loss: 2.028256\n",
      "Epoch 162, loss: 2.027086\n",
      "Epoch 163, loss: 2.029704\n",
      "Epoch 164, loss: 2.029585\n",
      "Epoch 165, loss: 2.025375\n",
      "Epoch 166, loss: 2.025267\n",
      "Epoch 167, loss: 2.024520\n",
      "Epoch 168, loss: 2.024976\n",
      "Epoch 169, loss: 2.025736\n",
      "Epoch 170, loss: 2.026978\n",
      "Epoch 171, loss: 2.025220\n",
      "Epoch 172, loss: 2.022520\n",
      "Epoch 173, loss: 2.024389\n",
      "Epoch 174, loss: 2.021974\n",
      "Epoch 175, loss: 2.021523\n",
      "Epoch 176, loss: 2.023284\n",
      "Epoch 177, loss: 2.023338\n",
      "Epoch 178, loss: 2.021391\n",
      "Epoch 179, loss: 2.019867\n",
      "Epoch 180, loss: 2.023630\n",
      "Epoch 181, loss: 2.020813\n",
      "Epoch 182, loss: 2.024075\n",
      "Epoch 183, loss: 2.020102\n",
      "Epoch 184, loss: 2.022303\n",
      "Epoch 185, loss: 2.018598\n",
      "Epoch 186, loss: 2.017847\n",
      "Epoch 187, loss: 2.020635\n",
      "Epoch 188, loss: 2.019061\n",
      "Epoch 189, loss: 2.018752\n",
      "Epoch 190, loss: 2.019900\n",
      "Epoch 191, loss: 2.019476\n",
      "Epoch 192, loss: 2.021923\n",
      "Epoch 193, loss: 2.019349\n",
      "Epoch 194, loss: 2.019557\n",
      "Epoch 195, loss: 2.019133\n",
      "Epoch 196, loss: 2.018696\n",
      "Epoch 197, loss: 2.018372\n",
      "Epoch 198, loss: 2.016430\n",
      "Epoch 199, loss: 2.018743\n",
      "lr: 0.1, rs: 0.0001, accuracy 200 epochs: 0.246\n",
      "Epoch 0, loss: 2.280275\n",
      "Epoch 1, loss: 2.235151\n",
      "Epoch 2, loss: 2.205087\n",
      "Epoch 3, loss: 2.189541\n",
      "Epoch 4, loss: 2.173837\n",
      "Epoch 5, loss: 2.164330\n",
      "Epoch 6, loss: 2.163736\n",
      "Epoch 7, loss: 2.153711\n",
      "Epoch 8, loss: 2.151791\n",
      "Epoch 9, loss: 2.144007\n",
      "Epoch 10, loss: 2.140364\n",
      "Epoch 11, loss: 2.136119\n",
      "Epoch 12, loss: 2.132668\n",
      "Epoch 13, loss: 2.130571\n",
      "Epoch 14, loss: 2.128465\n",
      "Epoch 15, loss: 2.123005\n",
      "Epoch 16, loss: 2.121583\n",
      "Epoch 17, loss: 2.117624\n",
      "Epoch 18, loss: 2.115124\n",
      "Epoch 19, loss: 2.116142\n",
      "Epoch 20, loss: 2.113521\n",
      "Epoch 21, loss: 2.112866\n",
      "Epoch 22, loss: 2.108955\n",
      "Epoch 23, loss: 2.106907\n",
      "Epoch 24, loss: 2.105747\n",
      "Epoch 25, loss: 2.105441\n",
      "Epoch 26, loss: 2.100699\n",
      "Epoch 27, loss: 2.103456\n",
      "Epoch 28, loss: 2.100506\n",
      "Epoch 29, loss: 2.098764\n",
      "Epoch 30, loss: 2.096331\n",
      "Epoch 31, loss: 2.096213\n",
      "Epoch 32, loss: 2.094883\n",
      "Epoch 33, loss: 2.093576\n",
      "Epoch 34, loss: 2.092149\n",
      "Epoch 35, loss: 2.090195\n",
      "Epoch 36, loss: 2.088838\n",
      "Epoch 37, loss: 2.087302\n",
      "Epoch 38, loss: 2.088697\n",
      "Epoch 39, loss: 2.087145\n",
      "Epoch 40, loss: 2.087141\n",
      "Epoch 41, loss: 2.084087\n",
      "Epoch 42, loss: 2.085303\n",
      "Epoch 43, loss: 2.082645\n",
      "Epoch 44, loss: 2.082754\n",
      "Epoch 45, loss: 2.079420\n",
      "Epoch 46, loss: 2.078073\n",
      "Epoch 47, loss: 2.078636\n",
      "Epoch 48, loss: 2.079368\n",
      "Epoch 49, loss: 2.075995\n",
      "Epoch 50, loss: 2.073666\n",
      "Epoch 51, loss: 2.074639\n",
      "Epoch 52, loss: 2.072404\n",
      "Epoch 53, loss: 2.074553\n",
      "Epoch 54, loss: 2.073486\n",
      "Epoch 55, loss: 2.074076\n",
      "Epoch 56, loss: 2.073113\n",
      "Epoch 57, loss: 2.070684\n",
      "Epoch 58, loss: 2.069559\n",
      "Epoch 59, loss: 2.067948\n",
      "Epoch 60, loss: 2.067857\n",
      "Epoch 61, loss: 2.067148\n",
      "Epoch 62, loss: 2.067387\n",
      "Epoch 63, loss: 2.067340\n",
      "Epoch 64, loss: 2.064510\n",
      "Epoch 65, loss: 2.064743\n",
      "Epoch 66, loss: 2.063769\n",
      "Epoch 67, loss: 2.061764\n",
      "Epoch 68, loss: 2.062489\n",
      "Epoch 69, loss: 2.061526\n",
      "Epoch 70, loss: 2.060220\n",
      "Epoch 71, loss: 2.059962\n",
      "Epoch 72, loss: 2.060230\n",
      "Epoch 73, loss: 2.061025\n",
      "Epoch 74, loss: 2.055940\n",
      "Epoch 75, loss: 2.058769\n",
      "Epoch 76, loss: 2.060025\n",
      "Epoch 77, loss: 2.059442\n",
      "Epoch 78, loss: 2.056106\n",
      "Epoch 79, loss: 2.053835\n",
      "Epoch 80, loss: 2.056196\n",
      "Epoch 81, loss: 2.057780\n",
      "Epoch 82, loss: 2.053331\n",
      "Epoch 83, loss: 2.056210\n",
      "Epoch 84, loss: 2.054255\n",
      "Epoch 85, loss: 2.051435\n",
      "Epoch 86, loss: 2.052126\n",
      "Epoch 87, loss: 2.050736\n",
      "Epoch 88, loss: 2.052986\n",
      "Epoch 89, loss: 2.048806\n",
      "Epoch 90, loss: 2.048191\n",
      "Epoch 91, loss: 2.049526\n",
      "Epoch 92, loss: 2.048267\n",
      "Epoch 93, loss: 2.044175\n",
      "Epoch 94, loss: 2.045485\n",
      "Epoch 95, loss: 2.047707\n",
      "Epoch 96, loss: 2.049192\n",
      "Epoch 97, loss: 2.043087\n",
      "Epoch 98, loss: 2.044385\n",
      "Epoch 99, loss: 2.043555\n",
      "Epoch 100, loss: 2.042972\n",
      "Epoch 101, loss: 2.046131\n",
      "Epoch 102, loss: 2.041658\n",
      "Epoch 103, loss: 2.045141\n",
      "Epoch 104, loss: 2.042942\n",
      "Epoch 105, loss: 2.038777\n",
      "Epoch 106, loss: 2.041360\n",
      "Epoch 107, loss: 2.040317\n",
      "Epoch 108, loss: 2.040636\n",
      "Epoch 109, loss: 2.038995\n",
      "Epoch 110, loss: 2.040810\n",
      "Epoch 111, loss: 2.040322\n",
      "Epoch 112, loss: 2.040568\n",
      "Epoch 113, loss: 2.038253\n",
      "Epoch 114, loss: 2.037800\n",
      "Epoch 115, loss: 2.034933\n",
      "Epoch 116, loss: 2.035836\n",
      "Epoch 117, loss: 2.034259\n",
      "Epoch 118, loss: 2.038187\n",
      "Epoch 119, loss: 2.036217\n",
      "Epoch 120, loss: 2.034612\n",
      "Epoch 121, loss: 2.035112\n",
      "Epoch 122, loss: 2.035447\n",
      "Epoch 123, loss: 2.033858\n",
      "Epoch 124, loss: 2.032926\n",
      "Epoch 125, loss: 2.035367\n",
      "Epoch 126, loss: 2.031302\n",
      "Epoch 127, loss: 2.033177\n",
      "Epoch 128, loss: 2.030560\n",
      "Epoch 129, loss: 2.031980\n",
      "Epoch 130, loss: 2.030085\n",
      "Epoch 131, loss: 2.031600\n",
      "Epoch 132, loss: 2.031926\n",
      "Epoch 133, loss: 2.031304\n",
      "Epoch 134, loss: 2.028230\n",
      "Epoch 135, loss: 2.030704\n",
      "Epoch 136, loss: 2.029294\n",
      "Epoch 137, loss: 2.030206\n",
      "Epoch 138, loss: 2.028639\n",
      "Epoch 139, loss: 2.027423\n",
      "Epoch 140, loss: 2.026688\n",
      "Epoch 141, loss: 2.029003\n",
      "Epoch 142, loss: 2.028873\n",
      "Epoch 143, loss: 2.025572\n",
      "Epoch 144, loss: 2.025188\n",
      "Epoch 145, loss: 2.026240\n",
      "Epoch 146, loss: 2.027408\n",
      "Epoch 147, loss: 2.027308\n",
      "Epoch 148, loss: 2.027320\n",
      "Epoch 149, loss: 2.026695\n",
      "Epoch 150, loss: 2.022289\n",
      "Epoch 151, loss: 2.020904\n",
      "Epoch 152, loss: 2.021890\n",
      "Epoch 153, loss: 2.021888\n",
      "Epoch 154, loss: 2.023756\n",
      "Epoch 155, loss: 2.022401\n",
      "Epoch 156, loss: 2.020193\n",
      "Epoch 157, loss: 2.020894\n",
      "Epoch 158, loss: 2.020508\n",
      "Epoch 159, loss: 2.020907\n",
      "Epoch 160, loss: 2.018793\n",
      "Epoch 161, loss: 2.020027\n",
      "Epoch 162, loss: 2.016205\n",
      "Epoch 163, loss: 2.019732\n",
      "Epoch 164, loss: 2.019190\n",
      "Epoch 165, loss: 2.017548\n",
      "Epoch 166, loss: 2.017228\n",
      "Epoch 167, loss: 2.015556\n",
      "Epoch 168, loss: 2.017760\n",
      "Epoch 169, loss: 2.017389\n",
      "Epoch 170, loss: 2.014371\n",
      "Epoch 171, loss: 2.018163\n",
      "Epoch 172, loss: 2.020249\n",
      "Epoch 173, loss: 2.016189\n",
      "Epoch 174, loss: 2.015322\n",
      "Epoch 175, loss: 2.015177\n",
      "Epoch 176, loss: 2.013440\n",
      "Epoch 177, loss: 2.015310\n",
      "Epoch 178, loss: 2.013265\n",
      "Epoch 179, loss: 2.011192\n",
      "Epoch 180, loss: 2.012445\n",
      "Epoch 181, loss: 2.013651\n",
      "Epoch 182, loss: 2.016531\n",
      "Epoch 183, loss: 2.011910\n",
      "Epoch 184, loss: 2.012283\n",
      "Epoch 185, loss: 2.010356\n",
      "Epoch 186, loss: 2.013626\n",
      "Epoch 187, loss: 2.008487\n",
      "Epoch 188, loss: 2.012922\n",
      "Epoch 189, loss: 2.010748\n",
      "Epoch 190, loss: 2.011528\n",
      "Epoch 191, loss: 2.010885\n",
      "Epoch 192, loss: 2.008841\n",
      "Epoch 193, loss: 2.008524\n",
      "Epoch 194, loss: 2.010373\n",
      "Epoch 195, loss: 2.008228\n",
      "Epoch 196, loss: 2.005883\n",
      "Epoch 197, loss: 2.005882\n",
      "Epoch 198, loss: 2.006948\n",
      "Epoch 199, loss: 2.009141\n",
      "lr: 0.1, rs: 1e-05, accuracy 200 epochs: 0.242\n",
      "Epoch 0, loss: 2.282812\n",
      "Epoch 1, loss: 2.233213\n",
      "Epoch 2, loss: 2.206444\n",
      "Epoch 3, loss: 2.189943\n",
      "Epoch 4, loss: 2.176142\n",
      "Epoch 5, loss: 2.165885\n",
      "Epoch 6, loss: 2.162465\n",
      "Epoch 7, loss: 2.153312\n",
      "Epoch 8, loss: 2.150412\n",
      "Epoch 9, loss: 2.145475\n",
      "Epoch 10, loss: 2.140208\n",
      "Epoch 11, loss: 2.133973\n",
      "Epoch 12, loss: 2.132125\n",
      "Epoch 13, loss: 2.130861\n",
      "Epoch 14, loss: 2.124194\n",
      "Epoch 15, loss: 2.122540\n",
      "Epoch 16, loss: 2.119872\n",
      "Epoch 17, loss: 2.121447\n",
      "Epoch 18, loss: 2.115804\n",
      "Epoch 19, loss: 2.112576\n",
      "Epoch 20, loss: 2.113606\n",
      "Epoch 21, loss: 2.111010\n",
      "Epoch 22, loss: 2.107486\n",
      "Epoch 23, loss: 2.110513\n",
      "Epoch 24, loss: 2.105910\n",
      "Epoch 25, loss: 2.106367\n",
      "Epoch 26, loss: 2.103818\n",
      "Epoch 27, loss: 2.106168\n",
      "Epoch 28, loss: 2.098603\n",
      "Epoch 29, loss: 2.096252\n",
      "Epoch 30, loss: 2.096416\n",
      "Epoch 31, loss: 2.097447\n",
      "Epoch 32, loss: 2.095781\n",
      "Epoch 33, loss: 2.091508\n",
      "Epoch 34, loss: 2.090974\n",
      "Epoch 35, loss: 2.092101\n",
      "Epoch 36, loss: 2.090127\n",
      "Epoch 37, loss: 2.087294\n",
      "Epoch 38, loss: 2.088734\n",
      "Epoch 39, loss: 2.087594\n",
      "Epoch 40, loss: 2.083079\n",
      "Epoch 41, loss: 2.083650\n",
      "Epoch 42, loss: 2.081464\n",
      "Epoch 43, loss: 2.083733\n",
      "Epoch 44, loss: 2.084752\n",
      "Epoch 45, loss: 2.080393\n",
      "Epoch 46, loss: 2.079668\n",
      "Epoch 47, loss: 2.078288\n",
      "Epoch 48, loss: 2.077485\n",
      "Epoch 49, loss: 2.080150\n",
      "Epoch 50, loss: 2.075053\n",
      "Epoch 51, loss: 2.074397\n",
      "Epoch 52, loss: 2.075145\n",
      "Epoch 53, loss: 2.073786\n",
      "Epoch 54, loss: 2.071163\n",
      "Epoch 55, loss: 2.071418\n",
      "Epoch 56, loss: 2.069808\n",
      "Epoch 57, loss: 2.069738\n",
      "Epoch 58, loss: 2.069664\n",
      "Epoch 59, loss: 2.070487\n",
      "Epoch 60, loss: 2.067965\n",
      "Epoch 61, loss: 2.068086\n",
      "Epoch 62, loss: 2.065780\n",
      "Epoch 63, loss: 2.064144\n",
      "Epoch 64, loss: 2.065923\n",
      "Epoch 65, loss: 2.061542\n",
      "Epoch 66, loss: 2.062442\n",
      "Epoch 67, loss: 2.062306\n",
      "Epoch 68, loss: 2.060970\n",
      "Epoch 69, loss: 2.062999\n",
      "Epoch 70, loss: 2.061939\n",
      "Epoch 71, loss: 2.061097\n",
      "Epoch 72, loss: 2.057957\n",
      "Epoch 73, loss: 2.060015\n",
      "Epoch 74, loss: 2.058437\n",
      "Epoch 75, loss: 2.058439\n",
      "Epoch 76, loss: 2.054887\n",
      "Epoch 77, loss: 2.056680\n",
      "Epoch 78, loss: 2.055625\n",
      "Epoch 79, loss: 2.053636\n",
      "Epoch 80, loss: 2.055639\n",
      "Epoch 81, loss: 2.055395\n",
      "Epoch 82, loss: 2.053558\n",
      "Epoch 83, loss: 2.051326\n",
      "Epoch 84, loss: 2.051580\n",
      "Epoch 85, loss: 2.049585\n",
      "Epoch 86, loss: 2.049522\n",
      "Epoch 87, loss: 2.050722\n",
      "Epoch 88, loss: 2.051383\n",
      "Epoch 89, loss: 2.049856\n",
      "Epoch 90, loss: 2.047623\n",
      "Epoch 91, loss: 2.048230\n",
      "Epoch 92, loss: 2.050324\n",
      "Epoch 93, loss: 2.048946\n",
      "Epoch 94, loss: 2.045527\n",
      "Epoch 95, loss: 2.045008\n",
      "Epoch 96, loss: 2.048578\n",
      "Epoch 97, loss: 2.045020\n",
      "Epoch 98, loss: 2.044188\n",
      "Epoch 99, loss: 2.046083\n",
      "Epoch 100, loss: 2.044282\n",
      "Epoch 101, loss: 2.043302\n",
      "Epoch 102, loss: 2.040899\n",
      "Epoch 103, loss: 2.041848\n",
      "Epoch 104, loss: 2.040699\n",
      "Epoch 105, loss: 2.041833\n",
      "Epoch 106, loss: 2.041935\n",
      "Epoch 107, loss: 2.042867\n",
      "Epoch 108, loss: 2.037991\n",
      "Epoch 109, loss: 2.039904\n",
      "Epoch 110, loss: 2.039312\n",
      "Epoch 111, loss: 2.038200\n",
      "Epoch 112, loss: 2.038929\n",
      "Epoch 113, loss: 2.037128\n",
      "Epoch 114, loss: 2.040286\n",
      "Epoch 115, loss: 2.040708\n",
      "Epoch 116, loss: 2.036446\n",
      "Epoch 117, loss: 2.036734\n",
      "Epoch 118, loss: 2.034378\n",
      "Epoch 119, loss: 2.038537\n",
      "Epoch 120, loss: 2.032774\n",
      "Epoch 121, loss: 2.033657\n",
      "Epoch 122, loss: 2.033909\n",
      "Epoch 123, loss: 2.035592\n",
      "Epoch 124, loss: 2.033255\n",
      "Epoch 125, loss: 2.030868\n",
      "Epoch 126, loss: 2.030681\n",
      "Epoch 127, loss: 2.032738\n",
      "Epoch 128, loss: 2.034770\n",
      "Epoch 129, loss: 2.029233\n",
      "Epoch 130, loss: 2.030257\n",
      "Epoch 131, loss: 2.030703\n",
      "Epoch 132, loss: 2.026330\n",
      "Epoch 133, loss: 2.028180\n",
      "Epoch 134, loss: 2.028291\n",
      "Epoch 135, loss: 2.029118\n",
      "Epoch 136, loss: 2.030144\n",
      "Epoch 137, loss: 2.026636\n",
      "Epoch 138, loss: 2.028502\n",
      "Epoch 139, loss: 2.027843\n",
      "Epoch 140, loss: 2.025909\n",
      "Epoch 141, loss: 2.025577\n",
      "Epoch 142, loss: 2.026568\n",
      "Epoch 143, loss: 2.024501\n",
      "Epoch 144, loss: 2.023983\n",
      "Epoch 145, loss: 2.023394\n",
      "Epoch 146, loss: 2.025794\n",
      "Epoch 147, loss: 2.022912\n",
      "Epoch 148, loss: 2.026893\n",
      "Epoch 149, loss: 2.022748\n",
      "Epoch 150, loss: 2.024809\n",
      "Epoch 151, loss: 2.021804\n",
      "Epoch 152, loss: 2.023181\n",
      "Epoch 153, loss: 2.021033\n",
      "Epoch 154, loss: 2.021734\n",
      "Epoch 155, loss: 2.021584\n",
      "Epoch 156, loss: 2.018280\n",
      "Epoch 157, loss: 2.019176\n",
      "Epoch 158, loss: 2.020638\n",
      "Epoch 159, loss: 2.018189\n",
      "Epoch 160, loss: 2.020173\n",
      "Epoch 161, loss: 2.017237\n",
      "Epoch 162, loss: 2.019056\n",
      "Epoch 163, loss: 2.018200\n",
      "Epoch 164, loss: 2.015694\n",
      "Epoch 165, loss: 2.017711\n",
      "Epoch 166, loss: 2.014995\n",
      "Epoch 167, loss: 2.020289\n",
      "Epoch 168, loss: 2.016531\n",
      "Epoch 169, loss: 2.019764\n",
      "Epoch 170, loss: 2.015505\n",
      "Epoch 171, loss: 2.014741\n",
      "Epoch 172, loss: 2.013021\n",
      "Epoch 173, loss: 2.015669\n",
      "Epoch 174, loss: 2.014400\n",
      "Epoch 175, loss: 2.012015\n",
      "Epoch 176, loss: 2.013196\n",
      "Epoch 177, loss: 2.014720\n",
      "Epoch 178, loss: 2.014351\n",
      "Epoch 179, loss: 2.011211\n",
      "Epoch 180, loss: 2.017115\n",
      "Epoch 181, loss: 2.011683\n",
      "Epoch 182, loss: 2.011203\n",
      "Epoch 183, loss: 2.013510\n",
      "Epoch 184, loss: 2.011810\n",
      "Epoch 185, loss: 2.011427\n",
      "Epoch 186, loss: 2.011069\n",
      "Epoch 187, loss: 2.010429\n",
      "Epoch 188, loss: 2.012917\n",
      "Epoch 189, loss: 2.009468\n",
      "Epoch 190, loss: 2.008358\n",
      "Epoch 191, loss: 2.008215\n",
      "Epoch 192, loss: 2.012889\n",
      "Epoch 193, loss: 2.010836\n",
      "Epoch 194, loss: 2.007033\n",
      "Epoch 195, loss: 2.005739\n",
      "Epoch 196, loss: 2.007080\n",
      "Epoch 197, loss: 2.007247\n",
      "Epoch 198, loss: 2.009546\n",
      "Epoch 199, loss: 2.005719\n",
      "lr: 0.1, rs: 1e-06, accuracy 200 epochs: 0.248\n",
      "Epoch 0, loss: 2.302450\n",
      "Epoch 1, loss: 2.294662\n",
      "Epoch 2, loss: 2.288335\n",
      "Epoch 3, loss: 2.282939\n",
      "Epoch 4, loss: 2.278293\n",
      "Epoch 5, loss: 2.274918\n",
      "Epoch 6, loss: 2.271606\n",
      "Epoch 7, loss: 2.269070\n",
      "Epoch 8, loss: 2.266863\n",
      "Epoch 9, loss: 2.265478\n",
      "Epoch 10, loss: 2.263745\n",
      "Epoch 11, loss: 2.262336\n",
      "Epoch 12, loss: 2.261353\n",
      "Epoch 13, loss: 2.260300\n",
      "Epoch 14, loss: 2.259531\n",
      "Epoch 15, loss: 2.258700\n",
      "Epoch 16, loss: 2.258417\n",
      "Epoch 17, loss: 2.257948\n",
      "Epoch 18, loss: 2.257379\n",
      "Epoch 19, loss: 2.257079\n",
      "Epoch 20, loss: 2.256927\n",
      "Epoch 21, loss: 2.256403\n",
      "Epoch 22, loss: 2.256342\n",
      "Epoch 23, loss: 2.256264\n",
      "Epoch 24, loss: 2.256096\n",
      "Epoch 25, loss: 2.255776\n",
      "Epoch 26, loss: 2.255687\n",
      "Epoch 27, loss: 2.255784\n",
      "Epoch 28, loss: 2.255747\n",
      "Epoch 29, loss: 2.255676\n",
      "Epoch 30, loss: 2.255512\n",
      "Epoch 31, loss: 2.255463\n",
      "Epoch 32, loss: 2.255500\n",
      "Epoch 33, loss: 2.255514\n",
      "Epoch 34, loss: 2.255413\n",
      "Epoch 35, loss: 2.255417\n",
      "Epoch 36, loss: 2.255312\n",
      "Epoch 37, loss: 2.255178\n",
      "Epoch 38, loss: 2.255380\n",
      "Epoch 39, loss: 2.255303\n",
      "Epoch 40, loss: 2.255275\n",
      "Epoch 41, loss: 2.255496\n",
      "Epoch 42, loss: 2.255163\n",
      "Epoch 43, loss: 2.255040\n",
      "Epoch 44, loss: 2.255104\n",
      "Epoch 45, loss: 2.255172\n",
      "Epoch 46, loss: 2.255180\n",
      "Epoch 47, loss: 2.255337\n",
      "Epoch 48, loss: 2.255222\n",
      "Epoch 49, loss: 2.255439\n",
      "Epoch 50, loss: 2.255174\n",
      "Epoch 51, loss: 2.255360\n",
      "Epoch 52, loss: 2.255233\n",
      "Epoch 53, loss: 2.255105\n",
      "Epoch 54, loss: 2.255198\n",
      "Epoch 55, loss: 2.255230\n",
      "Epoch 56, loss: 2.255195\n",
      "Epoch 57, loss: 2.255211\n",
      "Epoch 58, loss: 2.255275\n",
      "Epoch 59, loss: 2.255108\n",
      "Epoch 60, loss: 2.255144\n",
      "Epoch 61, loss: 2.255223\n",
      "Epoch 62, loss: 2.255177\n",
      "Epoch 63, loss: 2.255071\n",
      "Epoch 64, loss: 2.255147\n",
      "Epoch 65, loss: 2.255166\n",
      "Epoch 66, loss: 2.255028\n",
      "Epoch 67, loss: 2.255206\n",
      "Epoch 68, loss: 2.255057\n",
      "Epoch 69, loss: 2.255159\n",
      "Epoch 70, loss: 2.255286\n",
      "Epoch 71, loss: 2.255219\n",
      "Epoch 72, loss: 2.255110\n",
      "Epoch 73, loss: 2.255109\n",
      "Epoch 74, loss: 2.255076\n",
      "Epoch 75, loss: 2.254932\n",
      "Epoch 76, loss: 2.255168\n",
      "Epoch 77, loss: 2.255179\n",
      "Epoch 78, loss: 2.255223\n",
      "Epoch 79, loss: 2.255059\n",
      "Epoch 80, loss: 2.255297\n",
      "Epoch 81, loss: 2.255376\n",
      "Epoch 82, loss: 2.255052\n",
      "Epoch 83, loss: 2.255228\n",
      "Epoch 84, loss: 2.255040\n",
      "Epoch 85, loss: 2.255162\n",
      "Epoch 86, loss: 2.255212\n",
      "Epoch 87, loss: 2.255300\n",
      "Epoch 88, loss: 2.255008\n",
      "Epoch 89, loss: 2.255119\n",
      "Epoch 90, loss: 2.255250\n",
      "Epoch 91, loss: 2.255048\n",
      "Epoch 92, loss: 2.254672\n",
      "Epoch 93, loss: 2.255399\n",
      "Epoch 94, loss: 2.255226\n",
      "Epoch 95, loss: 2.255233\n",
      "Epoch 96, loss: 2.255033\n",
      "Epoch 97, loss: 2.255306\n",
      "Epoch 98, loss: 2.255220\n",
      "Epoch 99, loss: 2.255271\n",
      "Epoch 100, loss: 2.255218\n",
      "Epoch 101, loss: 2.255193\n",
      "Epoch 102, loss: 2.255096\n",
      "Epoch 103, loss: 2.255061\n",
      "Epoch 104, loss: 2.255425\n",
      "Epoch 105, loss: 2.255088\n",
      "Epoch 106, loss: 2.255120\n",
      "Epoch 107, loss: 2.255325\n",
      "Epoch 108, loss: 2.255061\n",
      "Epoch 109, loss: 2.255168\n",
      "Epoch 110, loss: 2.255206\n",
      "Epoch 111, loss: 2.255258\n",
      "Epoch 112, loss: 2.255236\n",
      "Epoch 113, loss: 2.255039\n",
      "Epoch 114, loss: 2.255285\n",
      "Epoch 115, loss: 2.255125\n",
      "Epoch 116, loss: 2.255047\n",
      "Epoch 117, loss: 2.255280\n",
      "Epoch 118, loss: 2.255093\n",
      "Epoch 119, loss: 2.255056\n",
      "Epoch 120, loss: 2.255209\n",
      "Epoch 121, loss: 2.255325\n",
      "Epoch 122, loss: 2.255116\n",
      "Epoch 123, loss: 2.255150\n",
      "Epoch 124, loss: 2.255326\n",
      "Epoch 125, loss: 2.255202\n",
      "Epoch 126, loss: 2.255166\n",
      "Epoch 127, loss: 2.255141\n",
      "Epoch 128, loss: 2.255234\n",
      "Epoch 129, loss: 2.255215\n",
      "Epoch 130, loss: 2.255223\n",
      "Epoch 131, loss: 2.254987\n",
      "Epoch 132, loss: 2.255284\n",
      "Epoch 133, loss: 2.255051\n",
      "Epoch 134, loss: 2.255094\n",
      "Epoch 135, loss: 2.255149\n",
      "Epoch 136, loss: 2.255059\n",
      "Epoch 137, loss: 2.255055\n",
      "Epoch 138, loss: 2.255182\n",
      "Epoch 139, loss: 2.255165\n",
      "Epoch 140, loss: 2.255201\n",
      "Epoch 141, loss: 2.255262\n",
      "Epoch 142, loss: 2.255147\n",
      "Epoch 143, loss: 2.255106\n",
      "Epoch 144, loss: 2.255027\n",
      "Epoch 145, loss: 2.255218\n",
      "Epoch 146, loss: 2.255096\n",
      "Epoch 147, loss: 2.255049\n",
      "Epoch 148, loss: 2.255348\n",
      "Epoch 149, loss: 2.255061\n",
      "Epoch 150, loss: 2.255207\n",
      "Epoch 151, loss: 2.255219\n",
      "Epoch 152, loss: 2.255102\n",
      "Epoch 153, loss: 2.255204\n",
      "Epoch 154, loss: 2.255290\n",
      "Epoch 155, loss: 2.255335\n",
      "Epoch 156, loss: 2.255075\n",
      "Epoch 157, loss: 2.254949\n",
      "Epoch 158, loss: 2.255296\n",
      "Epoch 159, loss: 2.255237\n",
      "Epoch 160, loss: 2.255340\n",
      "Epoch 161, loss: 2.255225\n",
      "Epoch 162, loss: 2.255241\n",
      "Epoch 163, loss: 2.255122\n",
      "Epoch 164, loss: 2.255350\n",
      "Epoch 165, loss: 2.255192\n",
      "Epoch 166, loss: 2.255501\n",
      "Epoch 167, loss: 2.254947\n",
      "Epoch 168, loss: 2.255375\n",
      "Epoch 169, loss: 2.255543\n",
      "Epoch 170, loss: 2.255100\n",
      "Epoch 171, loss: 2.255287\n",
      "Epoch 172, loss: 2.255373\n",
      "Epoch 173, loss: 2.255218\n",
      "Epoch 174, loss: 2.255171\n",
      "Epoch 175, loss: 2.255363\n",
      "Epoch 176, loss: 2.255130\n",
      "Epoch 177, loss: 2.255059\n",
      "Epoch 178, loss: 2.255006\n",
      "Epoch 179, loss: 2.255179\n",
      "Epoch 180, loss: 2.255118\n",
      "Epoch 181, loss: 2.255244\n",
      "Epoch 182, loss: 2.255161\n",
      "Epoch 183, loss: 2.255241\n",
      "Epoch 184, loss: 2.255428\n",
      "Epoch 185, loss: 2.255220\n",
      "Epoch 186, loss: 2.255191\n",
      "Epoch 187, loss: 2.255059\n",
      "Epoch 188, loss: 2.255103\n",
      "Epoch 189, loss: 2.255065\n",
      "Epoch 190, loss: 2.255352\n",
      "Epoch 191, loss: 2.255232\n",
      "Epoch 192, loss: 2.255221\n",
      "Epoch 193, loss: 2.255011\n",
      "Epoch 194, loss: 2.255186\n",
      "Epoch 195, loss: 2.255338\n",
      "Epoch 196, loss: 2.255087\n",
      "Epoch 197, loss: 2.254958\n",
      "Epoch 198, loss: 2.255130\n",
      "Epoch 199, loss: 2.255166\n",
      "lr: 0.01, rs: 0.1, accuracy 200 epochs: 0.229\n",
      "Epoch 0, loss: 2.299869\n",
      "Epoch 1, loss: 2.291263\n",
      "Epoch 2, loss: 2.283579\n",
      "Epoch 3, loss: 2.276653\n",
      "Epoch 4, loss: 2.270375\n",
      "Epoch 5, loss: 2.264349\n",
      "Epoch 6, loss: 2.258781\n",
      "Epoch 7, loss: 2.253751\n",
      "Epoch 8, loss: 2.249226\n",
      "Epoch 9, loss: 2.244762\n",
      "Epoch 10, loss: 2.240533\n",
      "Epoch 11, loss: 2.236606\n",
      "Epoch 12, loss: 2.233317\n",
      "Epoch 13, loss: 2.229673\n",
      "Epoch 14, loss: 2.226577\n",
      "Epoch 15, loss: 2.223769\n",
      "Epoch 16, loss: 2.220890\n",
      "Epoch 17, loss: 2.218180\n",
      "Epoch 18, loss: 2.215888\n",
      "Epoch 19, loss: 2.213634\n",
      "Epoch 20, loss: 2.211376\n",
      "Epoch 21, loss: 2.209242\n",
      "Epoch 22, loss: 2.207470\n",
      "Epoch 23, loss: 2.205593\n",
      "Epoch 24, loss: 2.204124\n",
      "Epoch 25, loss: 2.202605\n",
      "Epoch 26, loss: 2.200623\n",
      "Epoch 27, loss: 2.199409\n",
      "Epoch 28, loss: 2.198018\n",
      "Epoch 29, loss: 2.196786\n",
      "Epoch 30, loss: 2.195646\n",
      "Epoch 31, loss: 2.194564\n",
      "Epoch 32, loss: 2.193584\n",
      "Epoch 33, loss: 2.192330\n",
      "Epoch 34, loss: 2.191388\n",
      "Epoch 35, loss: 2.190484\n",
      "Epoch 36, loss: 2.189617\n",
      "Epoch 37, loss: 2.188680\n",
      "Epoch 38, loss: 2.187962\n",
      "Epoch 39, loss: 2.187155\n",
      "Epoch 40, loss: 2.186458\n",
      "Epoch 41, loss: 2.185409\n",
      "Epoch 42, loss: 2.185045\n",
      "Epoch 43, loss: 2.184239\n",
      "Epoch 44, loss: 2.183795\n",
      "Epoch 45, loss: 2.183068\n",
      "Epoch 46, loss: 2.182468\n",
      "Epoch 47, loss: 2.181947\n",
      "Epoch 48, loss: 2.181363\n",
      "Epoch 49, loss: 2.180948\n",
      "Epoch 50, loss: 2.180342\n",
      "Epoch 51, loss: 2.180093\n",
      "Epoch 52, loss: 2.179462\n",
      "Epoch 53, loss: 2.178892\n",
      "Epoch 54, loss: 2.178608\n",
      "Epoch 55, loss: 2.178288\n",
      "Epoch 56, loss: 2.177735\n",
      "Epoch 57, loss: 2.177364\n",
      "Epoch 58, loss: 2.177156\n",
      "Epoch 59, loss: 2.176638\n",
      "Epoch 60, loss: 2.176054\n",
      "Epoch 61, loss: 2.176017\n",
      "Epoch 62, loss: 2.175562\n",
      "Epoch 63, loss: 2.175116\n",
      "Epoch 64, loss: 2.175031\n",
      "Epoch 65, loss: 2.174812\n",
      "Epoch 66, loss: 2.174396\n",
      "Epoch 67, loss: 2.174206\n",
      "Epoch 68, loss: 2.173696\n",
      "Epoch 69, loss: 2.173416\n",
      "Epoch 70, loss: 2.173460\n",
      "Epoch 71, loss: 2.172949\n",
      "Epoch 72, loss: 2.172806\n",
      "Epoch 73, loss: 2.172621\n",
      "Epoch 74, loss: 2.172298\n",
      "Epoch 75, loss: 2.171903\n",
      "Epoch 76, loss: 2.171936\n",
      "Epoch 77, loss: 2.171663\n",
      "Epoch 78, loss: 2.171444\n",
      "Epoch 79, loss: 2.171254\n",
      "Epoch 80, loss: 2.171071\n",
      "Epoch 81, loss: 2.170862\n",
      "Epoch 82, loss: 2.170672\n",
      "Epoch 83, loss: 2.170559\n",
      "Epoch 84, loss: 2.170259\n",
      "Epoch 85, loss: 2.170242\n",
      "Epoch 86, loss: 2.169913\n",
      "Epoch 87, loss: 2.169786\n",
      "Epoch 88, loss: 2.169598\n",
      "Epoch 89, loss: 2.169564\n",
      "Epoch 90, loss: 2.169466\n",
      "Epoch 91, loss: 2.169318\n",
      "Epoch 92, loss: 2.169017\n",
      "Epoch 93, loss: 2.168939\n",
      "Epoch 94, loss: 2.168916\n",
      "Epoch 95, loss: 2.168498\n",
      "Epoch 96, loss: 2.168624\n",
      "Epoch 97, loss: 2.168334\n",
      "Epoch 98, loss: 2.168266\n",
      "Epoch 99, loss: 2.168374\n",
      "Epoch 100, loss: 2.167973\n",
      "Epoch 101, loss: 2.167923\n",
      "Epoch 102, loss: 2.167780\n",
      "Epoch 103, loss: 2.167740\n",
      "Epoch 104, loss: 2.167532\n",
      "Epoch 105, loss: 2.167417\n",
      "Epoch 106, loss: 2.167338\n",
      "Epoch 107, loss: 2.167178\n",
      "Epoch 108, loss: 2.167108\n",
      "Epoch 109, loss: 2.166995\n",
      "Epoch 110, loss: 2.167068\n",
      "Epoch 111, loss: 2.166606\n",
      "Epoch 112, loss: 2.166853\n",
      "Epoch 113, loss: 2.166738\n",
      "Epoch 114, loss: 2.166551\n",
      "Epoch 115, loss: 2.166448\n",
      "Epoch 116, loss: 2.166390\n",
      "Epoch 117, loss: 2.166427\n",
      "Epoch 118, loss: 2.166275\n",
      "Epoch 119, loss: 2.166229\n",
      "Epoch 120, loss: 2.166017\n",
      "Epoch 121, loss: 2.165919\n",
      "Epoch 122, loss: 2.165820\n",
      "Epoch 123, loss: 2.165748\n",
      "Epoch 124, loss: 2.165645\n",
      "Epoch 125, loss: 2.165454\n",
      "Epoch 126, loss: 2.165782\n",
      "Epoch 127, loss: 2.165523\n",
      "Epoch 128, loss: 2.165342\n",
      "Epoch 129, loss: 2.165385\n",
      "Epoch 130, loss: 2.165483\n",
      "Epoch 131, loss: 2.165250\n",
      "Epoch 132, loss: 2.165262\n",
      "Epoch 133, loss: 2.165113\n",
      "Epoch 134, loss: 2.165251\n",
      "Epoch 135, loss: 2.164904\n",
      "Epoch 136, loss: 2.164989\n",
      "Epoch 137, loss: 2.165044\n",
      "Epoch 138, loss: 2.164912\n",
      "Epoch 139, loss: 2.164952\n",
      "Epoch 140, loss: 2.164950\n",
      "Epoch 141, loss: 2.164765\n",
      "Epoch 142, loss: 2.164776\n",
      "Epoch 143, loss: 2.164848\n",
      "Epoch 144, loss: 2.164520\n",
      "Epoch 145, loss: 2.164501\n",
      "Epoch 146, loss: 2.164642\n",
      "Epoch 147, loss: 2.164313\n",
      "Epoch 148, loss: 2.164429\n",
      "Epoch 149, loss: 2.164225\n",
      "Epoch 150, loss: 2.164367\n",
      "Epoch 151, loss: 2.164289\n",
      "Epoch 152, loss: 2.164136\n",
      "Epoch 153, loss: 2.164259\n",
      "Epoch 154, loss: 2.164090\n",
      "Epoch 155, loss: 2.164061\n",
      "Epoch 156, loss: 2.163858\n",
      "Epoch 157, loss: 2.164009\n",
      "Epoch 158, loss: 2.163934\n",
      "Epoch 159, loss: 2.163933\n",
      "Epoch 160, loss: 2.163989\n",
      "Epoch 161, loss: 2.164005\n",
      "Epoch 162, loss: 2.163997\n",
      "Epoch 163, loss: 2.163743\n",
      "Epoch 164, loss: 2.163744\n",
      "Epoch 165, loss: 2.163950\n",
      "Epoch 166, loss: 2.163570\n",
      "Epoch 167, loss: 2.163557\n",
      "Epoch 168, loss: 2.163739\n",
      "Epoch 169, loss: 2.163609\n",
      "Epoch 170, loss: 2.163713\n",
      "Epoch 171, loss: 2.163513\n",
      "Epoch 172, loss: 2.163579\n",
      "Epoch 173, loss: 2.163531\n",
      "Epoch 174, loss: 2.163465\n",
      "Epoch 175, loss: 2.163384\n",
      "Epoch 176, loss: 2.163483\n",
      "Epoch 177, loss: 2.163305\n",
      "Epoch 178, loss: 2.163438\n",
      "Epoch 179, loss: 2.163416\n",
      "Epoch 180, loss: 2.163291\n",
      "Epoch 181, loss: 2.163099\n",
      "Epoch 182, loss: 2.163150\n",
      "Epoch 183, loss: 2.163348\n",
      "Epoch 184, loss: 2.163213\n",
      "Epoch 185, loss: 2.162966\n",
      "Epoch 186, loss: 2.163193\n",
      "Epoch 187, loss: 2.163161\n",
      "Epoch 188, loss: 2.163236\n",
      "Epoch 189, loss: 2.163229\n",
      "Epoch 190, loss: 2.162892\n",
      "Epoch 191, loss: 2.162972\n",
      "Epoch 192, loss: 2.162981\n",
      "Epoch 193, loss: 2.163102\n",
      "Epoch 194, loss: 2.162784\n",
      "Epoch 195, loss: 2.162815\n",
      "Epoch 196, loss: 2.162981\n",
      "Epoch 197, loss: 2.163033\n",
      "Epoch 198, loss: 2.162803\n",
      "Epoch 199, loss: 2.163006\n",
      "lr: 0.01, rs: 0.01, accuracy 200 epochs: 0.238\n",
      "Epoch 0, loss: 2.299338\n",
      "Epoch 1, loss: 2.290631\n",
      "Epoch 2, loss: 2.283081\n",
      "Epoch 3, loss: 2.275824\n",
      "Epoch 4, loss: 2.269176\n",
      "Epoch 5, loss: 2.262792\n",
      "Epoch 6, loss: 2.257108\n",
      "Epoch 7, loss: 2.251508\n",
      "Epoch 8, loss: 2.246466\n",
      "Epoch 9, loss: 2.241617\n",
      "Epoch 10, loss: 2.236867\n",
      "Epoch 11, loss: 2.232870\n",
      "Epoch 12, loss: 2.228433\n",
      "Epoch 13, loss: 2.224532\n",
      "Epoch 14, loss: 2.221034\n",
      "Epoch 15, loss: 2.217524\n",
      "Epoch 16, loss: 2.214241\n",
      "Epoch 17, loss: 2.211389\n",
      "Epoch 18, loss: 2.208293\n",
      "Epoch 19, loss: 2.205746\n",
      "Epoch 20, loss: 2.202970\n",
      "Epoch 21, loss: 2.200177\n",
      "Epoch 22, loss: 2.197775\n",
      "Epoch 23, loss: 2.195810\n",
      "Epoch 24, loss: 2.193414\n",
      "Epoch 25, loss: 2.191333\n",
      "Epoch 26, loss: 2.189347\n",
      "Epoch 27, loss: 2.187319\n",
      "Epoch 28, loss: 2.185855\n",
      "Epoch 29, loss: 2.184019\n",
      "Epoch 30, loss: 2.182222\n",
      "Epoch 31, loss: 2.180512\n",
      "Epoch 32, loss: 2.179536\n",
      "Epoch 33, loss: 2.177770\n",
      "Epoch 34, loss: 2.176346\n",
      "Epoch 35, loss: 2.174940\n",
      "Epoch 36, loss: 2.173870\n",
      "Epoch 37, loss: 2.172426\n",
      "Epoch 38, loss: 2.171159\n",
      "Epoch 39, loss: 2.169995\n",
      "Epoch 40, loss: 2.169091\n",
      "Epoch 41, loss: 2.167944\n",
      "Epoch 42, loss: 2.166718\n",
      "Epoch 43, loss: 2.165624\n",
      "Epoch 44, loss: 2.164700\n",
      "Epoch 45, loss: 2.163659\n",
      "Epoch 46, loss: 2.162790\n",
      "Epoch 47, loss: 2.161802\n",
      "Epoch 48, loss: 2.160821\n",
      "Epoch 49, loss: 2.160158\n",
      "Epoch 50, loss: 2.159225\n",
      "Epoch 51, loss: 2.158402\n",
      "Epoch 52, loss: 2.157581\n",
      "Epoch 53, loss: 2.156733\n",
      "Epoch 54, loss: 2.155981\n",
      "Epoch 55, loss: 2.155260\n",
      "Epoch 56, loss: 2.154609\n",
      "Epoch 57, loss: 2.153860\n",
      "Epoch 58, loss: 2.153104\n",
      "Epoch 59, loss: 2.152224\n",
      "Epoch 60, loss: 2.151797\n",
      "Epoch 61, loss: 2.150989\n",
      "Epoch 62, loss: 2.150328\n",
      "Epoch 63, loss: 2.149703\n",
      "Epoch 64, loss: 2.149358\n",
      "Epoch 65, loss: 2.148571\n",
      "Epoch 66, loss: 2.147919\n",
      "Epoch 67, loss: 2.147384\n",
      "Epoch 68, loss: 2.146690\n",
      "Epoch 69, loss: 2.146141\n",
      "Epoch 70, loss: 2.145802\n",
      "Epoch 71, loss: 2.145267\n",
      "Epoch 72, loss: 2.144718\n",
      "Epoch 73, loss: 2.144096\n",
      "Epoch 74, loss: 2.143477\n",
      "Epoch 75, loss: 2.143094\n",
      "Epoch 76, loss: 2.142568\n",
      "Epoch 77, loss: 2.141988\n",
      "Epoch 78, loss: 2.141450\n",
      "Epoch 79, loss: 2.141010\n",
      "Epoch 80, loss: 2.140601\n",
      "Epoch 81, loss: 2.140088\n",
      "Epoch 82, loss: 2.139847\n",
      "Epoch 83, loss: 2.139360\n",
      "Epoch 84, loss: 2.138870\n",
      "Epoch 85, loss: 2.138375\n",
      "Epoch 86, loss: 2.138019\n",
      "Epoch 87, loss: 2.137515\n",
      "Epoch 88, loss: 2.137151\n",
      "Epoch 89, loss: 2.136885\n",
      "Epoch 90, loss: 2.136436\n",
      "Epoch 91, loss: 2.136088\n",
      "Epoch 92, loss: 2.135527\n",
      "Epoch 93, loss: 2.135111\n",
      "Epoch 94, loss: 2.134730\n",
      "Epoch 95, loss: 2.134411\n",
      "Epoch 96, loss: 2.133941\n",
      "Epoch 97, loss: 2.133835\n",
      "Epoch 98, loss: 2.133292\n",
      "Epoch 99, loss: 2.132973\n",
      "Epoch 100, loss: 2.132691\n",
      "Epoch 101, loss: 2.132112\n",
      "Epoch 102, loss: 2.131867\n",
      "Epoch 103, loss: 2.131234\n",
      "Epoch 104, loss: 2.131435\n",
      "Epoch 105, loss: 2.130852\n",
      "Epoch 106, loss: 2.130575\n",
      "Epoch 107, loss: 2.130183\n",
      "Epoch 108, loss: 2.129773\n",
      "Epoch 109, loss: 2.129364\n",
      "Epoch 110, loss: 2.129134\n",
      "Epoch 111, loss: 2.128796\n",
      "Epoch 112, loss: 2.128523\n",
      "Epoch 113, loss: 2.128371\n",
      "Epoch 114, loss: 2.128131\n",
      "Epoch 115, loss: 2.127738\n",
      "Epoch 116, loss: 2.127223\n",
      "Epoch 117, loss: 2.127080\n",
      "Epoch 118, loss: 2.126796\n",
      "Epoch 119, loss: 2.126434\n",
      "Epoch 120, loss: 2.126320\n",
      "Epoch 121, loss: 2.125665\n",
      "Epoch 122, loss: 2.125581\n",
      "Epoch 123, loss: 2.125245\n",
      "Epoch 124, loss: 2.125007\n",
      "Epoch 125, loss: 2.124804\n",
      "Epoch 126, loss: 2.124678\n",
      "Epoch 127, loss: 2.124179\n",
      "Epoch 128, loss: 2.124051\n",
      "Epoch 129, loss: 2.123770\n",
      "Epoch 130, loss: 2.123419\n",
      "Epoch 131, loss: 2.122932\n",
      "Epoch 132, loss: 2.123030\n",
      "Epoch 133, loss: 2.122667\n",
      "Epoch 134, loss: 2.122258\n",
      "Epoch 135, loss: 2.122163\n",
      "Epoch 136, loss: 2.121794\n",
      "Epoch 137, loss: 2.121766\n",
      "Epoch 138, loss: 2.121382\n",
      "Epoch 139, loss: 2.121131\n",
      "Epoch 140, loss: 2.120974\n",
      "Epoch 141, loss: 2.120483\n",
      "Epoch 142, loss: 2.120402\n",
      "Epoch 143, loss: 2.120255\n",
      "Epoch 144, loss: 2.120051\n",
      "Epoch 145, loss: 2.119766\n",
      "Epoch 146, loss: 2.119494\n",
      "Epoch 147, loss: 2.119333\n",
      "Epoch 148, loss: 2.118979\n",
      "Epoch 149, loss: 2.119023\n",
      "Epoch 150, loss: 2.118398\n",
      "Epoch 151, loss: 2.118517\n",
      "Epoch 152, loss: 2.118213\n",
      "Epoch 153, loss: 2.118182\n",
      "Epoch 154, loss: 2.117965\n",
      "Epoch 155, loss: 2.117556\n",
      "Epoch 156, loss: 2.117621\n",
      "Epoch 157, loss: 2.117398\n",
      "Epoch 158, loss: 2.116901\n",
      "Epoch 159, loss: 2.116801\n",
      "Epoch 160, loss: 2.116645\n",
      "Epoch 161, loss: 2.116342\n",
      "Epoch 162, loss: 2.116287\n",
      "Epoch 163, loss: 2.115924\n",
      "Epoch 164, loss: 2.115628\n",
      "Epoch 165, loss: 2.115390\n",
      "Epoch 166, loss: 2.115223\n",
      "Epoch 167, loss: 2.115236\n",
      "Epoch 168, loss: 2.115065\n",
      "Epoch 169, loss: 2.114606\n",
      "Epoch 170, loss: 2.114757\n",
      "Epoch 171, loss: 2.114523\n",
      "Epoch 172, loss: 2.114078\n",
      "Epoch 173, loss: 2.113978\n",
      "Epoch 174, loss: 2.113754\n",
      "Epoch 175, loss: 2.113653\n",
      "Epoch 176, loss: 2.113523\n",
      "Epoch 177, loss: 2.113325\n",
      "Epoch 178, loss: 2.113249\n",
      "Epoch 179, loss: 2.112763\n",
      "Epoch 180, loss: 2.112578\n",
      "Epoch 181, loss: 2.112709\n",
      "Epoch 182, loss: 2.112375\n",
      "Epoch 183, loss: 2.112377\n",
      "Epoch 184, loss: 2.112258\n",
      "Epoch 185, loss: 2.111872\n",
      "Epoch 186, loss: 2.111892\n",
      "Epoch 187, loss: 2.111502\n",
      "Epoch 188, loss: 2.111418\n",
      "Epoch 189, loss: 2.111142\n",
      "Epoch 190, loss: 2.111097\n",
      "Epoch 191, loss: 2.110924\n",
      "Epoch 192, loss: 2.110843\n",
      "Epoch 193, loss: 2.110663\n",
      "Epoch 194, loss: 2.110567\n",
      "Epoch 195, loss: 2.110247\n",
      "Epoch 196, loss: 2.110194\n",
      "Epoch 197, loss: 2.109986\n",
      "Epoch 198, loss: 2.109781\n",
      "Epoch 199, loss: 2.109863\n",
      "lr: 0.01, rs: 0.001, accuracy 200 epochs: 0.245\n",
      "Epoch 0, loss: 2.299732\n",
      "Epoch 1, loss: 2.291061\n",
      "Epoch 2, loss: 2.283209\n",
      "Epoch 3, loss: 2.276182\n",
      "Epoch 4, loss: 2.269023\n",
      "Epoch 5, loss: 2.263220\n",
      "Epoch 6, loss: 2.257323\n",
      "Epoch 7, loss: 2.251700\n",
      "Epoch 8, loss: 2.246399\n",
      "Epoch 9, loss: 2.241543\n",
      "Epoch 10, loss: 2.236906\n",
      "Epoch 11, loss: 2.232353\n",
      "Epoch 12, loss: 2.228513\n",
      "Epoch 13, loss: 2.224312\n",
      "Epoch 14, loss: 2.220877\n",
      "Epoch 15, loss: 2.217232\n",
      "Epoch 16, loss: 2.213861\n",
      "Epoch 17, loss: 2.210929\n",
      "Epoch 18, loss: 2.207576\n",
      "Epoch 19, loss: 2.204708\n",
      "Epoch 20, loss: 2.202118\n",
      "Epoch 21, loss: 2.199618\n",
      "Epoch 22, loss: 2.197228\n",
      "Epoch 23, loss: 2.194770\n",
      "Epoch 24, loss: 2.192617\n",
      "Epoch 25, loss: 2.190365\n",
      "Epoch 26, loss: 2.188329\n",
      "Epoch 27, loss: 2.186332\n",
      "Epoch 28, loss: 2.184511\n",
      "Epoch 29, loss: 2.182532\n",
      "Epoch 30, loss: 2.181118\n",
      "Epoch 31, loss: 2.179151\n",
      "Epoch 32, loss: 2.177728\n",
      "Epoch 33, loss: 2.176124\n",
      "Epoch 34, loss: 2.174796\n",
      "Epoch 35, loss: 2.173613\n",
      "Epoch 36, loss: 2.172031\n",
      "Epoch 37, loss: 2.170747\n",
      "Epoch 38, loss: 2.169703\n",
      "Epoch 39, loss: 2.168124\n",
      "Epoch 40, loss: 2.167130\n",
      "Epoch 41, loss: 2.165859\n",
      "Epoch 42, loss: 2.164779\n",
      "Epoch 43, loss: 2.163542\n",
      "Epoch 44, loss: 2.162740\n",
      "Epoch 45, loss: 2.161557\n",
      "Epoch 46, loss: 2.160424\n",
      "Epoch 47, loss: 2.159643\n",
      "Epoch 48, loss: 2.158679\n",
      "Epoch 49, loss: 2.157506\n",
      "Epoch 50, loss: 2.156661\n",
      "Epoch 51, loss: 2.155927\n",
      "Epoch 52, loss: 2.155186\n",
      "Epoch 53, loss: 2.154340\n",
      "Epoch 54, loss: 2.153467\n",
      "Epoch 55, loss: 2.152607\n",
      "Epoch 56, loss: 2.151510\n",
      "Epoch 57, loss: 2.151033\n",
      "Epoch 58, loss: 2.150340\n",
      "Epoch 59, loss: 2.149677\n",
      "Epoch 60, loss: 2.148886\n",
      "Epoch 61, loss: 2.148246\n",
      "Epoch 62, loss: 2.147469\n",
      "Epoch 63, loss: 2.146652\n",
      "Epoch 64, loss: 2.146076\n",
      "Epoch 65, loss: 2.145344\n",
      "Epoch 66, loss: 2.144836\n",
      "Epoch 67, loss: 2.144336\n",
      "Epoch 68, loss: 2.143588\n",
      "Epoch 69, loss: 2.142898\n",
      "Epoch 70, loss: 2.142403\n",
      "Epoch 71, loss: 2.141595\n",
      "Epoch 72, loss: 2.141214\n",
      "Epoch 73, loss: 2.140679\n",
      "Epoch 74, loss: 2.140197\n",
      "Epoch 75, loss: 2.139457\n",
      "Epoch 76, loss: 2.138915\n",
      "Epoch 77, loss: 2.138565\n",
      "Epoch 78, loss: 2.137872\n",
      "Epoch 79, loss: 2.137631\n",
      "Epoch 80, loss: 2.136846\n",
      "Epoch 81, loss: 2.136235\n",
      "Epoch 82, loss: 2.136014\n",
      "Epoch 83, loss: 2.135178\n",
      "Epoch 84, loss: 2.134893\n",
      "Epoch 85, loss: 2.134538\n",
      "Epoch 86, loss: 2.134027\n",
      "Epoch 87, loss: 2.133779\n",
      "Epoch 88, loss: 2.132891\n",
      "Epoch 89, loss: 2.132511\n",
      "Epoch 90, loss: 2.132181\n",
      "Epoch 91, loss: 2.131780\n",
      "Epoch 92, loss: 2.131336\n",
      "Epoch 93, loss: 2.130830\n",
      "Epoch 94, loss: 2.130274\n",
      "Epoch 95, loss: 2.130023\n",
      "Epoch 96, loss: 2.129695\n",
      "Epoch 97, loss: 2.129150\n",
      "Epoch 98, loss: 2.128796\n",
      "Epoch 99, loss: 2.128272\n",
      "Epoch 100, loss: 2.127935\n",
      "Epoch 101, loss: 2.127565\n",
      "Epoch 102, loss: 2.127259\n",
      "Epoch 103, loss: 2.126691\n",
      "Epoch 104, loss: 2.126458\n",
      "Epoch 105, loss: 2.125779\n",
      "Epoch 106, loss: 2.125484\n",
      "Epoch 107, loss: 2.125128\n",
      "Epoch 108, loss: 2.124749\n",
      "Epoch 109, loss: 2.124581\n",
      "Epoch 110, loss: 2.124070\n",
      "Epoch 111, loss: 2.123699\n",
      "Epoch 112, loss: 2.123383\n",
      "Epoch 113, loss: 2.122885\n",
      "Epoch 114, loss: 2.122814\n",
      "Epoch 115, loss: 2.122234\n",
      "Epoch 116, loss: 2.122254\n",
      "Epoch 117, loss: 2.121755\n",
      "Epoch 118, loss: 2.121482\n",
      "Epoch 119, loss: 2.120851\n",
      "Epoch 120, loss: 2.120663\n",
      "Epoch 121, loss: 2.120383\n",
      "Epoch 122, loss: 2.120224\n",
      "Epoch 123, loss: 2.119588\n",
      "Epoch 124, loss: 2.119452\n",
      "Epoch 125, loss: 2.119051\n",
      "Epoch 126, loss: 2.118732\n",
      "Epoch 127, loss: 2.118499\n",
      "Epoch 128, loss: 2.118243\n",
      "Epoch 129, loss: 2.117742\n",
      "Epoch 130, loss: 2.117561\n",
      "Epoch 131, loss: 2.117329\n",
      "Epoch 132, loss: 2.117031\n",
      "Epoch 133, loss: 2.116764\n",
      "Epoch 134, loss: 2.116259\n",
      "Epoch 135, loss: 2.116214\n",
      "Epoch 136, loss: 2.115761\n",
      "Epoch 137, loss: 2.115560\n",
      "Epoch 138, loss: 2.115040\n",
      "Epoch 139, loss: 2.114935\n",
      "Epoch 140, loss: 2.114822\n",
      "Epoch 141, loss: 2.114482\n",
      "Epoch 142, loss: 2.114006\n",
      "Epoch 143, loss: 2.113809\n",
      "Epoch 144, loss: 2.113516\n",
      "Epoch 145, loss: 2.113340\n",
      "Epoch 146, loss: 2.113235\n",
      "Epoch 147, loss: 2.113075\n",
      "Epoch 148, loss: 2.112561\n",
      "Epoch 149, loss: 2.112205\n",
      "Epoch 150, loss: 2.112001\n",
      "Epoch 151, loss: 2.111762\n",
      "Epoch 152, loss: 2.111574\n",
      "Epoch 153, loss: 2.111161\n",
      "Epoch 154, loss: 2.111096\n",
      "Epoch 155, loss: 2.110775\n",
      "Epoch 156, loss: 2.110472\n",
      "Epoch 157, loss: 2.110334\n",
      "Epoch 158, loss: 2.109995\n",
      "Epoch 159, loss: 2.109671\n",
      "Epoch 160, loss: 2.109585\n",
      "Epoch 161, loss: 2.109125\n",
      "Epoch 162, loss: 2.109151\n",
      "Epoch 163, loss: 2.108770\n",
      "Epoch 164, loss: 2.108488\n",
      "Epoch 165, loss: 2.108408\n",
      "Epoch 166, loss: 2.108018\n",
      "Epoch 167, loss: 2.107885\n",
      "Epoch 168, loss: 2.107581\n",
      "Epoch 169, loss: 2.107459\n",
      "Epoch 170, loss: 2.107203\n",
      "Epoch 171, loss: 2.106793\n",
      "Epoch 172, loss: 2.106601\n",
      "Epoch 173, loss: 2.105898\n",
      "Epoch 174, loss: 2.106459\n",
      "Epoch 175, loss: 2.106221\n",
      "Epoch 176, loss: 2.105919\n",
      "Epoch 177, loss: 2.105408\n",
      "Epoch 178, loss: 2.105506\n",
      "Epoch 179, loss: 2.105365\n",
      "Epoch 180, loss: 2.104883\n",
      "Epoch 181, loss: 2.104722\n",
      "Epoch 182, loss: 2.104582\n",
      "Epoch 183, loss: 2.104530\n",
      "Epoch 184, loss: 2.104213\n",
      "Epoch 185, loss: 2.103991\n",
      "Epoch 186, loss: 2.103725\n",
      "Epoch 187, loss: 2.103355\n",
      "Epoch 188, loss: 2.103524\n",
      "Epoch 189, loss: 2.103114\n",
      "Epoch 190, loss: 2.103065\n",
      "Epoch 191, loss: 2.102650\n",
      "Epoch 192, loss: 2.102366\n",
      "Epoch 193, loss: 2.102333\n",
      "Epoch 194, loss: 2.102012\n",
      "Epoch 195, loss: 2.101839\n",
      "Epoch 196, loss: 2.101678\n",
      "Epoch 197, loss: 2.101480\n",
      "Epoch 198, loss: 2.101333\n",
      "Epoch 199, loss: 2.100946\n",
      "lr: 0.01, rs: 0.0001, accuracy 200 epochs: 0.243\n",
      "Epoch 0, loss: 2.299666\n",
      "Epoch 1, loss: 2.291220\n",
      "Epoch 2, loss: 2.283310\n",
      "Epoch 3, loss: 2.276368\n",
      "Epoch 4, loss: 2.269324\n",
      "Epoch 5, loss: 2.262908\n",
      "Epoch 6, loss: 2.257214\n",
      "Epoch 7, loss: 2.251839\n",
      "Epoch 8, loss: 2.246408\n",
      "Epoch 9, loss: 2.241563\n",
      "Epoch 10, loss: 2.236956\n",
      "Epoch 11, loss: 2.232622\n",
      "Epoch 12, loss: 2.228389\n",
      "Epoch 13, loss: 2.224382\n",
      "Epoch 14, loss: 2.220702\n",
      "Epoch 15, loss: 2.217281\n",
      "Epoch 16, loss: 2.213715\n",
      "Epoch 17, loss: 2.210860\n",
      "Epoch 18, loss: 2.207868\n",
      "Epoch 19, loss: 2.204692\n",
      "Epoch 20, loss: 2.201977\n",
      "Epoch 21, loss: 2.199554\n",
      "Epoch 22, loss: 2.197169\n",
      "Epoch 23, loss: 2.194896\n",
      "Epoch 24, loss: 2.192199\n",
      "Epoch 25, loss: 2.190487\n",
      "Epoch 26, loss: 2.187950\n",
      "Epoch 27, loss: 2.186347\n",
      "Epoch 28, loss: 2.184472\n",
      "Epoch 29, loss: 2.182777\n",
      "Epoch 30, loss: 2.180920\n",
      "Epoch 31, loss: 2.179111\n",
      "Epoch 32, loss: 2.177650\n",
      "Epoch 33, loss: 2.175979\n",
      "Epoch 34, loss: 2.174615\n",
      "Epoch 35, loss: 2.173317\n",
      "Epoch 36, loss: 2.171809\n",
      "Epoch 37, loss: 2.170556\n",
      "Epoch 38, loss: 2.169148\n",
      "Epoch 39, loss: 2.168061\n",
      "Epoch 40, loss: 2.166900\n",
      "Epoch 41, loss: 2.165744\n",
      "Epoch 42, loss: 2.164418\n",
      "Epoch 43, loss: 2.163499\n",
      "Epoch 44, loss: 2.162392\n",
      "Epoch 45, loss: 2.161281\n",
      "Epoch 46, loss: 2.160361\n",
      "Epoch 47, loss: 2.159268\n",
      "Epoch 48, loss: 2.158461\n",
      "Epoch 49, loss: 2.157392\n",
      "Epoch 50, loss: 2.156688\n",
      "Epoch 51, loss: 2.155680\n",
      "Epoch 52, loss: 2.154728\n",
      "Epoch 53, loss: 2.154001\n",
      "Epoch 54, loss: 2.153263\n",
      "Epoch 55, loss: 2.152323\n",
      "Epoch 56, loss: 2.151645\n",
      "Epoch 57, loss: 2.150769\n",
      "Epoch 58, loss: 2.149971\n",
      "Epoch 59, loss: 2.149269\n",
      "Epoch 60, loss: 2.148671\n",
      "Epoch 61, loss: 2.148093\n",
      "Epoch 62, loss: 2.147030\n",
      "Epoch 63, loss: 2.146518\n",
      "Epoch 64, loss: 2.145669\n",
      "Epoch 65, loss: 2.145398\n",
      "Epoch 66, loss: 2.144493\n",
      "Epoch 67, loss: 2.144049\n",
      "Epoch 68, loss: 2.143293\n",
      "Epoch 69, loss: 2.142813\n",
      "Epoch 70, loss: 2.141806\n",
      "Epoch 71, loss: 2.141593\n",
      "Epoch 72, loss: 2.140745\n",
      "Epoch 73, loss: 2.140410\n",
      "Epoch 74, loss: 2.139714\n",
      "Epoch 75, loss: 2.139296\n",
      "Epoch 76, loss: 2.138653\n",
      "Epoch 77, loss: 2.138200\n",
      "Epoch 78, loss: 2.137557\n",
      "Epoch 79, loss: 2.136978\n",
      "Epoch 80, loss: 2.136531\n",
      "Epoch 81, loss: 2.135865\n",
      "Epoch 82, loss: 2.135506\n",
      "Epoch 83, loss: 2.134915\n",
      "Epoch 84, loss: 2.134585\n",
      "Epoch 85, loss: 2.133986\n",
      "Epoch 86, loss: 2.133422\n",
      "Epoch 87, loss: 2.133191\n",
      "Epoch 88, loss: 2.132665\n",
      "Epoch 89, loss: 2.132054\n",
      "Epoch 90, loss: 2.131845\n",
      "Epoch 91, loss: 2.131346\n",
      "Epoch 92, loss: 2.130825\n",
      "Epoch 93, loss: 2.130330\n",
      "Epoch 94, loss: 2.130163\n",
      "Epoch 95, loss: 2.129597\n",
      "Epoch 96, loss: 2.128913\n",
      "Epoch 97, loss: 2.128591\n",
      "Epoch 98, loss: 2.128300\n",
      "Epoch 99, loss: 2.127893\n",
      "Epoch 100, loss: 2.127437\n",
      "Epoch 101, loss: 2.127107\n",
      "Epoch 102, loss: 2.126378\n",
      "Epoch 103, loss: 2.126170\n",
      "Epoch 104, loss: 2.126027\n",
      "Epoch 105, loss: 2.125399\n",
      "Epoch 106, loss: 2.125166\n",
      "Epoch 107, loss: 2.124579\n",
      "Epoch 108, loss: 2.124617\n",
      "Epoch 109, loss: 2.124014\n",
      "Epoch 110, loss: 2.123761\n",
      "Epoch 111, loss: 2.123256\n",
      "Epoch 112, loss: 2.122994\n",
      "Epoch 113, loss: 2.122573\n",
      "Epoch 114, loss: 2.122367\n",
      "Epoch 115, loss: 2.121776\n",
      "Epoch 116, loss: 2.121551\n",
      "Epoch 117, loss: 2.121029\n",
      "Epoch 118, loss: 2.120776\n",
      "Epoch 119, loss: 2.120149\n",
      "Epoch 120, loss: 2.120191\n",
      "Epoch 121, loss: 2.119920\n",
      "Epoch 122, loss: 2.119454\n",
      "Epoch 123, loss: 2.119254\n",
      "Epoch 124, loss: 2.118798\n",
      "Epoch 125, loss: 2.118479\n",
      "Epoch 126, loss: 2.118388\n",
      "Epoch 127, loss: 2.117932\n",
      "Epoch 128, loss: 2.117502\n",
      "Epoch 129, loss: 2.117268\n",
      "Epoch 130, loss: 2.117045\n",
      "Epoch 131, loss: 2.116700\n",
      "Epoch 132, loss: 2.116218\n",
      "Epoch 133, loss: 2.115985\n",
      "Epoch 134, loss: 2.115730\n",
      "Epoch 135, loss: 2.115445\n",
      "Epoch 136, loss: 2.115242\n",
      "Epoch 137, loss: 2.114757\n",
      "Epoch 138, loss: 2.114584\n",
      "Epoch 139, loss: 2.114328\n",
      "Epoch 140, loss: 2.114007\n",
      "Epoch 141, loss: 2.113811\n",
      "Epoch 142, loss: 2.113399\n",
      "Epoch 143, loss: 2.113041\n",
      "Epoch 144, loss: 2.112759\n",
      "Epoch 145, loss: 2.112703\n",
      "Epoch 146, loss: 2.112293\n",
      "Epoch 147, loss: 2.112060\n",
      "Epoch 148, loss: 2.111980\n",
      "Epoch 149, loss: 2.111593\n",
      "Epoch 150, loss: 2.111413\n",
      "Epoch 151, loss: 2.111162\n",
      "Epoch 152, loss: 2.110715\n",
      "Epoch 153, loss: 2.110503\n",
      "Epoch 154, loss: 2.110237\n",
      "Epoch 155, loss: 2.110041\n",
      "Epoch 156, loss: 2.109803\n",
      "Epoch 157, loss: 2.109654\n",
      "Epoch 158, loss: 2.109072\n",
      "Epoch 159, loss: 2.109026\n",
      "Epoch 160, loss: 2.108792\n",
      "Epoch 161, loss: 2.108474\n",
      "Epoch 162, loss: 2.108322\n",
      "Epoch 163, loss: 2.107815\n",
      "Epoch 164, loss: 2.107937\n",
      "Epoch 165, loss: 2.107522\n",
      "Epoch 166, loss: 2.107204\n",
      "Epoch 167, loss: 2.107214\n",
      "Epoch 168, loss: 2.106875\n",
      "Epoch 169, loss: 2.106576\n",
      "Epoch 170, loss: 2.106496\n",
      "Epoch 171, loss: 2.105918\n",
      "Epoch 172, loss: 2.105980\n",
      "Epoch 173, loss: 2.105826\n",
      "Epoch 174, loss: 2.105563\n",
      "Epoch 175, loss: 2.105293\n",
      "Epoch 176, loss: 2.104813\n",
      "Epoch 177, loss: 2.104782\n",
      "Epoch 178, loss: 2.104550\n",
      "Epoch 179, loss: 2.104338\n",
      "Epoch 180, loss: 2.104186\n",
      "Epoch 181, loss: 2.104054\n",
      "Epoch 182, loss: 2.103704\n",
      "Epoch 183, loss: 2.103536\n",
      "Epoch 184, loss: 2.103148\n",
      "Epoch 185, loss: 2.103115\n",
      "Epoch 186, loss: 2.102790\n",
      "Epoch 187, loss: 2.102694\n",
      "Epoch 188, loss: 2.102421\n",
      "Epoch 189, loss: 2.102186\n",
      "Epoch 190, loss: 2.101810\n",
      "Epoch 191, loss: 2.101849\n",
      "Epoch 192, loss: 2.101608\n",
      "Epoch 193, loss: 2.101542\n",
      "Epoch 194, loss: 2.101015\n",
      "Epoch 195, loss: 2.101059\n",
      "Epoch 196, loss: 2.100785\n",
      "Epoch 197, loss: 2.100512\n",
      "Epoch 198, loss: 2.100311\n",
      "Epoch 199, loss: 2.100261\n",
      "lr: 0.01, rs: 1e-05, accuracy 200 epochs: 0.24\n",
      "Epoch 0, loss: 2.299466\n",
      "Epoch 1, loss: 2.291021\n",
      "Epoch 2, loss: 2.283183\n",
      "Epoch 3, loss: 2.275881\n",
      "Epoch 4, loss: 2.269222\n",
      "Epoch 5, loss: 2.263028\n",
      "Epoch 6, loss: 2.257173\n",
      "Epoch 7, loss: 2.251729\n",
      "Epoch 8, loss: 2.246264\n",
      "Epoch 9, loss: 2.241281\n",
      "Epoch 10, loss: 2.236786\n",
      "Epoch 11, loss: 2.232151\n",
      "Epoch 12, loss: 2.228379\n",
      "Epoch 13, loss: 2.224346\n",
      "Epoch 14, loss: 2.220762\n",
      "Epoch 15, loss: 2.217201\n",
      "Epoch 16, loss: 2.213715\n",
      "Epoch 17, loss: 2.210696\n",
      "Epoch 18, loss: 2.207686\n",
      "Epoch 19, loss: 2.204781\n",
      "Epoch 20, loss: 2.202053\n",
      "Epoch 21, loss: 2.199515\n",
      "Epoch 22, loss: 2.196893\n",
      "Epoch 23, loss: 2.194648\n",
      "Epoch 24, loss: 2.192296\n",
      "Epoch 25, loss: 2.190342\n",
      "Epoch 26, loss: 2.188293\n",
      "Epoch 27, loss: 2.186230\n",
      "Epoch 28, loss: 2.184437\n",
      "Epoch 29, loss: 2.182489\n",
      "Epoch 30, loss: 2.180861\n",
      "Epoch 31, loss: 2.179396\n",
      "Epoch 32, loss: 2.177597\n",
      "Epoch 33, loss: 2.176285\n",
      "Epoch 34, loss: 2.174589\n",
      "Epoch 35, loss: 2.172963\n",
      "Epoch 36, loss: 2.171830\n",
      "Epoch 37, loss: 2.170587\n",
      "Epoch 38, loss: 2.169048\n",
      "Epoch 39, loss: 2.167893\n",
      "Epoch 40, loss: 2.166801\n",
      "Epoch 41, loss: 2.165489\n",
      "Epoch 42, loss: 2.164533\n",
      "Epoch 43, loss: 2.163429\n",
      "Epoch 44, loss: 2.162295\n",
      "Epoch 45, loss: 2.161237\n",
      "Epoch 46, loss: 2.160306\n",
      "Epoch 47, loss: 2.159314\n",
      "Epoch 48, loss: 2.158184\n",
      "Epoch 49, loss: 2.157290\n",
      "Epoch 50, loss: 2.156525\n",
      "Epoch 51, loss: 2.155732\n",
      "Epoch 52, loss: 2.154740\n",
      "Epoch 53, loss: 2.153889\n",
      "Epoch 54, loss: 2.152974\n",
      "Epoch 55, loss: 2.152249\n",
      "Epoch 56, loss: 2.151480\n",
      "Epoch 57, loss: 2.150725\n",
      "Epoch 58, loss: 2.149988\n",
      "Epoch 59, loss: 2.149169\n",
      "Epoch 60, loss: 2.148512\n",
      "Epoch 61, loss: 2.147805\n",
      "Epoch 62, loss: 2.147146\n",
      "Epoch 63, loss: 2.146365\n",
      "Epoch 64, loss: 2.145828\n",
      "Epoch 65, loss: 2.145130\n",
      "Epoch 66, loss: 2.144423\n",
      "Epoch 67, loss: 2.143633\n",
      "Epoch 68, loss: 2.143322\n",
      "Epoch 69, loss: 2.142404\n",
      "Epoch 70, loss: 2.142164\n",
      "Epoch 71, loss: 2.141200\n",
      "Epoch 72, loss: 2.140779\n",
      "Epoch 73, loss: 2.140210\n",
      "Epoch 74, loss: 2.139733\n",
      "Epoch 75, loss: 2.139021\n",
      "Epoch 76, loss: 2.138567\n",
      "Epoch 77, loss: 2.138136\n",
      "Epoch 78, loss: 2.137598\n",
      "Epoch 79, loss: 2.137013\n",
      "Epoch 80, loss: 2.136305\n",
      "Epoch 81, loss: 2.135831\n",
      "Epoch 82, loss: 2.135612\n",
      "Epoch 83, loss: 2.134964\n",
      "Epoch 84, loss: 2.134397\n",
      "Epoch 85, loss: 2.133926\n",
      "Epoch 86, loss: 2.133527\n",
      "Epoch 87, loss: 2.133323\n",
      "Epoch 88, loss: 2.132489\n",
      "Epoch 89, loss: 2.131971\n",
      "Epoch 90, loss: 2.131553\n",
      "Epoch 91, loss: 2.131198\n",
      "Epoch 92, loss: 2.130645\n",
      "Epoch 93, loss: 2.130040\n",
      "Epoch 94, loss: 2.129864\n",
      "Epoch 95, loss: 2.129448\n",
      "Epoch 96, loss: 2.129067\n",
      "Epoch 97, loss: 2.128650\n",
      "Epoch 98, loss: 2.128271\n",
      "Epoch 99, loss: 2.127791\n",
      "Epoch 100, loss: 2.127443\n",
      "Epoch 101, loss: 2.126709\n",
      "Epoch 102, loss: 2.126462\n",
      "Epoch 103, loss: 2.126300\n",
      "Epoch 104, loss: 2.125761\n",
      "Epoch 105, loss: 2.125375\n",
      "Epoch 106, loss: 2.124923\n",
      "Epoch 107, loss: 2.124571\n",
      "Epoch 108, loss: 2.124292\n",
      "Epoch 109, loss: 2.123861\n",
      "Epoch 110, loss: 2.123684\n",
      "Epoch 111, loss: 2.123165\n",
      "Epoch 112, loss: 2.122593\n",
      "Epoch 113, loss: 2.122507\n",
      "Epoch 114, loss: 2.122074\n",
      "Epoch 115, loss: 2.121959\n",
      "Epoch 116, loss: 2.121586\n",
      "Epoch 117, loss: 2.121035\n",
      "Epoch 118, loss: 2.120639\n",
      "Epoch 119, loss: 2.120329\n",
      "Epoch 120, loss: 2.119995\n",
      "Epoch 121, loss: 2.119805\n",
      "Epoch 122, loss: 2.119315\n",
      "Epoch 123, loss: 2.119034\n",
      "Epoch 124, loss: 2.118780\n",
      "Epoch 125, loss: 2.118439\n",
      "Epoch 126, loss: 2.118092\n",
      "Epoch 127, loss: 2.117721\n",
      "Epoch 128, loss: 2.117203\n",
      "Epoch 129, loss: 2.117291\n",
      "Epoch 130, loss: 2.117109\n",
      "Epoch 131, loss: 2.116490\n",
      "Epoch 132, loss: 2.116297\n",
      "Epoch 133, loss: 2.115836\n",
      "Epoch 134, loss: 2.115611\n",
      "Epoch 135, loss: 2.115357\n",
      "Epoch 136, loss: 2.114893\n",
      "Epoch 137, loss: 2.114817\n",
      "Epoch 138, loss: 2.114456\n",
      "Epoch 139, loss: 2.114142\n",
      "Epoch 140, loss: 2.114039\n",
      "Epoch 141, loss: 2.113651\n",
      "Epoch 142, loss: 2.113287\n",
      "Epoch 143, loss: 2.113105\n",
      "Epoch 144, loss: 2.113079\n",
      "Epoch 145, loss: 2.112562\n",
      "Epoch 146, loss: 2.112263\n",
      "Epoch 147, loss: 2.111977\n",
      "Epoch 148, loss: 2.111792\n",
      "Epoch 149, loss: 2.111401\n",
      "Epoch 150, loss: 2.111347\n",
      "Epoch 151, loss: 2.110908\n",
      "Epoch 152, loss: 2.110817\n",
      "Epoch 153, loss: 2.110467\n",
      "Epoch 154, loss: 2.110423\n",
      "Epoch 155, loss: 2.109892\n",
      "Epoch 156, loss: 2.109680\n",
      "Epoch 157, loss: 2.109504\n",
      "Epoch 158, loss: 2.109273\n",
      "Epoch 159, loss: 2.108839\n",
      "Epoch 160, loss: 2.108750\n",
      "Epoch 161, loss: 2.108320\n",
      "Epoch 162, loss: 2.108220\n",
      "Epoch 163, loss: 2.107935\n",
      "Epoch 164, loss: 2.107600\n",
      "Epoch 165, loss: 2.107565\n",
      "Epoch 166, loss: 2.107190\n",
      "Epoch 167, loss: 2.106871\n",
      "Epoch 168, loss: 2.106860\n",
      "Epoch 169, loss: 2.106369\n",
      "Epoch 170, loss: 2.106291\n",
      "Epoch 171, loss: 2.106312\n",
      "Epoch 172, loss: 2.105878\n",
      "Epoch 173, loss: 2.105519\n",
      "Epoch 174, loss: 2.105439\n",
      "Epoch 175, loss: 2.105270\n",
      "Epoch 176, loss: 2.104801\n",
      "Epoch 177, loss: 2.104917\n",
      "Epoch 178, loss: 2.104339\n",
      "Epoch 179, loss: 2.104191\n",
      "Epoch 180, loss: 2.104047\n",
      "Epoch 181, loss: 2.103804\n",
      "Epoch 182, loss: 2.103446\n",
      "Epoch 183, loss: 2.103162\n",
      "Epoch 184, loss: 2.103130\n",
      "Epoch 185, loss: 2.103030\n",
      "Epoch 186, loss: 2.102451\n",
      "Epoch 187, loss: 2.102534\n",
      "Epoch 188, loss: 2.102193\n",
      "Epoch 189, loss: 2.102206\n",
      "Epoch 190, loss: 2.101865\n",
      "Epoch 191, loss: 2.101707\n",
      "Epoch 192, loss: 2.101458\n",
      "Epoch 193, loss: 2.101559\n",
      "Epoch 194, loss: 2.100997\n",
      "Epoch 195, loss: 2.100903\n",
      "Epoch 196, loss: 2.100953\n",
      "Epoch 197, loss: 2.100596\n",
      "Epoch 198, loss: 2.100136\n",
      "Epoch 199, loss: 2.099943\n",
      "lr: 0.01, rs: 1e-06, accuracy 200 epochs: 0.243\n",
      "Epoch 0, loss: 2.305236\n",
      "Epoch 1, loss: 2.304214\n",
      "Epoch 2, loss: 2.303245\n",
      "Epoch 3, loss: 2.302284\n",
      "Epoch 4, loss: 2.301384\n",
      "Epoch 5, loss: 2.300509\n",
      "Epoch 6, loss: 2.299652\n",
      "Epoch 7, loss: 2.298818\n",
      "Epoch 8, loss: 2.298008\n",
      "Epoch 9, loss: 2.297194\n",
      "Epoch 10, loss: 2.296406\n",
      "Epoch 11, loss: 2.295651\n",
      "Epoch 12, loss: 2.294903\n",
      "Epoch 13, loss: 2.294158\n",
      "Epoch 14, loss: 2.293443\n",
      "Epoch 15, loss: 2.292738\n",
      "Epoch 16, loss: 2.292040\n",
      "Epoch 17, loss: 2.291354\n",
      "Epoch 18, loss: 2.290704\n",
      "Epoch 19, loss: 2.290036\n",
      "Epoch 20, loss: 2.289388\n",
      "Epoch 21, loss: 2.288780\n",
      "Epoch 22, loss: 2.288162\n",
      "Epoch 23, loss: 2.287545\n",
      "Epoch 24, loss: 2.286955\n",
      "Epoch 25, loss: 2.286374\n",
      "Epoch 26, loss: 2.285820\n",
      "Epoch 27, loss: 2.285245\n",
      "Epoch 28, loss: 2.284692\n",
      "Epoch 29, loss: 2.284157\n",
      "Epoch 30, loss: 2.283626\n",
      "Epoch 31, loss: 2.283109\n",
      "Epoch 32, loss: 2.282598\n",
      "Epoch 33, loss: 2.282120\n",
      "Epoch 34, loss: 2.281596\n",
      "Epoch 35, loss: 2.281133\n",
      "Epoch 36, loss: 2.280672\n",
      "Epoch 37, loss: 2.280200\n",
      "Epoch 38, loss: 2.279737\n",
      "Epoch 39, loss: 2.279276\n",
      "Epoch 40, loss: 2.278857\n",
      "Epoch 41, loss: 2.278417\n",
      "Epoch 42, loss: 2.277979\n",
      "Epoch 43, loss: 2.277584\n",
      "Epoch 44, loss: 2.277155\n",
      "Epoch 45, loss: 2.276787\n",
      "Epoch 46, loss: 2.276382\n",
      "Epoch 47, loss: 2.276014\n",
      "Epoch 48, loss: 2.275616\n",
      "Epoch 49, loss: 2.275258\n",
      "Epoch 50, loss: 2.274888\n",
      "Epoch 51, loss: 2.274501\n",
      "Epoch 52, loss: 2.274158\n",
      "Epoch 53, loss: 2.273823\n",
      "Epoch 54, loss: 2.273494\n",
      "Epoch 55, loss: 2.273134\n",
      "Epoch 56, loss: 2.272808\n",
      "Epoch 57, loss: 2.272488\n",
      "Epoch 58, loss: 2.272172\n",
      "Epoch 59, loss: 2.271866\n",
      "Epoch 60, loss: 2.271562\n",
      "Epoch 61, loss: 2.271275\n",
      "Epoch 62, loss: 2.270974\n",
      "Epoch 63, loss: 2.270687\n",
      "Epoch 64, loss: 2.270398\n",
      "Epoch 65, loss: 2.270111\n",
      "Epoch 66, loss: 2.269847\n",
      "Epoch 67, loss: 2.269558\n",
      "Epoch 68, loss: 2.269308\n",
      "Epoch 69, loss: 2.269043\n",
      "Epoch 70, loss: 2.268790\n",
      "Epoch 71, loss: 2.268546\n",
      "Epoch 72, loss: 2.268305\n",
      "Epoch 73, loss: 2.268064\n",
      "Epoch 74, loss: 2.267806\n",
      "Epoch 75, loss: 2.267589\n",
      "Epoch 76, loss: 2.267346\n",
      "Epoch 77, loss: 2.267106\n",
      "Epoch 78, loss: 2.266902\n",
      "Epoch 79, loss: 2.266683\n",
      "Epoch 80, loss: 2.266461\n",
      "Epoch 81, loss: 2.266262\n",
      "Epoch 82, loss: 2.266043\n",
      "Epoch 83, loss: 2.265849\n",
      "Epoch 84, loss: 2.265649\n",
      "Epoch 85, loss: 2.265448\n",
      "Epoch 86, loss: 2.265269\n",
      "Epoch 87, loss: 2.265068\n",
      "Epoch 88, loss: 2.264881\n",
      "Epoch 89, loss: 2.264703\n",
      "Epoch 90, loss: 2.264507\n",
      "Epoch 91, loss: 2.264326\n",
      "Epoch 92, loss: 2.264175\n",
      "Epoch 93, loss: 2.263983\n",
      "Epoch 94, loss: 2.263823\n",
      "Epoch 95, loss: 2.263649\n",
      "Epoch 96, loss: 2.263505\n",
      "Epoch 97, loss: 2.263340\n",
      "Epoch 98, loss: 2.263166\n",
      "Epoch 99, loss: 2.263014\n",
      "Epoch 100, loss: 2.262862\n",
      "Epoch 101, loss: 2.262721\n",
      "Epoch 102, loss: 2.262581\n",
      "Epoch 103, loss: 2.262457\n",
      "Epoch 104, loss: 2.262303\n",
      "Epoch 105, loss: 2.262168\n",
      "Epoch 106, loss: 2.262009\n",
      "Epoch 107, loss: 2.261877\n",
      "Epoch 108, loss: 2.261735\n",
      "Epoch 109, loss: 2.261615\n",
      "Epoch 110, loss: 2.261493\n",
      "Epoch 111, loss: 2.261375\n",
      "Epoch 112, loss: 2.261245\n",
      "Epoch 113, loss: 2.261106\n",
      "Epoch 114, loss: 2.261005\n",
      "Epoch 115, loss: 2.260884\n",
      "Epoch 116, loss: 2.260770\n",
      "Epoch 117, loss: 2.260663\n",
      "Epoch 118, loss: 2.260544\n",
      "Epoch 119, loss: 2.260429\n",
      "Epoch 120, loss: 2.260331\n",
      "Epoch 121, loss: 2.260226\n",
      "Epoch 122, loss: 2.260098\n",
      "Epoch 123, loss: 2.260012\n",
      "Epoch 124, loss: 2.259923\n",
      "Epoch 125, loss: 2.259818\n",
      "Epoch 126, loss: 2.259738\n",
      "Epoch 127, loss: 2.259618\n",
      "Epoch 128, loss: 2.259520\n",
      "Epoch 129, loss: 2.259437\n",
      "Epoch 130, loss: 2.259355\n",
      "Epoch 131, loss: 2.259253\n",
      "Epoch 132, loss: 2.259175\n",
      "Epoch 133, loss: 2.259087\n",
      "Epoch 134, loss: 2.259004\n",
      "Epoch 135, loss: 2.258914\n",
      "Epoch 136, loss: 2.258828\n",
      "Epoch 137, loss: 2.258746\n",
      "Epoch 138, loss: 2.258674\n",
      "Epoch 139, loss: 2.258604\n",
      "Epoch 140, loss: 2.258520\n",
      "Epoch 141, loss: 2.258451\n",
      "Epoch 142, loss: 2.258360\n",
      "Epoch 143, loss: 2.258285\n",
      "Epoch 144, loss: 2.258223\n",
      "Epoch 145, loss: 2.258149\n",
      "Epoch 146, loss: 2.258078\n",
      "Epoch 147, loss: 2.258023\n",
      "Epoch 148, loss: 2.257946\n",
      "Epoch 149, loss: 2.257880\n",
      "Epoch 150, loss: 2.257817\n",
      "Epoch 151, loss: 2.257762\n",
      "Epoch 152, loss: 2.257691\n",
      "Epoch 153, loss: 2.257625\n",
      "Epoch 154, loss: 2.257573\n",
      "Epoch 155, loss: 2.257513\n",
      "Epoch 156, loss: 2.257452\n",
      "Epoch 157, loss: 2.257369\n",
      "Epoch 158, loss: 2.257340\n",
      "Epoch 159, loss: 2.257280\n",
      "Epoch 160, loss: 2.257210\n",
      "Epoch 161, loss: 2.257163\n",
      "Epoch 162, loss: 2.257121\n",
      "Epoch 163, loss: 2.257064\n",
      "Epoch 164, loss: 2.257012\n",
      "Epoch 165, loss: 2.256949\n",
      "Epoch 166, loss: 2.256908\n",
      "Epoch 167, loss: 2.256855\n",
      "Epoch 168, loss: 2.256812\n",
      "Epoch 169, loss: 2.256770\n",
      "Epoch 170, loss: 2.256706\n",
      "Epoch 171, loss: 2.256652\n",
      "Epoch 172, loss: 2.256638\n",
      "Epoch 173, loss: 2.256591\n",
      "Epoch 174, loss: 2.256529\n",
      "Epoch 175, loss: 2.256495\n",
      "Epoch 176, loss: 2.256446\n",
      "Epoch 177, loss: 2.256396\n",
      "Epoch 178, loss: 2.256369\n",
      "Epoch 179, loss: 2.256328\n",
      "Epoch 180, loss: 2.256281\n",
      "Epoch 181, loss: 2.256244\n",
      "Epoch 182, loss: 2.256215\n",
      "Epoch 183, loss: 2.256181\n",
      "Epoch 184, loss: 2.256137\n",
      "Epoch 185, loss: 2.256101\n",
      "Epoch 186, loss: 2.256061\n",
      "Epoch 187, loss: 2.256016\n",
      "Epoch 188, loss: 2.255990\n",
      "Epoch 189, loss: 2.255946\n",
      "Epoch 190, loss: 2.255932\n",
      "Epoch 191, loss: 2.255901\n",
      "Epoch 192, loss: 2.255849\n",
      "Epoch 193, loss: 2.255833\n",
      "Epoch 194, loss: 2.255803\n",
      "Epoch 195, loss: 2.255764\n",
      "Epoch 196, loss: 2.255737\n",
      "Epoch 197, loss: 2.255716\n",
      "Epoch 198, loss: 2.255676\n",
      "Epoch 199, loss: 2.255645\n",
      "lr: 0.001, rs: 0.1, accuracy 200 epochs: 0.223\n",
      "Epoch 0, loss: 2.302463\n",
      "Epoch 1, loss: 2.301433\n",
      "Epoch 2, loss: 2.300461\n",
      "Epoch 3, loss: 2.299503\n",
      "Epoch 4, loss: 2.298593\n",
      "Epoch 5, loss: 2.297693\n",
      "Epoch 6, loss: 2.296832\n",
      "Epoch 7, loss: 2.295954\n",
      "Epoch 8, loss: 2.295091\n",
      "Epoch 9, loss: 2.294255\n",
      "Epoch 10, loss: 2.293427\n",
      "Epoch 11, loss: 2.292594\n",
      "Epoch 12, loss: 2.291776\n",
      "Epoch 13, loss: 2.290972\n",
      "Epoch 14, loss: 2.290161\n",
      "Epoch 15, loss: 2.289384\n",
      "Epoch 16, loss: 2.288589\n",
      "Epoch 17, loss: 2.287815\n",
      "Epoch 18, loss: 2.287037\n",
      "Epoch 19, loss: 2.286259\n",
      "Epoch 20, loss: 2.285516\n",
      "Epoch 21, loss: 2.284788\n",
      "Epoch 22, loss: 2.284016\n",
      "Epoch 23, loss: 2.283286\n",
      "Epoch 24, loss: 2.282556\n",
      "Epoch 25, loss: 2.281824\n",
      "Epoch 26, loss: 2.281134\n",
      "Epoch 27, loss: 2.280386\n",
      "Epoch 28, loss: 2.279702\n",
      "Epoch 29, loss: 2.278987\n",
      "Epoch 30, loss: 2.278285\n",
      "Epoch 31, loss: 2.277611\n",
      "Epoch 32, loss: 2.276912\n",
      "Epoch 33, loss: 2.276235\n",
      "Epoch 34, loss: 2.275563\n",
      "Epoch 35, loss: 2.274905\n",
      "Epoch 36, loss: 2.274246\n",
      "Epoch 37, loss: 2.273594\n",
      "Epoch 38, loss: 2.272959\n",
      "Epoch 39, loss: 2.272293\n",
      "Epoch 40, loss: 2.271664\n",
      "Epoch 41, loss: 2.271017\n",
      "Epoch 42, loss: 2.270395\n",
      "Epoch 43, loss: 2.269771\n",
      "Epoch 44, loss: 2.269146\n",
      "Epoch 45, loss: 2.268520\n",
      "Epoch 46, loss: 2.267928\n",
      "Epoch 47, loss: 2.267299\n",
      "Epoch 48, loss: 2.266718\n",
      "Epoch 49, loss: 2.266152\n",
      "Epoch 50, loss: 2.265528\n",
      "Epoch 51, loss: 2.264945\n",
      "Epoch 52, loss: 2.264377\n",
      "Epoch 53, loss: 2.263789\n",
      "Epoch 54, loss: 2.263232\n",
      "Epoch 55, loss: 2.262637\n",
      "Epoch 56, loss: 2.262082\n",
      "Epoch 57, loss: 2.261524\n",
      "Epoch 58, loss: 2.260973\n",
      "Epoch 59, loss: 2.260408\n",
      "Epoch 60, loss: 2.259851\n",
      "Epoch 61, loss: 2.259316\n",
      "Epoch 62, loss: 2.258771\n",
      "Epoch 63, loss: 2.258250\n",
      "Epoch 64, loss: 2.257722\n",
      "Epoch 65, loss: 2.257206\n",
      "Epoch 66, loss: 2.256672\n",
      "Epoch 67, loss: 2.256137\n",
      "Epoch 68, loss: 2.255617\n",
      "Epoch 69, loss: 2.255104\n",
      "Epoch 70, loss: 2.254597\n",
      "Epoch 71, loss: 2.254101\n",
      "Epoch 72, loss: 2.253598\n",
      "Epoch 73, loss: 2.253097\n",
      "Epoch 74, loss: 2.252614\n",
      "Epoch 75, loss: 2.252090\n",
      "Epoch 76, loss: 2.251627\n",
      "Epoch 77, loss: 2.251139\n",
      "Epoch 78, loss: 2.250665\n",
      "Epoch 79, loss: 2.250190\n",
      "Epoch 80, loss: 2.249709\n",
      "Epoch 81, loss: 2.249245\n",
      "Epoch 82, loss: 2.248771\n",
      "Epoch 83, loss: 2.248313\n",
      "Epoch 84, loss: 2.247849\n",
      "Epoch 85, loss: 2.247398\n",
      "Epoch 86, loss: 2.246928\n",
      "Epoch 87, loss: 2.246489\n",
      "Epoch 88, loss: 2.246044\n",
      "Epoch 89, loss: 2.245603\n",
      "Epoch 90, loss: 2.245183\n",
      "Epoch 91, loss: 2.244717\n",
      "Epoch 92, loss: 2.244291\n",
      "Epoch 93, loss: 2.243864\n",
      "Epoch 94, loss: 2.243439\n",
      "Epoch 95, loss: 2.242990\n",
      "Epoch 96, loss: 2.242552\n",
      "Epoch 97, loss: 2.242152\n",
      "Epoch 98, loss: 2.241725\n",
      "Epoch 99, loss: 2.241323\n",
      "Epoch 100, loss: 2.240909\n",
      "Epoch 101, loss: 2.240507\n",
      "Epoch 102, loss: 2.240110\n",
      "Epoch 103, loss: 2.239695\n",
      "Epoch 104, loss: 2.239295\n",
      "Epoch 105, loss: 2.238887\n",
      "Epoch 106, loss: 2.238505\n",
      "Epoch 107, loss: 2.238121\n",
      "Epoch 108, loss: 2.237735\n",
      "Epoch 109, loss: 2.237343\n",
      "Epoch 110, loss: 2.236948\n",
      "Epoch 111, loss: 2.236577\n",
      "Epoch 112, loss: 2.236203\n",
      "Epoch 113, loss: 2.235825\n",
      "Epoch 114, loss: 2.235431\n",
      "Epoch 115, loss: 2.235074\n",
      "Epoch 116, loss: 2.234704\n",
      "Epoch 117, loss: 2.234342\n",
      "Epoch 118, loss: 2.233964\n",
      "Epoch 119, loss: 2.233598\n",
      "Epoch 120, loss: 2.233248\n",
      "Epoch 121, loss: 2.232898\n",
      "Epoch 122, loss: 2.232541\n",
      "Epoch 123, loss: 2.232193\n",
      "Epoch 124, loss: 2.231846\n",
      "Epoch 125, loss: 2.231483\n",
      "Epoch 126, loss: 2.231139\n",
      "Epoch 127, loss: 2.230825\n",
      "Epoch 128, loss: 2.230463\n",
      "Epoch 129, loss: 2.230156\n",
      "Epoch 130, loss: 2.229789\n",
      "Epoch 131, loss: 2.229463\n",
      "Epoch 132, loss: 2.229135\n",
      "Epoch 133, loss: 2.228798\n",
      "Epoch 134, loss: 2.228486\n",
      "Epoch 135, loss: 2.228174\n",
      "Epoch 136, loss: 2.227829\n",
      "Epoch 137, loss: 2.227518\n",
      "Epoch 138, loss: 2.227175\n",
      "Epoch 139, loss: 2.226880\n",
      "Epoch 140, loss: 2.226550\n",
      "Epoch 141, loss: 2.226260\n",
      "Epoch 142, loss: 2.225936\n",
      "Epoch 143, loss: 2.225634\n",
      "Epoch 144, loss: 2.225323\n",
      "Epoch 145, loss: 2.225015\n",
      "Epoch 146, loss: 2.224709\n",
      "Epoch 147, loss: 2.224418\n",
      "Epoch 148, loss: 2.224121\n",
      "Epoch 149, loss: 2.223839\n",
      "Epoch 150, loss: 2.223541\n",
      "Epoch 151, loss: 2.223258\n",
      "Epoch 152, loss: 2.222951\n",
      "Epoch 153, loss: 2.222685\n",
      "Epoch 154, loss: 2.222384\n",
      "Epoch 155, loss: 2.222102\n",
      "Epoch 156, loss: 2.221810\n",
      "Epoch 157, loss: 2.221546\n",
      "Epoch 158, loss: 2.221239\n",
      "Epoch 159, loss: 2.220977\n",
      "Epoch 160, loss: 2.220690\n",
      "Epoch 161, loss: 2.220430\n",
      "Epoch 162, loss: 2.220147\n",
      "Epoch 163, loss: 2.219884\n",
      "Epoch 164, loss: 2.219628\n",
      "Epoch 165, loss: 2.219360\n",
      "Epoch 166, loss: 2.219086\n",
      "Epoch 167, loss: 2.218816\n",
      "Epoch 168, loss: 2.218549\n",
      "Epoch 169, loss: 2.218305\n",
      "Epoch 170, loss: 2.218049\n",
      "Epoch 171, loss: 2.217787\n",
      "Epoch 172, loss: 2.217539\n",
      "Epoch 173, loss: 2.217271\n",
      "Epoch 174, loss: 2.217018\n",
      "Epoch 175, loss: 2.216773\n",
      "Epoch 176, loss: 2.216529\n",
      "Epoch 177, loss: 2.216275\n",
      "Epoch 178, loss: 2.216033\n",
      "Epoch 179, loss: 2.215784\n",
      "Epoch 180, loss: 2.215544\n",
      "Epoch 181, loss: 2.215303\n",
      "Epoch 182, loss: 2.215064\n",
      "Epoch 183, loss: 2.214825\n",
      "Epoch 184, loss: 2.214610\n",
      "Epoch 185, loss: 2.214363\n",
      "Epoch 186, loss: 2.214109\n",
      "Epoch 187, loss: 2.213889\n",
      "Epoch 188, loss: 2.213669\n",
      "Epoch 189, loss: 2.213449\n",
      "Epoch 190, loss: 2.213222\n",
      "Epoch 191, loss: 2.212975\n",
      "Epoch 192, loss: 2.212766\n",
      "Epoch 193, loss: 2.212523\n",
      "Epoch 194, loss: 2.212305\n",
      "Epoch 195, loss: 2.212079\n",
      "Epoch 196, loss: 2.211877\n",
      "Epoch 197, loss: 2.211655\n",
      "Epoch 198, loss: 2.211437\n",
      "Epoch 199, loss: 2.211225\n",
      "lr: 0.001, rs: 0.01, accuracy 200 epochs: 0.228\n",
      "Epoch 0, loss: 2.302237\n",
      "Epoch 1, loss: 2.301228\n",
      "Epoch 2, loss: 2.300249\n",
      "Epoch 3, loss: 2.299296\n",
      "Epoch 4, loss: 2.298369\n",
      "Epoch 5, loss: 2.297476\n",
      "Epoch 6, loss: 2.296611\n",
      "Epoch 7, loss: 2.295745\n",
      "Epoch 8, loss: 2.294870\n",
      "Epoch 9, loss: 2.294013\n",
      "Epoch 10, loss: 2.293168\n",
      "Epoch 11, loss: 2.292350\n",
      "Epoch 12, loss: 2.291531\n",
      "Epoch 13, loss: 2.290700\n",
      "Epoch 14, loss: 2.289886\n",
      "Epoch 15, loss: 2.289088\n",
      "Epoch 16, loss: 2.288289\n",
      "Epoch 17, loss: 2.287479\n",
      "Epoch 18, loss: 2.286715\n",
      "Epoch 19, loss: 2.285912\n",
      "Epoch 20, loss: 2.285124\n",
      "Epoch 21, loss: 2.284385\n",
      "Epoch 22, loss: 2.283622\n",
      "Epoch 23, loss: 2.282860\n",
      "Epoch 24, loss: 2.282111\n",
      "Epoch 25, loss: 2.281370\n",
      "Epoch 26, loss: 2.280621\n",
      "Epoch 27, loss: 2.279880\n",
      "Epoch 28, loss: 2.279152\n",
      "Epoch 29, loss: 2.278439\n",
      "Epoch 30, loss: 2.277725\n",
      "Epoch 31, loss: 2.277000\n",
      "Epoch 32, loss: 2.276300\n",
      "Epoch 33, loss: 2.275603\n",
      "Epoch 34, loss: 2.274904\n",
      "Epoch 35, loss: 2.274224\n",
      "Epoch 36, loss: 2.273535\n",
      "Epoch 37, loss: 2.272843\n",
      "Epoch 38, loss: 2.272150\n",
      "Epoch 39, loss: 2.271502\n",
      "Epoch 40, loss: 2.270816\n",
      "Epoch 41, loss: 2.270153\n",
      "Epoch 42, loss: 2.269501\n",
      "Epoch 43, loss: 2.268855\n",
      "Epoch 44, loss: 2.268194\n",
      "Epoch 45, loss: 2.267554\n",
      "Epoch 46, loss: 2.266932\n",
      "Epoch 47, loss: 2.266272\n",
      "Epoch 48, loss: 2.265644\n",
      "Epoch 49, loss: 2.265020\n",
      "Epoch 50, loss: 2.264405\n",
      "Epoch 51, loss: 2.263773\n",
      "Epoch 52, loss: 2.263165\n",
      "Epoch 53, loss: 2.262540\n",
      "Epoch 54, loss: 2.261930\n",
      "Epoch 55, loss: 2.261328\n",
      "Epoch 56, loss: 2.260732\n",
      "Epoch 57, loss: 2.260126\n",
      "Epoch 58, loss: 2.259535\n",
      "Epoch 59, loss: 2.258976\n",
      "Epoch 60, loss: 2.258375\n",
      "Epoch 61, loss: 2.257788\n",
      "Epoch 62, loss: 2.257212\n",
      "Epoch 63, loss: 2.256633\n",
      "Epoch 64, loss: 2.256061\n",
      "Epoch 65, loss: 2.255506\n",
      "Epoch 66, loss: 2.254945\n",
      "Epoch 67, loss: 2.254375\n",
      "Epoch 68, loss: 2.253837\n",
      "Epoch 69, loss: 2.253278\n",
      "Epoch 70, loss: 2.252719\n",
      "Epoch 71, loss: 2.252171\n",
      "Epoch 72, loss: 2.251643\n",
      "Epoch 73, loss: 2.251108\n",
      "Epoch 74, loss: 2.250562\n",
      "Epoch 75, loss: 2.250034\n",
      "Epoch 76, loss: 2.249511\n",
      "Epoch 77, loss: 2.248978\n",
      "Epoch 78, loss: 2.248447\n",
      "Epoch 79, loss: 2.247940\n",
      "Epoch 80, loss: 2.247426\n",
      "Epoch 81, loss: 2.246905\n",
      "Epoch 82, loss: 2.246395\n",
      "Epoch 83, loss: 2.245888\n",
      "Epoch 84, loss: 2.245391\n",
      "Epoch 85, loss: 2.244887\n",
      "Epoch 86, loss: 2.244399\n",
      "Epoch 87, loss: 2.243868\n",
      "Epoch 88, loss: 2.243378\n",
      "Epoch 89, loss: 2.242909\n",
      "Epoch 90, loss: 2.242432\n",
      "Epoch 91, loss: 2.241946\n",
      "Epoch 92, loss: 2.241467\n",
      "Epoch 93, loss: 2.240991\n",
      "Epoch 94, loss: 2.240510\n",
      "Epoch 95, loss: 2.240029\n",
      "Epoch 96, loss: 2.239566\n",
      "Epoch 97, loss: 2.239095\n",
      "Epoch 98, loss: 2.238644\n",
      "Epoch 99, loss: 2.238170\n",
      "Epoch 100, loss: 2.237719\n",
      "Epoch 101, loss: 2.237267\n",
      "Epoch 102, loss: 2.236807\n",
      "Epoch 103, loss: 2.236341\n",
      "Epoch 104, loss: 2.235904\n",
      "Epoch 105, loss: 2.235462\n",
      "Epoch 106, loss: 2.235028\n",
      "Epoch 107, loss: 2.234584\n",
      "Epoch 108, loss: 2.234138\n",
      "Epoch 109, loss: 2.233723\n",
      "Epoch 110, loss: 2.233274\n",
      "Epoch 111, loss: 2.232857\n",
      "Epoch 112, loss: 2.232431\n",
      "Epoch 113, loss: 2.232002\n",
      "Epoch 114, loss: 2.231581\n",
      "Epoch 115, loss: 2.231165\n",
      "Epoch 116, loss: 2.230739\n",
      "Epoch 117, loss: 2.230310\n",
      "Epoch 118, loss: 2.229925\n",
      "Epoch 119, loss: 2.229503\n",
      "Epoch 120, loss: 2.229101\n",
      "Epoch 121, loss: 2.228686\n",
      "Epoch 122, loss: 2.228292\n",
      "Epoch 123, loss: 2.227878\n",
      "Epoch 124, loss: 2.227491\n",
      "Epoch 125, loss: 2.227089\n",
      "Epoch 126, loss: 2.226696\n",
      "Epoch 127, loss: 2.226313\n",
      "Epoch 128, loss: 2.225903\n",
      "Epoch 129, loss: 2.225535\n",
      "Epoch 130, loss: 2.225129\n",
      "Epoch 131, loss: 2.224757\n",
      "Epoch 132, loss: 2.224379\n",
      "Epoch 133, loss: 2.223991\n",
      "Epoch 134, loss: 2.223624\n",
      "Epoch 135, loss: 2.223248\n",
      "Epoch 136, loss: 2.222876\n",
      "Epoch 137, loss: 2.222491\n",
      "Epoch 138, loss: 2.222130\n",
      "Epoch 139, loss: 2.221772\n",
      "Epoch 140, loss: 2.221395\n",
      "Epoch 141, loss: 2.221038\n",
      "Epoch 142, loss: 2.220674\n",
      "Epoch 143, loss: 2.220319\n",
      "Epoch 144, loss: 2.219947\n",
      "Epoch 145, loss: 2.219604\n",
      "Epoch 146, loss: 2.219255\n",
      "Epoch 147, loss: 2.218886\n",
      "Epoch 148, loss: 2.218565\n",
      "Epoch 149, loss: 2.218211\n",
      "Epoch 150, loss: 2.217858\n",
      "Epoch 151, loss: 2.217514\n",
      "Epoch 152, loss: 2.217173\n",
      "Epoch 153, loss: 2.216853\n",
      "Epoch 154, loss: 2.216492\n",
      "Epoch 155, loss: 2.216150\n",
      "Epoch 156, loss: 2.215815\n",
      "Epoch 157, loss: 2.215491\n",
      "Epoch 158, loss: 2.215177\n",
      "Epoch 159, loss: 2.214838\n",
      "Epoch 160, loss: 2.214510\n",
      "Epoch 161, loss: 2.214196\n",
      "Epoch 162, loss: 2.213866\n",
      "Epoch 163, loss: 2.213542\n",
      "Epoch 164, loss: 2.213225\n",
      "Epoch 165, loss: 2.212901\n",
      "Epoch 166, loss: 2.212579\n",
      "Epoch 167, loss: 2.212282\n",
      "Epoch 168, loss: 2.211954\n",
      "Epoch 169, loss: 2.211643\n",
      "Epoch 170, loss: 2.211349\n",
      "Epoch 171, loss: 2.211044\n",
      "Epoch 172, loss: 2.210727\n",
      "Epoch 173, loss: 2.210420\n",
      "Epoch 174, loss: 2.210120\n",
      "Epoch 175, loss: 2.209809\n",
      "Epoch 176, loss: 2.209511\n",
      "Epoch 177, loss: 2.209214\n",
      "Epoch 178, loss: 2.208945\n",
      "Epoch 179, loss: 2.208634\n",
      "Epoch 180, loss: 2.208338\n",
      "Epoch 181, loss: 2.208050\n",
      "Epoch 182, loss: 2.207745\n",
      "Epoch 183, loss: 2.207457\n",
      "Epoch 184, loss: 2.207177\n",
      "Epoch 185, loss: 2.206902\n",
      "Epoch 186, loss: 2.206586\n",
      "Epoch 187, loss: 2.206316\n",
      "Epoch 188, loss: 2.206039\n",
      "Epoch 189, loss: 2.205762\n",
      "Epoch 190, loss: 2.205467\n",
      "Epoch 191, loss: 2.205193\n",
      "Epoch 192, loss: 2.204928\n",
      "Epoch 193, loss: 2.204662\n",
      "Epoch 194, loss: 2.204383\n",
      "Epoch 195, loss: 2.204119\n",
      "Epoch 196, loss: 2.203835\n",
      "Epoch 197, loss: 2.203569\n",
      "Epoch 198, loss: 2.203294\n",
      "Epoch 199, loss: 2.203036\n",
      "lr: 0.001, rs: 0.001, accuracy 200 epochs: 0.228\n",
      "Epoch 0, loss: 2.302107\n",
      "Epoch 1, loss: 2.301037\n",
      "Epoch 2, loss: 2.300034\n",
      "Epoch 3, loss: 2.299080\n",
      "Epoch 4, loss: 2.298162\n",
      "Epoch 5, loss: 2.297243\n",
      "Epoch 6, loss: 2.296368\n",
      "Epoch 7, loss: 2.295504\n",
      "Epoch 8, loss: 2.294641\n",
      "Epoch 9, loss: 2.293763\n",
      "Epoch 10, loss: 2.292924\n",
      "Epoch 11, loss: 2.292091\n",
      "Epoch 12, loss: 2.291273\n",
      "Epoch 13, loss: 2.290460\n",
      "Epoch 14, loss: 2.289644\n",
      "Epoch 15, loss: 2.288851\n",
      "Epoch 16, loss: 2.288007\n",
      "Epoch 17, loss: 2.287237\n",
      "Epoch 18, loss: 2.286435\n",
      "Epoch 19, loss: 2.285661\n",
      "Epoch 20, loss: 2.284887\n",
      "Epoch 21, loss: 2.284109\n",
      "Epoch 22, loss: 2.283341\n",
      "Epoch 23, loss: 2.282595\n",
      "Epoch 24, loss: 2.281844\n",
      "Epoch 25, loss: 2.281079\n",
      "Epoch 26, loss: 2.280359\n",
      "Epoch 27, loss: 2.279618\n",
      "Epoch 28, loss: 2.278895\n",
      "Epoch 29, loss: 2.278159\n",
      "Epoch 30, loss: 2.277421\n",
      "Epoch 31, loss: 2.276732\n",
      "Epoch 32, loss: 2.276009\n",
      "Epoch 33, loss: 2.275300\n",
      "Epoch 34, loss: 2.274603\n",
      "Epoch 35, loss: 2.273927\n",
      "Epoch 36, loss: 2.273233\n",
      "Epoch 37, loss: 2.272547\n",
      "Epoch 38, loss: 2.271851\n",
      "Epoch 39, loss: 2.271192\n",
      "Epoch 40, loss: 2.270512\n",
      "Epoch 41, loss: 2.269873\n",
      "Epoch 42, loss: 2.269200\n",
      "Epoch 43, loss: 2.268532\n",
      "Epoch 44, loss: 2.267885\n",
      "Epoch 45, loss: 2.267251\n",
      "Epoch 46, loss: 2.266601\n",
      "Epoch 47, loss: 2.265958\n",
      "Epoch 48, loss: 2.265326\n",
      "Epoch 49, loss: 2.264696\n",
      "Epoch 50, loss: 2.264068\n",
      "Epoch 51, loss: 2.263447\n",
      "Epoch 52, loss: 2.262829\n",
      "Epoch 53, loss: 2.262219\n",
      "Epoch 54, loss: 2.261611\n",
      "Epoch 55, loss: 2.260986\n",
      "Epoch 56, loss: 2.260387\n",
      "Epoch 57, loss: 2.259781\n",
      "Epoch 58, loss: 2.259188\n",
      "Epoch 59, loss: 2.258588\n",
      "Epoch 60, loss: 2.258015\n",
      "Epoch 61, loss: 2.257433\n",
      "Epoch 62, loss: 2.256861\n",
      "Epoch 63, loss: 2.256264\n",
      "Epoch 64, loss: 2.255680\n",
      "Epoch 65, loss: 2.255129\n",
      "Epoch 66, loss: 2.254569\n",
      "Epoch 67, loss: 2.254003\n",
      "Epoch 68, loss: 2.253455\n",
      "Epoch 69, loss: 2.252893\n",
      "Epoch 70, loss: 2.252350\n",
      "Epoch 71, loss: 2.251788\n",
      "Epoch 72, loss: 2.251239\n",
      "Epoch 73, loss: 2.250689\n",
      "Epoch 74, loss: 2.250165\n",
      "Epoch 75, loss: 2.249623\n",
      "Epoch 76, loss: 2.249101\n",
      "Epoch 77, loss: 2.248567\n",
      "Epoch 78, loss: 2.248043\n",
      "Epoch 79, loss: 2.247517\n",
      "Epoch 80, loss: 2.246999\n",
      "Epoch 81, loss: 2.246489\n",
      "Epoch 82, loss: 2.245962\n",
      "Epoch 83, loss: 2.245471\n",
      "Epoch 84, loss: 2.244960\n",
      "Epoch 85, loss: 2.244457\n",
      "Epoch 86, loss: 2.243937\n",
      "Epoch 87, loss: 2.243450\n",
      "Epoch 88, loss: 2.242946\n",
      "Epoch 89, loss: 2.242465\n",
      "Epoch 90, loss: 2.241962\n",
      "Epoch 91, loss: 2.241488\n",
      "Epoch 92, loss: 2.241004\n",
      "Epoch 93, loss: 2.240524\n",
      "Epoch 94, loss: 2.240035\n",
      "Epoch 95, loss: 2.239559\n",
      "Epoch 96, loss: 2.239093\n",
      "Epoch 97, loss: 2.238622\n",
      "Epoch 98, loss: 2.238162\n",
      "Epoch 99, loss: 2.237677\n",
      "Epoch 100, loss: 2.237216\n",
      "Epoch 101, loss: 2.236755\n",
      "Epoch 102, loss: 2.236315\n",
      "Epoch 103, loss: 2.235868\n",
      "Epoch 104, loss: 2.235416\n",
      "Epoch 105, loss: 2.234944\n",
      "Epoch 106, loss: 2.234507\n",
      "Epoch 107, loss: 2.234048\n",
      "Epoch 108, loss: 2.233602\n",
      "Epoch 109, loss: 2.233186\n",
      "Epoch 110, loss: 2.232734\n",
      "Epoch 111, loss: 2.232309\n",
      "Epoch 112, loss: 2.231884\n",
      "Epoch 113, loss: 2.231458\n",
      "Epoch 114, loss: 2.231034\n",
      "Epoch 115, loss: 2.230587\n",
      "Epoch 116, loss: 2.230182\n",
      "Epoch 117, loss: 2.229751\n",
      "Epoch 118, loss: 2.229335\n",
      "Epoch 119, loss: 2.228950\n",
      "Epoch 120, loss: 2.228514\n",
      "Epoch 121, loss: 2.228105\n",
      "Epoch 122, loss: 2.227680\n",
      "Epoch 123, loss: 2.227277\n",
      "Epoch 124, loss: 2.226887\n",
      "Epoch 125, loss: 2.226478\n",
      "Epoch 126, loss: 2.226081\n",
      "Epoch 127, loss: 2.225685\n",
      "Epoch 128, loss: 2.225280\n",
      "Epoch 129, loss: 2.224887\n",
      "Epoch 130, loss: 2.224505\n",
      "Epoch 131, loss: 2.224109\n",
      "Epoch 132, loss: 2.223730\n",
      "Epoch 133, loss: 2.223346\n",
      "Epoch 134, loss: 2.222982\n",
      "Epoch 135, loss: 2.222590\n",
      "Epoch 136, loss: 2.222200\n",
      "Epoch 137, loss: 2.221834\n",
      "Epoch 138, loss: 2.221472\n",
      "Epoch 139, loss: 2.221084\n",
      "Epoch 140, loss: 2.220703\n",
      "Epoch 141, loss: 2.220336\n",
      "Epoch 142, loss: 2.219988\n",
      "Epoch 143, loss: 2.219608\n",
      "Epoch 144, loss: 2.219253\n",
      "Epoch 145, loss: 2.218902\n",
      "Epoch 146, loss: 2.218533\n",
      "Epoch 147, loss: 2.218173\n",
      "Epoch 148, loss: 2.217835\n",
      "Epoch 149, loss: 2.217462\n",
      "Epoch 150, loss: 2.217131\n",
      "Epoch 151, loss: 2.216769\n",
      "Epoch 152, loss: 2.216451\n",
      "Epoch 153, loss: 2.216099\n",
      "Epoch 154, loss: 2.215740\n",
      "Epoch 155, loss: 2.215414\n",
      "Epoch 156, loss: 2.215056\n",
      "Epoch 157, loss: 2.214720\n",
      "Epoch 158, loss: 2.214400\n",
      "Epoch 159, loss: 2.214062\n",
      "Epoch 160, loss: 2.213705\n",
      "Epoch 161, loss: 2.213411\n",
      "Epoch 162, loss: 2.213066\n",
      "Epoch 163, loss: 2.212738\n",
      "Epoch 164, loss: 2.212426\n",
      "Epoch 165, loss: 2.212091\n",
      "Epoch 166, loss: 2.211761\n",
      "Epoch 167, loss: 2.211450\n",
      "Epoch 168, loss: 2.211129\n",
      "Epoch 169, loss: 2.210831\n",
      "Epoch 170, loss: 2.210505\n",
      "Epoch 171, loss: 2.210183\n",
      "Epoch 172, loss: 2.209876\n",
      "Epoch 173, loss: 2.209583\n",
      "Epoch 174, loss: 2.209262\n",
      "Epoch 175, loss: 2.208950\n",
      "Epoch 176, loss: 2.208656\n",
      "Epoch 177, loss: 2.208333\n",
      "Epoch 178, loss: 2.208042\n",
      "Epoch 179, loss: 2.207746\n",
      "Epoch 180, loss: 2.207445\n",
      "Epoch 181, loss: 2.207153\n",
      "Epoch 182, loss: 2.206855\n",
      "Epoch 183, loss: 2.206559\n",
      "Epoch 184, loss: 2.206266\n",
      "Epoch 185, loss: 2.205962\n",
      "Epoch 186, loss: 2.205686\n",
      "Epoch 187, loss: 2.205391\n",
      "Epoch 188, loss: 2.205109\n",
      "Epoch 189, loss: 2.204815\n",
      "Epoch 190, loss: 2.204538\n",
      "Epoch 191, loss: 2.204246\n",
      "Epoch 192, loss: 2.203966\n",
      "Epoch 193, loss: 2.203681\n",
      "Epoch 194, loss: 2.203417\n",
      "Epoch 195, loss: 2.203129\n",
      "Epoch 196, loss: 2.202858\n",
      "Epoch 197, loss: 2.202602\n",
      "Epoch 198, loss: 2.202311\n",
      "Epoch 199, loss: 2.202047\n",
      "lr: 0.001, rs: 0.0001, accuracy 200 epochs: 0.227\n",
      "Epoch 0, loss: 2.302680\n",
      "Epoch 1, loss: 2.301636\n",
      "Epoch 2, loss: 2.300664\n",
      "Epoch 3, loss: 2.299706\n",
      "Epoch 4, loss: 2.298763\n",
      "Epoch 5, loss: 2.297868\n",
      "Epoch 6, loss: 2.296969\n",
      "Epoch 7, loss: 2.296098\n",
      "Epoch 8, loss: 2.295228\n",
      "Epoch 9, loss: 2.294377\n",
      "Epoch 10, loss: 2.293531\n",
      "Epoch 11, loss: 2.292704\n",
      "Epoch 12, loss: 2.291864\n",
      "Epoch 13, loss: 2.291061\n",
      "Epoch 14, loss: 2.290228\n",
      "Epoch 15, loss: 2.289421\n",
      "Epoch 16, loss: 2.288630\n",
      "Epoch 17, loss: 2.287844\n",
      "Epoch 18, loss: 2.287029\n",
      "Epoch 19, loss: 2.286231\n",
      "Epoch 20, loss: 2.285454\n",
      "Epoch 21, loss: 2.284696\n",
      "Epoch 22, loss: 2.283928\n",
      "Epoch 23, loss: 2.283182\n",
      "Epoch 24, loss: 2.282411\n",
      "Epoch 25, loss: 2.281659\n",
      "Epoch 26, loss: 2.280919\n",
      "Epoch 27, loss: 2.280175\n",
      "Epoch 28, loss: 2.279446\n",
      "Epoch 29, loss: 2.278724\n",
      "Epoch 30, loss: 2.277984\n",
      "Epoch 31, loss: 2.277282\n",
      "Epoch 32, loss: 2.276548\n",
      "Epoch 33, loss: 2.275868\n",
      "Epoch 34, loss: 2.275164\n",
      "Epoch 35, loss: 2.274465\n",
      "Epoch 36, loss: 2.273787\n",
      "Epoch 37, loss: 2.273077\n",
      "Epoch 38, loss: 2.272398\n",
      "Epoch 39, loss: 2.271717\n",
      "Epoch 40, loss: 2.271043\n",
      "Epoch 41, loss: 2.270375\n",
      "Epoch 42, loss: 2.269719\n",
      "Epoch 43, loss: 2.269060\n",
      "Epoch 44, loss: 2.268409\n",
      "Epoch 45, loss: 2.267748\n",
      "Epoch 46, loss: 2.267118\n",
      "Epoch 47, loss: 2.266459\n",
      "Epoch 48, loss: 2.265827\n",
      "Epoch 49, loss: 2.265194\n",
      "Epoch 50, loss: 2.264587\n",
      "Epoch 51, loss: 2.263945\n",
      "Epoch 52, loss: 2.263328\n",
      "Epoch 53, loss: 2.262708\n",
      "Epoch 54, loss: 2.262095\n",
      "Epoch 55, loss: 2.261476\n",
      "Epoch 56, loss: 2.260864\n",
      "Epoch 57, loss: 2.260270\n",
      "Epoch 58, loss: 2.259669\n",
      "Epoch 59, loss: 2.259069\n",
      "Epoch 60, loss: 2.258498\n",
      "Epoch 61, loss: 2.257918\n",
      "Epoch 62, loss: 2.257322\n",
      "Epoch 63, loss: 2.256753\n",
      "Epoch 64, loss: 2.256175\n",
      "Epoch 65, loss: 2.255605\n",
      "Epoch 66, loss: 2.255020\n",
      "Epoch 67, loss: 2.254487\n",
      "Epoch 68, loss: 2.253921\n",
      "Epoch 69, loss: 2.253356\n",
      "Epoch 70, loss: 2.252781\n",
      "Epoch 71, loss: 2.252234\n",
      "Epoch 72, loss: 2.251692\n",
      "Epoch 73, loss: 2.251148\n",
      "Epoch 74, loss: 2.250602\n",
      "Epoch 75, loss: 2.250077\n",
      "Epoch 76, loss: 2.249521\n",
      "Epoch 77, loss: 2.249004\n",
      "Epoch 78, loss: 2.248464\n",
      "Epoch 79, loss: 2.247957\n",
      "Epoch 80, loss: 2.247432\n",
      "Epoch 81, loss: 2.246909\n",
      "Epoch 82, loss: 2.246394\n",
      "Epoch 83, loss: 2.245882\n",
      "Epoch 84, loss: 2.245366\n",
      "Epoch 85, loss: 2.244880\n",
      "Epoch 86, loss: 2.244359\n",
      "Epoch 87, loss: 2.243849\n",
      "Epoch 88, loss: 2.243347\n",
      "Epoch 89, loss: 2.242854\n",
      "Epoch 90, loss: 2.242379\n",
      "Epoch 91, loss: 2.241880\n",
      "Epoch 92, loss: 2.241421\n",
      "Epoch 93, loss: 2.240920\n",
      "Epoch 94, loss: 2.240432\n",
      "Epoch 95, loss: 2.239955\n",
      "Epoch 96, loss: 2.239491\n",
      "Epoch 97, loss: 2.239009\n",
      "Epoch 98, loss: 2.238544\n",
      "Epoch 99, loss: 2.238064\n",
      "Epoch 100, loss: 2.237609\n",
      "Epoch 101, loss: 2.237154\n",
      "Epoch 102, loss: 2.236685\n",
      "Epoch 103, loss: 2.236233\n",
      "Epoch 104, loss: 2.235768\n",
      "Epoch 105, loss: 2.235336\n",
      "Epoch 106, loss: 2.234877\n",
      "Epoch 107, loss: 2.234427\n",
      "Epoch 108, loss: 2.233992\n",
      "Epoch 109, loss: 2.233554\n",
      "Epoch 110, loss: 2.233103\n",
      "Epoch 111, loss: 2.232675\n",
      "Epoch 112, loss: 2.232236\n",
      "Epoch 113, loss: 2.231806\n",
      "Epoch 114, loss: 2.231398\n",
      "Epoch 115, loss: 2.230950\n",
      "Epoch 116, loss: 2.230528\n",
      "Epoch 117, loss: 2.230124\n",
      "Epoch 118, loss: 2.229667\n",
      "Epoch 119, loss: 2.229274\n",
      "Epoch 120, loss: 2.228859\n",
      "Epoch 121, loss: 2.228426\n",
      "Epoch 122, loss: 2.228018\n",
      "Epoch 123, loss: 2.227616\n",
      "Epoch 124, loss: 2.227214\n",
      "Epoch 125, loss: 2.226811\n",
      "Epoch 126, loss: 2.226415\n",
      "Epoch 127, loss: 2.226027\n",
      "Epoch 128, loss: 2.225618\n",
      "Epoch 129, loss: 2.225210\n",
      "Epoch 130, loss: 2.224845\n",
      "Epoch 131, loss: 2.224437\n",
      "Epoch 132, loss: 2.224048\n",
      "Epoch 133, loss: 2.223665\n",
      "Epoch 134, loss: 2.223284\n",
      "Epoch 135, loss: 2.222915\n",
      "Epoch 136, loss: 2.222520\n",
      "Epoch 137, loss: 2.222147\n",
      "Epoch 138, loss: 2.221771\n",
      "Epoch 139, loss: 2.221400\n",
      "Epoch 140, loss: 2.221018\n",
      "Epoch 141, loss: 2.220655\n",
      "Epoch 142, loss: 2.220285\n",
      "Epoch 143, loss: 2.219905\n",
      "Epoch 144, loss: 2.219564\n",
      "Epoch 145, loss: 2.219198\n",
      "Epoch 146, loss: 2.218838\n",
      "Epoch 147, loss: 2.218488\n",
      "Epoch 148, loss: 2.218122\n",
      "Epoch 149, loss: 2.217768\n",
      "Epoch 150, loss: 2.217406\n",
      "Epoch 151, loss: 2.217093\n",
      "Epoch 152, loss: 2.216716\n",
      "Epoch 153, loss: 2.216384\n",
      "Epoch 154, loss: 2.216048\n",
      "Epoch 155, loss: 2.215691\n",
      "Epoch 156, loss: 2.215345\n",
      "Epoch 157, loss: 2.215007\n",
      "Epoch 158, loss: 2.214675\n",
      "Epoch 159, loss: 2.214328\n",
      "Epoch 160, loss: 2.214003\n",
      "Epoch 161, loss: 2.213665\n",
      "Epoch 162, loss: 2.213327\n",
      "Epoch 163, loss: 2.213009\n",
      "Epoch 164, loss: 2.212694\n",
      "Epoch 165, loss: 2.212359\n",
      "Epoch 166, loss: 2.212028\n",
      "Epoch 167, loss: 2.211723\n",
      "Epoch 168, loss: 2.211377\n",
      "Epoch 169, loss: 2.211072\n",
      "Epoch 170, loss: 2.210784\n",
      "Epoch 171, loss: 2.210444\n",
      "Epoch 172, loss: 2.210141\n",
      "Epoch 173, loss: 2.209810\n",
      "Epoch 174, loss: 2.209511\n",
      "Epoch 175, loss: 2.209195\n",
      "Epoch 176, loss: 2.208886\n",
      "Epoch 177, loss: 2.208580\n",
      "Epoch 178, loss: 2.208297\n",
      "Epoch 179, loss: 2.207988\n",
      "Epoch 180, loss: 2.207679\n",
      "Epoch 181, loss: 2.207373\n",
      "Epoch 182, loss: 2.207081\n",
      "Epoch 183, loss: 2.206789\n",
      "Epoch 184, loss: 2.206511\n",
      "Epoch 185, loss: 2.206198\n",
      "Epoch 186, loss: 2.205910\n",
      "Epoch 187, loss: 2.205634\n",
      "Epoch 188, loss: 2.205338\n",
      "Epoch 189, loss: 2.205047\n",
      "Epoch 190, loss: 2.204760\n",
      "Epoch 191, loss: 2.204470\n",
      "Epoch 192, loss: 2.204197\n",
      "Epoch 193, loss: 2.203908\n",
      "Epoch 194, loss: 2.203638\n",
      "Epoch 195, loss: 2.203352\n",
      "Epoch 196, loss: 2.203076\n",
      "Epoch 197, loss: 2.202802\n",
      "Epoch 198, loss: 2.202520\n",
      "Epoch 199, loss: 2.202248\n",
      "lr: 0.001, rs: 1e-05, accuracy 200 epochs: 0.228\n",
      "Epoch 0, loss: 2.302260\n",
      "Epoch 1, loss: 2.301199\n",
      "Epoch 2, loss: 2.300164\n",
      "Epoch 3, loss: 2.299214\n",
      "Epoch 4, loss: 2.298263\n",
      "Epoch 5, loss: 2.297346\n",
      "Epoch 6, loss: 2.296467\n",
      "Epoch 7, loss: 2.295589\n",
      "Epoch 8, loss: 2.294736\n",
      "Epoch 9, loss: 2.293884\n",
      "Epoch 10, loss: 2.293029\n",
      "Epoch 11, loss: 2.292181\n",
      "Epoch 12, loss: 2.291369\n",
      "Epoch 13, loss: 2.290540\n",
      "Epoch 14, loss: 2.289736\n",
      "Epoch 15, loss: 2.288936\n",
      "Epoch 16, loss: 2.288136\n",
      "Epoch 17, loss: 2.287320\n",
      "Epoch 18, loss: 2.286568\n",
      "Epoch 19, loss: 2.285765\n",
      "Epoch 20, loss: 2.284998\n",
      "Epoch 21, loss: 2.284233\n",
      "Epoch 22, loss: 2.283469\n",
      "Epoch 23, loss: 2.282682\n",
      "Epoch 24, loss: 2.281967\n",
      "Epoch 25, loss: 2.281245\n",
      "Epoch 26, loss: 2.280458\n",
      "Epoch 27, loss: 2.279732\n",
      "Epoch 28, loss: 2.279003\n",
      "Epoch 29, loss: 2.278281\n",
      "Epoch 30, loss: 2.277582\n",
      "Epoch 31, loss: 2.276859\n",
      "Epoch 32, loss: 2.276150\n",
      "Epoch 33, loss: 2.275445\n",
      "Epoch 34, loss: 2.274736\n",
      "Epoch 35, loss: 2.274034\n",
      "Epoch 36, loss: 2.273354\n",
      "Epoch 37, loss: 2.272680\n",
      "Epoch 38, loss: 2.271993\n",
      "Epoch 39, loss: 2.271304\n",
      "Epoch 40, loss: 2.270646\n",
      "Epoch 41, loss: 2.269975\n",
      "Epoch 42, loss: 2.269317\n",
      "Epoch 43, loss: 2.268655\n",
      "Epoch 44, loss: 2.268023\n",
      "Epoch 45, loss: 2.267373\n",
      "Epoch 46, loss: 2.266709\n",
      "Epoch 47, loss: 2.266074\n",
      "Epoch 48, loss: 2.265444\n",
      "Epoch 49, loss: 2.264803\n",
      "Epoch 50, loss: 2.264168\n",
      "Epoch 51, loss: 2.263558\n",
      "Epoch 52, loss: 2.262945\n",
      "Epoch 53, loss: 2.262340\n",
      "Epoch 54, loss: 2.261706\n",
      "Epoch 55, loss: 2.261093\n",
      "Epoch 56, loss: 2.260506\n",
      "Epoch 57, loss: 2.259897\n",
      "Epoch 58, loss: 2.259308\n",
      "Epoch 59, loss: 2.258712\n",
      "Epoch 60, loss: 2.258112\n",
      "Epoch 61, loss: 2.257559\n",
      "Epoch 62, loss: 2.256975\n",
      "Epoch 63, loss: 2.256377\n",
      "Epoch 64, loss: 2.255815\n",
      "Epoch 65, loss: 2.255236\n",
      "Epoch 66, loss: 2.254687\n",
      "Epoch 67, loss: 2.254112\n",
      "Epoch 68, loss: 2.253549\n",
      "Epoch 69, loss: 2.252977\n",
      "Epoch 70, loss: 2.252442\n",
      "Epoch 71, loss: 2.251894\n",
      "Epoch 72, loss: 2.251343\n",
      "Epoch 73, loss: 2.250807\n",
      "Epoch 74, loss: 2.250260\n",
      "Epoch 75, loss: 2.249722\n",
      "Epoch 76, loss: 2.249191\n",
      "Epoch 77, loss: 2.248656\n",
      "Epoch 78, loss: 2.248141\n",
      "Epoch 79, loss: 2.247618\n",
      "Epoch 80, loss: 2.247097\n",
      "Epoch 81, loss: 2.246568\n",
      "Epoch 82, loss: 2.246060\n",
      "Epoch 83, loss: 2.245549\n",
      "Epoch 84, loss: 2.245041\n",
      "Epoch 85, loss: 2.244525\n",
      "Epoch 86, loss: 2.244021\n",
      "Epoch 87, loss: 2.243536\n",
      "Epoch 88, loss: 2.243042\n",
      "Epoch 89, loss: 2.242542\n",
      "Epoch 90, loss: 2.242043\n",
      "Epoch 91, loss: 2.241563\n",
      "Epoch 92, loss: 2.241071\n",
      "Epoch 93, loss: 2.240586\n",
      "Epoch 94, loss: 2.240108\n",
      "Epoch 95, loss: 2.239627\n",
      "Epoch 96, loss: 2.239146\n",
      "Epoch 97, loss: 2.238692\n",
      "Epoch 98, loss: 2.238227\n",
      "Epoch 99, loss: 2.237758\n",
      "Epoch 100, loss: 2.237302\n",
      "Epoch 101, loss: 2.236830\n",
      "Epoch 102, loss: 2.236378\n",
      "Epoch 103, loss: 2.235927\n",
      "Epoch 104, loss: 2.235492\n",
      "Epoch 105, loss: 2.235012\n",
      "Epoch 106, loss: 2.234556\n",
      "Epoch 107, loss: 2.234143\n",
      "Epoch 108, loss: 2.233680\n",
      "Epoch 109, loss: 2.233245\n",
      "Epoch 110, loss: 2.232802\n",
      "Epoch 111, loss: 2.232358\n",
      "Epoch 112, loss: 2.231930\n",
      "Epoch 113, loss: 2.231494\n",
      "Epoch 114, loss: 2.231056\n",
      "Epoch 115, loss: 2.230651\n",
      "Epoch 116, loss: 2.230219\n",
      "Epoch 117, loss: 2.229799\n",
      "Epoch 118, loss: 2.229431\n",
      "Epoch 119, loss: 2.228976\n",
      "Epoch 120, loss: 2.228563\n",
      "Epoch 121, loss: 2.228144\n",
      "Epoch 122, loss: 2.227730\n",
      "Epoch 123, loss: 2.227328\n",
      "Epoch 124, loss: 2.226921\n",
      "Epoch 125, loss: 2.226518\n",
      "Epoch 126, loss: 2.226116\n",
      "Epoch 127, loss: 2.225721\n",
      "Epoch 128, loss: 2.225337\n",
      "Epoch 129, loss: 2.224934\n",
      "Epoch 130, loss: 2.224542\n",
      "Epoch 131, loss: 2.224151\n",
      "Epoch 132, loss: 2.223777\n",
      "Epoch 133, loss: 2.223386\n",
      "Epoch 134, loss: 2.223004\n",
      "Epoch 135, loss: 2.222621\n",
      "Epoch 136, loss: 2.222238\n",
      "Epoch 137, loss: 2.221861\n",
      "Epoch 138, loss: 2.221476\n",
      "Epoch 139, loss: 2.221114\n",
      "Epoch 140, loss: 2.220753\n",
      "Epoch 141, loss: 2.220383\n",
      "Epoch 142, loss: 2.219998\n",
      "Epoch 143, loss: 2.219634\n",
      "Epoch 144, loss: 2.219279\n",
      "Epoch 145, loss: 2.218923\n",
      "Epoch 146, loss: 2.218574\n",
      "Epoch 147, loss: 2.218199\n",
      "Epoch 148, loss: 2.217865\n",
      "Epoch 149, loss: 2.217482\n",
      "Epoch 150, loss: 2.217152\n",
      "Epoch 151, loss: 2.216789\n",
      "Epoch 152, loss: 2.216452\n",
      "Epoch 153, loss: 2.216109\n",
      "Epoch 154, loss: 2.215754\n",
      "Epoch 155, loss: 2.215413\n",
      "Epoch 156, loss: 2.215081\n",
      "Epoch 157, loss: 2.214748\n",
      "Epoch 158, loss: 2.214409\n",
      "Epoch 159, loss: 2.214075\n",
      "Epoch 160, loss: 2.213748\n",
      "Epoch 161, loss: 2.213433\n",
      "Epoch 162, loss: 2.213087\n",
      "Epoch 163, loss: 2.212742\n",
      "Epoch 164, loss: 2.212430\n",
      "Epoch 165, loss: 2.212103\n",
      "Epoch 166, loss: 2.211782\n",
      "Epoch 167, loss: 2.211460\n",
      "Epoch 168, loss: 2.211126\n",
      "Epoch 169, loss: 2.210813\n",
      "Epoch 170, loss: 2.210508\n",
      "Epoch 171, loss: 2.210182\n",
      "Epoch 172, loss: 2.209869\n",
      "Epoch 173, loss: 2.209572\n",
      "Epoch 174, loss: 2.209258\n",
      "Epoch 175, loss: 2.208951\n",
      "Epoch 176, loss: 2.208631\n",
      "Epoch 177, loss: 2.208350\n",
      "Epoch 178, loss: 2.208038\n",
      "Epoch 179, loss: 2.207739\n",
      "Epoch 180, loss: 2.207431\n",
      "Epoch 181, loss: 2.207143\n",
      "Epoch 182, loss: 2.206826\n",
      "Epoch 183, loss: 2.206540\n",
      "Epoch 184, loss: 2.206241\n",
      "Epoch 185, loss: 2.205968\n",
      "Epoch 186, loss: 2.205665\n",
      "Epoch 187, loss: 2.205378\n",
      "Epoch 188, loss: 2.205096\n",
      "Epoch 189, loss: 2.204797\n",
      "Epoch 190, loss: 2.204518\n",
      "Epoch 191, loss: 2.204245\n",
      "Epoch 192, loss: 2.203969\n",
      "Epoch 193, loss: 2.203692\n",
      "Epoch 194, loss: 2.203406\n",
      "Epoch 195, loss: 2.203099\n",
      "Epoch 196, loss: 2.202846\n",
      "Epoch 197, loss: 2.202549\n",
      "Epoch 198, loss: 2.202294\n",
      "Epoch 199, loss: 2.202021\n",
      "lr: 0.001, rs: 1e-06, accuracy 200 epochs: 0.228\n",
      "Epoch 0, loss: 2.306018\n",
      "Epoch 1, loss: 2.305898\n",
      "Epoch 2, loss: 2.305784\n",
      "Epoch 3, loss: 2.305670\n",
      "Epoch 4, loss: 2.305555\n",
      "Epoch 5, loss: 2.305443\n",
      "Epoch 6, loss: 2.305333\n",
      "Epoch 7, loss: 2.305219\n",
      "Epoch 8, loss: 2.305109\n",
      "Epoch 9, loss: 2.305001\n",
      "Epoch 10, loss: 2.304893\n",
      "Epoch 11, loss: 2.304785\n",
      "Epoch 12, loss: 2.304678\n",
      "Epoch 13, loss: 2.304574\n",
      "Epoch 14, loss: 2.304466\n",
      "Epoch 15, loss: 2.304362\n",
      "Epoch 16, loss: 2.304258\n",
      "Epoch 17, loss: 2.304154\n",
      "Epoch 18, loss: 2.304052\n",
      "Epoch 19, loss: 2.303952\n",
      "Epoch 20, loss: 2.303849\n",
      "Epoch 21, loss: 2.303747\n",
      "Epoch 22, loss: 2.303647\n",
      "Epoch 23, loss: 2.303547\n",
      "Epoch 24, loss: 2.303447\n",
      "Epoch 25, loss: 2.303350\n",
      "Epoch 26, loss: 2.303252\n",
      "Epoch 27, loss: 2.303153\n",
      "Epoch 28, loss: 2.303057\n",
      "Epoch 29, loss: 2.302958\n",
      "Epoch 30, loss: 2.302862\n",
      "Epoch 31, loss: 2.302766\n",
      "Epoch 32, loss: 2.302672\n",
      "Epoch 33, loss: 2.302577\n",
      "Epoch 34, loss: 2.302482\n",
      "Epoch 35, loss: 2.302388\n",
      "Epoch 36, loss: 2.302293\n",
      "Epoch 37, loss: 2.302201\n",
      "Epoch 38, loss: 2.302105\n",
      "Epoch 39, loss: 2.302015\n",
      "Epoch 40, loss: 2.301920\n",
      "Epoch 41, loss: 2.301829\n",
      "Epoch 42, loss: 2.301736\n",
      "Epoch 43, loss: 2.301645\n",
      "Epoch 44, loss: 2.301555\n",
      "Epoch 45, loss: 2.301464\n",
      "Epoch 46, loss: 2.301375\n",
      "Epoch 47, loss: 2.301282\n",
      "Epoch 48, loss: 2.301191\n",
      "Epoch 49, loss: 2.301102\n",
      "Epoch 50, loss: 2.301015\n",
      "Epoch 51, loss: 2.300926\n",
      "Epoch 52, loss: 2.300837\n",
      "Epoch 53, loss: 2.300747\n",
      "Epoch 54, loss: 2.300659\n",
      "Epoch 55, loss: 2.300572\n",
      "Epoch 56, loss: 2.300484\n",
      "Epoch 57, loss: 2.300395\n",
      "Epoch 58, loss: 2.300310\n",
      "Epoch 59, loss: 2.300221\n",
      "Epoch 60, loss: 2.300137\n",
      "Epoch 61, loss: 2.300047\n",
      "Epoch 62, loss: 2.299961\n",
      "Epoch 63, loss: 2.299876\n",
      "Epoch 64, loss: 2.299790\n",
      "Epoch 65, loss: 2.299707\n",
      "Epoch 66, loss: 2.299620\n",
      "Epoch 67, loss: 2.299534\n",
      "Epoch 68, loss: 2.299448\n",
      "Epoch 69, loss: 2.299365\n",
      "Epoch 70, loss: 2.299281\n",
      "Epoch 71, loss: 2.299198\n",
      "Epoch 72, loss: 2.299112\n",
      "Epoch 73, loss: 2.299028\n",
      "Epoch 74, loss: 2.298942\n",
      "Epoch 75, loss: 2.298861\n",
      "Epoch 76, loss: 2.298777\n",
      "Epoch 77, loss: 2.298695\n",
      "Epoch 78, loss: 2.298611\n",
      "Epoch 79, loss: 2.298527\n",
      "Epoch 80, loss: 2.298445\n",
      "Epoch 81, loss: 2.298365\n",
      "Epoch 82, loss: 2.298284\n",
      "Epoch 83, loss: 2.298201\n",
      "Epoch 84, loss: 2.298119\n",
      "Epoch 85, loss: 2.298039\n",
      "Epoch 86, loss: 2.297955\n",
      "Epoch 87, loss: 2.297876\n",
      "Epoch 88, loss: 2.297793\n",
      "Epoch 89, loss: 2.297711\n",
      "Epoch 90, loss: 2.297633\n",
      "Epoch 91, loss: 2.297552\n",
      "Epoch 92, loss: 2.297475\n",
      "Epoch 93, loss: 2.297392\n",
      "Epoch 94, loss: 2.297312\n",
      "Epoch 95, loss: 2.297231\n",
      "Epoch 96, loss: 2.297153\n",
      "Epoch 97, loss: 2.297073\n",
      "Epoch 98, loss: 2.296993\n",
      "Epoch 99, loss: 2.296916\n",
      "Epoch 100, loss: 2.296836\n",
      "Epoch 101, loss: 2.296759\n",
      "Epoch 102, loss: 2.296680\n",
      "Epoch 103, loss: 2.296601\n",
      "Epoch 104, loss: 2.296524\n",
      "Epoch 105, loss: 2.296445\n",
      "Epoch 106, loss: 2.296367\n",
      "Epoch 107, loss: 2.296289\n",
      "Epoch 108, loss: 2.296213\n",
      "Epoch 109, loss: 2.296134\n",
      "Epoch 110, loss: 2.296058\n",
      "Epoch 111, loss: 2.295982\n",
      "Epoch 112, loss: 2.295904\n",
      "Epoch 113, loss: 2.295828\n",
      "Epoch 114, loss: 2.295751\n",
      "Epoch 115, loss: 2.295673\n",
      "Epoch 116, loss: 2.295598\n",
      "Epoch 117, loss: 2.295522\n",
      "Epoch 118, loss: 2.295445\n",
      "Epoch 119, loss: 2.295370\n",
      "Epoch 120, loss: 2.295295\n",
      "Epoch 121, loss: 2.295221\n",
      "Epoch 122, loss: 2.295145\n",
      "Epoch 123, loss: 2.295070\n",
      "Epoch 124, loss: 2.294994\n",
      "Epoch 125, loss: 2.294918\n",
      "Epoch 126, loss: 2.294844\n",
      "Epoch 127, loss: 2.294771\n",
      "Epoch 128, loss: 2.294696\n",
      "Epoch 129, loss: 2.294620\n",
      "Epoch 130, loss: 2.294548\n",
      "Epoch 131, loss: 2.294473\n",
      "Epoch 132, loss: 2.294401\n",
      "Epoch 133, loss: 2.294326\n",
      "Epoch 134, loss: 2.294253\n",
      "Epoch 135, loss: 2.294180\n",
      "Epoch 136, loss: 2.294108\n",
      "Epoch 137, loss: 2.294035\n",
      "Epoch 138, loss: 2.293963\n",
      "Epoch 139, loss: 2.293887\n",
      "Epoch 140, loss: 2.293815\n",
      "Epoch 141, loss: 2.293744\n",
      "Epoch 142, loss: 2.293671\n",
      "Epoch 143, loss: 2.293599\n",
      "Epoch 144, loss: 2.293526\n",
      "Epoch 145, loss: 2.293455\n",
      "Epoch 146, loss: 2.293384\n",
      "Epoch 147, loss: 2.293312\n",
      "Epoch 148, loss: 2.293242\n",
      "Epoch 149, loss: 2.293169\n",
      "Epoch 150, loss: 2.293097\n",
      "Epoch 151, loss: 2.293026\n",
      "Epoch 152, loss: 2.292956\n",
      "Epoch 153, loss: 2.292886\n",
      "Epoch 154, loss: 2.292814\n",
      "Epoch 155, loss: 2.292744\n",
      "Epoch 156, loss: 2.292676\n",
      "Epoch 157, loss: 2.292605\n",
      "Epoch 158, loss: 2.292534\n",
      "Epoch 159, loss: 2.292464\n",
      "Epoch 160, loss: 2.292395\n",
      "Epoch 161, loss: 2.292326\n",
      "Epoch 162, loss: 2.292257\n",
      "Epoch 163, loss: 2.292185\n",
      "Epoch 164, loss: 2.292118\n",
      "Epoch 165, loss: 2.292050\n",
      "Epoch 166, loss: 2.291979\n",
      "Epoch 167, loss: 2.291911\n",
      "Epoch 168, loss: 2.291842\n",
      "Epoch 169, loss: 2.291773\n",
      "Epoch 170, loss: 2.291704\n",
      "Epoch 171, loss: 2.291638\n",
      "Epoch 172, loss: 2.291569\n",
      "Epoch 173, loss: 2.291501\n",
      "Epoch 174, loss: 2.291434\n",
      "Epoch 175, loss: 2.291365\n",
      "Epoch 176, loss: 2.291298\n",
      "Epoch 177, loss: 2.291230\n",
      "Epoch 178, loss: 2.291163\n",
      "Epoch 179, loss: 2.291097\n",
      "Epoch 180, loss: 2.291028\n",
      "Epoch 181, loss: 2.290962\n",
      "Epoch 182, loss: 2.290895\n",
      "Epoch 183, loss: 2.290831\n",
      "Epoch 184, loss: 2.290764\n",
      "Epoch 185, loss: 2.290696\n",
      "Epoch 186, loss: 2.290629\n",
      "Epoch 187, loss: 2.290563\n",
      "Epoch 188, loss: 2.290497\n",
      "Epoch 189, loss: 2.290431\n",
      "Epoch 190, loss: 2.290367\n",
      "Epoch 191, loss: 2.290301\n",
      "Epoch 192, loss: 2.290234\n",
      "Epoch 193, loss: 2.290170\n",
      "Epoch 194, loss: 2.290105\n",
      "Epoch 195, loss: 2.290040\n",
      "Epoch 196, loss: 2.289975\n",
      "Epoch 197, loss: 2.289911\n",
      "Epoch 198, loss: 2.289845\n",
      "Epoch 199, loss: 2.289781\n",
      "lr: 0.0001, rs: 0.1, accuracy 200 epochs: 0.166\n",
      "Epoch 0, loss: 2.302708\n",
      "Epoch 1, loss: 2.302597\n",
      "Epoch 2, loss: 2.302485\n",
      "Epoch 3, loss: 2.302376\n",
      "Epoch 4, loss: 2.302268\n",
      "Epoch 5, loss: 2.302160\n",
      "Epoch 6, loss: 2.302052\n",
      "Epoch 7, loss: 2.301945\n",
      "Epoch 8, loss: 2.301840\n",
      "Epoch 9, loss: 2.301738\n",
      "Epoch 10, loss: 2.301630\n",
      "Epoch 11, loss: 2.301530\n",
      "Epoch 12, loss: 2.301427\n",
      "Epoch 13, loss: 2.301323\n",
      "Epoch 14, loss: 2.301221\n",
      "Epoch 15, loss: 2.301122\n",
      "Epoch 16, loss: 2.301019\n",
      "Epoch 17, loss: 2.300922\n",
      "Epoch 18, loss: 2.300821\n",
      "Epoch 19, loss: 2.300723\n",
      "Epoch 20, loss: 2.300624\n",
      "Epoch 21, loss: 2.300526\n",
      "Epoch 22, loss: 2.300428\n",
      "Epoch 23, loss: 2.300330\n",
      "Epoch 24, loss: 2.300234\n",
      "Epoch 25, loss: 2.300138\n",
      "Epoch 26, loss: 2.300042\n",
      "Epoch 27, loss: 2.299946\n",
      "Epoch 28, loss: 2.299852\n",
      "Epoch 29, loss: 2.299756\n",
      "Epoch 30, loss: 2.299662\n",
      "Epoch 31, loss: 2.299568\n",
      "Epoch 32, loss: 2.299474\n",
      "Epoch 33, loss: 2.299379\n",
      "Epoch 34, loss: 2.299287\n",
      "Epoch 35, loss: 2.299194\n",
      "Epoch 36, loss: 2.299101\n",
      "Epoch 37, loss: 2.299008\n",
      "Epoch 38, loss: 2.298916\n",
      "Epoch 39, loss: 2.298824\n",
      "Epoch 40, loss: 2.298732\n",
      "Epoch 41, loss: 2.298642\n",
      "Epoch 42, loss: 2.298551\n",
      "Epoch 43, loss: 2.298460\n",
      "Epoch 44, loss: 2.298368\n",
      "Epoch 45, loss: 2.298277\n",
      "Epoch 46, loss: 2.298189\n",
      "Epoch 47, loss: 2.298100\n",
      "Epoch 48, loss: 2.298008\n",
      "Epoch 49, loss: 2.297921\n",
      "Epoch 50, loss: 2.297829\n",
      "Epoch 51, loss: 2.297740\n",
      "Epoch 52, loss: 2.297653\n",
      "Epoch 53, loss: 2.297562\n",
      "Epoch 54, loss: 2.297473\n",
      "Epoch 55, loss: 2.297385\n",
      "Epoch 56, loss: 2.297297\n",
      "Epoch 57, loss: 2.297208\n",
      "Epoch 58, loss: 2.297123\n",
      "Epoch 59, loss: 2.297034\n",
      "Epoch 60, loss: 2.296944\n",
      "Epoch 61, loss: 2.296857\n",
      "Epoch 62, loss: 2.296770\n",
      "Epoch 63, loss: 2.296684\n",
      "Epoch 64, loss: 2.296597\n",
      "Epoch 65, loss: 2.296508\n",
      "Epoch 66, loss: 2.296421\n",
      "Epoch 67, loss: 2.296335\n",
      "Epoch 68, loss: 2.296250\n",
      "Epoch 69, loss: 2.296163\n",
      "Epoch 70, loss: 2.296075\n",
      "Epoch 71, loss: 2.295989\n",
      "Epoch 72, loss: 2.295905\n",
      "Epoch 73, loss: 2.295819\n",
      "Epoch 74, loss: 2.295732\n",
      "Epoch 75, loss: 2.295646\n",
      "Epoch 76, loss: 2.295561\n",
      "Epoch 77, loss: 2.295474\n",
      "Epoch 78, loss: 2.295389\n",
      "Epoch 79, loss: 2.295304\n",
      "Epoch 80, loss: 2.295219\n",
      "Epoch 81, loss: 2.295135\n",
      "Epoch 82, loss: 2.295050\n",
      "Epoch 83, loss: 2.294964\n",
      "Epoch 84, loss: 2.294881\n",
      "Epoch 85, loss: 2.294795\n",
      "Epoch 86, loss: 2.294712\n",
      "Epoch 87, loss: 2.294627\n",
      "Epoch 88, loss: 2.294542\n",
      "Epoch 89, loss: 2.294459\n",
      "Epoch 90, loss: 2.294374\n",
      "Epoch 91, loss: 2.294290\n",
      "Epoch 92, loss: 2.294208\n",
      "Epoch 93, loss: 2.294123\n",
      "Epoch 94, loss: 2.294039\n",
      "Epoch 95, loss: 2.293956\n",
      "Epoch 96, loss: 2.293871\n",
      "Epoch 97, loss: 2.293788\n",
      "Epoch 98, loss: 2.293706\n",
      "Epoch 99, loss: 2.293622\n",
      "Epoch 100, loss: 2.293539\n",
      "Epoch 101, loss: 2.293457\n",
      "Epoch 102, loss: 2.293374\n",
      "Epoch 103, loss: 2.293290\n",
      "Epoch 104, loss: 2.293207\n",
      "Epoch 105, loss: 2.293126\n",
      "Epoch 106, loss: 2.293041\n",
      "Epoch 107, loss: 2.292960\n",
      "Epoch 108, loss: 2.292879\n",
      "Epoch 109, loss: 2.292794\n",
      "Epoch 110, loss: 2.292713\n",
      "Epoch 111, loss: 2.292631\n",
      "Epoch 112, loss: 2.292548\n",
      "Epoch 113, loss: 2.292466\n",
      "Epoch 114, loss: 2.292384\n",
      "Epoch 115, loss: 2.292302\n",
      "Epoch 116, loss: 2.292221\n",
      "Epoch 117, loss: 2.292140\n",
      "Epoch 118, loss: 2.292058\n",
      "Epoch 119, loss: 2.291977\n",
      "Epoch 120, loss: 2.291894\n",
      "Epoch 121, loss: 2.291814\n",
      "Epoch 122, loss: 2.291734\n",
      "Epoch 123, loss: 2.291652\n",
      "Epoch 124, loss: 2.291570\n",
      "Epoch 125, loss: 2.291490\n",
      "Epoch 126, loss: 2.291407\n",
      "Epoch 127, loss: 2.291329\n",
      "Epoch 128, loss: 2.291247\n",
      "Epoch 129, loss: 2.291166\n",
      "Epoch 130, loss: 2.291088\n",
      "Epoch 131, loss: 2.291005\n",
      "Epoch 132, loss: 2.290925\n",
      "Epoch 133, loss: 2.290846\n",
      "Epoch 134, loss: 2.290763\n",
      "Epoch 135, loss: 2.290686\n",
      "Epoch 136, loss: 2.290603\n",
      "Epoch 137, loss: 2.290523\n",
      "Epoch 138, loss: 2.290445\n",
      "Epoch 139, loss: 2.290364\n",
      "Epoch 140, loss: 2.290284\n",
      "Epoch 141, loss: 2.290203\n",
      "Epoch 142, loss: 2.290125\n",
      "Epoch 143, loss: 2.290046\n",
      "Epoch 144, loss: 2.289967\n",
      "Epoch 145, loss: 2.289887\n",
      "Epoch 146, loss: 2.289809\n",
      "Epoch 147, loss: 2.289727\n",
      "Epoch 148, loss: 2.289650\n",
      "Epoch 149, loss: 2.289571\n",
      "Epoch 150, loss: 2.289492\n",
      "Epoch 151, loss: 2.289414\n",
      "Epoch 152, loss: 2.289331\n",
      "Epoch 153, loss: 2.289252\n",
      "Epoch 154, loss: 2.289176\n",
      "Epoch 155, loss: 2.289096\n",
      "Epoch 156, loss: 2.289018\n",
      "Epoch 157, loss: 2.288940\n",
      "Epoch 158, loss: 2.288863\n",
      "Epoch 159, loss: 2.288783\n",
      "Epoch 160, loss: 2.288704\n",
      "Epoch 161, loss: 2.288626\n",
      "Epoch 162, loss: 2.288548\n",
      "Epoch 163, loss: 2.288470\n",
      "Epoch 164, loss: 2.288392\n",
      "Epoch 165, loss: 2.288314\n",
      "Epoch 166, loss: 2.288235\n",
      "Epoch 167, loss: 2.288158\n",
      "Epoch 168, loss: 2.288081\n",
      "Epoch 169, loss: 2.288003\n",
      "Epoch 170, loss: 2.287926\n",
      "Epoch 171, loss: 2.287846\n",
      "Epoch 172, loss: 2.287770\n",
      "Epoch 173, loss: 2.287693\n",
      "Epoch 174, loss: 2.287616\n",
      "Epoch 175, loss: 2.287539\n",
      "Epoch 176, loss: 2.287461\n",
      "Epoch 177, loss: 2.287383\n",
      "Epoch 178, loss: 2.287308\n",
      "Epoch 179, loss: 2.287232\n",
      "Epoch 180, loss: 2.287153\n",
      "Epoch 181, loss: 2.287077\n",
      "Epoch 182, loss: 2.287000\n",
      "Epoch 183, loss: 2.286923\n",
      "Epoch 184, loss: 2.286846\n",
      "Epoch 185, loss: 2.286770\n",
      "Epoch 186, loss: 2.286693\n",
      "Epoch 187, loss: 2.286616\n",
      "Epoch 188, loss: 2.286539\n",
      "Epoch 189, loss: 2.286464\n",
      "Epoch 190, loss: 2.286388\n",
      "Epoch 191, loss: 2.286313\n",
      "Epoch 192, loss: 2.286235\n",
      "Epoch 193, loss: 2.286159\n",
      "Epoch 194, loss: 2.286083\n",
      "Epoch 195, loss: 2.286008\n",
      "Epoch 196, loss: 2.285934\n",
      "Epoch 197, loss: 2.285857\n",
      "Epoch 198, loss: 2.285782\n",
      "Epoch 199, loss: 2.285706\n",
      "lr: 0.0001, rs: 0.01, accuracy 200 epochs: 0.172\n",
      "Epoch 0, loss: 2.302897\n",
      "Epoch 1, loss: 2.302785\n",
      "Epoch 2, loss: 2.302679\n",
      "Epoch 3, loss: 2.302568\n",
      "Epoch 4, loss: 2.302459\n",
      "Epoch 5, loss: 2.302351\n",
      "Epoch 6, loss: 2.302246\n",
      "Epoch 7, loss: 2.302138\n",
      "Epoch 8, loss: 2.302033\n",
      "Epoch 9, loss: 2.301929\n",
      "Epoch 10, loss: 2.301821\n",
      "Epoch 11, loss: 2.301718\n",
      "Epoch 12, loss: 2.301615\n",
      "Epoch 13, loss: 2.301512\n",
      "Epoch 14, loss: 2.301410\n",
      "Epoch 15, loss: 2.301309\n",
      "Epoch 16, loss: 2.301206\n",
      "Epoch 17, loss: 2.301108\n",
      "Epoch 18, loss: 2.301006\n",
      "Epoch 19, loss: 2.300908\n",
      "Epoch 20, loss: 2.300810\n",
      "Epoch 21, loss: 2.300711\n",
      "Epoch 22, loss: 2.300612\n",
      "Epoch 23, loss: 2.300515\n",
      "Epoch 24, loss: 2.300415\n",
      "Epoch 25, loss: 2.300320\n",
      "Epoch 26, loss: 2.300223\n",
      "Epoch 27, loss: 2.300126\n",
      "Epoch 28, loss: 2.300030\n",
      "Epoch 29, loss: 2.299933\n",
      "Epoch 30, loss: 2.299838\n",
      "Epoch 31, loss: 2.299742\n",
      "Epoch 32, loss: 2.299647\n",
      "Epoch 33, loss: 2.299555\n",
      "Epoch 34, loss: 2.299459\n",
      "Epoch 35, loss: 2.299365\n",
      "Epoch 36, loss: 2.299271\n",
      "Epoch 37, loss: 2.299178\n",
      "Epoch 38, loss: 2.299084\n",
      "Epoch 39, loss: 2.298992\n",
      "Epoch 40, loss: 2.298899\n",
      "Epoch 41, loss: 2.298807\n",
      "Epoch 42, loss: 2.298714\n",
      "Epoch 43, loss: 2.298621\n",
      "Epoch 44, loss: 2.298530\n",
      "Epoch 45, loss: 2.298437\n",
      "Epoch 46, loss: 2.298347\n",
      "Epoch 47, loss: 2.298256\n",
      "Epoch 48, loss: 2.298164\n",
      "Epoch 49, loss: 2.298073\n",
      "Epoch 50, loss: 2.297982\n",
      "Epoch 51, loss: 2.297892\n",
      "Epoch 52, loss: 2.297804\n",
      "Epoch 53, loss: 2.297711\n",
      "Epoch 54, loss: 2.297620\n",
      "Epoch 55, loss: 2.297531\n",
      "Epoch 56, loss: 2.297442\n",
      "Epoch 57, loss: 2.297352\n",
      "Epoch 58, loss: 2.297262\n",
      "Epoch 59, loss: 2.297173\n",
      "Epoch 60, loss: 2.297085\n",
      "Epoch 61, loss: 2.296996\n",
      "Epoch 62, loss: 2.296907\n",
      "Epoch 63, loss: 2.296818\n",
      "Epoch 64, loss: 2.296730\n",
      "Epoch 65, loss: 2.296641\n",
      "Epoch 66, loss: 2.296552\n",
      "Epoch 67, loss: 2.296463\n",
      "Epoch 68, loss: 2.296376\n",
      "Epoch 69, loss: 2.296289\n",
      "Epoch 70, loss: 2.296201\n",
      "Epoch 71, loss: 2.296114\n",
      "Epoch 72, loss: 2.296026\n",
      "Epoch 73, loss: 2.295939\n",
      "Epoch 74, loss: 2.295853\n",
      "Epoch 75, loss: 2.295765\n",
      "Epoch 76, loss: 2.295676\n",
      "Epoch 77, loss: 2.295588\n",
      "Epoch 78, loss: 2.295503\n",
      "Epoch 79, loss: 2.295416\n",
      "Epoch 80, loss: 2.295330\n",
      "Epoch 81, loss: 2.295243\n",
      "Epoch 82, loss: 2.295155\n",
      "Epoch 83, loss: 2.295070\n",
      "Epoch 84, loss: 2.294982\n",
      "Epoch 85, loss: 2.294897\n",
      "Epoch 86, loss: 2.294811\n",
      "Epoch 87, loss: 2.294723\n",
      "Epoch 88, loss: 2.294641\n",
      "Epoch 89, loss: 2.294552\n",
      "Epoch 90, loss: 2.294469\n",
      "Epoch 91, loss: 2.294381\n",
      "Epoch 92, loss: 2.294297\n",
      "Epoch 93, loss: 2.294211\n",
      "Epoch 94, loss: 2.294126\n",
      "Epoch 95, loss: 2.294041\n",
      "Epoch 96, loss: 2.293954\n",
      "Epoch 97, loss: 2.293870\n",
      "Epoch 98, loss: 2.293785\n",
      "Epoch 99, loss: 2.293700\n",
      "Epoch 100, loss: 2.293616\n",
      "Epoch 101, loss: 2.293530\n",
      "Epoch 102, loss: 2.293444\n",
      "Epoch 103, loss: 2.293363\n",
      "Epoch 104, loss: 2.293276\n",
      "Epoch 105, loss: 2.293193\n",
      "Epoch 106, loss: 2.293109\n",
      "Epoch 107, loss: 2.293024\n",
      "Epoch 108, loss: 2.292940\n",
      "Epoch 109, loss: 2.292855\n",
      "Epoch 110, loss: 2.292770\n",
      "Epoch 111, loss: 2.292690\n",
      "Epoch 112, loss: 2.292604\n",
      "Epoch 113, loss: 2.292522\n",
      "Epoch 114, loss: 2.292436\n",
      "Epoch 115, loss: 2.292352\n",
      "Epoch 116, loss: 2.292269\n",
      "Epoch 117, loss: 2.292186\n",
      "Epoch 118, loss: 2.292101\n",
      "Epoch 119, loss: 2.292019\n",
      "Epoch 120, loss: 2.291936\n",
      "Epoch 121, loss: 2.291852\n",
      "Epoch 122, loss: 2.291770\n",
      "Epoch 123, loss: 2.291687\n",
      "Epoch 124, loss: 2.291604\n",
      "Epoch 125, loss: 2.291520\n",
      "Epoch 126, loss: 2.291439\n",
      "Epoch 127, loss: 2.291355\n",
      "Epoch 128, loss: 2.291272\n",
      "Epoch 129, loss: 2.291192\n",
      "Epoch 130, loss: 2.291108\n",
      "Epoch 131, loss: 2.291026\n",
      "Epoch 132, loss: 2.290944\n",
      "Epoch 133, loss: 2.290859\n",
      "Epoch 134, loss: 2.290778\n",
      "Epoch 135, loss: 2.290697\n",
      "Epoch 136, loss: 2.290614\n",
      "Epoch 137, loss: 2.290532\n",
      "Epoch 138, loss: 2.290450\n",
      "Epoch 139, loss: 2.290368\n",
      "Epoch 140, loss: 2.290286\n",
      "Epoch 141, loss: 2.290207\n",
      "Epoch 142, loss: 2.290122\n",
      "Epoch 143, loss: 2.290042\n",
      "Epoch 144, loss: 2.289960\n",
      "Epoch 145, loss: 2.289882\n",
      "Epoch 146, loss: 2.289798\n",
      "Epoch 147, loss: 2.289716\n",
      "Epoch 148, loss: 2.289635\n",
      "Epoch 149, loss: 2.289554\n",
      "Epoch 150, loss: 2.289474\n",
      "Epoch 151, loss: 2.289391\n",
      "Epoch 152, loss: 2.289312\n",
      "Epoch 153, loss: 2.289230\n",
      "Epoch 154, loss: 2.289149\n",
      "Epoch 155, loss: 2.289069\n",
      "Epoch 156, loss: 2.288988\n",
      "Epoch 157, loss: 2.288908\n",
      "Epoch 158, loss: 2.288825\n",
      "Epoch 159, loss: 2.288748\n",
      "Epoch 160, loss: 2.288667\n",
      "Epoch 161, loss: 2.288587\n",
      "Epoch 162, loss: 2.288505\n",
      "Epoch 163, loss: 2.288426\n",
      "Epoch 164, loss: 2.288345\n",
      "Epoch 165, loss: 2.288266\n",
      "Epoch 166, loss: 2.288186\n",
      "Epoch 167, loss: 2.288106\n",
      "Epoch 168, loss: 2.288025\n",
      "Epoch 169, loss: 2.287946\n",
      "Epoch 170, loss: 2.287867\n",
      "Epoch 171, loss: 2.287787\n",
      "Epoch 172, loss: 2.287706\n",
      "Epoch 173, loss: 2.287628\n",
      "Epoch 174, loss: 2.287548\n",
      "Epoch 175, loss: 2.287468\n",
      "Epoch 176, loss: 2.287388\n",
      "Epoch 177, loss: 2.287309\n",
      "Epoch 178, loss: 2.287230\n",
      "Epoch 179, loss: 2.287150\n",
      "Epoch 180, loss: 2.287072\n",
      "Epoch 181, loss: 2.286995\n",
      "Epoch 182, loss: 2.286913\n",
      "Epoch 183, loss: 2.286835\n",
      "Epoch 184, loss: 2.286756\n",
      "Epoch 185, loss: 2.286678\n",
      "Epoch 186, loss: 2.286599\n",
      "Epoch 187, loss: 2.286520\n",
      "Epoch 188, loss: 2.286443\n",
      "Epoch 189, loss: 2.286363\n",
      "Epoch 190, loss: 2.286287\n",
      "Epoch 191, loss: 2.286205\n",
      "Epoch 192, loss: 2.286129\n",
      "Epoch 193, loss: 2.286050\n",
      "Epoch 194, loss: 2.285972\n",
      "Epoch 195, loss: 2.285895\n",
      "Epoch 196, loss: 2.285816\n",
      "Epoch 197, loss: 2.285738\n",
      "Epoch 198, loss: 2.285660\n",
      "Epoch 199, loss: 2.285582\n",
      "lr: 0.0001, rs: 0.001, accuracy 200 epochs: 0.169\n",
      "Epoch 0, loss: 2.302616\n",
      "Epoch 1, loss: 2.302502\n",
      "Epoch 2, loss: 2.302390\n",
      "Epoch 3, loss: 2.302279\n",
      "Epoch 4, loss: 2.302169\n",
      "Epoch 5, loss: 2.302061\n",
      "Epoch 6, loss: 2.301955\n",
      "Epoch 7, loss: 2.301845\n",
      "Epoch 8, loss: 2.301738\n",
      "Epoch 9, loss: 2.301633\n",
      "Epoch 10, loss: 2.301526\n",
      "Epoch 11, loss: 2.301425\n",
      "Epoch 12, loss: 2.301319\n",
      "Epoch 13, loss: 2.301215\n",
      "Epoch 14, loss: 2.301115\n",
      "Epoch 15, loss: 2.301011\n",
      "Epoch 16, loss: 2.300909\n",
      "Epoch 17, loss: 2.300807\n",
      "Epoch 18, loss: 2.300710\n",
      "Epoch 19, loss: 2.300608\n",
      "Epoch 20, loss: 2.300509\n",
      "Epoch 21, loss: 2.300410\n",
      "Epoch 22, loss: 2.300310\n",
      "Epoch 23, loss: 2.300213\n",
      "Epoch 24, loss: 2.300115\n",
      "Epoch 25, loss: 2.300019\n",
      "Epoch 26, loss: 2.299922\n",
      "Epoch 27, loss: 2.299824\n",
      "Epoch 28, loss: 2.299729\n",
      "Epoch 29, loss: 2.299633\n",
      "Epoch 30, loss: 2.299538\n",
      "Epoch 31, loss: 2.299442\n",
      "Epoch 32, loss: 2.299347\n",
      "Epoch 33, loss: 2.299253\n",
      "Epoch 34, loss: 2.299159\n",
      "Epoch 35, loss: 2.299065\n",
      "Epoch 36, loss: 2.298971\n",
      "Epoch 37, loss: 2.298878\n",
      "Epoch 38, loss: 2.298785\n",
      "Epoch 39, loss: 2.298693\n",
      "Epoch 40, loss: 2.298598\n",
      "Epoch 41, loss: 2.298507\n",
      "Epoch 42, loss: 2.298414\n",
      "Epoch 43, loss: 2.298324\n",
      "Epoch 44, loss: 2.298232\n",
      "Epoch 45, loss: 2.298141\n",
      "Epoch 46, loss: 2.298048\n",
      "Epoch 47, loss: 2.297958\n",
      "Epoch 48, loss: 2.297865\n",
      "Epoch 49, loss: 2.297775\n",
      "Epoch 50, loss: 2.297686\n",
      "Epoch 51, loss: 2.297594\n",
      "Epoch 52, loss: 2.297506\n",
      "Epoch 53, loss: 2.297415\n",
      "Epoch 54, loss: 2.297325\n",
      "Epoch 55, loss: 2.297237\n",
      "Epoch 56, loss: 2.297145\n",
      "Epoch 57, loss: 2.297057\n",
      "Epoch 58, loss: 2.296967\n",
      "Epoch 59, loss: 2.296879\n",
      "Epoch 60, loss: 2.296791\n",
      "Epoch 61, loss: 2.296701\n",
      "Epoch 62, loss: 2.296613\n",
      "Epoch 63, loss: 2.296524\n",
      "Epoch 64, loss: 2.296438\n",
      "Epoch 65, loss: 2.296349\n",
      "Epoch 66, loss: 2.296261\n",
      "Epoch 67, loss: 2.296174\n",
      "Epoch 68, loss: 2.296085\n",
      "Epoch 69, loss: 2.295997\n",
      "Epoch 70, loss: 2.295910\n",
      "Epoch 71, loss: 2.295824\n",
      "Epoch 72, loss: 2.295735\n",
      "Epoch 73, loss: 2.295648\n",
      "Epoch 74, loss: 2.295562\n",
      "Epoch 75, loss: 2.295476\n",
      "Epoch 76, loss: 2.295390\n",
      "Epoch 77, loss: 2.295303\n",
      "Epoch 78, loss: 2.295215\n",
      "Epoch 79, loss: 2.295129\n",
      "Epoch 80, loss: 2.295043\n",
      "Epoch 81, loss: 2.294956\n",
      "Epoch 82, loss: 2.294868\n",
      "Epoch 83, loss: 2.294784\n",
      "Epoch 84, loss: 2.294698\n",
      "Epoch 85, loss: 2.294615\n",
      "Epoch 86, loss: 2.294526\n",
      "Epoch 87, loss: 2.294441\n",
      "Epoch 88, loss: 2.294355\n",
      "Epoch 89, loss: 2.294271\n",
      "Epoch 90, loss: 2.294185\n",
      "Epoch 91, loss: 2.294100\n",
      "Epoch 92, loss: 2.294016\n",
      "Epoch 93, loss: 2.293928\n",
      "Epoch 94, loss: 2.293844\n",
      "Epoch 95, loss: 2.293759\n",
      "Epoch 96, loss: 2.293674\n",
      "Epoch 97, loss: 2.293588\n",
      "Epoch 98, loss: 2.293504\n",
      "Epoch 99, loss: 2.293423\n",
      "Epoch 100, loss: 2.293335\n",
      "Epoch 101, loss: 2.293253\n",
      "Epoch 102, loss: 2.293168\n",
      "Epoch 103, loss: 2.293085\n",
      "Epoch 104, loss: 2.293000\n",
      "Epoch 105, loss: 2.292915\n",
      "Epoch 106, loss: 2.292831\n",
      "Epoch 107, loss: 2.292747\n",
      "Epoch 108, loss: 2.292663\n",
      "Epoch 109, loss: 2.292581\n",
      "Epoch 110, loss: 2.292497\n",
      "Epoch 111, loss: 2.292411\n",
      "Epoch 112, loss: 2.292330\n",
      "Epoch 113, loss: 2.292245\n",
      "Epoch 114, loss: 2.292162\n",
      "Epoch 115, loss: 2.292081\n",
      "Epoch 116, loss: 2.291995\n",
      "Epoch 117, loss: 2.291913\n",
      "Epoch 118, loss: 2.291832\n",
      "Epoch 119, loss: 2.291748\n",
      "Epoch 120, loss: 2.291664\n",
      "Epoch 121, loss: 2.291581\n",
      "Epoch 122, loss: 2.291499\n",
      "Epoch 123, loss: 2.291418\n",
      "Epoch 124, loss: 2.291335\n",
      "Epoch 125, loss: 2.291251\n",
      "Epoch 126, loss: 2.291169\n",
      "Epoch 127, loss: 2.291085\n",
      "Epoch 128, loss: 2.291004\n",
      "Epoch 129, loss: 2.290921\n",
      "Epoch 130, loss: 2.290839\n",
      "Epoch 131, loss: 2.290757\n",
      "Epoch 132, loss: 2.290674\n",
      "Epoch 133, loss: 2.290592\n",
      "Epoch 134, loss: 2.290511\n",
      "Epoch 135, loss: 2.290433\n",
      "Epoch 136, loss: 2.290348\n",
      "Epoch 137, loss: 2.290269\n",
      "Epoch 138, loss: 2.290186\n",
      "Epoch 139, loss: 2.290106\n",
      "Epoch 140, loss: 2.290024\n",
      "Epoch 141, loss: 2.289941\n",
      "Epoch 142, loss: 2.289859\n",
      "Epoch 143, loss: 2.289779\n",
      "Epoch 144, loss: 2.289698\n",
      "Epoch 145, loss: 2.289615\n",
      "Epoch 146, loss: 2.289536\n",
      "Epoch 147, loss: 2.289456\n",
      "Epoch 148, loss: 2.289374\n",
      "Epoch 149, loss: 2.289292\n",
      "Epoch 150, loss: 2.289213\n",
      "Epoch 151, loss: 2.289132\n",
      "Epoch 152, loss: 2.289051\n",
      "Epoch 153, loss: 2.288970\n",
      "Epoch 154, loss: 2.288890\n",
      "Epoch 155, loss: 2.288810\n",
      "Epoch 156, loss: 2.288729\n",
      "Epoch 157, loss: 2.288649\n",
      "Epoch 158, loss: 2.288569\n",
      "Epoch 159, loss: 2.288487\n",
      "Epoch 160, loss: 2.288408\n",
      "Epoch 161, loss: 2.288328\n",
      "Epoch 162, loss: 2.288248\n",
      "Epoch 163, loss: 2.288167\n",
      "Epoch 164, loss: 2.288088\n",
      "Epoch 165, loss: 2.288010\n",
      "Epoch 166, loss: 2.287927\n",
      "Epoch 167, loss: 2.287850\n",
      "Epoch 168, loss: 2.287770\n",
      "Epoch 169, loss: 2.287691\n",
      "Epoch 170, loss: 2.287609\n",
      "Epoch 171, loss: 2.287531\n",
      "Epoch 172, loss: 2.287454\n",
      "Epoch 173, loss: 2.287372\n",
      "Epoch 174, loss: 2.287293\n",
      "Epoch 175, loss: 2.287215\n",
      "Epoch 176, loss: 2.287136\n",
      "Epoch 177, loss: 2.287056\n",
      "Epoch 178, loss: 2.286978\n",
      "Epoch 179, loss: 2.286898\n",
      "Epoch 180, loss: 2.286820\n",
      "Epoch 181, loss: 2.286741\n",
      "Epoch 182, loss: 2.286663\n",
      "Epoch 183, loss: 2.286583\n",
      "Epoch 184, loss: 2.286505\n",
      "Epoch 185, loss: 2.286428\n",
      "Epoch 186, loss: 2.286348\n",
      "Epoch 187, loss: 2.286270\n",
      "Epoch 188, loss: 2.286192\n",
      "Epoch 189, loss: 2.286113\n",
      "Epoch 190, loss: 2.286036\n",
      "Epoch 191, loss: 2.285956\n",
      "Epoch 192, loss: 2.285878\n",
      "Epoch 193, loss: 2.285802\n",
      "Epoch 194, loss: 2.285722\n",
      "Epoch 195, loss: 2.285648\n",
      "Epoch 196, loss: 2.285568\n",
      "Epoch 197, loss: 2.285490\n",
      "Epoch 198, loss: 2.285411\n",
      "Epoch 199, loss: 2.285333\n",
      "lr: 0.0001, rs: 0.0001, accuracy 200 epochs: 0.171\n",
      "Epoch 0, loss: 2.302475\n",
      "Epoch 1, loss: 2.302364\n",
      "Epoch 2, loss: 2.302260\n",
      "Epoch 3, loss: 2.302153\n",
      "Epoch 4, loss: 2.302047\n",
      "Epoch 5, loss: 2.301943\n",
      "Epoch 6, loss: 2.301839\n",
      "Epoch 7, loss: 2.301738\n",
      "Epoch 8, loss: 2.301634\n",
      "Epoch 9, loss: 2.301533\n",
      "Epoch 10, loss: 2.301430\n",
      "Epoch 11, loss: 2.301330\n",
      "Epoch 12, loss: 2.301228\n",
      "Epoch 13, loss: 2.301128\n",
      "Epoch 14, loss: 2.301027\n",
      "Epoch 15, loss: 2.300930\n",
      "Epoch 16, loss: 2.300831\n",
      "Epoch 17, loss: 2.300731\n",
      "Epoch 18, loss: 2.300636\n",
      "Epoch 19, loss: 2.300540\n",
      "Epoch 20, loss: 2.300439\n",
      "Epoch 21, loss: 2.300344\n",
      "Epoch 22, loss: 2.300247\n",
      "Epoch 23, loss: 2.300151\n",
      "Epoch 24, loss: 2.300055\n",
      "Epoch 25, loss: 2.299960\n",
      "Epoch 26, loss: 2.299865\n",
      "Epoch 27, loss: 2.299770\n",
      "Epoch 28, loss: 2.299678\n",
      "Epoch 29, loss: 2.299582\n",
      "Epoch 30, loss: 2.299490\n",
      "Epoch 31, loss: 2.299393\n",
      "Epoch 32, loss: 2.299301\n",
      "Epoch 33, loss: 2.299207\n",
      "Epoch 34, loss: 2.299114\n",
      "Epoch 35, loss: 2.299022\n",
      "Epoch 36, loss: 2.298929\n",
      "Epoch 37, loss: 2.298837\n",
      "Epoch 38, loss: 2.298745\n",
      "Epoch 39, loss: 2.298653\n",
      "Epoch 40, loss: 2.298563\n",
      "Epoch 41, loss: 2.298474\n",
      "Epoch 42, loss: 2.298380\n",
      "Epoch 43, loss: 2.298288\n",
      "Epoch 44, loss: 2.298199\n",
      "Epoch 45, loss: 2.298106\n",
      "Epoch 46, loss: 2.298017\n",
      "Epoch 47, loss: 2.297927\n",
      "Epoch 48, loss: 2.297836\n",
      "Epoch 49, loss: 2.297746\n",
      "Epoch 50, loss: 2.297655\n",
      "Epoch 51, loss: 2.297568\n",
      "Epoch 52, loss: 2.297478\n",
      "Epoch 53, loss: 2.297389\n",
      "Epoch 54, loss: 2.297300\n",
      "Epoch 55, loss: 2.297210\n",
      "Epoch 56, loss: 2.297121\n",
      "Epoch 57, loss: 2.297031\n",
      "Epoch 58, loss: 2.296945\n",
      "Epoch 59, loss: 2.296857\n",
      "Epoch 60, loss: 2.296766\n",
      "Epoch 61, loss: 2.296678\n",
      "Epoch 62, loss: 2.296588\n",
      "Epoch 63, loss: 2.296503\n",
      "Epoch 64, loss: 2.296415\n",
      "Epoch 65, loss: 2.296326\n",
      "Epoch 66, loss: 2.296240\n",
      "Epoch 67, loss: 2.296153\n",
      "Epoch 68, loss: 2.296065\n",
      "Epoch 69, loss: 2.295977\n",
      "Epoch 70, loss: 2.295889\n",
      "Epoch 71, loss: 2.295803\n",
      "Epoch 72, loss: 2.295716\n",
      "Epoch 73, loss: 2.295630\n",
      "Epoch 74, loss: 2.295543\n",
      "Epoch 75, loss: 2.295457\n",
      "Epoch 76, loss: 2.295371\n",
      "Epoch 77, loss: 2.295283\n",
      "Epoch 78, loss: 2.295198\n",
      "Epoch 79, loss: 2.295108\n",
      "Epoch 80, loss: 2.295023\n",
      "Epoch 81, loss: 2.294939\n",
      "Epoch 82, loss: 2.294854\n",
      "Epoch 83, loss: 2.294765\n",
      "Epoch 84, loss: 2.294681\n",
      "Epoch 85, loss: 2.294595\n",
      "Epoch 86, loss: 2.294511\n",
      "Epoch 87, loss: 2.294425\n",
      "Epoch 88, loss: 2.294338\n",
      "Epoch 89, loss: 2.294253\n",
      "Epoch 90, loss: 2.294166\n",
      "Epoch 91, loss: 2.294082\n",
      "Epoch 92, loss: 2.293998\n",
      "Epoch 93, loss: 2.293913\n",
      "Epoch 94, loss: 2.293826\n",
      "Epoch 95, loss: 2.293743\n",
      "Epoch 96, loss: 2.293658\n",
      "Epoch 97, loss: 2.293575\n",
      "Epoch 98, loss: 2.293489\n",
      "Epoch 99, loss: 2.293404\n",
      "Epoch 100, loss: 2.293321\n",
      "Epoch 101, loss: 2.293236\n",
      "Epoch 102, loss: 2.293152\n",
      "Epoch 103, loss: 2.293066\n",
      "Epoch 104, loss: 2.292985\n",
      "Epoch 105, loss: 2.292900\n",
      "Epoch 106, loss: 2.292816\n",
      "Epoch 107, loss: 2.292731\n",
      "Epoch 108, loss: 2.292648\n",
      "Epoch 109, loss: 2.292564\n",
      "Epoch 110, loss: 2.292481\n",
      "Epoch 111, loss: 2.292396\n",
      "Epoch 112, loss: 2.292314\n",
      "Epoch 113, loss: 2.292233\n",
      "Epoch 114, loss: 2.292146\n",
      "Epoch 115, loss: 2.292064\n",
      "Epoch 116, loss: 2.291980\n",
      "Epoch 117, loss: 2.291899\n",
      "Epoch 118, loss: 2.291816\n",
      "Epoch 119, loss: 2.291731\n",
      "Epoch 120, loss: 2.291649\n",
      "Epoch 121, loss: 2.291565\n",
      "Epoch 122, loss: 2.291487\n",
      "Epoch 123, loss: 2.291403\n",
      "Epoch 124, loss: 2.291321\n",
      "Epoch 125, loss: 2.291236\n",
      "Epoch 126, loss: 2.291154\n",
      "Epoch 127, loss: 2.291073\n",
      "Epoch 128, loss: 2.290989\n",
      "Epoch 129, loss: 2.290906\n",
      "Epoch 130, loss: 2.290824\n",
      "Epoch 131, loss: 2.290741\n",
      "Epoch 132, loss: 2.290661\n",
      "Epoch 133, loss: 2.290580\n",
      "Epoch 134, loss: 2.290497\n",
      "Epoch 135, loss: 2.290415\n",
      "Epoch 136, loss: 2.290334\n",
      "Epoch 137, loss: 2.290254\n",
      "Epoch 138, loss: 2.290171\n",
      "Epoch 139, loss: 2.290090\n",
      "Epoch 140, loss: 2.290005\n",
      "Epoch 141, loss: 2.289926\n",
      "Epoch 142, loss: 2.289846\n",
      "Epoch 143, loss: 2.289763\n",
      "Epoch 144, loss: 2.289682\n",
      "Epoch 145, loss: 2.289601\n",
      "Epoch 146, loss: 2.289522\n",
      "Epoch 147, loss: 2.289440\n",
      "Epoch 148, loss: 2.289359\n",
      "Epoch 149, loss: 2.289278\n",
      "Epoch 150, loss: 2.289195\n",
      "Epoch 151, loss: 2.289117\n",
      "Epoch 152, loss: 2.289037\n",
      "Epoch 153, loss: 2.288956\n",
      "Epoch 154, loss: 2.288875\n",
      "Epoch 155, loss: 2.288793\n",
      "Epoch 156, loss: 2.288713\n",
      "Epoch 157, loss: 2.288634\n",
      "Epoch 158, loss: 2.288552\n",
      "Epoch 159, loss: 2.288476\n",
      "Epoch 160, loss: 2.288395\n",
      "Epoch 161, loss: 2.288312\n",
      "Epoch 162, loss: 2.288233\n",
      "Epoch 163, loss: 2.288153\n",
      "Epoch 164, loss: 2.288073\n",
      "Epoch 165, loss: 2.287994\n",
      "Epoch 166, loss: 2.287915\n",
      "Epoch 167, loss: 2.287833\n",
      "Epoch 168, loss: 2.287755\n",
      "Epoch 169, loss: 2.287676\n",
      "Epoch 170, loss: 2.287596\n",
      "Epoch 171, loss: 2.287517\n",
      "Epoch 172, loss: 2.287437\n",
      "Epoch 173, loss: 2.287357\n",
      "Epoch 174, loss: 2.287279\n",
      "Epoch 175, loss: 2.287200\n",
      "Epoch 176, loss: 2.287123\n",
      "Epoch 177, loss: 2.287043\n",
      "Epoch 178, loss: 2.286963\n",
      "Epoch 179, loss: 2.286884\n",
      "Epoch 180, loss: 2.286806\n",
      "Epoch 181, loss: 2.286727\n",
      "Epoch 182, loss: 2.286646\n",
      "Epoch 183, loss: 2.286570\n",
      "Epoch 184, loss: 2.286490\n",
      "Epoch 185, loss: 2.286411\n",
      "Epoch 186, loss: 2.286335\n",
      "Epoch 187, loss: 2.286256\n",
      "Epoch 188, loss: 2.286177\n",
      "Epoch 189, loss: 2.286098\n",
      "Epoch 190, loss: 2.286022\n",
      "Epoch 191, loss: 2.285942\n",
      "Epoch 192, loss: 2.285864\n",
      "Epoch 193, loss: 2.285786\n",
      "Epoch 194, loss: 2.285708\n",
      "Epoch 195, loss: 2.285630\n",
      "Epoch 196, loss: 2.285552\n",
      "Epoch 197, loss: 2.285474\n",
      "Epoch 198, loss: 2.285396\n",
      "Epoch 199, loss: 2.285319\n",
      "lr: 0.0001, rs: 1e-05, accuracy 200 epochs: 0.175\n",
      "Epoch 0, loss: 2.302629\n",
      "Epoch 1, loss: 2.302519\n",
      "Epoch 2, loss: 2.302413\n",
      "Epoch 3, loss: 2.302308\n",
      "Epoch 4, loss: 2.302199\n",
      "Epoch 5, loss: 2.302095\n",
      "Epoch 6, loss: 2.301989\n",
      "Epoch 7, loss: 2.301884\n",
      "Epoch 8, loss: 2.301782\n",
      "Epoch 9, loss: 2.301677\n",
      "Epoch 10, loss: 2.301574\n",
      "Epoch 11, loss: 2.301472\n",
      "Epoch 12, loss: 2.301370\n",
      "Epoch 13, loss: 2.301270\n",
      "Epoch 14, loss: 2.301168\n",
      "Epoch 15, loss: 2.301070\n",
      "Epoch 16, loss: 2.300970\n",
      "Epoch 17, loss: 2.300870\n",
      "Epoch 18, loss: 2.300772\n",
      "Epoch 19, loss: 2.300672\n",
      "Epoch 20, loss: 2.300575\n",
      "Epoch 21, loss: 2.300476\n",
      "Epoch 22, loss: 2.300382\n",
      "Epoch 23, loss: 2.300284\n",
      "Epoch 24, loss: 2.300188\n",
      "Epoch 25, loss: 2.300091\n",
      "Epoch 26, loss: 2.299994\n",
      "Epoch 27, loss: 2.299899\n",
      "Epoch 28, loss: 2.299804\n",
      "Epoch 29, loss: 2.299710\n",
      "Epoch 30, loss: 2.299615\n",
      "Epoch 31, loss: 2.299521\n",
      "Epoch 32, loss: 2.299428\n",
      "Epoch 33, loss: 2.299335\n",
      "Epoch 34, loss: 2.299242\n",
      "Epoch 35, loss: 2.299149\n",
      "Epoch 36, loss: 2.299057\n",
      "Epoch 37, loss: 2.298962\n",
      "Epoch 38, loss: 2.298870\n",
      "Epoch 39, loss: 2.298777\n",
      "Epoch 40, loss: 2.298684\n",
      "Epoch 41, loss: 2.298595\n",
      "Epoch 42, loss: 2.298503\n",
      "Epoch 43, loss: 2.298410\n",
      "Epoch 44, loss: 2.298319\n",
      "Epoch 45, loss: 2.298228\n",
      "Epoch 46, loss: 2.298137\n",
      "Epoch 47, loss: 2.298048\n",
      "Epoch 48, loss: 2.297957\n",
      "Epoch 49, loss: 2.297867\n",
      "Epoch 50, loss: 2.297776\n",
      "Epoch 51, loss: 2.297686\n",
      "Epoch 52, loss: 2.297597\n",
      "Epoch 53, loss: 2.297508\n",
      "Epoch 54, loss: 2.297418\n",
      "Epoch 55, loss: 2.297329\n",
      "Epoch 56, loss: 2.297238\n",
      "Epoch 57, loss: 2.297150\n",
      "Epoch 58, loss: 2.297062\n",
      "Epoch 59, loss: 2.296973\n",
      "Epoch 60, loss: 2.296884\n",
      "Epoch 61, loss: 2.296796\n",
      "Epoch 62, loss: 2.296709\n",
      "Epoch 63, loss: 2.296619\n",
      "Epoch 64, loss: 2.296531\n",
      "Epoch 65, loss: 2.296443\n",
      "Epoch 66, loss: 2.296354\n",
      "Epoch 67, loss: 2.296268\n",
      "Epoch 68, loss: 2.296179\n",
      "Epoch 69, loss: 2.296095\n",
      "Epoch 70, loss: 2.296005\n",
      "Epoch 71, loss: 2.295916\n",
      "Epoch 72, loss: 2.295830\n",
      "Epoch 73, loss: 2.295745\n",
      "Epoch 74, loss: 2.295654\n",
      "Epoch 75, loss: 2.295570\n",
      "Epoch 76, loss: 2.295485\n",
      "Epoch 77, loss: 2.295397\n",
      "Epoch 78, loss: 2.295309\n",
      "Epoch 79, loss: 2.295223\n",
      "Epoch 80, loss: 2.295138\n",
      "Epoch 81, loss: 2.295051\n",
      "Epoch 82, loss: 2.294965\n",
      "Epoch 83, loss: 2.294879\n",
      "Epoch 84, loss: 2.294793\n",
      "Epoch 85, loss: 2.294707\n",
      "Epoch 86, loss: 2.294622\n",
      "Epoch 87, loss: 2.294536\n",
      "Epoch 88, loss: 2.294450\n",
      "Epoch 89, loss: 2.294364\n",
      "Epoch 90, loss: 2.294279\n",
      "Epoch 91, loss: 2.294196\n",
      "Epoch 92, loss: 2.294109\n",
      "Epoch 93, loss: 2.294026\n",
      "Epoch 94, loss: 2.293937\n",
      "Epoch 95, loss: 2.293854\n",
      "Epoch 96, loss: 2.293769\n",
      "Epoch 97, loss: 2.293685\n",
      "Epoch 98, loss: 2.293599\n",
      "Epoch 99, loss: 2.293515\n",
      "Epoch 100, loss: 2.293430\n",
      "Epoch 101, loss: 2.293344\n",
      "Epoch 102, loss: 2.293262\n",
      "Epoch 103, loss: 2.293178\n",
      "Epoch 104, loss: 2.293094\n",
      "Epoch 105, loss: 2.293008\n",
      "Epoch 106, loss: 2.292925\n",
      "Epoch 107, loss: 2.292841\n",
      "Epoch 108, loss: 2.292758\n",
      "Epoch 109, loss: 2.292675\n",
      "Epoch 110, loss: 2.292591\n",
      "Epoch 111, loss: 2.292507\n",
      "Epoch 112, loss: 2.292423\n",
      "Epoch 113, loss: 2.292338\n",
      "Epoch 114, loss: 2.292256\n",
      "Epoch 115, loss: 2.292174\n",
      "Epoch 116, loss: 2.292089\n",
      "Epoch 117, loss: 2.292005\n",
      "Epoch 118, loss: 2.291922\n",
      "Epoch 119, loss: 2.291840\n",
      "Epoch 120, loss: 2.291757\n",
      "Epoch 121, loss: 2.291677\n",
      "Epoch 122, loss: 2.291591\n",
      "Epoch 123, loss: 2.291510\n",
      "Epoch 124, loss: 2.291427\n",
      "Epoch 125, loss: 2.291344\n",
      "Epoch 126, loss: 2.291262\n",
      "Epoch 127, loss: 2.291177\n",
      "Epoch 128, loss: 2.291095\n",
      "Epoch 129, loss: 2.291016\n",
      "Epoch 130, loss: 2.290931\n",
      "Epoch 131, loss: 2.290849\n",
      "Epoch 132, loss: 2.290768\n",
      "Epoch 133, loss: 2.290684\n",
      "Epoch 134, loss: 2.290603\n",
      "Epoch 135, loss: 2.290520\n",
      "Epoch 136, loss: 2.290440\n",
      "Epoch 137, loss: 2.290358\n",
      "Epoch 138, loss: 2.290276\n",
      "Epoch 139, loss: 2.290193\n",
      "Epoch 140, loss: 2.290112\n",
      "Epoch 141, loss: 2.290032\n",
      "Epoch 142, loss: 2.289949\n",
      "Epoch 143, loss: 2.289869\n",
      "Epoch 144, loss: 2.289789\n",
      "Epoch 145, loss: 2.289706\n",
      "Epoch 146, loss: 2.289624\n",
      "Epoch 147, loss: 2.289544\n",
      "Epoch 148, loss: 2.289462\n",
      "Epoch 149, loss: 2.289382\n",
      "Epoch 150, loss: 2.289302\n",
      "Epoch 151, loss: 2.289220\n",
      "Epoch 152, loss: 2.289139\n",
      "Epoch 153, loss: 2.289060\n",
      "Epoch 154, loss: 2.288978\n",
      "Epoch 155, loss: 2.288898\n",
      "Epoch 156, loss: 2.288816\n",
      "Epoch 157, loss: 2.288737\n",
      "Epoch 158, loss: 2.288658\n",
      "Epoch 159, loss: 2.288577\n",
      "Epoch 160, loss: 2.288497\n",
      "Epoch 161, loss: 2.288417\n",
      "Epoch 162, loss: 2.288336\n",
      "Epoch 163, loss: 2.288255\n",
      "Epoch 164, loss: 2.288177\n",
      "Epoch 165, loss: 2.288097\n",
      "Epoch 166, loss: 2.288017\n",
      "Epoch 167, loss: 2.287936\n",
      "Epoch 168, loss: 2.287860\n",
      "Epoch 169, loss: 2.287778\n",
      "Epoch 170, loss: 2.287699\n",
      "Epoch 171, loss: 2.287618\n",
      "Epoch 172, loss: 2.287541\n",
      "Epoch 173, loss: 2.287460\n",
      "Epoch 174, loss: 2.287381\n",
      "Epoch 175, loss: 2.287301\n",
      "Epoch 176, loss: 2.287223\n",
      "Epoch 177, loss: 2.287144\n",
      "Epoch 178, loss: 2.287065\n",
      "Epoch 179, loss: 2.286987\n",
      "Epoch 180, loss: 2.286906\n",
      "Epoch 181, loss: 2.286826\n",
      "Epoch 182, loss: 2.286752\n",
      "Epoch 183, loss: 2.286670\n",
      "Epoch 184, loss: 2.286591\n",
      "Epoch 185, loss: 2.286512\n",
      "Epoch 186, loss: 2.286434\n",
      "Epoch 187, loss: 2.286356\n",
      "Epoch 188, loss: 2.286278\n",
      "Epoch 189, loss: 2.286199\n",
      "Epoch 190, loss: 2.286122\n",
      "Epoch 191, loss: 2.286042\n",
      "Epoch 192, loss: 2.285964\n",
      "Epoch 193, loss: 2.285886\n",
      "Epoch 194, loss: 2.285810\n",
      "Epoch 195, loss: 2.285730\n",
      "Epoch 196, loss: 2.285651\n",
      "Epoch 197, loss: 2.285574\n",
      "Epoch 198, loss: 2.285496\n",
      "Epoch 199, loss: 2.285420\n",
      "lr: 0.0001, rs: 1e-06, accuracy 200 epochs: 0.176\n",
      "Epoch 0, loss: 2.305878\n",
      "Epoch 1, loss: 2.305867\n",
      "Epoch 2, loss: 2.305855\n",
      "Epoch 3, loss: 2.305843\n",
      "Epoch 4, loss: 2.305832\n",
      "Epoch 5, loss: 2.305820\n",
      "Epoch 6, loss: 2.305808\n",
      "Epoch 7, loss: 2.305797\n",
      "Epoch 8, loss: 2.305785\n",
      "Epoch 9, loss: 2.305774\n",
      "Epoch 10, loss: 2.305762\n",
      "Epoch 11, loss: 2.305750\n",
      "Epoch 12, loss: 2.305739\n",
      "Epoch 13, loss: 2.305727\n",
      "Epoch 14, loss: 2.305716\n",
      "Epoch 15, loss: 2.305704\n",
      "Epoch 16, loss: 2.305693\n",
      "Epoch 17, loss: 2.305681\n",
      "Epoch 18, loss: 2.305670\n",
      "Epoch 19, loss: 2.305658\n",
      "Epoch 20, loss: 2.305647\n",
      "Epoch 21, loss: 2.305635\n",
      "Epoch 22, loss: 2.305624\n",
      "Epoch 23, loss: 2.305612\n",
      "Epoch 24, loss: 2.305601\n",
      "Epoch 25, loss: 2.305589\n",
      "Epoch 26, loss: 2.305578\n",
      "Epoch 27, loss: 2.305567\n",
      "Epoch 28, loss: 2.305555\n",
      "Epoch 29, loss: 2.305544\n",
      "Epoch 30, loss: 2.305533\n",
      "Epoch 31, loss: 2.305521\n",
      "Epoch 32, loss: 2.305510\n",
      "Epoch 33, loss: 2.305498\n",
      "Epoch 34, loss: 2.305487\n",
      "Epoch 35, loss: 2.305476\n",
      "Epoch 36, loss: 2.305464\n",
      "Epoch 37, loss: 2.305453\n",
      "Epoch 38, loss: 2.305442\n",
      "Epoch 39, loss: 2.305431\n",
      "Epoch 40, loss: 2.305419\n",
      "Epoch 41, loss: 2.305408\n",
      "Epoch 42, loss: 2.305397\n",
      "Epoch 43, loss: 2.305386\n",
      "Epoch 44, loss: 2.305374\n",
      "Epoch 45, loss: 2.305363\n",
      "Epoch 46, loss: 2.305352\n",
      "Epoch 47, loss: 2.305341\n",
      "Epoch 48, loss: 2.305329\n",
      "Epoch 49, loss: 2.305318\n",
      "Epoch 50, loss: 2.305307\n",
      "Epoch 51, loss: 2.305296\n",
      "Epoch 52, loss: 2.305285\n",
      "Epoch 53, loss: 2.305274\n",
      "Epoch 54, loss: 2.305262\n",
      "Epoch 55, loss: 2.305251\n",
      "Epoch 56, loss: 2.305240\n",
      "Epoch 57, loss: 2.305229\n",
      "Epoch 58, loss: 2.305218\n",
      "Epoch 59, loss: 2.305207\n",
      "Epoch 60, loss: 2.305196\n",
      "Epoch 61, loss: 2.305185\n",
      "Epoch 62, loss: 2.305174\n",
      "Epoch 63, loss: 2.305162\n",
      "Epoch 64, loss: 2.305151\n",
      "Epoch 65, loss: 2.305140\n",
      "Epoch 66, loss: 2.305129\n",
      "Epoch 67, loss: 2.305118\n",
      "Epoch 68, loss: 2.305107\n",
      "Epoch 69, loss: 2.305096\n",
      "Epoch 70, loss: 2.305085\n",
      "Epoch 71, loss: 2.305075\n",
      "Epoch 72, loss: 2.305063\n",
      "Epoch 73, loss: 2.305052\n",
      "Epoch 74, loss: 2.305041\n",
      "Epoch 75, loss: 2.305031\n",
      "Epoch 76, loss: 2.305020\n",
      "Epoch 77, loss: 2.305008\n",
      "Epoch 78, loss: 2.304998\n",
      "Epoch 79, loss: 2.304987\n",
      "Epoch 80, loss: 2.304976\n",
      "Epoch 81, loss: 2.304965\n",
      "Epoch 82, loss: 2.304954\n",
      "Epoch 83, loss: 2.304943\n",
      "Epoch 84, loss: 2.304932\n",
      "Epoch 85, loss: 2.304921\n",
      "Epoch 86, loss: 2.304910\n",
      "Epoch 87, loss: 2.304900\n",
      "Epoch 88, loss: 2.304888\n",
      "Epoch 89, loss: 2.304878\n",
      "Epoch 90, loss: 2.304867\n",
      "Epoch 91, loss: 2.304856\n",
      "Epoch 92, loss: 2.304845\n",
      "Epoch 93, loss: 2.304835\n",
      "Epoch 94, loss: 2.304824\n",
      "Epoch 95, loss: 2.304813\n",
      "Epoch 96, loss: 2.304802\n",
      "Epoch 97, loss: 2.304791\n",
      "Epoch 98, loss: 2.304781\n",
      "Epoch 99, loss: 2.304770\n",
      "Epoch 100, loss: 2.304759\n",
      "Epoch 101, loss: 2.304748\n",
      "Epoch 102, loss: 2.304738\n",
      "Epoch 103, loss: 2.304727\n",
      "Epoch 104, loss: 2.304716\n",
      "Epoch 105, loss: 2.304706\n",
      "Epoch 106, loss: 2.304695\n",
      "Epoch 107, loss: 2.304684\n",
      "Epoch 108, loss: 2.304673\n",
      "Epoch 109, loss: 2.304663\n",
      "Epoch 110, loss: 2.304652\n",
      "Epoch 111, loss: 2.304641\n",
      "Epoch 112, loss: 2.304631\n",
      "Epoch 113, loss: 2.304620\n",
      "Epoch 114, loss: 2.304609\n",
      "Epoch 115, loss: 2.304599\n",
      "Epoch 116, loss: 2.304588\n",
      "Epoch 117, loss: 2.304578\n",
      "Epoch 118, loss: 2.304567\n",
      "Epoch 119, loss: 2.304556\n",
      "Epoch 120, loss: 2.304546\n",
      "Epoch 121, loss: 2.304535\n",
      "Epoch 122, loss: 2.304525\n",
      "Epoch 123, loss: 2.304514\n",
      "Epoch 124, loss: 2.304503\n",
      "Epoch 125, loss: 2.304493\n",
      "Epoch 126, loss: 2.304482\n",
      "Epoch 127, loss: 2.304472\n",
      "Epoch 128, loss: 2.304461\n",
      "Epoch 129, loss: 2.304451\n",
      "Epoch 130, loss: 2.304440\n",
      "Epoch 131, loss: 2.304430\n",
      "Epoch 132, loss: 2.304419\n",
      "Epoch 133, loss: 2.304408\n",
      "Epoch 134, loss: 2.304398\n",
      "Epoch 135, loss: 2.304387\n",
      "Epoch 136, loss: 2.304377\n",
      "Epoch 137, loss: 2.304367\n",
      "Epoch 138, loss: 2.304356\n",
      "Epoch 139, loss: 2.304345\n",
      "Epoch 140, loss: 2.304335\n",
      "Epoch 141, loss: 2.304325\n",
      "Epoch 142, loss: 2.304314\n",
      "Epoch 143, loss: 2.304304\n",
      "Epoch 144, loss: 2.304293\n",
      "Epoch 145, loss: 2.304283\n",
      "Epoch 146, loss: 2.304272\n",
      "Epoch 147, loss: 2.304262\n",
      "Epoch 148, loss: 2.304252\n",
      "Epoch 149, loss: 2.304241\n",
      "Epoch 150, loss: 2.304231\n",
      "Epoch 151, loss: 2.304220\n",
      "Epoch 152, loss: 2.304210\n",
      "Epoch 153, loss: 2.304200\n",
      "Epoch 154, loss: 2.304189\n",
      "Epoch 155, loss: 2.304179\n",
      "Epoch 156, loss: 2.304169\n",
      "Epoch 157, loss: 2.304159\n",
      "Epoch 158, loss: 2.304148\n",
      "Epoch 159, loss: 2.304138\n",
      "Epoch 160, loss: 2.304127\n",
      "Epoch 161, loss: 2.304117\n",
      "Epoch 162, loss: 2.304107\n",
      "Epoch 163, loss: 2.304096\n",
      "Epoch 164, loss: 2.304086\n",
      "Epoch 165, loss: 2.304076\n",
      "Epoch 166, loss: 2.304066\n",
      "Epoch 167, loss: 2.304055\n",
      "Epoch 168, loss: 2.304045\n",
      "Epoch 169, loss: 2.304035\n",
      "Epoch 170, loss: 2.304025\n",
      "Epoch 171, loss: 2.304014\n",
      "Epoch 172, loss: 2.304004\n",
      "Epoch 173, loss: 2.303994\n",
      "Epoch 174, loss: 2.303984\n",
      "Epoch 175, loss: 2.303973\n",
      "Epoch 176, loss: 2.303963\n",
      "Epoch 177, loss: 2.303953\n",
      "Epoch 178, loss: 2.303943\n",
      "Epoch 179, loss: 2.303932\n",
      "Epoch 180, loss: 2.303922\n",
      "Epoch 181, loss: 2.303912\n",
      "Epoch 182, loss: 2.303902\n",
      "Epoch 183, loss: 2.303892\n",
      "Epoch 184, loss: 2.303881\n",
      "Epoch 185, loss: 2.303871\n",
      "Epoch 186, loss: 2.303861\n",
      "Epoch 187, loss: 2.303851\n",
      "Epoch 188, loss: 2.303841\n",
      "Epoch 189, loss: 2.303831\n",
      "Epoch 190, loss: 2.303820\n",
      "Epoch 191, loss: 2.303810\n",
      "Epoch 192, loss: 2.303800\n",
      "Epoch 193, loss: 2.303790\n",
      "Epoch 194, loss: 2.303780\n",
      "Epoch 195, loss: 2.303770\n",
      "Epoch 196, loss: 2.303760\n",
      "Epoch 197, loss: 2.303750\n",
      "Epoch 198, loss: 2.303740\n",
      "Epoch 199, loss: 2.303729\n",
      "lr: 1e-05, rs: 0.1, accuracy 200 epochs: 0.097\n",
      "Epoch 0, loss: 2.302844\n",
      "Epoch 1, loss: 2.302834\n",
      "Epoch 2, loss: 2.302823\n",
      "Epoch 3, loss: 2.302812\n",
      "Epoch 4, loss: 2.302801\n",
      "Epoch 5, loss: 2.302790\n",
      "Epoch 6, loss: 2.302780\n",
      "Epoch 7, loss: 2.302769\n",
      "Epoch 8, loss: 2.302758\n",
      "Epoch 9, loss: 2.302747\n",
      "Epoch 10, loss: 2.302736\n",
      "Epoch 11, loss: 2.302726\n",
      "Epoch 12, loss: 2.302715\n",
      "Epoch 13, loss: 2.302704\n",
      "Epoch 14, loss: 2.302694\n",
      "Epoch 15, loss: 2.302683\n",
      "Epoch 16, loss: 2.302672\n",
      "Epoch 17, loss: 2.302662\n",
      "Epoch 18, loss: 2.302651\n",
      "Epoch 19, loss: 2.302640\n",
      "Epoch 20, loss: 2.302630\n",
      "Epoch 21, loss: 2.302619\n",
      "Epoch 22, loss: 2.302608\n",
      "Epoch 23, loss: 2.302597\n",
      "Epoch 24, loss: 2.302587\n",
      "Epoch 25, loss: 2.302576\n",
      "Epoch 26, loss: 2.302566\n",
      "Epoch 27, loss: 2.302555\n",
      "Epoch 28, loss: 2.302544\n",
      "Epoch 29, loss: 2.302534\n",
      "Epoch 30, loss: 2.302523\n",
      "Epoch 31, loss: 2.302512\n",
      "Epoch 32, loss: 2.302502\n",
      "Epoch 33, loss: 2.302491\n",
      "Epoch 34, loss: 2.302481\n",
      "Epoch 35, loss: 2.302470\n",
      "Epoch 36, loss: 2.302459\n",
      "Epoch 37, loss: 2.302449\n",
      "Epoch 38, loss: 2.302439\n",
      "Epoch 39, loss: 2.302428\n",
      "Epoch 40, loss: 2.302417\n",
      "Epoch 41, loss: 2.302407\n",
      "Epoch 42, loss: 2.302397\n",
      "Epoch 43, loss: 2.302386\n",
      "Epoch 44, loss: 2.302375\n",
      "Epoch 45, loss: 2.302365\n",
      "Epoch 46, loss: 2.302354\n",
      "Epoch 47, loss: 2.302344\n",
      "Epoch 48, loss: 2.302333\n",
      "Epoch 49, loss: 2.302323\n",
      "Epoch 50, loss: 2.302312\n",
      "Epoch 51, loss: 2.302302\n",
      "Epoch 52, loss: 2.302292\n",
      "Epoch 53, loss: 2.302281\n",
      "Epoch 54, loss: 2.302271\n",
      "Epoch 55, loss: 2.302260\n",
      "Epoch 56, loss: 2.302250\n",
      "Epoch 57, loss: 2.302239\n",
      "Epoch 58, loss: 2.302229\n",
      "Epoch 59, loss: 2.302218\n",
      "Epoch 60, loss: 2.302208\n",
      "Epoch 61, loss: 2.302198\n",
      "Epoch 62, loss: 2.302187\n",
      "Epoch 63, loss: 2.302177\n",
      "Epoch 64, loss: 2.302167\n",
      "Epoch 65, loss: 2.302156\n",
      "Epoch 66, loss: 2.302146\n",
      "Epoch 67, loss: 2.302135\n",
      "Epoch 68, loss: 2.302125\n",
      "Epoch 69, loss: 2.302115\n",
      "Epoch 70, loss: 2.302105\n",
      "Epoch 71, loss: 2.302094\n",
      "Epoch 72, loss: 2.302084\n",
      "Epoch 73, loss: 2.302073\n",
      "Epoch 74, loss: 2.302063\n",
      "Epoch 75, loss: 2.302053\n",
      "Epoch 76, loss: 2.302042\n",
      "Epoch 77, loss: 2.302032\n",
      "Epoch 78, loss: 2.302022\n",
      "Epoch 79, loss: 2.302012\n",
      "Epoch 80, loss: 2.302001\n",
      "Epoch 81, loss: 2.301991\n",
      "Epoch 82, loss: 2.301981\n",
      "Epoch 83, loss: 2.301971\n",
      "Epoch 84, loss: 2.301960\n",
      "Epoch 85, loss: 2.301950\n",
      "Epoch 86, loss: 2.301940\n",
      "Epoch 87, loss: 2.301930\n",
      "Epoch 88, loss: 2.301919\n",
      "Epoch 89, loss: 2.301909\n",
      "Epoch 90, loss: 2.301899\n",
      "Epoch 91, loss: 2.301889\n",
      "Epoch 92, loss: 2.301878\n",
      "Epoch 93, loss: 2.301868\n",
      "Epoch 94, loss: 2.301858\n",
      "Epoch 95, loss: 2.301848\n",
      "Epoch 96, loss: 2.301838\n",
      "Epoch 97, loss: 2.301828\n",
      "Epoch 98, loss: 2.301817\n",
      "Epoch 99, loss: 2.301807\n",
      "Epoch 100, loss: 2.301797\n",
      "Epoch 101, loss: 2.301787\n",
      "Epoch 102, loss: 2.301777\n",
      "Epoch 103, loss: 2.301766\n",
      "Epoch 104, loss: 2.301756\n",
      "Epoch 105, loss: 2.301746\n",
      "Epoch 106, loss: 2.301736\n",
      "Epoch 107, loss: 2.301726\n",
      "Epoch 108, loss: 2.301716\n",
      "Epoch 109, loss: 2.301706\n",
      "Epoch 110, loss: 2.301696\n",
      "Epoch 111, loss: 2.301686\n",
      "Epoch 112, loss: 2.301675\n",
      "Epoch 113, loss: 2.301665\n",
      "Epoch 114, loss: 2.301655\n",
      "Epoch 115, loss: 2.301645\n",
      "Epoch 116, loss: 2.301635\n",
      "Epoch 117, loss: 2.301625\n",
      "Epoch 118, loss: 2.301615\n",
      "Epoch 119, loss: 2.301605\n",
      "Epoch 120, loss: 2.301595\n",
      "Epoch 121, loss: 2.301585\n",
      "Epoch 122, loss: 2.301574\n",
      "Epoch 123, loss: 2.301565\n",
      "Epoch 124, loss: 2.301554\n",
      "Epoch 125, loss: 2.301544\n",
      "Epoch 126, loss: 2.301534\n",
      "Epoch 127, loss: 2.301524\n",
      "Epoch 128, loss: 2.301514\n",
      "Epoch 129, loss: 2.301504\n",
      "Epoch 130, loss: 2.301494\n",
      "Epoch 131, loss: 2.301484\n",
      "Epoch 132, loss: 2.301474\n",
      "Epoch 133, loss: 2.301464\n",
      "Epoch 134, loss: 2.301454\n",
      "Epoch 135, loss: 2.301444\n",
      "Epoch 136, loss: 2.301434\n",
      "Epoch 137, loss: 2.301424\n",
      "Epoch 138, loss: 2.301414\n",
      "Epoch 139, loss: 2.301405\n",
      "Epoch 140, loss: 2.301394\n",
      "Epoch 141, loss: 2.301385\n",
      "Epoch 142, loss: 2.301374\n",
      "Epoch 143, loss: 2.301365\n",
      "Epoch 144, loss: 2.301355\n",
      "Epoch 145, loss: 2.301345\n",
      "Epoch 146, loss: 2.301335\n",
      "Epoch 147, loss: 2.301325\n",
      "Epoch 148, loss: 2.301315\n",
      "Epoch 149, loss: 2.301305\n",
      "Epoch 150, loss: 2.301295\n",
      "Epoch 151, loss: 2.301285\n",
      "Epoch 152, loss: 2.301275\n",
      "Epoch 153, loss: 2.301265\n",
      "Epoch 154, loss: 2.301255\n",
      "Epoch 155, loss: 2.301245\n",
      "Epoch 156, loss: 2.301236\n",
      "Epoch 157, loss: 2.301226\n",
      "Epoch 158, loss: 2.301216\n",
      "Epoch 159, loss: 2.301206\n",
      "Epoch 160, loss: 2.301196\n",
      "Epoch 161, loss: 2.301186\n",
      "Epoch 162, loss: 2.301177\n",
      "Epoch 163, loss: 2.301166\n",
      "Epoch 164, loss: 2.301157\n",
      "Epoch 165, loss: 2.301147\n",
      "Epoch 166, loss: 2.301137\n",
      "Epoch 167, loss: 2.301127\n",
      "Epoch 168, loss: 2.301117\n",
      "Epoch 169, loss: 2.301107\n",
      "Epoch 170, loss: 2.301098\n",
      "Epoch 171, loss: 2.301088\n",
      "Epoch 172, loss: 2.301078\n",
      "Epoch 173, loss: 2.301068\n",
      "Epoch 174, loss: 2.301058\n",
      "Epoch 175, loss: 2.301048\n",
      "Epoch 176, loss: 2.301039\n",
      "Epoch 177, loss: 2.301029\n",
      "Epoch 178, loss: 2.301019\n",
      "Epoch 179, loss: 2.301009\n",
      "Epoch 180, loss: 2.300999\n",
      "Epoch 181, loss: 2.300990\n",
      "Epoch 182, loss: 2.300980\n",
      "Epoch 183, loss: 2.300970\n",
      "Epoch 184, loss: 2.300961\n",
      "Epoch 185, loss: 2.300951\n",
      "Epoch 186, loss: 2.300941\n",
      "Epoch 187, loss: 2.300931\n",
      "Epoch 188, loss: 2.300921\n",
      "Epoch 189, loss: 2.300912\n",
      "Epoch 190, loss: 2.300902\n",
      "Epoch 191, loss: 2.300892\n",
      "Epoch 192, loss: 2.300882\n",
      "Epoch 193, loss: 2.300873\n",
      "Epoch 194, loss: 2.300863\n",
      "Epoch 195, loss: 2.300853\n",
      "Epoch 196, loss: 2.300843\n",
      "Epoch 197, loss: 2.300834\n",
      "Epoch 198, loss: 2.300824\n",
      "Epoch 199, loss: 2.300814\n",
      "lr: 1e-05, rs: 0.01, accuracy 200 epochs: 0.118\n",
      "Epoch 0, loss: 2.303100\n",
      "Epoch 1, loss: 2.303089\n",
      "Epoch 2, loss: 2.303077\n",
      "Epoch 3, loss: 2.303066\n",
      "Epoch 4, loss: 2.303055\n",
      "Epoch 5, loss: 2.303043\n",
      "Epoch 6, loss: 2.303032\n",
      "Epoch 7, loss: 2.303020\n",
      "Epoch 8, loss: 2.303009\n",
      "Epoch 9, loss: 2.302998\n",
      "Epoch 10, loss: 2.302986\n",
      "Epoch 11, loss: 2.302975\n",
      "Epoch 12, loss: 2.302964\n",
      "Epoch 13, loss: 2.302952\n",
      "Epoch 14, loss: 2.302941\n",
      "Epoch 15, loss: 2.302930\n",
      "Epoch 16, loss: 2.302919\n",
      "Epoch 17, loss: 2.302907\n",
      "Epoch 18, loss: 2.302896\n",
      "Epoch 19, loss: 2.302885\n",
      "Epoch 20, loss: 2.302874\n",
      "Epoch 21, loss: 2.302862\n",
      "Epoch 22, loss: 2.302851\n",
      "Epoch 23, loss: 2.302840\n",
      "Epoch 24, loss: 2.302829\n",
      "Epoch 25, loss: 2.302818\n",
      "Epoch 26, loss: 2.302806\n",
      "Epoch 27, loss: 2.302795\n",
      "Epoch 28, loss: 2.302784\n",
      "Epoch 29, loss: 2.302773\n",
      "Epoch 30, loss: 2.302762\n",
      "Epoch 31, loss: 2.302751\n",
      "Epoch 32, loss: 2.302740\n",
      "Epoch 33, loss: 2.302729\n",
      "Epoch 34, loss: 2.302717\n",
      "Epoch 35, loss: 2.302706\n",
      "Epoch 36, loss: 2.302695\n",
      "Epoch 37, loss: 2.302684\n",
      "Epoch 38, loss: 2.302673\n",
      "Epoch 39, loss: 2.302662\n",
      "Epoch 40, loss: 2.302651\n",
      "Epoch 41, loss: 2.302640\n",
      "Epoch 42, loss: 2.302629\n",
      "Epoch 43, loss: 2.302618\n",
      "Epoch 44, loss: 2.302607\n",
      "Epoch 45, loss: 2.302596\n",
      "Epoch 46, loss: 2.302585\n",
      "Epoch 47, loss: 2.302574\n",
      "Epoch 48, loss: 2.302563\n",
      "Epoch 49, loss: 2.302552\n",
      "Epoch 50, loss: 2.302541\n",
      "Epoch 51, loss: 2.302530\n",
      "Epoch 52, loss: 2.302519\n",
      "Epoch 53, loss: 2.302508\n",
      "Epoch 54, loss: 2.302497\n",
      "Epoch 55, loss: 2.302486\n",
      "Epoch 56, loss: 2.302475\n",
      "Epoch 57, loss: 2.302464\n",
      "Epoch 58, loss: 2.302454\n",
      "Epoch 59, loss: 2.302443\n",
      "Epoch 60, loss: 2.302432\n",
      "Epoch 61, loss: 2.302421\n",
      "Epoch 62, loss: 2.302410\n",
      "Epoch 63, loss: 2.302399\n",
      "Epoch 64, loss: 2.302388\n",
      "Epoch 65, loss: 2.302377\n",
      "Epoch 66, loss: 2.302367\n",
      "Epoch 67, loss: 2.302356\n",
      "Epoch 68, loss: 2.302345\n",
      "Epoch 69, loss: 2.302334\n",
      "Epoch 70, loss: 2.302323\n",
      "Epoch 71, loss: 2.302313\n",
      "Epoch 72, loss: 2.302302\n",
      "Epoch 73, loss: 2.302291\n",
      "Epoch 74, loss: 2.302280\n",
      "Epoch 75, loss: 2.302269\n",
      "Epoch 76, loss: 2.302259\n",
      "Epoch 77, loss: 2.302248\n",
      "Epoch 78, loss: 2.302237\n",
      "Epoch 79, loss: 2.302226\n",
      "Epoch 80, loss: 2.302216\n",
      "Epoch 81, loss: 2.302205\n",
      "Epoch 82, loss: 2.302194\n",
      "Epoch 83, loss: 2.302184\n",
      "Epoch 84, loss: 2.302173\n",
      "Epoch 85, loss: 2.302162\n",
      "Epoch 86, loss: 2.302152\n",
      "Epoch 87, loss: 2.302141\n",
      "Epoch 88, loss: 2.302130\n",
      "Epoch 89, loss: 2.302119\n",
      "Epoch 90, loss: 2.302109\n",
      "Epoch 91, loss: 2.302098\n",
      "Epoch 92, loss: 2.302088\n",
      "Epoch 93, loss: 2.302077\n",
      "Epoch 94, loss: 2.302066\n",
      "Epoch 95, loss: 2.302056\n",
      "Epoch 96, loss: 2.302045\n",
      "Epoch 97, loss: 2.302034\n",
      "Epoch 98, loss: 2.302024\n",
      "Epoch 99, loss: 2.302013\n",
      "Epoch 100, loss: 2.302003\n",
      "Epoch 101, loss: 2.301992\n",
      "Epoch 102, loss: 2.301982\n",
      "Epoch 103, loss: 2.301971\n",
      "Epoch 104, loss: 2.301960\n",
      "Epoch 105, loss: 2.301950\n",
      "Epoch 106, loss: 2.301939\n",
      "Epoch 107, loss: 2.301929\n",
      "Epoch 108, loss: 2.301918\n",
      "Epoch 109, loss: 2.301908\n",
      "Epoch 110, loss: 2.301897\n",
      "Epoch 111, loss: 2.301887\n",
      "Epoch 112, loss: 2.301876\n",
      "Epoch 113, loss: 2.301866\n",
      "Epoch 114, loss: 2.301855\n",
      "Epoch 115, loss: 2.301845\n",
      "Epoch 116, loss: 2.301834\n",
      "Epoch 117, loss: 2.301824\n",
      "Epoch 118, loss: 2.301813\n",
      "Epoch 119, loss: 2.301803\n",
      "Epoch 120, loss: 2.301792\n",
      "Epoch 121, loss: 2.301782\n",
      "Epoch 122, loss: 2.301772\n",
      "Epoch 123, loss: 2.301761\n",
      "Epoch 124, loss: 2.301751\n",
      "Epoch 125, loss: 2.301740\n",
      "Epoch 126, loss: 2.301730\n",
      "Epoch 127, loss: 2.301719\n",
      "Epoch 128, loss: 2.301709\n",
      "Epoch 129, loss: 2.301699\n",
      "Epoch 130, loss: 2.301688\n",
      "Epoch 131, loss: 2.301678\n",
      "Epoch 132, loss: 2.301667\n",
      "Epoch 133, loss: 2.301657\n",
      "Epoch 134, loss: 2.301647\n",
      "Epoch 135, loss: 2.301637\n",
      "Epoch 136, loss: 2.301626\n",
      "Epoch 137, loss: 2.301616\n",
      "Epoch 138, loss: 2.301605\n",
      "Epoch 139, loss: 2.301595\n",
      "Epoch 140, loss: 2.301585\n",
      "Epoch 141, loss: 2.301575\n",
      "Epoch 142, loss: 2.301564\n",
      "Epoch 143, loss: 2.301554\n",
      "Epoch 144, loss: 2.301543\n",
      "Epoch 145, loss: 2.301533\n",
      "Epoch 146, loss: 2.301523\n",
      "Epoch 147, loss: 2.301513\n",
      "Epoch 148, loss: 2.301502\n",
      "Epoch 149, loss: 2.301492\n",
      "Epoch 150, loss: 2.301482\n",
      "Epoch 151, loss: 2.301472\n",
      "Epoch 152, loss: 2.301461\n",
      "Epoch 153, loss: 2.301451\n",
      "Epoch 154, loss: 2.301441\n",
      "Epoch 155, loss: 2.301430\n",
      "Epoch 156, loss: 2.301420\n",
      "Epoch 157, loss: 2.301410\n",
      "Epoch 158, loss: 2.301400\n",
      "Epoch 159, loss: 2.301390\n",
      "Epoch 160, loss: 2.301379\n",
      "Epoch 161, loss: 2.301369\n",
      "Epoch 162, loss: 2.301359\n",
      "Epoch 163, loss: 2.301349\n",
      "Epoch 164, loss: 2.301339\n",
      "Epoch 165, loss: 2.301328\n",
      "Epoch 166, loss: 2.301318\n",
      "Epoch 167, loss: 2.301308\n",
      "Epoch 168, loss: 2.301298\n",
      "Epoch 169, loss: 2.301288\n",
      "Epoch 170, loss: 2.301278\n",
      "Epoch 171, loss: 2.301268\n",
      "Epoch 172, loss: 2.301257\n",
      "Epoch 173, loss: 2.301247\n",
      "Epoch 174, loss: 2.301237\n",
      "Epoch 175, loss: 2.301227\n",
      "Epoch 176, loss: 2.301217\n",
      "Epoch 177, loss: 2.301207\n",
      "Epoch 178, loss: 2.301197\n",
      "Epoch 179, loss: 2.301186\n",
      "Epoch 180, loss: 2.301176\n",
      "Epoch 181, loss: 2.301166\n",
      "Epoch 182, loss: 2.301156\n",
      "Epoch 183, loss: 2.301146\n",
      "Epoch 184, loss: 2.301136\n",
      "Epoch 185, loss: 2.301126\n",
      "Epoch 186, loss: 2.301116\n",
      "Epoch 187, loss: 2.301106\n",
      "Epoch 188, loss: 2.301096\n",
      "Epoch 189, loss: 2.301085\n",
      "Epoch 190, loss: 2.301076\n",
      "Epoch 191, loss: 2.301066\n",
      "Epoch 192, loss: 2.301056\n",
      "Epoch 193, loss: 2.301045\n",
      "Epoch 194, loss: 2.301035\n",
      "Epoch 195, loss: 2.301025\n",
      "Epoch 196, loss: 2.301015\n",
      "Epoch 197, loss: 2.301006\n",
      "Epoch 198, loss: 2.300995\n",
      "Epoch 199, loss: 2.300985\n",
      "lr: 1e-05, rs: 0.001, accuracy 200 epochs: 0.121\n",
      "Epoch 0, loss: 2.302804\n",
      "Epoch 1, loss: 2.302792\n",
      "Epoch 2, loss: 2.302780\n",
      "Epoch 3, loss: 2.302768\n",
      "Epoch 4, loss: 2.302756\n",
      "Epoch 5, loss: 2.302745\n",
      "Epoch 6, loss: 2.302733\n",
      "Epoch 7, loss: 2.302721\n",
      "Epoch 8, loss: 2.302709\n",
      "Epoch 9, loss: 2.302697\n",
      "Epoch 10, loss: 2.302686\n",
      "Epoch 11, loss: 2.302674\n",
      "Epoch 12, loss: 2.302662\n",
      "Epoch 13, loss: 2.302650\n",
      "Epoch 14, loss: 2.302639\n",
      "Epoch 15, loss: 2.302627\n",
      "Epoch 16, loss: 2.302616\n",
      "Epoch 17, loss: 2.302604\n",
      "Epoch 18, loss: 2.302592\n",
      "Epoch 19, loss: 2.302581\n",
      "Epoch 20, loss: 2.302569\n",
      "Epoch 21, loss: 2.302557\n",
      "Epoch 22, loss: 2.302546\n",
      "Epoch 23, loss: 2.302534\n",
      "Epoch 24, loss: 2.302523\n",
      "Epoch 25, loss: 2.302511\n",
      "Epoch 26, loss: 2.302500\n",
      "Epoch 27, loss: 2.302488\n",
      "Epoch 28, loss: 2.302476\n",
      "Epoch 29, loss: 2.302465\n",
      "Epoch 30, loss: 2.302453\n",
      "Epoch 31, loss: 2.302442\n",
      "Epoch 32, loss: 2.302430\n",
      "Epoch 33, loss: 2.302419\n",
      "Epoch 34, loss: 2.302407\n",
      "Epoch 35, loss: 2.302396\n",
      "Epoch 36, loss: 2.302384\n",
      "Epoch 37, loss: 2.302373\n",
      "Epoch 38, loss: 2.302362\n",
      "Epoch 39, loss: 2.302350\n",
      "Epoch 40, loss: 2.302339\n",
      "Epoch 41, loss: 2.302327\n",
      "Epoch 42, loss: 2.302316\n",
      "Epoch 43, loss: 2.302305\n",
      "Epoch 44, loss: 2.302293\n",
      "Epoch 45, loss: 2.302282\n",
      "Epoch 46, loss: 2.302270\n",
      "Epoch 47, loss: 2.302259\n",
      "Epoch 48, loss: 2.302248\n",
      "Epoch 49, loss: 2.302237\n",
      "Epoch 50, loss: 2.302225\n",
      "Epoch 51, loss: 2.302214\n",
      "Epoch 52, loss: 2.302203\n",
      "Epoch 53, loss: 2.302191\n",
      "Epoch 54, loss: 2.302180\n",
      "Epoch 55, loss: 2.302169\n",
      "Epoch 56, loss: 2.302158\n",
      "Epoch 57, loss: 2.302146\n",
      "Epoch 58, loss: 2.302135\n",
      "Epoch 59, loss: 2.302124\n",
      "Epoch 60, loss: 2.302113\n",
      "Epoch 61, loss: 2.302101\n",
      "Epoch 62, loss: 2.302090\n",
      "Epoch 63, loss: 2.302079\n",
      "Epoch 64, loss: 2.302068\n",
      "Epoch 65, loss: 2.302057\n",
      "Epoch 66, loss: 2.302046\n",
      "Epoch 67, loss: 2.302034\n",
      "Epoch 68, loss: 2.302023\n",
      "Epoch 69, loss: 2.302012\n",
      "Epoch 70, loss: 2.302001\n",
      "Epoch 71, loss: 2.301990\n",
      "Epoch 72, loss: 2.301979\n",
      "Epoch 73, loss: 2.301968\n",
      "Epoch 74, loss: 2.301957\n",
      "Epoch 75, loss: 2.301946\n",
      "Epoch 76, loss: 2.301935\n",
      "Epoch 77, loss: 2.301924\n",
      "Epoch 78, loss: 2.301912\n",
      "Epoch 79, loss: 2.301902\n",
      "Epoch 80, loss: 2.301891\n",
      "Epoch 81, loss: 2.301879\n",
      "Epoch 82, loss: 2.301868\n",
      "Epoch 83, loss: 2.301857\n",
      "Epoch 84, loss: 2.301847\n",
      "Epoch 85, loss: 2.301836\n",
      "Epoch 86, loss: 2.301825\n",
      "Epoch 87, loss: 2.301814\n",
      "Epoch 88, loss: 2.301803\n",
      "Epoch 89, loss: 2.301792\n",
      "Epoch 90, loss: 2.301780\n",
      "Epoch 91, loss: 2.301770\n",
      "Epoch 92, loss: 2.301759\n",
      "Epoch 93, loss: 2.301748\n",
      "Epoch 94, loss: 2.301737\n",
      "Epoch 95, loss: 2.301726\n",
      "Epoch 96, loss: 2.301715\n",
      "Epoch 97, loss: 2.301704\n",
      "Epoch 98, loss: 2.301694\n",
      "Epoch 99, loss: 2.301683\n",
      "Epoch 100, loss: 2.301672\n",
      "Epoch 101, loss: 2.301661\n",
      "Epoch 102, loss: 2.301650\n",
      "Epoch 103, loss: 2.301639\n",
      "Epoch 104, loss: 2.301629\n",
      "Epoch 105, loss: 2.301618\n",
      "Epoch 106, loss: 2.301607\n",
      "Epoch 107, loss: 2.301596\n",
      "Epoch 108, loss: 2.301585\n",
      "Epoch 109, loss: 2.301575\n",
      "Epoch 110, loss: 2.301564\n",
      "Epoch 111, loss: 2.301553\n",
      "Epoch 112, loss: 2.301542\n",
      "Epoch 113, loss: 2.301531\n",
      "Epoch 114, loss: 2.301521\n",
      "Epoch 115, loss: 2.301510\n",
      "Epoch 116, loss: 2.301499\n",
      "Epoch 117, loss: 2.301489\n",
      "Epoch 118, loss: 2.301478\n",
      "Epoch 119, loss: 2.301467\n",
      "Epoch 120, loss: 2.301456\n",
      "Epoch 121, loss: 2.301446\n",
      "Epoch 122, loss: 2.301435\n",
      "Epoch 123, loss: 2.301425\n",
      "Epoch 124, loss: 2.301414\n",
      "Epoch 125, loss: 2.301403\n",
      "Epoch 126, loss: 2.301392\n",
      "Epoch 127, loss: 2.301382\n",
      "Epoch 128, loss: 2.301371\n",
      "Epoch 129, loss: 2.301361\n",
      "Epoch 130, loss: 2.301350\n",
      "Epoch 131, loss: 2.301340\n",
      "Epoch 132, loss: 2.301329\n",
      "Epoch 133, loss: 2.301318\n",
      "Epoch 134, loss: 2.301307\n",
      "Epoch 135, loss: 2.301297\n",
      "Epoch 136, loss: 2.301286\n",
      "Epoch 137, loss: 2.301276\n",
      "Epoch 138, loss: 2.301265\n",
      "Epoch 139, loss: 2.301255\n",
      "Epoch 140, loss: 2.301244\n",
      "Epoch 141, loss: 2.301233\n",
      "Epoch 142, loss: 2.301223\n",
      "Epoch 143, loss: 2.301213\n",
      "Epoch 144, loss: 2.301202\n",
      "Epoch 145, loss: 2.301192\n",
      "Epoch 146, loss: 2.301181\n",
      "Epoch 147, loss: 2.301170\n",
      "Epoch 148, loss: 2.301160\n",
      "Epoch 149, loss: 2.301150\n",
      "Epoch 150, loss: 2.301139\n",
      "Epoch 151, loss: 2.301129\n",
      "Epoch 152, loss: 2.301118\n",
      "Epoch 153, loss: 2.301108\n",
      "Epoch 154, loss: 2.301097\n",
      "Epoch 155, loss: 2.301087\n",
      "Epoch 156, loss: 2.301076\n",
      "Epoch 157, loss: 2.301066\n",
      "Epoch 158, loss: 2.301055\n",
      "Epoch 159, loss: 2.301045\n",
      "Epoch 160, loss: 2.301035\n",
      "Epoch 161, loss: 2.301024\n",
      "Epoch 162, loss: 2.301014\n",
      "Epoch 163, loss: 2.301003\n",
      "Epoch 164, loss: 2.300993\n",
      "Epoch 165, loss: 2.300983\n",
      "Epoch 166, loss: 2.300972\n",
      "Epoch 167, loss: 2.300962\n",
      "Epoch 168, loss: 2.300951\n",
      "Epoch 169, loss: 2.300941\n",
      "Epoch 170, loss: 2.300931\n",
      "Epoch 171, loss: 2.300921\n",
      "Epoch 172, loss: 2.300910\n",
      "Epoch 173, loss: 2.300900\n",
      "Epoch 174, loss: 2.300890\n",
      "Epoch 175, loss: 2.300879\n",
      "Epoch 176, loss: 2.300869\n",
      "Epoch 177, loss: 2.300859\n",
      "Epoch 178, loss: 2.300848\n",
      "Epoch 179, loss: 2.300838\n",
      "Epoch 180, loss: 2.300828\n",
      "Epoch 181, loss: 2.300817\n",
      "Epoch 182, loss: 2.300807\n",
      "Epoch 183, loss: 2.300797\n",
      "Epoch 184, loss: 2.300787\n",
      "Epoch 185, loss: 2.300776\n",
      "Epoch 186, loss: 2.300766\n",
      "Epoch 187, loss: 2.300756\n",
      "Epoch 188, loss: 2.300746\n",
      "Epoch 189, loss: 2.300736\n",
      "Epoch 190, loss: 2.300725\n",
      "Epoch 191, loss: 2.300715\n",
      "Epoch 192, loss: 2.300705\n",
      "Epoch 193, loss: 2.300695\n",
      "Epoch 194, loss: 2.300685\n",
      "Epoch 195, loss: 2.300674\n",
      "Epoch 196, loss: 2.300664\n",
      "Epoch 197, loss: 2.300654\n",
      "Epoch 198, loss: 2.300644\n",
      "Epoch 199, loss: 2.300634\n",
      "lr: 1e-05, rs: 0.0001, accuracy 200 epochs: 0.128\n",
      "Epoch 0, loss: 2.302623\n",
      "Epoch 1, loss: 2.302611\n",
      "Epoch 2, loss: 2.302600\n",
      "Epoch 3, loss: 2.302588\n",
      "Epoch 4, loss: 2.302577\n",
      "Epoch 5, loss: 2.302565\n",
      "Epoch 6, loss: 2.302554\n",
      "Epoch 7, loss: 2.302543\n",
      "Epoch 8, loss: 2.302531\n",
      "Epoch 9, loss: 2.302520\n",
      "Epoch 10, loss: 2.302508\n",
      "Epoch 11, loss: 2.302497\n",
      "Epoch 12, loss: 2.302485\n",
      "Epoch 13, loss: 2.302474\n",
      "Epoch 14, loss: 2.302463\n",
      "Epoch 15, loss: 2.302451\n",
      "Epoch 16, loss: 2.302440\n",
      "Epoch 17, loss: 2.302429\n",
      "Epoch 18, loss: 2.302417\n",
      "Epoch 19, loss: 2.302406\n",
      "Epoch 20, loss: 2.302395\n",
      "Epoch 21, loss: 2.302383\n",
      "Epoch 22, loss: 2.302372\n",
      "Epoch 23, loss: 2.302361\n",
      "Epoch 24, loss: 2.302350\n",
      "Epoch 25, loss: 2.302339\n",
      "Epoch 26, loss: 2.302327\n",
      "Epoch 27, loss: 2.302316\n",
      "Epoch 28, loss: 2.302305\n",
      "Epoch 29, loss: 2.302294\n",
      "Epoch 30, loss: 2.302282\n",
      "Epoch 31, loss: 2.302271\n",
      "Epoch 32, loss: 2.302260\n",
      "Epoch 33, loss: 2.302249\n",
      "Epoch 34, loss: 2.302238\n",
      "Epoch 35, loss: 2.302226\n",
      "Epoch 36, loss: 2.302215\n",
      "Epoch 37, loss: 2.302204\n",
      "Epoch 38, loss: 2.302193\n",
      "Epoch 39, loss: 2.302182\n",
      "Epoch 40, loss: 2.302171\n",
      "Epoch 41, loss: 2.302160\n",
      "Epoch 42, loss: 2.302149\n",
      "Epoch 43, loss: 2.302138\n",
      "Epoch 44, loss: 2.302126\n",
      "Epoch 45, loss: 2.302115\n",
      "Epoch 46, loss: 2.302104\n",
      "Epoch 47, loss: 2.302093\n",
      "Epoch 48, loss: 2.302082\n",
      "Epoch 49, loss: 2.302071\n",
      "Epoch 50, loss: 2.302060\n",
      "Epoch 51, loss: 2.302049\n",
      "Epoch 52, loss: 2.302038\n",
      "Epoch 53, loss: 2.302027\n",
      "Epoch 54, loss: 2.302016\n",
      "Epoch 55, loss: 2.302005\n",
      "Epoch 56, loss: 2.301994\n",
      "Epoch 57, loss: 2.301983\n",
      "Epoch 58, loss: 2.301973\n",
      "Epoch 59, loss: 2.301962\n",
      "Epoch 60, loss: 2.301950\n",
      "Epoch 61, loss: 2.301940\n",
      "Epoch 62, loss: 2.301929\n",
      "Epoch 63, loss: 2.301918\n",
      "Epoch 64, loss: 2.301907\n",
      "Epoch 65, loss: 2.301896\n",
      "Epoch 66, loss: 2.301885\n",
      "Epoch 67, loss: 2.301874\n",
      "Epoch 68, loss: 2.301863\n",
      "Epoch 69, loss: 2.301852\n",
      "Epoch 70, loss: 2.301842\n",
      "Epoch 71, loss: 2.301831\n",
      "Epoch 72, loss: 2.301820\n",
      "Epoch 73, loss: 2.301809\n",
      "Epoch 74, loss: 2.301798\n",
      "Epoch 75, loss: 2.301788\n",
      "Epoch 76, loss: 2.301777\n",
      "Epoch 77, loss: 2.301766\n",
      "Epoch 78, loss: 2.301755\n",
      "Epoch 79, loss: 2.301744\n",
      "Epoch 80, loss: 2.301734\n",
      "Epoch 81, loss: 2.301723\n",
      "Epoch 82, loss: 2.301712\n",
      "Epoch 83, loss: 2.301701\n",
      "Epoch 84, loss: 2.301691\n",
      "Epoch 85, loss: 2.301680\n",
      "Epoch 86, loss: 2.301669\n",
      "Epoch 87, loss: 2.301658\n",
      "Epoch 88, loss: 2.301648\n",
      "Epoch 89, loss: 2.301637\n",
      "Epoch 90, loss: 2.301626\n",
      "Epoch 91, loss: 2.301616\n",
      "Epoch 92, loss: 2.301605\n",
      "Epoch 93, loss: 2.301594\n",
      "Epoch 94, loss: 2.301584\n",
      "Epoch 95, loss: 2.301573\n",
      "Epoch 96, loss: 2.301562\n",
      "Epoch 97, loss: 2.301552\n",
      "Epoch 98, loss: 2.301541\n",
      "Epoch 99, loss: 2.301531\n",
      "Epoch 100, loss: 2.301520\n",
      "Epoch 101, loss: 2.301509\n",
      "Epoch 102, loss: 2.301499\n",
      "Epoch 103, loss: 2.301488\n",
      "Epoch 104, loss: 2.301477\n",
      "Epoch 105, loss: 2.301467\n",
      "Epoch 106, loss: 2.301456\n",
      "Epoch 107, loss: 2.301446\n",
      "Epoch 108, loss: 2.301435\n",
      "Epoch 109, loss: 2.301425\n",
      "Epoch 110, loss: 2.301414\n",
      "Epoch 111, loss: 2.301403\n",
      "Epoch 112, loss: 2.301393\n",
      "Epoch 113, loss: 2.301382\n",
      "Epoch 114, loss: 2.301372\n",
      "Epoch 115, loss: 2.301361\n",
      "Epoch 116, loss: 2.301351\n",
      "Epoch 117, loss: 2.301341\n",
      "Epoch 118, loss: 2.301330\n",
      "Epoch 119, loss: 2.301319\n",
      "Epoch 120, loss: 2.301309\n",
      "Epoch 121, loss: 2.301298\n",
      "Epoch 122, loss: 2.301288\n",
      "Epoch 123, loss: 2.301278\n",
      "Epoch 124, loss: 2.301267\n",
      "Epoch 125, loss: 2.301257\n",
      "Epoch 126, loss: 2.301246\n",
      "Epoch 127, loss: 2.301236\n",
      "Epoch 128, loss: 2.301225\n",
      "Epoch 129, loss: 2.301215\n",
      "Epoch 130, loss: 2.301205\n",
      "Epoch 131, loss: 2.301194\n",
      "Epoch 132, loss: 2.301184\n",
      "Epoch 133, loss: 2.301173\n",
      "Epoch 134, loss: 2.301163\n",
      "Epoch 135, loss: 2.301153\n",
      "Epoch 136, loss: 2.301142\n",
      "Epoch 137, loss: 2.301132\n",
      "Epoch 138, loss: 2.301121\n",
      "Epoch 139, loss: 2.301111\n",
      "Epoch 140, loss: 2.301101\n",
      "Epoch 141, loss: 2.301090\n",
      "Epoch 142, loss: 2.301080\n",
      "Epoch 143, loss: 2.301070\n",
      "Epoch 144, loss: 2.301059\n",
      "Epoch 145, loss: 2.301049\n",
      "Epoch 146, loss: 2.301039\n",
      "Epoch 147, loss: 2.301028\n",
      "Epoch 148, loss: 2.301018\n",
      "Epoch 149, loss: 2.301008\n",
      "Epoch 150, loss: 2.300998\n",
      "Epoch 151, loss: 2.300987\n",
      "Epoch 152, loss: 2.300977\n",
      "Epoch 153, loss: 2.300967\n",
      "Epoch 154, loss: 2.300956\n",
      "Epoch 155, loss: 2.300946\n",
      "Epoch 156, loss: 2.300936\n",
      "Epoch 157, loss: 2.300926\n",
      "Epoch 158, loss: 2.300915\n",
      "Epoch 159, loss: 2.300905\n",
      "Epoch 160, loss: 2.300895\n",
      "Epoch 161, loss: 2.300885\n",
      "Epoch 162, loss: 2.300874\n",
      "Epoch 163, loss: 2.300864\n",
      "Epoch 164, loss: 2.300854\n",
      "Epoch 165, loss: 2.300844\n",
      "Epoch 166, loss: 2.300834\n",
      "Epoch 167, loss: 2.300823\n",
      "Epoch 168, loss: 2.300813\n",
      "Epoch 169, loss: 2.300803\n",
      "Epoch 170, loss: 2.300793\n",
      "Epoch 171, loss: 2.300783\n",
      "Epoch 172, loss: 2.300773\n",
      "Epoch 173, loss: 2.300762\n",
      "Epoch 174, loss: 2.300752\n",
      "Epoch 175, loss: 2.300742\n",
      "Epoch 176, loss: 2.300732\n",
      "Epoch 177, loss: 2.300722\n",
      "Epoch 178, loss: 2.300712\n",
      "Epoch 179, loss: 2.300702\n",
      "Epoch 180, loss: 2.300691\n",
      "Epoch 181, loss: 2.300681\n",
      "Epoch 182, loss: 2.300671\n",
      "Epoch 183, loss: 2.300661\n",
      "Epoch 184, loss: 2.300651\n",
      "Epoch 185, loss: 2.300641\n",
      "Epoch 186, loss: 2.300631\n",
      "Epoch 187, loss: 2.300621\n",
      "Epoch 188, loss: 2.300611\n",
      "Epoch 189, loss: 2.300601\n",
      "Epoch 190, loss: 2.300591\n",
      "Epoch 191, loss: 2.300581\n",
      "Epoch 192, loss: 2.300571\n",
      "Epoch 193, loss: 2.300561\n",
      "Epoch 194, loss: 2.300550\n",
      "Epoch 195, loss: 2.300540\n",
      "Epoch 196, loss: 2.300530\n",
      "Epoch 197, loss: 2.300520\n",
      "Epoch 198, loss: 2.300510\n",
      "Epoch 199, loss: 2.300500\n",
      "lr: 1e-05, rs: 1e-05, accuracy 200 epochs: 0.133\n",
      "Epoch 0, loss: 2.302705\n",
      "Epoch 1, loss: 2.302693\n",
      "Epoch 2, loss: 2.302681\n",
      "Epoch 3, loss: 2.302669\n",
      "Epoch 4, loss: 2.302658\n",
      "Epoch 5, loss: 2.302646\n",
      "Epoch 6, loss: 2.302634\n",
      "Epoch 7, loss: 2.302622\n",
      "Epoch 8, loss: 2.302611\n",
      "Epoch 9, loss: 2.302599\n",
      "Epoch 10, loss: 2.302587\n",
      "Epoch 11, loss: 2.302576\n",
      "Epoch 12, loss: 2.302564\n",
      "Epoch 13, loss: 2.302553\n",
      "Epoch 14, loss: 2.302541\n",
      "Epoch 15, loss: 2.302529\n",
      "Epoch 16, loss: 2.302518\n",
      "Epoch 17, loss: 2.302506\n",
      "Epoch 18, loss: 2.302495\n",
      "Epoch 19, loss: 2.302483\n",
      "Epoch 20, loss: 2.302471\n",
      "Epoch 21, loss: 2.302460\n",
      "Epoch 22, loss: 2.302448\n",
      "Epoch 23, loss: 2.302437\n",
      "Epoch 24, loss: 2.302425\n",
      "Epoch 25, loss: 2.302414\n",
      "Epoch 26, loss: 2.302403\n",
      "Epoch 27, loss: 2.302391\n",
      "Epoch 28, loss: 2.302379\n",
      "Epoch 29, loss: 2.302368\n",
      "Epoch 30, loss: 2.302356\n",
      "Epoch 31, loss: 2.302345\n",
      "Epoch 32, loss: 2.302334\n",
      "Epoch 33, loss: 2.302322\n",
      "Epoch 34, loss: 2.302311\n",
      "Epoch 35, loss: 2.302299\n",
      "Epoch 36, loss: 2.302288\n",
      "Epoch 37, loss: 2.302277\n",
      "Epoch 38, loss: 2.302265\n",
      "Epoch 39, loss: 2.302254\n",
      "Epoch 40, loss: 2.302242\n",
      "Epoch 41, loss: 2.302231\n",
      "Epoch 42, loss: 2.302220\n",
      "Epoch 43, loss: 2.302209\n",
      "Epoch 44, loss: 2.302197\n",
      "Epoch 45, loss: 2.302186\n",
      "Epoch 46, loss: 2.302175\n",
      "Epoch 47, loss: 2.302164\n",
      "Epoch 48, loss: 2.302152\n",
      "Epoch 49, loss: 2.302141\n",
      "Epoch 50, loss: 2.302130\n",
      "Epoch 51, loss: 2.302119\n",
      "Epoch 52, loss: 2.302107\n",
      "Epoch 53, loss: 2.302096\n",
      "Epoch 54, loss: 2.302085\n",
      "Epoch 55, loss: 2.302074\n",
      "Epoch 56, loss: 2.302062\n",
      "Epoch 57, loss: 2.302051\n",
      "Epoch 58, loss: 2.302040\n",
      "Epoch 59, loss: 2.302029\n",
      "Epoch 60, loss: 2.302018\n",
      "Epoch 61, loss: 2.302007\n",
      "Epoch 62, loss: 2.301996\n",
      "Epoch 63, loss: 2.301984\n",
      "Epoch 64, loss: 2.301973\n",
      "Epoch 65, loss: 2.301962\n",
      "Epoch 66, loss: 2.301951\n",
      "Epoch 67, loss: 2.301940\n",
      "Epoch 68, loss: 2.301929\n",
      "Epoch 69, loss: 2.301918\n",
      "Epoch 70, loss: 2.301907\n",
      "Epoch 71, loss: 2.301896\n",
      "Epoch 72, loss: 2.301885\n",
      "Epoch 73, loss: 2.301874\n",
      "Epoch 74, loss: 2.301863\n",
      "Epoch 75, loss: 2.301851\n",
      "Epoch 76, loss: 2.301841\n",
      "Epoch 77, loss: 2.301830\n",
      "Epoch 78, loss: 2.301819\n",
      "Epoch 79, loss: 2.301808\n",
      "Epoch 80, loss: 2.301797\n",
      "Epoch 81, loss: 2.301786\n",
      "Epoch 82, loss: 2.301775\n",
      "Epoch 83, loss: 2.301764\n",
      "Epoch 84, loss: 2.301753\n",
      "Epoch 85, loss: 2.301742\n",
      "Epoch 86, loss: 2.301731\n",
      "Epoch 87, loss: 2.301720\n",
      "Epoch 88, loss: 2.301709\n",
      "Epoch 89, loss: 2.301698\n",
      "Epoch 90, loss: 2.301687\n",
      "Epoch 91, loss: 2.301677\n",
      "Epoch 92, loss: 2.301666\n",
      "Epoch 93, loss: 2.301655\n",
      "Epoch 94, loss: 2.301644\n",
      "Epoch 95, loss: 2.301633\n",
      "Epoch 96, loss: 2.301622\n",
      "Epoch 97, loss: 2.301611\n",
      "Epoch 98, loss: 2.301601\n",
      "Epoch 99, loss: 2.301590\n",
      "Epoch 100, loss: 2.301579\n",
      "Epoch 101, loss: 2.301568\n",
      "Epoch 102, loss: 2.301557\n",
      "Epoch 103, loss: 2.301547\n",
      "Epoch 104, loss: 2.301536\n",
      "Epoch 105, loss: 2.301525\n",
      "Epoch 106, loss: 2.301514\n",
      "Epoch 107, loss: 2.301504\n",
      "Epoch 108, loss: 2.301493\n",
      "Epoch 109, loss: 2.301482\n",
      "Epoch 110, loss: 2.301471\n",
      "Epoch 111, loss: 2.301461\n",
      "Epoch 112, loss: 2.301450\n",
      "Epoch 113, loss: 2.301439\n",
      "Epoch 114, loss: 2.301428\n",
      "Epoch 115, loss: 2.301418\n",
      "Epoch 116, loss: 2.301407\n",
      "Epoch 117, loss: 2.301396\n",
      "Epoch 118, loss: 2.301386\n",
      "Epoch 119, loss: 2.301375\n",
      "Epoch 120, loss: 2.301364\n",
      "Epoch 121, loss: 2.301354\n",
      "Epoch 122, loss: 2.301343\n",
      "Epoch 123, loss: 2.301333\n",
      "Epoch 124, loss: 2.301322\n",
      "Epoch 125, loss: 2.301311\n",
      "Epoch 126, loss: 2.301301\n",
      "Epoch 127, loss: 2.301290\n",
      "Epoch 128, loss: 2.301279\n",
      "Epoch 129, loss: 2.301269\n",
      "Epoch 130, loss: 2.301258\n",
      "Epoch 131, loss: 2.301248\n",
      "Epoch 132, loss: 2.301237\n",
      "Epoch 133, loss: 2.301227\n",
      "Epoch 134, loss: 2.301216\n",
      "Epoch 135, loss: 2.301206\n",
      "Epoch 136, loss: 2.301195\n",
      "Epoch 137, loss: 2.301184\n",
      "Epoch 138, loss: 2.301174\n",
      "Epoch 139, loss: 2.301163\n",
      "Epoch 140, loss: 2.301153\n",
      "Epoch 141, loss: 2.301142\n",
      "Epoch 142, loss: 2.301132\n",
      "Epoch 143, loss: 2.301121\n",
      "Epoch 144, loss: 2.301111\n",
      "Epoch 145, loss: 2.301100\n",
      "Epoch 146, loss: 2.301090\n",
      "Epoch 147, loss: 2.301079\n",
      "Epoch 148, loss: 2.301069\n",
      "Epoch 149, loss: 2.301059\n",
      "Epoch 150, loss: 2.301048\n",
      "Epoch 151, loss: 2.301038\n",
      "Epoch 152, loss: 2.301027\n",
      "Epoch 153, loss: 2.301017\n",
      "Epoch 154, loss: 2.301006\n",
      "Epoch 155, loss: 2.300996\n",
      "Epoch 156, loss: 2.300986\n",
      "Epoch 157, loss: 2.300975\n",
      "Epoch 158, loss: 2.300965\n",
      "Epoch 159, loss: 2.300954\n",
      "Epoch 160, loss: 2.300944\n",
      "Epoch 161, loss: 2.300934\n",
      "Epoch 162, loss: 2.300923\n",
      "Epoch 163, loss: 2.300913\n",
      "Epoch 164, loss: 2.300903\n",
      "Epoch 165, loss: 2.300892\n",
      "Epoch 166, loss: 2.300882\n",
      "Epoch 167, loss: 2.300872\n",
      "Epoch 168, loss: 2.300861\n",
      "Epoch 169, loss: 2.300851\n",
      "Epoch 170, loss: 2.300841\n",
      "Epoch 171, loss: 2.300830\n",
      "Epoch 172, loss: 2.300820\n",
      "Epoch 173, loss: 2.300810\n",
      "Epoch 174, loss: 2.300799\n",
      "Epoch 175, loss: 2.300789\n",
      "Epoch 176, loss: 2.300779\n",
      "Epoch 177, loss: 2.300768\n",
      "Epoch 178, loss: 2.300758\n",
      "Epoch 179, loss: 2.300748\n",
      "Epoch 180, loss: 2.300738\n",
      "Epoch 181, loss: 2.300728\n",
      "Epoch 182, loss: 2.300717\n",
      "Epoch 183, loss: 2.300707\n",
      "Epoch 184, loss: 2.300697\n",
      "Epoch 185, loss: 2.300687\n",
      "Epoch 186, loss: 2.300676\n",
      "Epoch 187, loss: 2.300666\n",
      "Epoch 188, loss: 2.300656\n",
      "Epoch 189, loss: 2.300646\n",
      "Epoch 190, loss: 2.300636\n",
      "Epoch 191, loss: 2.300625\n",
      "Epoch 192, loss: 2.300615\n",
      "Epoch 193, loss: 2.300605\n",
      "Epoch 194, loss: 2.300595\n",
      "Epoch 195, loss: 2.300584\n",
      "Epoch 196, loss: 2.300575\n",
      "Epoch 197, loss: 2.300564\n",
      "Epoch 198, loss: 2.300554\n",
      "Epoch 199, loss: 2.300544\n",
      "lr: 1e-05, rs: 1e-06, accuracy 200 epochs: 0.12\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-1bf9a1a92f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best validation accuracy achieved: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "bbest_classifier00\n",
    "\n",
    "learning_rates = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "# TODO use validation set to find the best hyperparameters\n",
    "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
    "# than provided initially\n",
    "scores = []\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strengths:\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        loss_history = classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=lr, batch_size=batch_size, reg=rs)\n",
    "        pred = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        print(f\"lr: {lr}, rs: {rs}, accuracy 200 epochs: {accuracy}\")\n",
    "        scores.append((lr, rs, accuracy))\n",
    "        \n",
    "\n",
    "best_val_accuracy = max(scores, key=lambda x: x[2])\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.281209\n",
      "Epoch 1, loss: 2.235599\n",
      "Epoch 2, loss: 2.205942\n",
      "Epoch 3, loss: 2.188588\n",
      "Epoch 4, loss: 2.175351\n",
      "Epoch 5, loss: 2.167096\n",
      "Epoch 6, loss: 2.157953\n",
      "Epoch 7, loss: 2.156120\n",
      "Epoch 8, loss: 2.148508\n",
      "Epoch 9, loss: 2.141957\n",
      "Epoch 10, loss: 2.137942\n",
      "Epoch 11, loss: 2.133738\n",
      "Epoch 12, loss: 2.133136\n",
      "Epoch 13, loss: 2.129140\n",
      "Epoch 14, loss: 2.125129\n",
      "Epoch 15, loss: 2.123006\n",
      "Epoch 16, loss: 2.123066\n",
      "Epoch 17, loss: 2.119193\n",
      "Epoch 18, loss: 2.116286\n",
      "Epoch 19, loss: 2.114610\n",
      "Epoch 20, loss: 2.112005\n",
      "Epoch 21, loss: 2.111872\n",
      "Epoch 22, loss: 2.109338\n",
      "Epoch 23, loss: 2.113577\n",
      "Epoch 24, loss: 2.106339\n",
      "Epoch 25, loss: 2.103247\n",
      "Epoch 26, loss: 2.105824\n",
      "Epoch 27, loss: 2.103322\n",
      "Epoch 28, loss: 2.100563\n",
      "Epoch 29, loss: 2.097177\n",
      "Epoch 30, loss: 2.096268\n",
      "Epoch 31, loss: 2.095610\n",
      "Epoch 32, loss: 2.091977\n",
      "Epoch 33, loss: 2.094471\n",
      "Epoch 34, loss: 2.093402\n",
      "Epoch 35, loss: 2.090827\n",
      "Epoch 36, loss: 2.088665\n",
      "Epoch 37, loss: 2.090017\n",
      "Epoch 38, loss: 2.089402\n",
      "Epoch 39, loss: 2.085726\n",
      "Epoch 40, loss: 2.085874\n",
      "Epoch 41, loss: 2.083832\n",
      "Epoch 42, loss: 2.082412\n",
      "Epoch 43, loss: 2.082828\n",
      "Epoch 44, loss: 2.082271\n",
      "Epoch 45, loss: 2.080848\n",
      "Epoch 46, loss: 2.080483\n",
      "Epoch 47, loss: 2.082008\n",
      "Epoch 48, loss: 2.078327\n",
      "Epoch 49, loss: 2.075316\n",
      "Epoch 50, loss: 2.074521\n",
      "Epoch 51, loss: 2.074689\n",
      "Epoch 52, loss: 2.071130\n",
      "Epoch 53, loss: 2.074233\n",
      "Epoch 54, loss: 2.072954\n",
      "Epoch 55, loss: 2.071755\n",
      "Epoch 56, loss: 2.072748\n",
      "Epoch 57, loss: 2.069654\n",
      "Epoch 58, loss: 2.072720\n",
      "Epoch 59, loss: 2.065645\n",
      "Epoch 60, loss: 2.068987\n",
      "Epoch 61, loss: 2.066030\n",
      "Epoch 62, loss: 2.066338\n",
      "Epoch 63, loss: 2.064341\n",
      "Epoch 64, loss: 2.065109\n",
      "Epoch 65, loss: 2.065817\n",
      "Epoch 66, loss: 2.064300\n",
      "Epoch 67, loss: 2.062814\n",
      "Epoch 68, loss: 2.061441\n",
      "Epoch 69, loss: 2.064414\n",
      "Epoch 70, loss: 2.059520\n",
      "Epoch 71, loss: 2.059920\n",
      "Epoch 72, loss: 2.059196\n",
      "Epoch 73, loss: 2.061676\n",
      "Epoch 74, loss: 2.056611\n",
      "Epoch 75, loss: 2.056321\n",
      "Epoch 76, loss: 2.057530\n",
      "Epoch 77, loss: 2.057507\n",
      "Epoch 78, loss: 2.057819\n",
      "Epoch 79, loss: 2.054775\n",
      "Epoch 80, loss: 2.052435\n",
      "Epoch 81, loss: 2.054135\n",
      "Epoch 82, loss: 2.053671\n",
      "Epoch 83, loss: 2.052603\n",
      "Epoch 84, loss: 2.050780\n",
      "Epoch 85, loss: 2.053796\n",
      "Epoch 86, loss: 2.051710\n",
      "Epoch 87, loss: 2.052177\n",
      "Epoch 88, loss: 2.048737\n",
      "Epoch 89, loss: 2.048957\n",
      "Epoch 90, loss: 2.050308\n",
      "Epoch 91, loss: 2.049488\n",
      "Epoch 92, loss: 2.048142\n",
      "Epoch 93, loss: 2.047880\n",
      "Epoch 94, loss: 2.047972\n",
      "Epoch 95, loss: 2.046681\n",
      "Epoch 96, loss: 2.047156\n",
      "Epoch 97, loss: 2.042430\n",
      "Epoch 98, loss: 2.043647\n",
      "Epoch 99, loss: 2.048943\n",
      "Epoch 100, loss: 2.043604\n",
      "Epoch 101, loss: 2.044869\n",
      "Epoch 102, loss: 2.043342\n",
      "Epoch 103, loss: 2.042211\n",
      "Epoch 104, loss: 2.041641\n",
      "Epoch 105, loss: 2.040404\n",
      "Epoch 106, loss: 2.039992\n",
      "Epoch 107, loss: 2.039038\n",
      "Epoch 108, loss: 2.039662\n",
      "Epoch 109, loss: 2.039662\n",
      "Epoch 110, loss: 2.038659\n",
      "Epoch 111, loss: 2.038579\n",
      "Epoch 112, loss: 2.039236\n",
      "Epoch 113, loss: 2.037086\n",
      "Epoch 114, loss: 2.036746\n",
      "Epoch 115, loss: 2.038094\n",
      "Epoch 116, loss: 2.036088\n",
      "Epoch 117, loss: 2.032843\n",
      "Epoch 118, loss: 2.035801\n",
      "Epoch 119, loss: 2.036830\n",
      "Epoch 120, loss: 2.034422\n",
      "Epoch 121, loss: 2.033493\n",
      "Epoch 122, loss: 2.035702\n",
      "Epoch 123, loss: 2.032516\n",
      "Epoch 124, loss: 2.033922\n",
      "Epoch 125, loss: 2.031321\n",
      "Epoch 126, loss: 2.032085\n",
      "Epoch 127, loss: 2.028699\n",
      "Epoch 128, loss: 2.030798\n",
      "Epoch 129, loss: 2.029862\n",
      "Epoch 130, loss: 2.032367\n",
      "Epoch 131, loss: 2.027106\n",
      "Epoch 132, loss: 2.030288\n",
      "Epoch 133, loss: 2.028548\n",
      "Epoch 134, loss: 2.028410\n",
      "Epoch 135, loss: 2.029442\n",
      "Epoch 136, loss: 2.027177\n",
      "Epoch 137, loss: 2.026163\n",
      "Epoch 138, loss: 2.026834\n",
      "Epoch 139, loss: 2.026851\n",
      "Epoch 140, loss: 2.024308\n",
      "Epoch 141, loss: 2.025345\n",
      "Epoch 142, loss: 2.023984\n",
      "Epoch 143, loss: 2.025564\n",
      "Epoch 144, loss: 2.023724\n",
      "Epoch 145, loss: 2.021804\n",
      "Epoch 146, loss: 2.025887\n",
      "Epoch 147, loss: 2.024050\n",
      "Epoch 148, loss: 2.021039\n",
      "Epoch 149, loss: 2.023175\n",
      "Epoch 150, loss: 2.026484\n",
      "Epoch 151, loss: 2.023213\n",
      "Epoch 152, loss: 2.022140\n",
      "Epoch 153, loss: 2.021191\n",
      "Epoch 154, loss: 2.019501\n",
      "Epoch 155, loss: 2.021984\n",
      "Epoch 156, loss: 2.023473\n",
      "Epoch 157, loss: 2.022569\n",
      "Epoch 158, loss: 2.020415\n",
      "Epoch 159, loss: 2.019928\n",
      "Epoch 160, loss: 2.020664\n",
      "Epoch 161, loss: 2.021077\n",
      "Epoch 162, loss: 2.019176\n",
      "Epoch 163, loss: 2.018546\n",
      "Epoch 164, loss: 2.019258\n",
      "Epoch 165, loss: 2.014690\n",
      "Epoch 166, loss: 2.016506\n",
      "Epoch 167, loss: 2.015988\n",
      "Epoch 168, loss: 2.016903\n",
      "Epoch 169, loss: 2.017693\n",
      "Epoch 170, loss: 2.018232\n",
      "Epoch 171, loss: 2.016536\n",
      "Epoch 172, loss: 2.016382\n",
      "Epoch 173, loss: 2.016807\n",
      "Epoch 174, loss: 2.014513\n",
      "Epoch 175, loss: 2.013552\n",
      "Epoch 176, loss: 2.012547\n",
      "Epoch 177, loss: 2.012060\n",
      "Epoch 178, loss: 2.012719\n",
      "Epoch 179, loss: 2.012105\n",
      "Epoch 180, loss: 2.013347\n",
      "Epoch 181, loss: 2.013810\n",
      "Epoch 182, loss: 2.012527\n",
      "Epoch 183, loss: 2.011816\n",
      "Epoch 184, loss: 2.009995\n",
      "Epoch 185, loss: 2.007599\n",
      "Epoch 186, loss: 2.010859\n",
      "Epoch 187, loss: 2.009747\n",
      "Epoch 188, loss: 2.010212\n",
      "Epoch 189, loss: 2.009036\n",
      "Epoch 190, loss: 2.009199\n",
      "Epoch 191, loss: 2.008301\n",
      "Epoch 192, loss: 2.008735\n",
      "Epoch 193, loss: 2.008560\n",
      "Epoch 194, loss: 2.006244\n",
      "Epoch 195, loss: 2.006569\n",
      "Epoch 196, loss: 2.010733\n",
      "Epoch 197, loss: 2.008880\n",
      "Epoch 198, loss: 2.009915\n",
      "Epoch 199, loss: 2.011643\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy\n",
    "best_classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = best_classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=0.1, batch_size=batch_size, reg=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3073)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape\n",
    "best_calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.195000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
