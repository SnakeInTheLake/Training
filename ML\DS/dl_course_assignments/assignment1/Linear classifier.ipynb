{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXTz4tJj97T6"
   },
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1598096448689,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "wnXEKNbO97UH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2106,
     "status": "ok",
     "timestamp": 1598096452414,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "6_JO4b2_97UQ"
   },
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3I1IwYa97UW"
   },
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7251,
     "status": "ok",
     "timestamp": 1598096459690,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "4Aur4klu97UX"
   },
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qe4r9TMJ97Uc"
   },
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1598097064802,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "S9nd5n_p97Ud",
    "outputId": "1948baca-f450-46d0-d636-cced1d957a6b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ht4HpyPm97Uk"
   },
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598097061970,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "E9iTxWY697Uz"
   },
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQL-Nsuq97U3"
   },
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3AjgRFVa97U9"
   },
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1598097612283,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "ARy0owvN97U-",
    "outputId": "776a2704-155c-4cad-f3c4-f56cc5eb5cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyhxCrUF97VD"
   },
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1598097619129,
     "user": {
      "displayName": "Павел Ананьев",
      "photoUrl": "",
      "userId": "07746041064703407151"
     },
     "user_tz": -180
    },
    "id": "O8FMYat297VI",
    "outputId": "fafb7e17-8645-44d5-fec5-e8e715e10f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1BT6gp997VN"
   },
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4t1KGaO997VY",
    "outputId": "b8ad43fd-aec2-4ff0-c5e1-7a47b0d15280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2l177lKo97Vc"
   },
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0nOy7z_97Vh",
    "outputId": "fdcb6684-23dd-474e-c98d-96d8c2c90a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDzxkrWd97Vm"
   },
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzM4MWDD97Vm"
   },
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZCr9ZO197Vr",
    "outputId": "5c900ba3-650f-467c-c3a5-3dd316b7ae0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.484015\n",
      "Epoch 1, loss: 2.356050\n",
      "Epoch 2, loss: 2.317979\n",
      "Epoch 3, loss: 2.306623\n",
      "Epoch 4, loss: 2.303297\n",
      "Epoch 5, loss: 2.302304\n",
      "Epoch 6, loss: 2.301991\n",
      "Epoch 7, loss: 2.301899\n",
      "Epoch 8, loss: 2.301881\n",
      "Epoch 9, loss: 2.301857\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofeK7ydV97Vu",
    "outputId": "bd482ea2-5365-4e1b-cce6-916c7cffe74f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blcJKJWW97Vy",
    "outputId": "de3b5fdb-9788-4f95-e8c9-f319095b264d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.127\n",
      "Epoch 0, loss: 2.301890\n",
      "Epoch 1, loss: 2.301866\n",
      "Epoch 2, loss: 2.301834\n",
      "Epoch 3, loss: 2.301874\n",
      "Epoch 4, loss: 2.301892\n",
      "Epoch 5, loss: 2.301864\n",
      "Epoch 6, loss: 2.301880\n",
      "Epoch 7, loss: 2.301844\n",
      "Epoch 8, loss: 2.301878\n",
      "Epoch 9, loss: 2.301869\n",
      "Epoch 10, loss: 2.301858\n",
      "Epoch 11, loss: 2.301852\n",
      "Epoch 12, loss: 2.301887\n",
      "Epoch 13, loss: 2.301867\n",
      "Epoch 14, loss: 2.301868\n",
      "Epoch 15, loss: 2.301866\n",
      "Epoch 16, loss: 2.301873\n",
      "Epoch 17, loss: 2.301863\n",
      "Epoch 18, loss: 2.301867\n",
      "Epoch 19, loss: 2.301881\n",
      "Epoch 20, loss: 2.301849\n",
      "Epoch 21, loss: 2.301864\n",
      "Epoch 22, loss: 2.301849\n",
      "Epoch 23, loss: 2.301870\n",
      "Epoch 24, loss: 2.301869\n",
      "Epoch 25, loss: 2.301857\n",
      "Epoch 26, loss: 2.301877\n",
      "Epoch 27, loss: 2.301867\n",
      "Epoch 28, loss: 2.301849\n",
      "Epoch 29, loss: 2.301854\n",
      "Epoch 30, loss: 2.301862\n",
      "Epoch 31, loss: 2.301862\n",
      "Epoch 32, loss: 2.301853\n",
      "Epoch 33, loss: 2.301877\n",
      "Epoch 34, loss: 2.301866\n",
      "Epoch 35, loss: 2.301865\n",
      "Epoch 36, loss: 2.301858\n",
      "Epoch 37, loss: 2.301851\n",
      "Epoch 38, loss: 2.301872\n",
      "Epoch 39, loss: 2.301859\n",
      "Epoch 40, loss: 2.301866\n",
      "Epoch 41, loss: 2.301858\n",
      "Epoch 42, loss: 2.301863\n",
      "Epoch 43, loss: 2.301867\n",
      "Epoch 44, loss: 2.301864\n",
      "Epoch 45, loss: 2.301872\n",
      "Epoch 46, loss: 2.301868\n",
      "Epoch 47, loss: 2.301883\n",
      "Epoch 48, loss: 2.301870\n",
      "Epoch 49, loss: 2.301858\n",
      "Epoch 50, loss: 2.301856\n",
      "Epoch 51, loss: 2.301865\n",
      "Epoch 52, loss: 2.301870\n",
      "Epoch 53, loss: 2.301870\n",
      "Epoch 54, loss: 2.301863\n",
      "Epoch 55, loss: 2.301847\n",
      "Epoch 56, loss: 2.301873\n",
      "Epoch 57, loss: 2.301872\n",
      "Epoch 58, loss: 2.301868\n",
      "Epoch 59, loss: 2.301851\n",
      "Epoch 60, loss: 2.301860\n",
      "Epoch 61, loss: 2.301859\n",
      "Epoch 62, loss: 2.301867\n",
      "Epoch 63, loss: 2.301865\n",
      "Epoch 64, loss: 2.301871\n",
      "Epoch 65, loss: 2.301869\n",
      "Epoch 66, loss: 2.301848\n",
      "Epoch 67, loss: 2.301860\n",
      "Epoch 68, loss: 2.301864\n",
      "Epoch 69, loss: 2.301860\n",
      "Epoch 70, loss: 2.301864\n",
      "Epoch 71, loss: 2.301873\n",
      "Epoch 72, loss: 2.301851\n",
      "Epoch 73, loss: 2.301871\n",
      "Epoch 74, loss: 2.301889\n",
      "Epoch 75, loss: 2.301869\n",
      "Epoch 76, loss: 2.301877\n",
      "Epoch 77, loss: 2.301871\n",
      "Epoch 78, loss: 2.301864\n",
      "Epoch 79, loss: 2.301866\n",
      "Epoch 80, loss: 2.301871\n",
      "Epoch 81, loss: 2.301868\n",
      "Epoch 82, loss: 2.301862\n",
      "Epoch 83, loss: 2.301852\n",
      "Epoch 84, loss: 2.301876\n",
      "Epoch 85, loss: 2.301856\n",
      "Epoch 86, loss: 2.301868\n",
      "Epoch 87, loss: 2.301865\n",
      "Epoch 88, loss: 2.301863\n",
      "Epoch 89, loss: 2.301878\n",
      "Epoch 90, loss: 2.301864\n",
      "Epoch 91, loss: 2.301873\n",
      "Epoch 92, loss: 2.301861\n",
      "Epoch 93, loss: 2.301872\n",
      "Epoch 94, loss: 2.301884\n",
      "Epoch 95, loss: 2.301877\n",
      "Epoch 96, loss: 2.301870\n",
      "Epoch 97, loss: 2.301869\n",
      "Epoch 98, loss: 2.301898\n",
      "Epoch 99, loss: 2.301862\n",
      "Accuracy after training for 100 epochs:  0.121\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIbd7snu97V2"
   },
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MkHWVgaY97V8",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "797476aa-0d19-434f-f28c-be925aab2d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 5.186141\n",
      "Epoch 1, loss: 5.125887\n",
      "Epoch 2, loss: 5.198077\n",
      "Epoch 3, loss: 5.199631\n",
      "Epoch 4, loss: 5.133310\n",
      "Epoch 5, loss: 5.175098\n",
      "Epoch 6, loss: 5.145396\n",
      "Epoch 7, loss: 5.165092\n",
      "Epoch 8, loss: 5.141969\n",
      "Epoch 9, loss: 5.180585\n",
      "Epoch 10, loss: 5.113504\n",
      "Epoch 11, loss: 5.202511\n",
      "Epoch 12, loss: 5.171129\n",
      "Epoch 13, loss: 5.166855\n",
      "Epoch 14, loss: 5.120661\n",
      "Epoch 15, loss: 5.226637\n",
      "Epoch 16, loss: 5.165494\n",
      "Epoch 17, loss: 5.143919\n",
      "Epoch 18, loss: 5.141213\n",
      "Epoch 19, loss: 5.222701\n",
      "Epoch 20, loss: 5.211022\n",
      "Epoch 21, loss: 5.122087\n",
      "Epoch 22, loss: 5.135717\n",
      "Epoch 23, loss: 5.158091\n",
      "Epoch 24, loss: 5.152587\n",
      "Epoch 25, loss: 5.110849\n",
      "Epoch 26, loss: 5.193260\n",
      "Epoch 27, loss: 5.172000\n",
      "Epoch 28, loss: 5.172537\n",
      "Epoch 29, loss: 5.110268\n",
      "Epoch 30, loss: 5.168118\n",
      "Epoch 31, loss: 5.132810\n",
      "Epoch 32, loss: 5.125692\n",
      "Epoch 33, loss: 5.146285\n",
      "Epoch 34, loss: 5.136509\n",
      "Epoch 35, loss: 5.190810\n",
      "Epoch 36, loss: 5.194122\n",
      "Epoch 37, loss: 5.137755\n",
      "Epoch 38, loss: 5.160583\n",
      "Epoch 39, loss: 5.121656\n",
      "Epoch 40, loss: 5.106807\n",
      "Epoch 41, loss: 5.120798\n",
      "Epoch 42, loss: 5.109638\n",
      "Epoch 43, loss: 5.154404\n",
      "Epoch 44, loss: 5.148208\n",
      "Epoch 45, loss: 5.100542\n",
      "Epoch 46, loss: 5.176326\n",
      "Epoch 47, loss: 5.165581\n",
      "Epoch 48, loss: 5.198681\n",
      "Epoch 49, loss: 5.140843\n",
      "Epoch 50, loss: 5.140421\n",
      "Epoch 51, loss: 5.114373\n",
      "Epoch 52, loss: 5.177605\n",
      "Epoch 53, loss: 5.133262\n",
      "Epoch 54, loss: 5.156603\n",
      "Epoch 55, loss: 5.154159\n",
      "Epoch 56, loss: 5.150278\n",
      "Epoch 57, loss: 5.119381\n",
      "Epoch 58, loss: 5.179910\n",
      "Epoch 59, loss: 5.105557\n",
      "Epoch 60, loss: 5.197332\n",
      "Epoch 61, loss: 5.159773\n",
      "Epoch 62, loss: 5.160327\n",
      "Epoch 63, loss: 5.175087\n",
      "Epoch 64, loss: 5.159932\n",
      "Epoch 65, loss: 5.150291\n",
      "Epoch 66, loss: 5.173473\n",
      "Epoch 67, loss: 5.128237\n",
      "Epoch 68, loss: 5.105711\n",
      "Epoch 69, loss: 5.185396\n",
      "Epoch 70, loss: 5.140653\n",
      "Epoch 71, loss: 5.220392\n",
      "Epoch 72, loss: 5.172495\n",
      "Epoch 73, loss: 5.138814\n",
      "Epoch 74, loss: 5.179649\n",
      "Epoch 75, loss: 5.199410\n",
      "Epoch 76, loss: 5.166303\n",
      "Epoch 77, loss: 5.138130\n",
      "Epoch 78, loss: 5.173945\n",
      "Epoch 79, loss: 5.136165\n",
      "Epoch 80, loss: 5.141977\n",
      "Epoch 81, loss: 5.159561\n",
      "Epoch 82, loss: 5.149431\n",
      "Epoch 83, loss: 5.104794\n",
      "Epoch 84, loss: 5.125051\n",
      "Epoch 85, loss: 5.150990\n",
      "Epoch 86, loss: 5.127533\n",
      "Epoch 87, loss: 5.118980\n",
      "Epoch 88, loss: 5.149927\n",
      "Epoch 89, loss: 5.115324\n",
      "Epoch 90, loss: 5.240889\n",
      "Epoch 91, loss: 5.170011\n",
      "Epoch 92, loss: 5.155836\n",
      "Epoch 93, loss: 5.113723\n",
      "Epoch 94, loss: 5.157226\n",
      "Epoch 95, loss: 5.129699\n",
      "Epoch 96, loss: 5.136231\n",
      "Epoch 97, loss: 5.151147\n",
      "Epoch 98, loss: 5.116507\n",
      "Epoch 99, loss: 5.151317\n",
      "Epoch 100, loss: 5.142151\n",
      "Epoch 101, loss: 5.209456\n",
      "Epoch 102, loss: 5.124614\n",
      "Epoch 103, loss: 5.172771\n",
      "Epoch 104, loss: 5.115437\n",
      "Epoch 105, loss: 5.134356\n",
      "Epoch 106, loss: 5.191403\n",
      "Epoch 107, loss: 5.158742\n",
      "Epoch 108, loss: 5.111294\n",
      "Epoch 109, loss: 5.142622\n",
      "Epoch 110, loss: 5.143267\n",
      "Epoch 111, loss: 5.169151\n",
      "Epoch 112, loss: 5.195955\n",
      "Epoch 113, loss: 5.150131\n",
      "Epoch 114, loss: 5.175401\n",
      "Epoch 115, loss: 5.169119\n",
      "Epoch 116, loss: 5.132800\n",
      "Epoch 117, loss: 5.165776\n",
      "Epoch 118, loss: 5.172913\n",
      "Epoch 119, loss: 5.219464\n",
      "Epoch 120, loss: 5.157292\n",
      "Epoch 121, loss: 5.095194\n",
      "Epoch 122, loss: 5.125403\n",
      "Epoch 123, loss: 5.142327\n",
      "Epoch 124, loss: 5.133811\n",
      "Epoch 125, loss: 5.126948\n",
      "Epoch 126, loss: 5.183473\n",
      "Epoch 127, loss: 5.146369\n",
      "Epoch 128, loss: 5.159540\n",
      "Epoch 129, loss: 5.192513\n",
      "Epoch 130, loss: 5.198285\n",
      "Epoch 131, loss: 5.117100\n",
      "Epoch 132, loss: 5.171865\n",
      "Epoch 133, loss: 5.164892\n",
      "Epoch 134, loss: 5.167503\n",
      "Epoch 135, loss: 5.186622\n",
      "Epoch 136, loss: 5.155968\n",
      "Epoch 137, loss: 5.206458\n",
      "Epoch 138, loss: 5.166872\n",
      "Epoch 139, loss: 5.097560\n",
      "Epoch 140, loss: 5.152272\n",
      "Epoch 141, loss: 5.111193\n",
      "Epoch 142, loss: 5.147278\n",
      "Epoch 143, loss: 5.197386\n",
      "Epoch 144, loss: 5.139204\n",
      "Epoch 145, loss: 5.207340\n",
      "Epoch 146, loss: 5.089914\n",
      "Epoch 147, loss: 5.169113\n",
      "Epoch 148, loss: 5.125834\n",
      "Epoch 149, loss: 5.134814\n",
      "Epoch 150, loss: 5.135760\n",
      "Epoch 151, loss: 5.125018\n",
      "Epoch 152, loss: 5.191448\n",
      "Epoch 153, loss: 5.134484\n",
      "Epoch 154, loss: 5.143401\n",
      "Epoch 155, loss: 5.145834\n",
      "Epoch 156, loss: 5.169722\n",
      "Epoch 157, loss: 5.154120\n",
      "Epoch 158, loss: 5.162059\n",
      "Epoch 159, loss: 5.185957\n",
      "Epoch 160, loss: 5.172164\n",
      "Epoch 161, loss: 5.173779\n",
      "Epoch 162, loss: 5.171791\n",
      "Epoch 163, loss: 5.175656\n",
      "Epoch 164, loss: 5.141120\n",
      "Epoch 165, loss: 5.174153\n",
      "Epoch 166, loss: 5.167458\n",
      "Epoch 167, loss: 5.127976\n",
      "Epoch 168, loss: 5.150092\n",
      "Epoch 169, loss: 5.120816\n",
      "Epoch 170, loss: 5.174093\n",
      "Epoch 171, loss: 5.180780\n",
      "Epoch 172, loss: 5.223407\n",
      "Epoch 173, loss: 5.180623\n",
      "Epoch 174, loss: 5.094634\n",
      "Epoch 175, loss: 5.192836\n",
      "Epoch 176, loss: 5.109197\n",
      "Epoch 177, loss: 5.160287\n",
      "Epoch 178, loss: 5.151380\n",
      "Epoch 179, loss: 5.160632\n",
      "Epoch 180, loss: 5.105345\n",
      "Epoch 181, loss: 5.089663\n",
      "Epoch 182, loss: 5.169189\n",
      "Epoch 183, loss: 5.123461\n",
      "Epoch 184, loss: 5.120070\n",
      "Epoch 185, loss: 5.209965\n",
      "Epoch 186, loss: 5.190941\n",
      "Epoch 187, loss: 5.119519\n",
      "Epoch 188, loss: 5.177454\n",
      "Epoch 189, loss: 5.200988\n",
      "Epoch 190, loss: 5.205567\n",
      "Epoch 191, loss: 5.171043\n",
      "Epoch 192, loss: 5.192967\n",
      "Epoch 193, loss: 5.165344\n",
      "Epoch 194, loss: 5.169447\n",
      "Epoch 195, loss: 5.162267\n",
      "Epoch 196, loss: 5.175257\n",
      "Epoch 197, loss: 5.117015\n",
      "Epoch 198, loss: 5.165085\n",
      "Epoch 199, loss: 5.141278\n",
      "lr: 0.1, rs: 0.1, accuracy 200 epochs: 0.111\n",
      "Epoch 0, loss: 5.220005\n",
      "Epoch 1, loss: 5.250701\n",
      "Epoch 2, loss: 5.198597\n",
      "Epoch 3, loss: 5.215162\n",
      "Epoch 4, loss: 5.208710\n",
      "Epoch 5, loss: 5.278782\n",
      "Epoch 6, loss: 5.225954\n",
      "Epoch 7, loss: 5.281824\n",
      "Epoch 8, loss: 5.281040\n",
      "Epoch 9, loss: 5.262597\n",
      "Epoch 10, loss: 5.209707\n",
      "Epoch 11, loss: 5.276151\n",
      "Epoch 12, loss: 5.239965\n",
      "Epoch 13, loss: 5.213918\n",
      "Epoch 14, loss: 5.220950\n",
      "Epoch 15, loss: 5.248309\n",
      "Epoch 16, loss: 5.238907\n",
      "Epoch 17, loss: 5.211321\n",
      "Epoch 18, loss: 5.260603\n",
      "Epoch 19, loss: 5.259598\n",
      "Epoch 20, loss: 5.265047\n",
      "Epoch 21, loss: 5.240619\n",
      "Epoch 22, loss: 5.196459\n",
      "Epoch 23, loss: 5.233737\n",
      "Epoch 24, loss: 5.233571\n",
      "Epoch 25, loss: 5.264239\n",
      "Epoch 26, loss: 5.277485\n",
      "Epoch 27, loss: 5.259212\n",
      "Epoch 28, loss: 5.275902\n",
      "Epoch 29, loss: 5.265717\n",
      "Epoch 30, loss: 5.226915\n",
      "Epoch 31, loss: 5.247208\n",
      "Epoch 32, loss: 5.249787\n",
      "Epoch 33, loss: 5.235799\n",
      "Epoch 34, loss: 5.225492\n",
      "Epoch 35, loss: 5.209603\n",
      "Epoch 36, loss: 5.224434\n",
      "Epoch 37, loss: 5.217166\n",
      "Epoch 38, loss: 5.169456\n",
      "Epoch 39, loss: 5.288500\n",
      "Epoch 40, loss: 5.262701\n",
      "Epoch 41, loss: 5.255814\n",
      "Epoch 42, loss: 5.264929\n",
      "Epoch 43, loss: 5.251138\n",
      "Epoch 44, loss: 5.251320\n",
      "Epoch 45, loss: 5.259575\n",
      "Epoch 46, loss: 5.263161\n",
      "Epoch 47, loss: 5.239227\n",
      "Epoch 48, loss: 5.220484\n",
      "Epoch 49, loss: 5.248168\n",
      "Epoch 50, loss: 5.240049\n",
      "Epoch 51, loss: 5.254000\n",
      "Epoch 52, loss: 5.240113\n",
      "Epoch 53, loss: 5.190510\n",
      "Epoch 54, loss: 5.269738\n",
      "Epoch 55, loss: 5.275595\n",
      "Epoch 56, loss: 5.227975\n",
      "Epoch 57, loss: 5.239107\n",
      "Epoch 58, loss: 5.273980\n",
      "Epoch 59, loss: 5.233514\n",
      "Epoch 60, loss: 5.216239\n",
      "Epoch 61, loss: 5.244222\n",
      "Epoch 62, loss: 5.226976\n",
      "Epoch 63, loss: 5.247469\n",
      "Epoch 64, loss: 5.212957\n",
      "Epoch 65, loss: 5.247515\n",
      "Epoch 66, loss: 5.225078\n",
      "Epoch 67, loss: 5.250118\n",
      "Epoch 68, loss: 5.249411\n",
      "Epoch 69, loss: 5.226139\n",
      "Epoch 70, loss: 5.259193\n",
      "Epoch 71, loss: 5.237931\n",
      "Epoch 72, loss: 5.195523\n",
      "Epoch 73, loss: 5.270047\n",
      "Epoch 74, loss: 5.225829\n",
      "Epoch 75, loss: 5.275953\n",
      "Epoch 76, loss: 5.190961\n",
      "Epoch 77, loss: 5.266903\n",
      "Epoch 78, loss: 5.233303\n",
      "Epoch 79, loss: 5.171945\n",
      "Epoch 80, loss: 5.254843\n",
      "Epoch 81, loss: 5.240659\n",
      "Epoch 82, loss: 5.259455\n",
      "Epoch 83, loss: 5.200002\n",
      "Epoch 84, loss: 5.224600\n",
      "Epoch 85, loss: 5.251942\n",
      "Epoch 86, loss: 5.265211\n",
      "Epoch 87, loss: 5.224310\n",
      "Epoch 88, loss: 5.235498\n",
      "Epoch 89, loss: 5.241097\n",
      "Epoch 90, loss: 5.265454\n",
      "Epoch 91, loss: 5.246300\n",
      "Epoch 92, loss: 5.218842\n",
      "Epoch 93, loss: 5.239596\n",
      "Epoch 94, loss: 5.273132\n",
      "Epoch 95, loss: 5.278914\n",
      "Epoch 96, loss: 5.241662\n",
      "Epoch 97, loss: 5.254104\n",
      "Epoch 98, loss: 5.257977\n",
      "Epoch 99, loss: 5.267979\n",
      "Epoch 100, loss: 5.258219\n",
      "Epoch 101, loss: 5.248366\n",
      "Epoch 102, loss: 5.240826\n",
      "Epoch 103, loss: 5.191585\n",
      "Epoch 104, loss: 5.242468\n",
      "Epoch 105, loss: 5.204555\n",
      "Epoch 106, loss: 5.206956\n",
      "Epoch 107, loss: 5.216649\n",
      "Epoch 108, loss: 5.206276\n",
      "Epoch 109, loss: 5.181969\n",
      "Epoch 110, loss: 5.323218\n",
      "Epoch 111, loss: 5.228939\n",
      "Epoch 112, loss: 5.249404\n",
      "Epoch 113, loss: 5.238501\n",
      "Epoch 114, loss: 5.252567\n",
      "Epoch 115, loss: 5.158265\n",
      "Epoch 116, loss: 5.244761\n",
      "Epoch 117, loss: 5.314681\n",
      "Epoch 118, loss: 5.227262\n",
      "Epoch 119, loss: 5.241113\n",
      "Epoch 120, loss: 5.248804\n",
      "Epoch 121, loss: 5.238183\n",
      "Epoch 122, loss: 5.249029\n",
      "Epoch 123, loss: 5.239388\n",
      "Epoch 124, loss: 5.273808\n",
      "Epoch 125, loss: 5.244948\n",
      "Epoch 126, loss: 5.257823\n",
      "Epoch 127, loss: 5.198428\n",
      "Epoch 128, loss: 5.240834\n",
      "Epoch 129, loss: 5.221816\n",
      "Epoch 130, loss: 5.196962\n",
      "Epoch 131, loss: 5.224773\n",
      "Epoch 132, loss: 5.226591\n",
      "Epoch 133, loss: 5.279066\n",
      "Epoch 134, loss: 5.229921\n",
      "Epoch 135, loss: 5.167687\n",
      "Epoch 136, loss: 5.202927\n",
      "Epoch 137, loss: 5.278169\n",
      "Epoch 138, loss: 5.275054\n",
      "Epoch 139, loss: 5.202211\n",
      "Epoch 140, loss: 5.177136\n",
      "Epoch 141, loss: 5.278855\n",
      "Epoch 142, loss: 5.247882\n",
      "Epoch 143, loss: 5.202301\n",
      "Epoch 144, loss: 5.259109\n",
      "Epoch 145, loss: 5.201029\n",
      "Epoch 146, loss: 5.260321\n",
      "Epoch 147, loss: 5.229978\n",
      "Epoch 148, loss: 5.216078\n",
      "Epoch 149, loss: 5.256479\n",
      "Epoch 150, loss: 5.218697\n",
      "Epoch 151, loss: 5.145392\n",
      "Epoch 152, loss: 5.275656\n",
      "Epoch 153, loss: 5.249383\n",
      "Epoch 154, loss: 5.191804\n",
      "Epoch 155, loss: 5.260363\n",
      "Epoch 156, loss: 5.214591\n",
      "Epoch 157, loss: 5.234855\n",
      "Epoch 158, loss: 5.282586\n",
      "Epoch 159, loss: 5.248324\n",
      "Epoch 160, loss: 5.254427\n",
      "Epoch 161, loss: 5.255409\n",
      "Epoch 162, loss: 5.259198\n",
      "Epoch 163, loss: 5.247497\n",
      "Epoch 164, loss: 5.309611\n",
      "Epoch 165, loss: 5.259898\n",
      "Epoch 166, loss: 5.244639\n",
      "Epoch 167, loss: 5.286957\n",
      "Epoch 168, loss: 5.268261\n",
      "Epoch 169, loss: 5.317403\n",
      "Epoch 170, loss: 5.224707\n",
      "Epoch 171, loss: 5.220715\n",
      "Epoch 172, loss: 5.286529\n",
      "Epoch 173, loss: 5.261168\n",
      "Epoch 174, loss: 5.226179\n",
      "Epoch 175, loss: 5.247510\n",
      "Epoch 176, loss: 5.252585\n",
      "Epoch 177, loss: 5.192745\n",
      "Epoch 178, loss: 5.274372\n",
      "Epoch 179, loss: 5.248591\n",
      "Epoch 180, loss: 5.233139\n",
      "Epoch 181, loss: 5.232910\n",
      "Epoch 182, loss: 5.253211\n",
      "Epoch 183, loss: 5.230576\n",
      "Epoch 184, loss: 5.227377\n",
      "Epoch 185, loss: 5.236362\n",
      "Epoch 186, loss: 5.261179\n",
      "Epoch 187, loss: 5.286554\n",
      "Epoch 188, loss: 5.238636\n",
      "Epoch 189, loss: 5.246853\n",
      "Epoch 190, loss: 5.252210\n",
      "Epoch 191, loss: 5.191409\n",
      "Epoch 192, loss: 5.188743\n",
      "Epoch 193, loss: 5.268832\n",
      "Epoch 194, loss: 5.225228\n",
      "Epoch 195, loss: 5.284451\n",
      "Epoch 196, loss: 5.187835\n",
      "Epoch 197, loss: 5.231315\n",
      "Epoch 198, loss: 5.187933\n",
      "Epoch 199, loss: 5.222860\n",
      "lr: 0.1, rs: 0.01, accuracy 200 epochs: 0.13\n",
      "Epoch 0, loss: 5.252634\n",
      "Epoch 1, loss: 5.215427\n",
      "Epoch 2, loss: 5.189305\n",
      "Epoch 3, loss: 5.157512\n",
      "Epoch 4, loss: 5.200183\n",
      "Epoch 5, loss: 5.146110\n",
      "Epoch 6, loss: 5.210647\n",
      "Epoch 7, loss: 5.245783\n",
      "Epoch 8, loss: 5.247684\n",
      "Epoch 9, loss: 5.211063\n",
      "Epoch 10, loss: 5.233904\n",
      "Epoch 11, loss: 5.221202\n",
      "Epoch 12, loss: 5.187707\n",
      "Epoch 13, loss: 5.232617\n",
      "Epoch 14, loss: 5.255894\n",
      "Epoch 15, loss: 5.253137\n",
      "Epoch 16, loss: 5.244493\n",
      "Epoch 17, loss: 5.189754\n",
      "Epoch 18, loss: 5.219917\n",
      "Epoch 19, loss: 5.172899\n",
      "Epoch 20, loss: 5.156459\n",
      "Epoch 21, loss: 5.235515\n",
      "Epoch 22, loss: 5.170386\n",
      "Epoch 23, loss: 5.206957\n",
      "Epoch 24, loss: 5.300513\n",
      "Epoch 25, loss: 5.267184\n",
      "Epoch 26, loss: 5.230360\n",
      "Epoch 27, loss: 5.259665\n",
      "Epoch 28, loss: 5.193730\n",
      "Epoch 29, loss: 5.189827\n",
      "Epoch 30, loss: 5.222013\n",
      "Epoch 31, loss: 5.219251\n",
      "Epoch 32, loss: 5.189543\n",
      "Epoch 33, loss: 5.271333\n",
      "Epoch 34, loss: 5.257329\n",
      "Epoch 35, loss: 5.264102\n",
      "Epoch 36, loss: 5.184055\n",
      "Epoch 37, loss: 5.215026\n",
      "Epoch 38, loss: 5.180314\n",
      "Epoch 39, loss: 5.135560\n",
      "Epoch 40, loss: 5.252780\n",
      "Epoch 41, loss: 5.264135\n",
      "Epoch 42, loss: 5.203037\n",
      "Epoch 43, loss: 5.151698\n",
      "Epoch 44, loss: 5.181372\n",
      "Epoch 45, loss: 5.294706\n",
      "Epoch 46, loss: 5.179964\n",
      "Epoch 47, loss: 5.193552\n",
      "Epoch 48, loss: 5.271447\n",
      "Epoch 49, loss: 5.186744\n",
      "Epoch 50, loss: 5.155689\n",
      "Epoch 51, loss: 5.166043\n",
      "Epoch 52, loss: 5.229683\n",
      "Epoch 53, loss: 5.256012\n",
      "Epoch 54, loss: 5.260296\n",
      "Epoch 55, loss: 5.253471\n",
      "Epoch 56, loss: 5.208521\n",
      "Epoch 57, loss: 5.264912\n",
      "Epoch 58, loss: 5.254253\n",
      "Epoch 59, loss: 5.235632\n",
      "Epoch 60, loss: 5.206159\n",
      "Epoch 61, loss: 5.182365\n",
      "Epoch 62, loss: 5.288552\n",
      "Epoch 63, loss: 5.189490\n",
      "Epoch 64, loss: 5.240689\n",
      "Epoch 65, loss: 5.270120\n",
      "Epoch 66, loss: 5.237335\n",
      "Epoch 67, loss: 5.154562\n",
      "Epoch 68, loss: 5.242534\n",
      "Epoch 69, loss: 5.227650\n",
      "Epoch 70, loss: 5.245282\n",
      "Epoch 71, loss: 5.211118\n",
      "Epoch 72, loss: 5.177419\n",
      "Epoch 73, loss: 5.171565\n",
      "Epoch 74, loss: 5.234188\n",
      "Epoch 75, loss: 5.230643\n",
      "Epoch 76, loss: 5.221378\n",
      "Epoch 77, loss: 5.211211\n",
      "Epoch 78, loss: 5.225295\n",
      "Epoch 79, loss: 5.189072\n",
      "Epoch 80, loss: 5.204950\n",
      "Epoch 81, loss: 5.213841\n",
      "Epoch 82, loss: 5.250856\n",
      "Epoch 83, loss: 5.289171\n",
      "Epoch 84, loss: 5.200757\n",
      "Epoch 85, loss: 5.188438\n",
      "Epoch 86, loss: 5.186955\n",
      "Epoch 87, loss: 5.204059\n",
      "Epoch 88, loss: 5.231459\n",
      "Epoch 89, loss: 5.234984\n",
      "Epoch 90, loss: 5.213839\n",
      "Epoch 91, loss: 5.207637\n",
      "Epoch 92, loss: 5.203023\n",
      "Epoch 93, loss: 5.236832\n",
      "Epoch 94, loss: 5.213859\n",
      "Epoch 95, loss: 5.209217\n",
      "Epoch 96, loss: 5.224116\n",
      "Epoch 97, loss: 5.207461\n",
      "Epoch 98, loss: 5.238951\n",
      "Epoch 99, loss: 5.219707\n",
      "Epoch 100, loss: 5.223168\n",
      "Epoch 101, loss: 5.243699\n",
      "Epoch 102, loss: 5.305627\n",
      "Epoch 103, loss: 5.175702\n",
      "Epoch 104, loss: 5.172998\n",
      "Epoch 105, loss: 5.229227\n",
      "Epoch 106, loss: 5.271318\n",
      "Epoch 107, loss: 5.303119\n",
      "Epoch 108, loss: 5.266844\n",
      "Epoch 109, loss: 5.179788\n",
      "Epoch 110, loss: 5.221744\n",
      "Epoch 111, loss: 5.228896\n",
      "Epoch 112, loss: 5.269908\n",
      "Epoch 113, loss: 5.286427\n",
      "Epoch 114, loss: 5.207899\n",
      "Epoch 115, loss: 5.222911\n",
      "Epoch 116, loss: 5.212629\n",
      "Epoch 117, loss: 5.238425\n",
      "Epoch 118, loss: 5.221949\n",
      "Epoch 119, loss: 5.224308\n",
      "Epoch 120, loss: 5.179607\n",
      "Epoch 121, loss: 5.220655\n",
      "Epoch 122, loss: 5.194720\n",
      "Epoch 123, loss: 5.250143\n",
      "Epoch 124, loss: 5.254646\n",
      "Epoch 125, loss: 5.230238\n",
      "Epoch 126, loss: 5.264673\n",
      "Epoch 127, loss: 5.253950\n",
      "Epoch 128, loss: 5.195152\n",
      "Epoch 129, loss: 5.206701\n",
      "Epoch 130, loss: 5.193975\n",
      "Epoch 131, loss: 5.212512\n",
      "Epoch 132, loss: 5.243063\n",
      "Epoch 133, loss: 5.288585\n",
      "Epoch 134, loss: 5.170824\n",
      "Epoch 135, loss: 5.248601\n",
      "Epoch 136, loss: 5.210895\n",
      "Epoch 137, loss: 5.212110\n",
      "Epoch 138, loss: 5.227065\n",
      "Epoch 139, loss: 5.240605\n",
      "Epoch 140, loss: 5.246857\n",
      "Epoch 141, loss: 5.228794\n",
      "Epoch 142, loss: 5.284560\n",
      "Epoch 143, loss: 5.172555\n",
      "Epoch 144, loss: 5.166925\n",
      "Epoch 145, loss: 5.226163\n",
      "Epoch 146, loss: 5.205215\n",
      "Epoch 147, loss: 5.262963\n",
      "Epoch 148, loss: 5.179265\n",
      "Epoch 149, loss: 5.196308\n",
      "Epoch 150, loss: 5.238063\n",
      "Epoch 151, loss: 5.261729\n",
      "Epoch 152, loss: 5.203827\n",
      "Epoch 153, loss: 5.221845\n",
      "Epoch 154, loss: 5.289977\n",
      "Epoch 155, loss: 5.177452\n",
      "Epoch 156, loss: 5.246674\n",
      "Epoch 157, loss: 5.162811\n",
      "Epoch 158, loss: 5.227760\n",
      "Epoch 159, loss: 5.196754\n",
      "Epoch 160, loss: 5.240498\n",
      "Epoch 161, loss: 5.266321\n",
      "Epoch 162, loss: 5.230480\n",
      "Epoch 163, loss: 5.252844\n",
      "Epoch 164, loss: 5.256324\n",
      "Epoch 165, loss: 5.243244\n",
      "Epoch 166, loss: 5.239640\n",
      "Epoch 167, loss: 5.246463\n",
      "Epoch 168, loss: 5.250962\n",
      "Epoch 169, loss: 5.204626\n",
      "Epoch 170, loss: 5.264498\n",
      "Epoch 171, loss: 5.239828\n",
      "Epoch 172, loss: 5.218426\n",
      "Epoch 173, loss: 5.257383\n",
      "Epoch 174, loss: 5.248699\n",
      "Epoch 175, loss: 5.197284\n",
      "Epoch 176, loss: 5.216333\n",
      "Epoch 177, loss: 5.217679\n",
      "Epoch 178, loss: 5.244441\n",
      "Epoch 179, loss: 5.183930\n",
      "Epoch 180, loss: 5.247307\n",
      "Epoch 181, loss: 5.251148\n",
      "Epoch 182, loss: 5.243098\n",
      "Epoch 183, loss: 5.194713\n",
      "Epoch 184, loss: 5.183031\n",
      "Epoch 185, loss: 5.201663\n",
      "Epoch 186, loss: 5.188382\n",
      "Epoch 187, loss: 5.235713\n",
      "Epoch 188, loss: 5.194567\n",
      "Epoch 189, loss: 5.156075\n",
      "Epoch 190, loss: 5.250512\n",
      "Epoch 191, loss: 5.251687\n",
      "Epoch 192, loss: 5.211926\n",
      "Epoch 193, loss: 5.239680\n",
      "Epoch 194, loss: 5.223948\n",
      "Epoch 195, loss: 5.273991\n",
      "Epoch 196, loss: 5.232995\n",
      "Epoch 197, loss: 5.229199\n",
      "Epoch 198, loss: 5.214727\n",
      "Epoch 199, loss: 5.224683\n",
      "lr: 0.1, rs: 0.001, accuracy 200 epochs: 0.183\n",
      "Epoch 0, loss: 5.173479\n",
      "Epoch 1, loss: 5.117922\n",
      "Epoch 2, loss: 5.166279\n",
      "Epoch 3, loss: 5.089111\n",
      "Epoch 4, loss: 5.046196\n",
      "Epoch 5, loss: 5.045568\n",
      "Epoch 6, loss: 5.038445\n",
      "Epoch 7, loss: 5.025252\n",
      "Epoch 8, loss: 4.995012\n",
      "Epoch 9, loss: 5.015446\n",
      "Epoch 10, loss: 5.025298\n",
      "Epoch 11, loss: 4.993059\n",
      "Epoch 12, loss: 5.007601\n",
      "Epoch 13, loss: 5.042017\n",
      "Epoch 14, loss: 4.974724\n",
      "Epoch 15, loss: 4.996517\n",
      "Epoch 16, loss: 5.002605\n",
      "Epoch 17, loss: 4.980425\n",
      "Epoch 18, loss: 4.979343\n",
      "Epoch 19, loss: 5.020132\n",
      "Epoch 20, loss: 4.999226\n",
      "Epoch 21, loss: 4.963400\n",
      "Epoch 22, loss: 5.011924\n",
      "Epoch 23, loss: 4.987818\n",
      "Epoch 24, loss: 5.035353\n",
      "Epoch 25, loss: 5.043868\n",
      "Epoch 26, loss: 5.036331\n",
      "Epoch 27, loss: 4.962486\n",
      "Epoch 28, loss: 5.053896\n",
      "Epoch 29, loss: 5.017640\n",
      "Epoch 30, loss: 4.992095\n",
      "Epoch 31, loss: 5.023628\n",
      "Epoch 32, loss: 4.988802\n",
      "Epoch 33, loss: 5.035921\n",
      "Epoch 34, loss: 5.045609\n",
      "Epoch 35, loss: 4.987572\n",
      "Epoch 36, loss: 4.994544\n",
      "Epoch 37, loss: 4.993464\n",
      "Epoch 38, loss: 5.022813\n",
      "Epoch 39, loss: 4.970483\n",
      "Epoch 40, loss: 4.976223\n",
      "Epoch 41, loss: 4.992611\n",
      "Epoch 42, loss: 5.003763\n",
      "Epoch 43, loss: 4.988252\n",
      "Epoch 44, loss: 5.063621\n",
      "Epoch 45, loss: 4.959760\n",
      "Epoch 46, loss: 4.956121\n",
      "Epoch 47, loss: 4.959540\n",
      "Epoch 48, loss: 4.977117\n",
      "Epoch 49, loss: 4.974116\n",
      "Epoch 50, loss: 4.999617\n",
      "Epoch 51, loss: 5.025825\n",
      "Epoch 52, loss: 5.040186\n",
      "Epoch 53, loss: 5.004203\n",
      "Epoch 54, loss: 5.060524\n",
      "Epoch 55, loss: 5.002811\n",
      "Epoch 56, loss: 5.049805\n",
      "Epoch 57, loss: 4.959940\n",
      "Epoch 58, loss: 5.027422\n",
      "Epoch 59, loss: 4.983783\n",
      "Epoch 60, loss: 5.036558\n",
      "Epoch 61, loss: 5.058087\n",
      "Epoch 62, loss: 5.002611\n",
      "Epoch 63, loss: 4.993330\n",
      "Epoch 64, loss: 4.993997\n",
      "Epoch 65, loss: 4.962024\n",
      "Epoch 66, loss: 4.988712\n",
      "Epoch 67, loss: 5.041568\n",
      "Epoch 68, loss: 4.971557\n",
      "Epoch 69, loss: 4.988985\n",
      "Epoch 70, loss: 5.022396\n",
      "Epoch 71, loss: 5.000322\n",
      "Epoch 72, loss: 4.954144\n",
      "Epoch 73, loss: 4.996211\n",
      "Epoch 74, loss: 5.007682\n",
      "Epoch 75, loss: 5.048858\n",
      "Epoch 76, loss: 5.023699\n",
      "Epoch 77, loss: 5.000495\n",
      "Epoch 78, loss: 5.030032\n",
      "Epoch 79, loss: 5.019815\n",
      "Epoch 80, loss: 4.980661\n",
      "Epoch 81, loss: 5.061663\n",
      "Epoch 82, loss: 5.071807\n",
      "Epoch 83, loss: 4.980088\n",
      "Epoch 84, loss: 5.055090\n",
      "Epoch 85, loss: 4.975211\n",
      "Epoch 86, loss: 4.973314\n",
      "Epoch 87, loss: 4.969103\n",
      "Epoch 88, loss: 5.045823\n",
      "Epoch 89, loss: 4.959589\n",
      "Epoch 90, loss: 4.988579\n",
      "Epoch 91, loss: 4.965721\n",
      "Epoch 92, loss: 5.023672\n",
      "Epoch 93, loss: 5.018010\n",
      "Epoch 94, loss: 5.013291\n",
      "Epoch 95, loss: 4.994018\n",
      "Epoch 96, loss: 5.009600\n",
      "Epoch 97, loss: 4.995666\n",
      "Epoch 98, loss: 4.992989\n",
      "Epoch 99, loss: 5.017561\n",
      "Epoch 100, loss: 4.999929\n",
      "Epoch 101, loss: 4.992487\n",
      "Epoch 102, loss: 4.974857\n",
      "Epoch 103, loss: 4.979141\n",
      "Epoch 104, loss: 5.056023\n",
      "Epoch 105, loss: 5.067881\n",
      "Epoch 106, loss: 5.008334\n",
      "Epoch 107, loss: 4.977179\n",
      "Epoch 108, loss: 4.945234\n",
      "Epoch 109, loss: 4.941300\n",
      "Epoch 110, loss: 5.023779\n",
      "Epoch 111, loss: 4.949610\n",
      "Epoch 112, loss: 5.036351\n",
      "Epoch 113, loss: 5.046054\n",
      "Epoch 114, loss: 5.025140\n",
      "Epoch 115, loss: 4.978528\n",
      "Epoch 116, loss: 5.040647\n",
      "Epoch 117, loss: 5.017151\n",
      "Epoch 118, loss: 5.022938\n",
      "Epoch 119, loss: 5.015390\n",
      "Epoch 120, loss: 5.003927\n",
      "Epoch 121, loss: 5.011559\n",
      "Epoch 122, loss: 4.969928\n",
      "Epoch 123, loss: 4.989416\n",
      "Epoch 124, loss: 5.002131\n",
      "Epoch 125, loss: 5.030804\n",
      "Epoch 126, loss: 4.963942\n",
      "Epoch 127, loss: 5.000529\n",
      "Epoch 128, loss: 4.943290\n",
      "Epoch 129, loss: 5.011067\n",
      "Epoch 130, loss: 5.022134\n",
      "Epoch 131, loss: 4.956290\n",
      "Epoch 132, loss: 5.070240\n",
      "Epoch 133, loss: 4.977432\n",
      "Epoch 134, loss: 5.046708\n",
      "Epoch 135, loss: 5.026039\n",
      "Epoch 136, loss: 5.045938\n",
      "Epoch 137, loss: 4.967752\n",
      "Epoch 138, loss: 5.003858\n",
      "Epoch 139, loss: 5.029892\n",
      "Epoch 140, loss: 4.966473\n",
      "Epoch 141, loss: 5.018422\n",
      "Epoch 142, loss: 5.006331\n",
      "Epoch 143, loss: 4.958332\n",
      "Epoch 144, loss: 4.994394\n",
      "Epoch 145, loss: 4.960338\n",
      "Epoch 146, loss: 4.988028\n",
      "Epoch 147, loss: 5.020052\n",
      "Epoch 148, loss: 5.034628\n",
      "Epoch 149, loss: 4.978760\n",
      "Epoch 150, loss: 5.020490\n",
      "Epoch 151, loss: 4.995696\n",
      "Epoch 152, loss: 4.976992\n",
      "Epoch 153, loss: 4.990244\n",
      "Epoch 154, loss: 4.953915\n",
      "Epoch 155, loss: 5.027644\n",
      "Epoch 156, loss: 5.013724\n",
      "Epoch 157, loss: 4.969768\n",
      "Epoch 158, loss: 5.033229\n",
      "Epoch 159, loss: 5.052711\n",
      "Epoch 160, loss: 4.997746\n",
      "Epoch 161, loss: 5.020091\n",
      "Epoch 162, loss: 4.982426\n",
      "Epoch 163, loss: 5.058147\n",
      "Epoch 164, loss: 4.995294\n",
      "Epoch 165, loss: 4.963299\n",
      "Epoch 166, loss: 5.005350\n",
      "Epoch 167, loss: 5.037667\n",
      "Epoch 168, loss: 5.002955\n",
      "Epoch 169, loss: 5.036908\n",
      "Epoch 170, loss: 5.002851\n",
      "Epoch 171, loss: 4.982783\n",
      "Epoch 172, loss: 5.024665\n",
      "Epoch 173, loss: 4.956086\n",
      "Epoch 174, loss: 4.945345\n",
      "Epoch 175, loss: 5.020432\n",
      "Epoch 176, loss: 4.989771\n",
      "Epoch 177, loss: 5.025246\n",
      "Epoch 178, loss: 5.019244\n",
      "Epoch 179, loss: 4.981001\n",
      "Epoch 180, loss: 4.999909\n",
      "Epoch 181, loss: 5.009313\n",
      "Epoch 182, loss: 5.011080\n",
      "Epoch 183, loss: 5.070909\n",
      "Epoch 184, loss: 5.010189\n",
      "Epoch 185, loss: 5.018497\n",
      "Epoch 186, loss: 5.003182\n",
      "Epoch 187, loss: 4.988895\n",
      "Epoch 188, loss: 5.015805\n",
      "Epoch 189, loss: 5.011824\n",
      "Epoch 190, loss: 4.980146\n",
      "Epoch 191, loss: 5.042611\n",
      "Epoch 192, loss: 4.988146\n",
      "Epoch 193, loss: 4.925188\n",
      "Epoch 194, loss: 4.994886\n",
      "Epoch 195, loss: 5.027444\n",
      "Epoch 196, loss: 4.985465\n",
      "Epoch 197, loss: 5.023465\n",
      "Epoch 198, loss: 4.992554\n",
      "Epoch 199, loss: 5.009335\n",
      "lr: 0.1, rs: 0.0001, accuracy 200 epochs: 0.14\n",
      "Epoch 0, loss: 5.178409\n",
      "Epoch 1, loss: 5.121825\n",
      "Epoch 2, loss: 5.077059\n",
      "Epoch 3, loss: 5.031558\n",
      "Epoch 4, loss: 5.045729\n",
      "Epoch 5, loss: 4.982151\n",
      "Epoch 6, loss: 5.007404\n",
      "Epoch 7, loss: 4.936976\n",
      "Epoch 8, loss: 4.989219\n",
      "Epoch 9, loss: 4.898283\n",
      "Epoch 10, loss: 4.873272\n",
      "Epoch 11, loss: 4.797202\n",
      "Epoch 12, loss: 4.871527\n",
      "Epoch 13, loss: 4.846101\n",
      "Epoch 14, loss: 4.840798\n",
      "Epoch 15, loss: 4.856080\n",
      "Epoch 16, loss: 4.806430\n",
      "Epoch 17, loss: 4.775982\n",
      "Epoch 18, loss: 4.781033\n",
      "Epoch 19, loss: 4.833416\n",
      "Epoch 20, loss: 4.786371\n",
      "Epoch 21, loss: 4.753833\n",
      "Epoch 22, loss: 4.762172\n",
      "Epoch 23, loss: 4.782279\n",
      "Epoch 24, loss: 4.744668\n",
      "Epoch 25, loss: 4.716930\n",
      "Epoch 26, loss: 4.639797\n",
      "Epoch 27, loss: 4.818088\n",
      "Epoch 28, loss: 4.732014\n",
      "Epoch 29, loss: 4.701735\n",
      "Epoch 30, loss: 4.731507\n",
      "Epoch 31, loss: 4.687586\n",
      "Epoch 32, loss: 4.675390\n",
      "Epoch 33, loss: 4.715326\n",
      "Epoch 34, loss: 4.749442\n",
      "Epoch 35, loss: 4.640310\n",
      "Epoch 36, loss: 4.643495\n",
      "Epoch 37, loss: 4.660538\n",
      "Epoch 38, loss: 4.667302\n",
      "Epoch 39, loss: 4.672596\n",
      "Epoch 40, loss: 4.639020\n",
      "Epoch 41, loss: 4.704891\n",
      "Epoch 42, loss: 4.688079\n",
      "Epoch 43, loss: 4.697770\n",
      "Epoch 44, loss: 4.654099\n",
      "Epoch 45, loss: 4.678749\n",
      "Epoch 46, loss: 4.705920\n",
      "Epoch 47, loss: 4.656295\n",
      "Epoch 48, loss: 4.635766\n",
      "Epoch 49, loss: 4.671463\n",
      "Epoch 50, loss: 4.618736\n",
      "Epoch 51, loss: 4.632129\n",
      "Epoch 52, loss: 4.632561\n",
      "Epoch 53, loss: 4.639172\n",
      "Epoch 54, loss: 4.606733\n",
      "Epoch 55, loss: 4.696926\n",
      "Epoch 56, loss: 4.625821\n",
      "Epoch 57, loss: 4.666404\n",
      "Epoch 58, loss: 4.619852\n",
      "Epoch 59, loss: 4.628913\n",
      "Epoch 60, loss: 4.627689\n",
      "Epoch 61, loss: 4.602459\n",
      "Epoch 62, loss: 4.637890\n",
      "Epoch 63, loss: 4.646995\n",
      "Epoch 64, loss: 4.612609\n",
      "Epoch 65, loss: 4.634180\n",
      "Epoch 66, loss: 4.598262\n",
      "Epoch 67, loss: 4.643268\n",
      "Epoch 68, loss: 4.620725\n",
      "Epoch 69, loss: 4.587917\n",
      "Epoch 70, loss: 4.621776\n",
      "Epoch 71, loss: 4.593513\n",
      "Epoch 72, loss: 4.607130\n",
      "Epoch 73, loss: 4.608878\n",
      "Epoch 74, loss: 4.585802\n",
      "Epoch 75, loss: 4.564931\n",
      "Epoch 76, loss: 4.607808\n",
      "Epoch 77, loss: 4.621219\n",
      "Epoch 78, loss: 4.582216\n",
      "Epoch 79, loss: 4.564097\n",
      "Epoch 80, loss: 4.593257\n",
      "Epoch 81, loss: 4.591965\n",
      "Epoch 82, loss: 4.601902\n",
      "Epoch 83, loss: 4.593518\n",
      "Epoch 84, loss: 4.623654\n",
      "Epoch 85, loss: 4.583077\n",
      "Epoch 86, loss: 4.568634\n",
      "Epoch 87, loss: 4.521512\n",
      "Epoch 88, loss: 4.564690\n",
      "Epoch 89, loss: 4.558629\n",
      "Epoch 90, loss: 4.601013\n",
      "Epoch 91, loss: 4.601037\n",
      "Epoch 92, loss: 4.589013\n",
      "Epoch 93, loss: 4.629155\n",
      "Epoch 94, loss: 4.594775\n",
      "Epoch 95, loss: 4.569716\n",
      "Epoch 96, loss: 4.542886\n",
      "Epoch 97, loss: 4.634679\n",
      "Epoch 98, loss: 4.542726\n",
      "Epoch 99, loss: 4.558129\n",
      "Epoch 100, loss: 4.601205\n",
      "Epoch 101, loss: 4.567266\n",
      "Epoch 102, loss: 4.578585\n",
      "Epoch 103, loss: 4.614643\n",
      "Epoch 104, loss: 4.556942\n",
      "Epoch 105, loss: 4.568236\n",
      "Epoch 106, loss: 4.593505\n",
      "Epoch 107, loss: 4.626131\n",
      "Epoch 108, loss: 4.537686\n",
      "Epoch 109, loss: 4.540366\n",
      "Epoch 110, loss: 4.565007\n",
      "Epoch 111, loss: 4.559982\n",
      "Epoch 112, loss: 4.576203\n",
      "Epoch 113, loss: 4.545192\n",
      "Epoch 114, loss: 4.669261\n",
      "Epoch 115, loss: 4.554037\n",
      "Epoch 116, loss: 4.517727\n",
      "Epoch 117, loss: 4.557078\n",
      "Epoch 118, loss: 4.574978\n",
      "Epoch 119, loss: 4.533641\n",
      "Epoch 120, loss: 4.594135\n",
      "Epoch 121, loss: 4.586493\n",
      "Epoch 122, loss: 4.579499\n",
      "Epoch 123, loss: 4.522355\n",
      "Epoch 124, loss: 4.577565\n",
      "Epoch 125, loss: 4.567473\n",
      "Epoch 126, loss: 4.651456\n",
      "Epoch 127, loss: 4.571204\n",
      "Epoch 128, loss: 4.617843\n",
      "Epoch 129, loss: 4.603156\n",
      "Epoch 130, loss: 4.530450\n",
      "Epoch 131, loss: 4.534290\n",
      "Epoch 132, loss: 4.572756\n",
      "Epoch 133, loss: 4.606654\n",
      "Epoch 134, loss: 4.569636\n",
      "Epoch 135, loss: 4.547369\n",
      "Epoch 136, loss: 4.624455\n",
      "Epoch 137, loss: 4.542676\n",
      "Epoch 138, loss: 4.593181\n",
      "Epoch 139, loss: 4.632039\n",
      "Epoch 140, loss: 4.491176\n",
      "Epoch 141, loss: 4.571605\n",
      "Epoch 142, loss: 4.597204\n",
      "Epoch 143, loss: 4.561687\n",
      "Epoch 144, loss: 4.648605\n",
      "Epoch 145, loss: 4.575004\n",
      "Epoch 146, loss: 4.557918\n",
      "Epoch 147, loss: 4.530192\n",
      "Epoch 148, loss: 4.502424\n",
      "Epoch 149, loss: 4.563429\n",
      "Epoch 150, loss: 4.543918\n",
      "Epoch 151, loss: 4.568564\n",
      "Epoch 152, loss: 4.559392\n",
      "Epoch 153, loss: 4.585730\n",
      "Epoch 154, loss: 4.552843\n",
      "Epoch 155, loss: 4.577485\n",
      "Epoch 156, loss: 4.567891\n",
      "Epoch 157, loss: 4.508977\n",
      "Epoch 158, loss: 4.561722\n",
      "Epoch 159, loss: 4.506575\n",
      "Epoch 160, loss: 4.525499\n",
      "Epoch 161, loss: 4.570755\n",
      "Epoch 162, loss: 4.595380\n",
      "Epoch 163, loss: 4.506195\n",
      "Epoch 164, loss: 4.564008\n",
      "Epoch 165, loss: 4.534759\n",
      "Epoch 166, loss: 4.575447\n",
      "Epoch 167, loss: 4.612057\n",
      "Epoch 168, loss: 4.531254\n",
      "Epoch 169, loss: 4.542467\n",
      "Epoch 170, loss: 4.516268\n",
      "Epoch 171, loss: 4.554595\n",
      "Epoch 172, loss: 4.540894\n",
      "Epoch 173, loss: 4.599988\n",
      "Epoch 174, loss: 4.591262\n",
      "Epoch 175, loss: 4.462042\n",
      "Epoch 176, loss: 4.528878\n",
      "Epoch 177, loss: 4.511917\n",
      "Epoch 178, loss: 4.553677\n",
      "Epoch 179, loss: 4.568301\n",
      "Epoch 180, loss: 4.575448\n",
      "Epoch 181, loss: 4.567346\n",
      "Epoch 182, loss: 4.587165\n",
      "Epoch 183, loss: 4.570585\n",
      "Epoch 184, loss: 4.555691\n",
      "Epoch 185, loss: 4.522481\n",
      "Epoch 186, loss: 4.554309\n",
      "Epoch 187, loss: 4.540749\n",
      "Epoch 188, loss: 4.579356\n",
      "Epoch 189, loss: 4.527810\n",
      "Epoch 190, loss: 4.553968\n",
      "Epoch 191, loss: 4.515981\n",
      "Epoch 192, loss: 4.560248\n",
      "Epoch 193, loss: 4.641717\n",
      "Epoch 194, loss: 4.479026\n",
      "Epoch 195, loss: 4.596775\n",
      "Epoch 196, loss: 4.575210\n",
      "Epoch 197, loss: 4.557054\n",
      "Epoch 198, loss: 4.567172\n",
      "Epoch 199, loss: 4.600585\n",
      "lr: 0.1, rs: 1e-05, accuracy 200 epochs: 0.157\n",
      "Epoch 0, loss: 5.297431\n",
      "Epoch 1, loss: 5.089955\n",
      "Epoch 2, loss: 5.126630\n",
      "Epoch 3, loss: 5.064044\n",
      "Epoch 4, loss: 4.992613\n",
      "Epoch 5, loss: 4.969422\n",
      "Epoch 6, loss: 4.940251\n",
      "Epoch 7, loss: 4.855952\n",
      "Epoch 8, loss: 4.917030\n",
      "Epoch 9, loss: 4.926423\n",
      "Epoch 10, loss: 4.880873\n",
      "Epoch 11, loss: 4.862246\n",
      "Epoch 12, loss: 4.840590\n",
      "Epoch 13, loss: 4.796134\n",
      "Epoch 14, loss: 4.794586\n",
      "Epoch 15, loss: 4.809215\n",
      "Epoch 16, loss: 4.755275\n",
      "Epoch 17, loss: 4.692548\n",
      "Epoch 18, loss: 4.729518\n",
      "Epoch 19, loss: 4.703232\n",
      "Epoch 20, loss: 4.767550\n",
      "Epoch 21, loss: 4.683668\n",
      "Epoch 22, loss: 4.696939\n",
      "Epoch 23, loss: 4.725370\n",
      "Epoch 24, loss: 4.676681\n",
      "Epoch 25, loss: 4.652040\n",
      "Epoch 26, loss: 4.688301\n",
      "Epoch 27, loss: 4.749677\n",
      "Epoch 28, loss: 4.669385\n",
      "Epoch 29, loss: 4.593341\n",
      "Epoch 30, loss: 4.676203\n",
      "Epoch 31, loss: 4.647007\n",
      "Epoch 32, loss: 4.669218\n",
      "Epoch 33, loss: 4.618666\n",
      "Epoch 34, loss: 4.643947\n",
      "Epoch 35, loss: 4.640566\n",
      "Epoch 36, loss: 4.576417\n",
      "Epoch 37, loss: 4.652205\n",
      "Epoch 38, loss: 4.690894\n",
      "Epoch 39, loss: 4.573968\n",
      "Epoch 40, loss: 4.583698\n",
      "Epoch 41, loss: 4.582003\n",
      "Epoch 42, loss: 4.555422\n",
      "Epoch 43, loss: 4.560033\n",
      "Epoch 44, loss: 4.568268\n",
      "Epoch 45, loss: 4.519757\n",
      "Epoch 46, loss: 4.562122\n",
      "Epoch 47, loss: 4.550707\n",
      "Epoch 48, loss: 4.524312\n",
      "Epoch 49, loss: 4.551688\n",
      "Epoch 50, loss: 4.544768\n",
      "Epoch 51, loss: 4.559951\n",
      "Epoch 52, loss: 4.512676\n",
      "Epoch 53, loss: 4.499957\n",
      "Epoch 54, loss: 4.508219\n",
      "Epoch 55, loss: 4.562608\n",
      "Epoch 56, loss: 4.488203\n",
      "Epoch 57, loss: 4.530820\n",
      "Epoch 58, loss: 4.580806\n",
      "Epoch 59, loss: 4.482361\n",
      "Epoch 60, loss: 4.470040\n",
      "Epoch 61, loss: 4.431924\n",
      "Epoch 62, loss: 4.461829\n",
      "Epoch 63, loss: 4.469323\n",
      "Epoch 64, loss: 4.523792\n",
      "Epoch 65, loss: 4.481864\n",
      "Epoch 66, loss: 4.458630\n",
      "Epoch 67, loss: 4.460847\n",
      "Epoch 68, loss: 4.452549\n",
      "Epoch 69, loss: 4.371398\n",
      "Epoch 70, loss: 4.471622\n",
      "Epoch 71, loss: 4.447226\n",
      "Epoch 72, loss: 4.461149\n",
      "Epoch 73, loss: 4.407746\n",
      "Epoch 74, loss: 4.455250\n",
      "Epoch 75, loss: 4.432691\n",
      "Epoch 76, loss: 4.404579\n",
      "Epoch 77, loss: 4.458799\n",
      "Epoch 78, loss: 4.409877\n",
      "Epoch 79, loss: 4.390546\n",
      "Epoch 80, loss: 4.344418\n",
      "Epoch 81, loss: 4.419122\n",
      "Epoch 82, loss: 4.353844\n",
      "Epoch 83, loss: 4.456482\n",
      "Epoch 84, loss: 4.397892\n",
      "Epoch 85, loss: 4.370095\n",
      "Epoch 86, loss: 4.296115\n",
      "Epoch 87, loss: 4.401951\n",
      "Epoch 88, loss: 4.378279\n",
      "Epoch 89, loss: 4.371440\n",
      "Epoch 90, loss: 4.407887\n",
      "Epoch 91, loss: 4.349482\n",
      "Epoch 92, loss: 4.377689\n",
      "Epoch 93, loss: 4.312592\n",
      "Epoch 94, loss: 4.299677\n",
      "Epoch 95, loss: 4.390193\n",
      "Epoch 96, loss: 4.401531\n",
      "Epoch 97, loss: 4.384791\n",
      "Epoch 98, loss: 4.376533\n",
      "Epoch 99, loss: 4.391522\n",
      "Epoch 100, loss: 4.368131\n",
      "Epoch 101, loss: 4.324235\n",
      "Epoch 102, loss: 4.363965\n",
      "Epoch 103, loss: 4.364834\n",
      "Epoch 104, loss: 4.343800\n",
      "Epoch 105, loss: 4.321839\n",
      "Epoch 106, loss: 4.398307\n",
      "Epoch 107, loss: 4.356820\n",
      "Epoch 108, loss: 4.337166\n",
      "Epoch 109, loss: 4.348941\n",
      "Epoch 110, loss: 4.307185\n",
      "Epoch 111, loss: 4.327851\n",
      "Epoch 112, loss: 4.376198\n",
      "Epoch 113, loss: 4.294481\n",
      "Epoch 114, loss: 4.251552\n",
      "Epoch 115, loss: 4.321933\n",
      "Epoch 116, loss: 4.320637\n",
      "Epoch 117, loss: 4.354161\n",
      "Epoch 118, loss: 4.362343\n",
      "Epoch 119, loss: 4.313997\n",
      "Epoch 120, loss: 4.309864\n",
      "Epoch 121, loss: 4.320489\n",
      "Epoch 122, loss: 4.290587\n",
      "Epoch 123, loss: 4.293595\n",
      "Epoch 124, loss: 4.335770\n",
      "Epoch 125, loss: 4.352016\n",
      "Epoch 126, loss: 4.293764\n",
      "Epoch 127, loss: 4.324795\n",
      "Epoch 128, loss: 4.280795\n",
      "Epoch 129, loss: 4.324917\n",
      "Epoch 130, loss: 4.282786\n",
      "Epoch 131, loss: 4.276766\n",
      "Epoch 132, loss: 4.338383\n",
      "Epoch 133, loss: 4.309256\n",
      "Epoch 134, loss: 4.285084\n",
      "Epoch 135, loss: 4.300398\n",
      "Epoch 136, loss: 4.264722\n",
      "Epoch 137, loss: 4.213127\n",
      "Epoch 138, loss: 4.262840\n",
      "Epoch 139, loss: 4.314491\n",
      "Epoch 140, loss: 4.290298\n",
      "Epoch 141, loss: 4.322278\n",
      "Epoch 142, loss: 4.270478\n",
      "Epoch 143, loss: 4.279701\n",
      "Epoch 144, loss: 4.259433\n",
      "Epoch 145, loss: 4.278033\n",
      "Epoch 146, loss: 4.265573\n",
      "Epoch 147, loss: 4.263386\n",
      "Epoch 148, loss: 4.216141\n",
      "Epoch 149, loss: 4.227112\n",
      "Epoch 150, loss: 4.290259\n",
      "Epoch 151, loss: 4.312074\n",
      "Epoch 152, loss: 4.248014\n",
      "Epoch 153, loss: 4.226445\n",
      "Epoch 154, loss: 4.218740\n",
      "Epoch 155, loss: 4.241551\n",
      "Epoch 156, loss: 4.259870\n",
      "Epoch 157, loss: 4.198563\n",
      "Epoch 158, loss: 4.260044\n",
      "Epoch 159, loss: 4.292226\n",
      "Epoch 160, loss: 4.223168\n",
      "Epoch 161, loss: 4.211358\n",
      "Epoch 162, loss: 4.213014\n",
      "Epoch 163, loss: 4.226015\n",
      "Epoch 164, loss: 4.190892\n",
      "Epoch 165, loss: 4.224255\n",
      "Epoch 166, loss: 4.249977\n",
      "Epoch 167, loss: 4.224522\n",
      "Epoch 168, loss: 4.200415\n",
      "Epoch 169, loss: 4.214440\n",
      "Epoch 170, loss: 4.233736\n",
      "Epoch 171, loss: 4.188840\n",
      "Epoch 172, loss: 4.243595\n",
      "Epoch 173, loss: 4.217054\n",
      "Epoch 174, loss: 4.236709\n",
      "Epoch 175, loss: 4.232906\n",
      "Epoch 176, loss: 4.268666\n",
      "Epoch 177, loss: 4.225674\n",
      "Epoch 178, loss: 4.176244\n",
      "Epoch 179, loss: 4.221773\n",
      "Epoch 180, loss: 4.205905\n",
      "Epoch 181, loss: 4.220760\n",
      "Epoch 182, loss: 4.169209\n",
      "Epoch 183, loss: 4.207115\n",
      "Epoch 184, loss: 4.188653\n",
      "Epoch 185, loss: 4.158020\n",
      "Epoch 186, loss: 4.237986\n",
      "Epoch 187, loss: 4.166060\n",
      "Epoch 188, loss: 4.216805\n",
      "Epoch 189, loss: 4.116040\n",
      "Epoch 190, loss: 4.197315\n",
      "Epoch 191, loss: 4.166073\n",
      "Epoch 192, loss: 4.180069\n",
      "Epoch 193, loss: 4.200485\n",
      "Epoch 194, loss: 4.204248\n",
      "Epoch 195, loss: 4.172142\n",
      "Epoch 196, loss: 4.196639\n",
      "Epoch 197, loss: 4.114926\n",
      "Epoch 198, loss: 4.194807\n",
      "Epoch 199, loss: 4.119225\n",
      "lr: 0.1, rs: 1e-06, accuracy 200 epochs: 0.164\n",
      "Epoch 0, loss: 2.408462\n",
      "Epoch 1, loss: 2.410427\n",
      "Epoch 2, loss: 2.404429\n",
      "Epoch 3, loss: 2.407278\n",
      "Epoch 4, loss: 2.410304\n",
      "Epoch 5, loss: 2.407082\n",
      "Epoch 6, loss: 2.403853\n",
      "Epoch 7, loss: 2.410308\n",
      "Epoch 8, loss: 2.406430\n",
      "Epoch 9, loss: 2.407047\n",
      "Epoch 10, loss: 2.403900\n",
      "Epoch 11, loss: 2.406665\n",
      "Epoch 12, loss: 2.409618\n",
      "Epoch 13, loss: 2.404971\n",
      "Epoch 14, loss: 2.409710\n",
      "Epoch 15, loss: 2.412103\n",
      "Epoch 16, loss: 2.407587\n",
      "Epoch 17, loss: 2.402373\n",
      "Epoch 18, loss: 2.410196\n",
      "Epoch 19, loss: 2.405199\n",
      "Epoch 20, loss: 2.409607\n",
      "Epoch 21, loss: 2.407063\n",
      "Epoch 22, loss: 2.410085\n",
      "Epoch 23, loss: 2.405798\n",
      "Epoch 24, loss: 2.406488\n",
      "Epoch 25, loss: 2.407603\n",
      "Epoch 26, loss: 2.407986\n",
      "Epoch 27, loss: 2.403744\n",
      "Epoch 28, loss: 2.405664\n",
      "Epoch 29, loss: 2.409444\n",
      "Epoch 30, loss: 2.406587\n",
      "Epoch 31, loss: 2.407698\n",
      "Epoch 32, loss: 2.410432\n",
      "Epoch 33, loss: 2.408054\n",
      "Epoch 34, loss: 2.404798\n",
      "Epoch 35, loss: 2.405176\n",
      "Epoch 36, loss: 2.405735\n",
      "Epoch 37, loss: 2.404161\n",
      "Epoch 38, loss: 2.408067\n",
      "Epoch 39, loss: 2.406320\n",
      "Epoch 40, loss: 2.415107\n",
      "Epoch 41, loss: 2.407689\n",
      "Epoch 42, loss: 2.407042\n",
      "Epoch 43, loss: 2.408166\n",
      "Epoch 44, loss: 2.407587\n",
      "Epoch 45, loss: 2.409190\n",
      "Epoch 46, loss: 2.409336\n",
      "Epoch 47, loss: 2.411170\n",
      "Epoch 48, loss: 2.414558\n",
      "Epoch 49, loss: 2.411174\n",
      "Epoch 50, loss: 2.405719\n",
      "Epoch 51, loss: 2.412795\n",
      "Epoch 52, loss: 2.404979\n",
      "Epoch 53, loss: 2.411005\n",
      "Epoch 54, loss: 2.403897\n",
      "Epoch 55, loss: 2.406269\n",
      "Epoch 56, loss: 2.410389\n",
      "Epoch 57, loss: 2.406438\n",
      "Epoch 58, loss: 2.403620\n",
      "Epoch 59, loss: 2.407045\n",
      "Epoch 60, loss: 2.414243\n",
      "Epoch 61, loss: 2.401472\n",
      "Epoch 62, loss: 2.405513\n",
      "Epoch 63, loss: 2.406063\n",
      "Epoch 64, loss: 2.406686\n",
      "Epoch 65, loss: 2.412923\n",
      "Epoch 66, loss: 2.407335\n",
      "Epoch 67, loss: 2.411180\n",
      "Epoch 68, loss: 2.403383\n",
      "Epoch 69, loss: 2.405701\n",
      "Epoch 70, loss: 2.406663\n",
      "Epoch 71, loss: 2.410689\n",
      "Epoch 72, loss: 2.407712\n",
      "Epoch 73, loss: 2.407585\n",
      "Epoch 74, loss: 2.403040\n",
      "Epoch 75, loss: 2.409012\n",
      "Epoch 76, loss: 2.406992\n",
      "Epoch 77, loss: 2.410643\n",
      "Epoch 78, loss: 2.403039\n",
      "Epoch 79, loss: 2.407900\n",
      "Epoch 80, loss: 2.407227\n",
      "Epoch 81, loss: 2.406766\n",
      "Epoch 82, loss: 2.409238\n",
      "Epoch 83, loss: 2.402687\n",
      "Epoch 84, loss: 2.409137\n",
      "Epoch 85, loss: 2.409000\n",
      "Epoch 86, loss: 2.406749\n",
      "Epoch 87, loss: 2.408371\n",
      "Epoch 88, loss: 2.411664\n",
      "Epoch 89, loss: 2.406552\n",
      "Epoch 90, loss: 2.409499\n",
      "Epoch 91, loss: 2.406124\n",
      "Epoch 92, loss: 2.407635\n",
      "Epoch 93, loss: 2.413452\n",
      "Epoch 94, loss: 2.414323\n",
      "Epoch 95, loss: 2.410330\n",
      "Epoch 96, loss: 2.409818\n",
      "Epoch 97, loss: 2.409267\n",
      "Epoch 98, loss: 2.410561\n",
      "Epoch 99, loss: 2.410982\n",
      "Epoch 100, loss: 2.410191\n",
      "Epoch 101, loss: 2.404934\n",
      "Epoch 102, loss: 2.409626\n",
      "Epoch 103, loss: 2.407377\n",
      "Epoch 104, loss: 2.406267\n",
      "Epoch 105, loss: 2.410837\n",
      "Epoch 106, loss: 2.403034\n",
      "Epoch 107, loss: 2.407435\n",
      "Epoch 108, loss: 2.402232\n",
      "Epoch 109, loss: 2.407661\n",
      "Epoch 110, loss: 2.405430\n",
      "Epoch 111, loss: 2.407156\n",
      "Epoch 112, loss: 2.410472\n",
      "Epoch 113, loss: 2.409595\n",
      "Epoch 114, loss: 2.405952\n",
      "Epoch 115, loss: 2.405352\n",
      "Epoch 116, loss: 2.406874\n",
      "Epoch 117, loss: 2.408074\n",
      "Epoch 118, loss: 2.406359\n",
      "Epoch 119, loss: 2.409344\n",
      "Epoch 120, loss: 2.410970\n",
      "Epoch 121, loss: 2.403623\n",
      "Epoch 122, loss: 2.407017\n",
      "Epoch 123, loss: 2.408459\n",
      "Epoch 124, loss: 2.408203\n",
      "Epoch 125, loss: 2.410770\n",
      "Epoch 126, loss: 2.409326\n",
      "Epoch 127, loss: 2.403707\n",
      "Epoch 128, loss: 2.403714\n",
      "Epoch 129, loss: 2.411365\n",
      "Epoch 130, loss: 2.407549\n",
      "Epoch 131, loss: 2.408599\n",
      "Epoch 132, loss: 2.405904\n",
      "Epoch 133, loss: 2.408439\n",
      "Epoch 134, loss: 2.401333\n",
      "Epoch 135, loss: 2.408522\n",
      "Epoch 136, loss: 2.410483\n",
      "Epoch 137, loss: 2.408761\n",
      "Epoch 138, loss: 2.407467\n",
      "Epoch 139, loss: 2.401786\n",
      "Epoch 140, loss: 2.407401\n",
      "Epoch 141, loss: 2.405980\n",
      "Epoch 142, loss: 2.408665\n",
      "Epoch 143, loss: 2.406157\n",
      "Epoch 144, loss: 2.403675\n",
      "Epoch 145, loss: 2.406074\n",
      "Epoch 146, loss: 2.410867\n",
      "Epoch 147, loss: 2.404348\n",
      "Epoch 148, loss: 2.403775\n",
      "Epoch 149, loss: 2.403780\n",
      "Epoch 150, loss: 2.406944\n",
      "Epoch 151, loss: 2.412226\n",
      "Epoch 152, loss: 2.407865\n",
      "Epoch 153, loss: 2.407288\n",
      "Epoch 154, loss: 2.407265\n",
      "Epoch 155, loss: 2.411193\n",
      "Epoch 156, loss: 2.405596\n",
      "Epoch 157, loss: 2.409363\n",
      "Epoch 158, loss: 2.412581\n",
      "Epoch 159, loss: 2.405650\n",
      "Epoch 160, loss: 2.413673\n",
      "Epoch 161, loss: 2.409508\n",
      "Epoch 162, loss: 2.400801\n",
      "Epoch 163, loss: 2.405728\n",
      "Epoch 164, loss: 2.412665\n",
      "Epoch 165, loss: 2.407932\n",
      "Epoch 166, loss: 2.411854\n",
      "Epoch 167, loss: 2.413718\n",
      "Epoch 168, loss: 2.406410\n",
      "Epoch 169, loss: 2.405139\n",
      "Epoch 170, loss: 2.407286\n",
      "Epoch 171, loss: 2.407901\n",
      "Epoch 172, loss: 2.408326\n",
      "Epoch 173, loss: 2.407552\n",
      "Epoch 174, loss: 2.410540\n",
      "Epoch 175, loss: 2.406163\n",
      "Epoch 176, loss: 2.410556\n",
      "Epoch 177, loss: 2.402596\n",
      "Epoch 178, loss: 2.408390\n",
      "Epoch 179, loss: 2.410195\n",
      "Epoch 180, loss: 2.413130\n",
      "Epoch 181, loss: 2.406646\n",
      "Epoch 182, loss: 2.415634\n",
      "Epoch 183, loss: 2.408230\n",
      "Epoch 184, loss: 2.411973\n",
      "Epoch 185, loss: 2.407299\n",
      "Epoch 186, loss: 2.406151\n",
      "Epoch 187, loss: 2.408691\n",
      "Epoch 188, loss: 2.404491\n",
      "Epoch 189, loss: 2.406687\n",
      "Epoch 190, loss: 2.408518\n",
      "Epoch 191, loss: 2.405855\n",
      "Epoch 192, loss: 2.409987\n",
      "Epoch 193, loss: 2.409726\n",
      "Epoch 194, loss: 2.405405\n",
      "Epoch 195, loss: 2.409350\n",
      "Epoch 196, loss: 2.408139\n",
      "Epoch 197, loss: 2.406378\n",
      "Epoch 198, loss: 2.410807\n",
      "Epoch 199, loss: 2.408580\n",
      "lr: 0.01, rs: 0.1, accuracy 200 epochs: 0.155\n",
      "Epoch 0, loss: 2.350191\n",
      "Epoch 1, loss: 2.321173\n",
      "Epoch 2, loss: 2.317825\n",
      "Epoch 3, loss: 2.322311\n",
      "Epoch 4, loss: 2.323950\n",
      "Epoch 5, loss: 2.321975\n",
      "Epoch 6, loss: 2.327393\n",
      "Epoch 7, loss: 2.321462\n",
      "Epoch 8, loss: 2.327159\n",
      "Epoch 9, loss: 2.319284\n",
      "Epoch 10, loss: 2.320739\n",
      "Epoch 11, loss: 2.323421\n",
      "Epoch 12, loss: 2.324073\n",
      "Epoch 13, loss: 2.321197\n",
      "Epoch 14, loss: 2.326751\n",
      "Epoch 15, loss: 2.324679\n",
      "Epoch 16, loss: 2.319640\n",
      "Epoch 17, loss: 2.317641\n",
      "Epoch 18, loss: 2.320674\n",
      "Epoch 19, loss: 2.319654\n",
      "Epoch 20, loss: 2.321627\n",
      "Epoch 21, loss: 2.322806\n",
      "Epoch 22, loss: 2.321458\n",
      "Epoch 23, loss: 2.325634\n",
      "Epoch 24, loss: 2.319039\n",
      "Epoch 25, loss: 2.325929\n",
      "Epoch 26, loss: 2.321802\n",
      "Epoch 27, loss: 2.323026\n",
      "Epoch 28, loss: 2.320520\n",
      "Epoch 29, loss: 2.319650\n",
      "Epoch 30, loss: 2.324046\n",
      "Epoch 31, loss: 2.321564\n",
      "Epoch 32, loss: 2.324362\n",
      "Epoch 33, loss: 2.322845\n",
      "Epoch 34, loss: 2.315338\n",
      "Epoch 35, loss: 2.325288\n",
      "Epoch 36, loss: 2.320753\n",
      "Epoch 37, loss: 2.324792\n",
      "Epoch 38, loss: 2.320645\n",
      "Epoch 39, loss: 2.318700\n",
      "Epoch 40, loss: 2.320711\n",
      "Epoch 41, loss: 2.320233\n",
      "Epoch 42, loss: 2.325298\n",
      "Epoch 43, loss: 2.319677\n",
      "Epoch 44, loss: 2.325562\n",
      "Epoch 45, loss: 2.315362\n",
      "Epoch 46, loss: 2.322816\n",
      "Epoch 47, loss: 2.320840\n",
      "Epoch 48, loss: 2.322005\n",
      "Epoch 49, loss: 2.321774\n",
      "Epoch 50, loss: 2.315771\n",
      "Epoch 51, loss: 2.322709\n",
      "Epoch 52, loss: 2.321363\n",
      "Epoch 53, loss: 2.321732\n",
      "Epoch 54, loss: 2.320757\n",
      "Epoch 55, loss: 2.318185\n",
      "Epoch 56, loss: 2.324923\n",
      "Epoch 57, loss: 2.318815\n",
      "Epoch 58, loss: 2.318580\n",
      "Epoch 59, loss: 2.321335\n",
      "Epoch 60, loss: 2.322838\n",
      "Epoch 61, loss: 2.323735\n",
      "Epoch 62, loss: 2.321866\n",
      "Epoch 63, loss: 2.325516\n",
      "Epoch 64, loss: 2.318505\n",
      "Epoch 65, loss: 2.323573\n",
      "Epoch 66, loss: 2.322794\n",
      "Epoch 67, loss: 2.321559\n",
      "Epoch 68, loss: 2.323002\n",
      "Epoch 69, loss: 2.317996\n",
      "Epoch 70, loss: 2.321475\n",
      "Epoch 71, loss: 2.320558\n",
      "Epoch 72, loss: 2.318729\n",
      "Epoch 73, loss: 2.326234\n",
      "Epoch 74, loss: 2.324967\n",
      "Epoch 75, loss: 2.318235\n",
      "Epoch 76, loss: 2.323598\n",
      "Epoch 77, loss: 2.322847\n",
      "Epoch 78, loss: 2.324005\n",
      "Epoch 79, loss: 2.319759\n",
      "Epoch 80, loss: 2.317409\n",
      "Epoch 81, loss: 2.318068\n",
      "Epoch 82, loss: 2.320119\n",
      "Epoch 83, loss: 2.321579\n",
      "Epoch 84, loss: 2.325026\n",
      "Epoch 85, loss: 2.321835\n",
      "Epoch 86, loss: 2.321952\n",
      "Epoch 87, loss: 2.325225\n",
      "Epoch 88, loss: 2.319682\n",
      "Epoch 89, loss: 2.320474\n",
      "Epoch 90, loss: 2.319214\n",
      "Epoch 91, loss: 2.318847\n",
      "Epoch 92, loss: 2.319684\n",
      "Epoch 93, loss: 2.319111\n",
      "Epoch 94, loss: 2.324177\n",
      "Epoch 95, loss: 2.320821\n",
      "Epoch 96, loss: 2.325795\n",
      "Epoch 97, loss: 2.323766\n",
      "Epoch 98, loss: 2.322016\n",
      "Epoch 99, loss: 2.324551\n",
      "Epoch 100, loss: 2.323221\n",
      "Epoch 101, loss: 2.322912\n",
      "Epoch 102, loss: 2.321871\n",
      "Epoch 103, loss: 2.324923\n",
      "Epoch 104, loss: 2.322337\n",
      "Epoch 105, loss: 2.322450\n",
      "Epoch 106, loss: 2.318851\n",
      "Epoch 107, loss: 2.322268\n",
      "Epoch 108, loss: 2.321825\n",
      "Epoch 109, loss: 2.314683\n",
      "Epoch 110, loss: 2.323172\n",
      "Epoch 111, loss: 2.327324\n",
      "Epoch 112, loss: 2.321591\n",
      "Epoch 113, loss: 2.324834\n",
      "Epoch 114, loss: 2.321149\n",
      "Epoch 115, loss: 2.320283\n",
      "Epoch 116, loss: 2.317383\n",
      "Epoch 117, loss: 2.321864\n",
      "Epoch 118, loss: 2.323480\n",
      "Epoch 119, loss: 2.316730\n",
      "Epoch 120, loss: 2.319790\n",
      "Epoch 121, loss: 2.321585\n",
      "Epoch 122, loss: 2.319859\n",
      "Epoch 123, loss: 2.323166\n",
      "Epoch 124, loss: 2.318315\n",
      "Epoch 125, loss: 2.323365\n",
      "Epoch 126, loss: 2.324499\n",
      "Epoch 127, loss: 2.320507\n",
      "Epoch 128, loss: 2.320843\n",
      "Epoch 129, loss: 2.321231\n",
      "Epoch 130, loss: 2.321649\n",
      "Epoch 131, loss: 2.319166\n",
      "Epoch 132, loss: 2.321201\n",
      "Epoch 133, loss: 2.321404\n",
      "Epoch 134, loss: 2.321549\n",
      "Epoch 135, loss: 2.323184\n",
      "Epoch 136, loss: 2.316618\n",
      "Epoch 137, loss: 2.322831\n",
      "Epoch 138, loss: 2.321842\n",
      "Epoch 139, loss: 2.321764\n",
      "Epoch 140, loss: 2.323897\n",
      "Epoch 141, loss: 2.319397\n",
      "Epoch 142, loss: 2.323195\n",
      "Epoch 143, loss: 2.322309\n",
      "Epoch 144, loss: 2.321726\n",
      "Epoch 145, loss: 2.326133\n",
      "Epoch 146, loss: 2.316357\n",
      "Epoch 147, loss: 2.323687\n",
      "Epoch 148, loss: 2.320306\n",
      "Epoch 149, loss: 2.321776\n",
      "Epoch 150, loss: 2.320189\n",
      "Epoch 151, loss: 2.319605\n",
      "Epoch 152, loss: 2.321521\n",
      "Epoch 153, loss: 2.320338\n",
      "Epoch 154, loss: 2.316330\n",
      "Epoch 155, loss: 2.322452\n",
      "Epoch 156, loss: 2.322482\n",
      "Epoch 157, loss: 2.318428\n",
      "Epoch 158, loss: 2.320875\n",
      "Epoch 159, loss: 2.327756\n",
      "Epoch 160, loss: 2.321859\n",
      "Epoch 161, loss: 2.322368\n",
      "Epoch 162, loss: 2.316693\n",
      "Epoch 163, loss: 2.324817\n",
      "Epoch 164, loss: 2.318967\n",
      "Epoch 165, loss: 2.318227\n",
      "Epoch 166, loss: 2.321424\n",
      "Epoch 167, loss: 2.325059\n",
      "Epoch 168, loss: 2.326411\n",
      "Epoch 169, loss: 2.323111\n",
      "Epoch 170, loss: 2.322719\n",
      "Epoch 171, loss: 2.324270\n",
      "Epoch 172, loss: 2.320552\n",
      "Epoch 173, loss: 2.322405\n",
      "Epoch 174, loss: 2.324495\n",
      "Epoch 175, loss: 2.319505\n",
      "Epoch 176, loss: 2.323516\n",
      "Epoch 177, loss: 2.324356\n",
      "Epoch 178, loss: 2.320393\n",
      "Epoch 179, loss: 2.323616\n",
      "Epoch 180, loss: 2.322692\n",
      "Epoch 181, loss: 2.321314\n",
      "Epoch 182, loss: 2.318506\n",
      "Epoch 183, loss: 2.326037\n",
      "Epoch 184, loss: 2.321887\n",
      "Epoch 185, loss: 2.321239\n",
      "Epoch 186, loss: 2.321308\n",
      "Epoch 187, loss: 2.317069\n",
      "Epoch 188, loss: 2.323121\n",
      "Epoch 189, loss: 2.316724\n",
      "Epoch 190, loss: 2.325040\n",
      "Epoch 191, loss: 2.322986\n",
      "Epoch 192, loss: 2.319907\n",
      "Epoch 193, loss: 2.317919\n",
      "Epoch 194, loss: 2.317158\n",
      "Epoch 195, loss: 2.325273\n",
      "Epoch 196, loss: 2.321398\n",
      "Epoch 197, loss: 2.319818\n",
      "Epoch 198, loss: 2.320171\n",
      "Epoch 199, loss: 2.322595\n",
      "lr: 0.01, rs: 0.01, accuracy 200 epochs: 0.209\n",
      "Epoch 0, loss: 2.322181\n",
      "Epoch 1, loss: 2.266533\n",
      "Epoch 2, loss: 2.251744\n",
      "Epoch 3, loss: 2.246126\n",
      "Epoch 4, loss: 2.240102\n",
      "Epoch 5, loss: 2.233259\n",
      "Epoch 6, loss: 2.227965\n",
      "Epoch 7, loss: 2.227012\n",
      "Epoch 8, loss: 2.227798\n",
      "Epoch 9, loss: 2.221117\n",
      "Epoch 10, loss: 2.221829\n",
      "Epoch 11, loss: 2.222793\n",
      "Epoch 12, loss: 2.221964\n",
      "Epoch 13, loss: 2.223807\n",
      "Epoch 14, loss: 2.219454\n",
      "Epoch 15, loss: 2.224028\n",
      "Epoch 16, loss: 2.219039\n",
      "Epoch 17, loss: 2.221624\n",
      "Epoch 18, loss: 2.216027\n",
      "Epoch 19, loss: 2.222222\n",
      "Epoch 20, loss: 2.218013\n",
      "Epoch 21, loss: 2.221430\n",
      "Epoch 22, loss: 2.221438\n",
      "Epoch 23, loss: 2.221767\n",
      "Epoch 24, loss: 2.219497\n",
      "Epoch 25, loss: 2.219179\n",
      "Epoch 26, loss: 2.220986\n",
      "Epoch 27, loss: 2.221638\n",
      "Epoch 28, loss: 2.221239\n",
      "Epoch 29, loss: 2.219411\n",
      "Epoch 30, loss: 2.220417\n",
      "Epoch 31, loss: 2.216769\n",
      "Epoch 32, loss: 2.217517\n",
      "Epoch 33, loss: 2.223547\n",
      "Epoch 34, loss: 2.219127\n",
      "Epoch 35, loss: 2.217065\n",
      "Epoch 36, loss: 2.221059\n",
      "Epoch 37, loss: 2.218930\n",
      "Epoch 38, loss: 2.219575\n",
      "Epoch 39, loss: 2.215297\n",
      "Epoch 40, loss: 2.218210\n",
      "Epoch 41, loss: 2.216876\n",
      "Epoch 42, loss: 2.218669\n",
      "Epoch 43, loss: 2.220329\n",
      "Epoch 44, loss: 2.218359\n",
      "Epoch 45, loss: 2.220322\n",
      "Epoch 46, loss: 2.216712\n",
      "Epoch 47, loss: 2.220272\n",
      "Epoch 48, loss: 2.221410\n",
      "Epoch 49, loss: 2.219249\n",
      "Epoch 50, loss: 2.217918\n",
      "Epoch 51, loss: 2.219911\n",
      "Epoch 52, loss: 2.221027\n",
      "Epoch 53, loss: 2.221868\n",
      "Epoch 54, loss: 2.218411\n",
      "Epoch 55, loss: 2.219391\n",
      "Epoch 56, loss: 2.222060\n",
      "Epoch 57, loss: 2.216071\n",
      "Epoch 58, loss: 2.220504\n",
      "Epoch 59, loss: 2.216796\n",
      "Epoch 60, loss: 2.221044\n",
      "Epoch 61, loss: 2.219078\n",
      "Epoch 62, loss: 2.218309\n",
      "Epoch 63, loss: 2.222110\n",
      "Epoch 64, loss: 2.215911\n",
      "Epoch 65, loss: 2.218693\n",
      "Epoch 66, loss: 2.218975\n",
      "Epoch 67, loss: 2.218793\n",
      "Epoch 68, loss: 2.218579\n",
      "Epoch 69, loss: 2.221566\n",
      "Epoch 70, loss: 2.219046\n",
      "Epoch 71, loss: 2.220577\n",
      "Epoch 72, loss: 2.215510\n",
      "Epoch 73, loss: 2.221533\n",
      "Epoch 74, loss: 2.219785\n",
      "Epoch 75, loss: 2.217721\n",
      "Epoch 76, loss: 2.217088\n",
      "Epoch 77, loss: 2.220099\n",
      "Epoch 78, loss: 2.221978\n",
      "Epoch 79, loss: 2.218288\n",
      "Epoch 80, loss: 2.218163\n",
      "Epoch 81, loss: 2.214661\n",
      "Epoch 82, loss: 2.221105\n",
      "Epoch 83, loss: 2.215343\n",
      "Epoch 84, loss: 2.218384\n",
      "Epoch 85, loss: 2.223064\n",
      "Epoch 86, loss: 2.218370\n",
      "Epoch 87, loss: 2.223061\n",
      "Epoch 88, loss: 2.217902\n",
      "Epoch 89, loss: 2.218948\n",
      "Epoch 90, loss: 2.218672\n",
      "Epoch 91, loss: 2.214632\n",
      "Epoch 92, loss: 2.223648\n",
      "Epoch 93, loss: 2.216694\n",
      "Epoch 94, loss: 2.212022\n",
      "Epoch 95, loss: 2.225779\n",
      "Epoch 96, loss: 2.223051\n",
      "Epoch 97, loss: 2.219175\n",
      "Epoch 98, loss: 2.218755\n",
      "Epoch 99, loss: 2.218294\n",
      "Epoch 100, loss: 2.222691\n",
      "Epoch 101, loss: 2.220448\n",
      "Epoch 102, loss: 2.220859\n",
      "Epoch 103, loss: 2.220137\n",
      "Epoch 104, loss: 2.215004\n",
      "Epoch 105, loss: 2.216431\n",
      "Epoch 106, loss: 2.220551\n",
      "Epoch 107, loss: 2.219177\n",
      "Epoch 108, loss: 2.215542\n",
      "Epoch 109, loss: 2.218258\n",
      "Epoch 110, loss: 2.217615\n",
      "Epoch 111, loss: 2.218610\n",
      "Epoch 112, loss: 2.218087\n",
      "Epoch 113, loss: 2.216758\n",
      "Epoch 114, loss: 2.221913\n",
      "Epoch 115, loss: 2.222511\n",
      "Epoch 116, loss: 2.220806\n",
      "Epoch 117, loss: 2.222395\n",
      "Epoch 118, loss: 2.218951\n",
      "Epoch 119, loss: 2.224136\n",
      "Epoch 120, loss: 2.221506\n",
      "Epoch 121, loss: 2.220787\n",
      "Epoch 122, loss: 2.218140\n",
      "Epoch 123, loss: 2.220133\n",
      "Epoch 124, loss: 2.217335\n",
      "Epoch 125, loss: 2.220791\n",
      "Epoch 126, loss: 2.221219\n",
      "Epoch 127, loss: 2.217726\n",
      "Epoch 128, loss: 2.217653\n",
      "Epoch 129, loss: 2.221743\n",
      "Epoch 130, loss: 2.216803\n",
      "Epoch 131, loss: 2.216361\n",
      "Epoch 132, loss: 2.217174\n",
      "Epoch 133, loss: 2.217977\n",
      "Epoch 134, loss: 2.218360\n",
      "Epoch 135, loss: 2.211334\n",
      "Epoch 136, loss: 2.218901\n",
      "Epoch 137, loss: 2.214248\n",
      "Epoch 138, loss: 2.219470\n",
      "Epoch 139, loss: 2.216442\n",
      "Epoch 140, loss: 2.215768\n",
      "Epoch 141, loss: 2.219015\n",
      "Epoch 142, loss: 2.221162\n",
      "Epoch 143, loss: 2.219560\n",
      "Epoch 144, loss: 2.213721\n",
      "Epoch 145, loss: 2.208316\n",
      "Epoch 146, loss: 2.216466\n",
      "Epoch 147, loss: 2.218002\n",
      "Epoch 148, loss: 2.219311\n",
      "Epoch 149, loss: 2.217809\n",
      "Epoch 150, loss: 2.214890\n",
      "Epoch 151, loss: 2.220712\n",
      "Epoch 152, loss: 2.219375\n",
      "Epoch 153, loss: 2.220943\n",
      "Epoch 154, loss: 2.220678\n",
      "Epoch 155, loss: 2.216562\n",
      "Epoch 156, loss: 2.224117\n",
      "Epoch 157, loss: 2.216787\n",
      "Epoch 158, loss: 2.220408\n",
      "Epoch 159, loss: 2.218966\n",
      "Epoch 160, loss: 2.219569\n",
      "Epoch 161, loss: 2.215348\n",
      "Epoch 162, loss: 2.216737\n",
      "Epoch 163, loss: 2.220498\n",
      "Epoch 164, loss: 2.218683\n",
      "Epoch 165, loss: 2.222462\n",
      "Epoch 166, loss: 2.220555\n",
      "Epoch 167, loss: 2.222409\n",
      "Epoch 168, loss: 2.216737\n",
      "Epoch 169, loss: 2.221033\n",
      "Epoch 170, loss: 2.219504\n",
      "Epoch 171, loss: 2.218288\n",
      "Epoch 172, loss: 2.221662\n",
      "Epoch 173, loss: 2.223106\n",
      "Epoch 174, loss: 2.216165\n",
      "Epoch 175, loss: 2.221626\n",
      "Epoch 176, loss: 2.219745\n",
      "Epoch 177, loss: 2.215027\n",
      "Epoch 178, loss: 2.220374\n",
      "Epoch 179, loss: 2.212831\n",
      "Epoch 180, loss: 2.215876\n",
      "Epoch 181, loss: 2.218628\n",
      "Epoch 182, loss: 2.215617\n",
      "Epoch 183, loss: 2.215888\n",
      "Epoch 184, loss: 2.221122\n",
      "Epoch 185, loss: 2.215407\n",
      "Epoch 186, loss: 2.221685\n",
      "Epoch 187, loss: 2.219575\n",
      "Epoch 188, loss: 2.217436\n",
      "Epoch 189, loss: 2.218348\n",
      "Epoch 190, loss: 2.220119\n",
      "Epoch 191, loss: 2.216136\n",
      "Epoch 192, loss: 2.223820\n",
      "Epoch 193, loss: 2.218020\n",
      "Epoch 194, loss: 2.222615\n",
      "Epoch 195, loss: 2.216210\n",
      "Epoch 196, loss: 2.218451\n",
      "Epoch 197, loss: 2.216802\n",
      "Epoch 198, loss: 2.219560\n",
      "Epoch 199, loss: 2.219977\n",
      "lr: 0.01, rs: 0.001, accuracy 200 epochs: 0.216\n",
      "Epoch 0, loss: 2.313945\n",
      "Epoch 1, loss: 2.255722\n",
      "Epoch 2, loss: 2.240081\n",
      "Epoch 3, loss: 2.221089\n",
      "Epoch 4, loss: 2.209296\n",
      "Epoch 5, loss: 2.206906\n",
      "Epoch 6, loss: 2.196478\n",
      "Epoch 7, loss: 2.186790\n",
      "Epoch 8, loss: 2.181985\n",
      "Epoch 9, loss: 2.180230\n",
      "Epoch 10, loss: 2.169280\n",
      "Epoch 11, loss: 2.163558\n",
      "Epoch 12, loss: 2.158226\n",
      "Epoch 13, loss: 2.163347\n",
      "Epoch 14, loss: 2.158491\n",
      "Epoch 15, loss: 2.147417\n",
      "Epoch 16, loss: 2.153585\n",
      "Epoch 17, loss: 2.143217\n",
      "Epoch 18, loss: 2.139547\n",
      "Epoch 19, loss: 2.142464\n",
      "Epoch 20, loss: 2.141218\n",
      "Epoch 21, loss: 2.135173\n",
      "Epoch 22, loss: 2.132853\n",
      "Epoch 23, loss: 2.131236\n",
      "Epoch 24, loss: 2.134334\n",
      "Epoch 25, loss: 2.124991\n",
      "Epoch 26, loss: 2.127056\n",
      "Epoch 27, loss: 2.129724\n",
      "Epoch 28, loss: 2.125198\n",
      "Epoch 29, loss: 2.117975\n",
      "Epoch 30, loss: 2.118372\n",
      "Epoch 31, loss: 2.116872\n",
      "Epoch 32, loss: 2.117029\n",
      "Epoch 33, loss: 2.112136\n",
      "Epoch 34, loss: 2.117195\n",
      "Epoch 35, loss: 2.111961\n",
      "Epoch 36, loss: 2.111241\n",
      "Epoch 37, loss: 2.111405\n",
      "Epoch 38, loss: 2.109284\n",
      "Epoch 39, loss: 2.104119\n",
      "Epoch 40, loss: 2.107504\n",
      "Epoch 41, loss: 2.104185\n",
      "Epoch 42, loss: 2.106680\n",
      "Epoch 43, loss: 2.109329\n",
      "Epoch 44, loss: 2.106573\n",
      "Epoch 45, loss: 2.104296\n",
      "Epoch 46, loss: 2.100759\n",
      "Epoch 47, loss: 2.100677\n",
      "Epoch 48, loss: 2.101379\n",
      "Epoch 49, loss: 2.098300\n",
      "Epoch 50, loss: 2.097206\n",
      "Epoch 51, loss: 2.093655\n",
      "Epoch 52, loss: 2.101525\n",
      "Epoch 53, loss: 2.093531\n",
      "Epoch 54, loss: 2.094617\n",
      "Epoch 55, loss: 2.098326\n",
      "Epoch 56, loss: 2.094051\n",
      "Epoch 57, loss: 2.096864\n",
      "Epoch 58, loss: 2.094374\n",
      "Epoch 59, loss: 2.097067\n",
      "Epoch 60, loss: 2.096084\n",
      "Epoch 61, loss: 2.092783\n",
      "Epoch 62, loss: 2.094687\n",
      "Epoch 63, loss: 2.094480\n",
      "Epoch 64, loss: 2.092399\n",
      "Epoch 65, loss: 2.096125\n",
      "Epoch 66, loss: 2.095565\n",
      "Epoch 67, loss: 2.091644\n",
      "Epoch 68, loss: 2.094980\n",
      "Epoch 69, loss: 2.092225\n",
      "Epoch 70, loss: 2.091084\n",
      "Epoch 71, loss: 2.085508\n",
      "Epoch 72, loss: 2.088894\n",
      "Epoch 73, loss: 2.091243\n",
      "Epoch 74, loss: 2.089513\n",
      "Epoch 75, loss: 2.087037\n",
      "Epoch 76, loss: 2.085650\n",
      "Epoch 77, loss: 2.086909\n",
      "Epoch 78, loss: 2.087208\n",
      "Epoch 79, loss: 2.083093\n",
      "Epoch 80, loss: 2.082011\n",
      "Epoch 81, loss: 2.087965\n",
      "Epoch 82, loss: 2.089373\n",
      "Epoch 83, loss: 2.083298\n",
      "Epoch 84, loss: 2.090040\n",
      "Epoch 85, loss: 2.081414\n",
      "Epoch 86, loss: 2.085810\n",
      "Epoch 87, loss: 2.083527\n",
      "Epoch 88, loss: 2.089047\n",
      "Epoch 89, loss: 2.085682\n",
      "Epoch 90, loss: 2.082876\n",
      "Epoch 91, loss: 2.083280\n",
      "Epoch 92, loss: 2.082612\n",
      "Epoch 93, loss: 2.081580\n",
      "Epoch 94, loss: 2.082714\n",
      "Epoch 95, loss: 2.080358\n",
      "Epoch 96, loss: 2.080613\n",
      "Epoch 97, loss: 2.086719\n",
      "Epoch 98, loss: 2.084575\n",
      "Epoch 99, loss: 2.082641\n",
      "Epoch 100, loss: 2.087164\n",
      "Epoch 101, loss: 2.079593\n",
      "Epoch 102, loss: 2.086164\n",
      "Epoch 103, loss: 2.083984\n",
      "Epoch 104, loss: 2.084506\n",
      "Epoch 105, loss: 2.081544\n",
      "Epoch 106, loss: 2.081251\n",
      "Epoch 107, loss: 2.079234\n",
      "Epoch 108, loss: 2.084427\n",
      "Epoch 109, loss: 2.086301\n",
      "Epoch 110, loss: 2.080004\n",
      "Epoch 111, loss: 2.080646\n",
      "Epoch 112, loss: 2.082783\n",
      "Epoch 113, loss: 2.079855\n",
      "Epoch 114, loss: 2.075878\n",
      "Epoch 115, loss: 2.082915\n",
      "Epoch 116, loss: 2.077351\n",
      "Epoch 117, loss: 2.081192\n",
      "Epoch 118, loss: 2.078861\n",
      "Epoch 119, loss: 2.078433\n",
      "Epoch 120, loss: 2.079776\n",
      "Epoch 121, loss: 2.076847\n",
      "Epoch 122, loss: 2.083420\n",
      "Epoch 123, loss: 2.083083\n",
      "Epoch 124, loss: 2.081621\n",
      "Epoch 125, loss: 2.079986\n",
      "Epoch 126, loss: 2.081598\n",
      "Epoch 127, loss: 2.080470\n",
      "Epoch 128, loss: 2.073506\n",
      "Epoch 129, loss: 2.078870\n",
      "Epoch 130, loss: 2.076619\n",
      "Epoch 131, loss: 2.077138\n",
      "Epoch 132, loss: 2.077448\n",
      "Epoch 133, loss: 2.078351\n",
      "Epoch 134, loss: 2.078278\n",
      "Epoch 135, loss: 2.076166\n",
      "Epoch 136, loss: 2.074833\n",
      "Epoch 137, loss: 2.080245\n",
      "Epoch 138, loss: 2.077861\n",
      "Epoch 139, loss: 2.078530\n",
      "Epoch 140, loss: 2.077005\n",
      "Epoch 141, loss: 2.078932\n",
      "Epoch 142, loss: 2.081738\n",
      "Epoch 143, loss: 2.082127\n",
      "Epoch 144, loss: 2.079154\n",
      "Epoch 145, loss: 2.078447\n",
      "Epoch 146, loss: 2.081251\n",
      "Epoch 147, loss: 2.083315\n",
      "Epoch 148, loss: 2.077069\n",
      "Epoch 149, loss: 2.079423\n",
      "Epoch 150, loss: 2.079739\n",
      "Epoch 151, loss: 2.078068\n",
      "Epoch 152, loss: 2.075217\n",
      "Epoch 153, loss: 2.077640\n",
      "Epoch 154, loss: 2.077685\n",
      "Epoch 155, loss: 2.076108\n",
      "Epoch 156, loss: 2.079859\n",
      "Epoch 157, loss: 2.078859\n",
      "Epoch 158, loss: 2.075840\n",
      "Epoch 159, loss: 2.078069\n",
      "Epoch 160, loss: 2.074243\n",
      "Epoch 161, loss: 2.076363\n",
      "Epoch 162, loss: 2.078180\n",
      "Epoch 163, loss: 2.073098\n",
      "Epoch 164, loss: 2.080721\n",
      "Epoch 165, loss: 2.078399\n",
      "Epoch 166, loss: 2.079573\n",
      "Epoch 167, loss: 2.078338\n",
      "Epoch 168, loss: 2.080556\n",
      "Epoch 169, loss: 2.078094\n",
      "Epoch 170, loss: 2.075826\n",
      "Epoch 171, loss: 2.073952\n",
      "Epoch 172, loss: 2.080864\n",
      "Epoch 173, loss: 2.076910\n",
      "Epoch 174, loss: 2.073456\n",
      "Epoch 175, loss: 2.074308\n",
      "Epoch 176, loss: 2.076737\n",
      "Epoch 177, loss: 2.074808\n",
      "Epoch 178, loss: 2.077563\n",
      "Epoch 179, loss: 2.078240\n",
      "Epoch 180, loss: 2.079265\n",
      "Epoch 181, loss: 2.080850\n",
      "Epoch 182, loss: 2.076226\n",
      "Epoch 183, loss: 2.074749\n",
      "Epoch 184, loss: 2.082303\n",
      "Epoch 185, loss: 2.072531\n",
      "Epoch 186, loss: 2.075074\n",
      "Epoch 187, loss: 2.081823\n",
      "Epoch 188, loss: 2.076616\n",
      "Epoch 189, loss: 2.074796\n",
      "Epoch 190, loss: 2.079858\n",
      "Epoch 191, loss: 2.074996\n",
      "Epoch 192, loss: 2.076743\n",
      "Epoch 193, loss: 2.072518\n",
      "Epoch 194, loss: 2.076197\n",
      "Epoch 195, loss: 2.074434\n",
      "Epoch 196, loss: 2.073590\n",
      "Epoch 197, loss: 2.077477\n",
      "Epoch 198, loss: 2.077787\n",
      "Epoch 199, loss: 2.071800\n",
      "lr: 0.01, rs: 0.0001, accuracy 200 epochs: 0.216\n",
      "Epoch 0, loss: 2.318535\n",
      "Epoch 1, loss: 2.260260\n",
      "Epoch 2, loss: 2.236945\n",
      "Epoch 3, loss: 2.222146\n",
      "Epoch 4, loss: 2.206235\n",
      "Epoch 5, loss: 2.199516\n",
      "Epoch 6, loss: 2.188202\n",
      "Epoch 7, loss: 2.181657\n",
      "Epoch 8, loss: 2.169134\n",
      "Epoch 9, loss: 2.166535\n",
      "Epoch 10, loss: 2.165376\n",
      "Epoch 11, loss: 2.154528\n",
      "Epoch 12, loss: 2.150255\n",
      "Epoch 13, loss: 2.149123\n",
      "Epoch 14, loss: 2.143834\n",
      "Epoch 15, loss: 2.141727\n",
      "Epoch 16, loss: 2.133101\n",
      "Epoch 17, loss: 2.132415\n",
      "Epoch 18, loss: 2.128728\n",
      "Epoch 19, loss: 2.124017\n",
      "Epoch 20, loss: 2.129158\n",
      "Epoch 21, loss: 2.118667\n",
      "Epoch 22, loss: 2.112244\n",
      "Epoch 23, loss: 2.109243\n",
      "Epoch 24, loss: 2.108884\n",
      "Epoch 25, loss: 2.101242\n",
      "Epoch 26, loss: 2.101078\n",
      "Epoch 27, loss: 2.103364\n",
      "Epoch 28, loss: 2.099385\n",
      "Epoch 29, loss: 2.091541\n",
      "Epoch 30, loss: 2.097411\n",
      "Epoch 31, loss: 2.088081\n",
      "Epoch 32, loss: 2.090913\n",
      "Epoch 33, loss: 2.086031\n",
      "Epoch 34, loss: 2.086098\n",
      "Epoch 35, loss: 2.078445\n",
      "Epoch 36, loss: 2.081346\n",
      "Epoch 37, loss: 2.078438\n",
      "Epoch 38, loss: 2.076551\n",
      "Epoch 39, loss: 2.076917\n",
      "Epoch 40, loss: 2.071706\n",
      "Epoch 41, loss: 2.075903\n",
      "Epoch 42, loss: 2.073749\n",
      "Epoch 43, loss: 2.072030\n",
      "Epoch 44, loss: 2.068173\n",
      "Epoch 45, loss: 2.065952\n",
      "Epoch 46, loss: 2.066127\n",
      "Epoch 47, loss: 2.059438\n",
      "Epoch 48, loss: 2.057280\n",
      "Epoch 49, loss: 2.058037\n",
      "Epoch 50, loss: 2.057384\n",
      "Epoch 51, loss: 2.059429\n",
      "Epoch 52, loss: 2.054546\n",
      "Epoch 53, loss: 2.054464\n",
      "Epoch 54, loss: 2.046945\n",
      "Epoch 55, loss: 2.050774\n",
      "Epoch 56, loss: 2.047310\n",
      "Epoch 57, loss: 2.050481\n",
      "Epoch 58, loss: 2.039431\n",
      "Epoch 59, loss: 2.042167\n",
      "Epoch 60, loss: 2.045738\n",
      "Epoch 61, loss: 2.047726\n",
      "Epoch 62, loss: 2.035171\n",
      "Epoch 63, loss: 2.038483\n",
      "Epoch 64, loss: 2.039866\n",
      "Epoch 65, loss: 2.034349\n",
      "Epoch 66, loss: 2.039161\n",
      "Epoch 67, loss: 2.035571\n",
      "Epoch 68, loss: 2.037831\n",
      "Epoch 69, loss: 2.029856\n",
      "Epoch 70, loss: 2.031176\n",
      "Epoch 71, loss: 2.029479\n",
      "Epoch 72, loss: 2.032967\n",
      "Epoch 73, loss: 2.028760\n",
      "Epoch 74, loss: 2.027262\n",
      "Epoch 75, loss: 2.025829\n",
      "Epoch 76, loss: 2.021250\n",
      "Epoch 77, loss: 2.028433\n",
      "Epoch 78, loss: 2.021214\n",
      "Epoch 79, loss: 2.021391\n",
      "Epoch 80, loss: 2.018746\n",
      "Epoch 81, loss: 2.012414\n",
      "Epoch 82, loss: 2.016178\n",
      "Epoch 83, loss: 2.019993\n",
      "Epoch 84, loss: 2.012691\n",
      "Epoch 85, loss: 2.019733\n",
      "Epoch 86, loss: 2.013315\n",
      "Epoch 87, loss: 2.017487\n",
      "Epoch 88, loss: 2.011436\n",
      "Epoch 89, loss: 2.010462\n",
      "Epoch 90, loss: 2.013911\n",
      "Epoch 91, loss: 2.009929\n",
      "Epoch 92, loss: 2.009590\n",
      "Epoch 93, loss: 2.006868\n",
      "Epoch 94, loss: 2.008887\n",
      "Epoch 95, loss: 2.007464\n",
      "Epoch 96, loss: 2.003132\n",
      "Epoch 97, loss: 2.011571\n",
      "Epoch 98, loss: 2.007774\n",
      "Epoch 99, loss: 1.999797\n",
      "Epoch 100, loss: 2.005439\n",
      "Epoch 101, loss: 2.002656\n",
      "Epoch 102, loss: 2.005440\n",
      "Epoch 103, loss: 2.003515\n",
      "Epoch 104, loss: 2.001622\n",
      "Epoch 105, loss: 1.999253\n",
      "Epoch 106, loss: 2.000616\n",
      "Epoch 107, loss: 1.998433\n",
      "Epoch 108, loss: 1.993176\n",
      "Epoch 109, loss: 1.996043\n",
      "Epoch 110, loss: 1.995986\n",
      "Epoch 111, loss: 1.992305\n",
      "Epoch 112, loss: 1.991192\n",
      "Epoch 113, loss: 1.989209\n",
      "Epoch 114, loss: 1.994290\n",
      "Epoch 115, loss: 1.996130\n",
      "Epoch 116, loss: 1.989223\n",
      "Epoch 117, loss: 1.991516\n",
      "Epoch 118, loss: 1.988264\n",
      "Epoch 119, loss: 1.988763\n",
      "Epoch 120, loss: 1.990084\n",
      "Epoch 121, loss: 1.989174\n",
      "Epoch 122, loss: 1.987207\n",
      "Epoch 123, loss: 1.986180\n",
      "Epoch 124, loss: 1.985217\n",
      "Epoch 125, loss: 1.984259\n",
      "Epoch 126, loss: 1.983264\n",
      "Epoch 127, loss: 1.985627\n",
      "Epoch 128, loss: 1.982674\n",
      "Epoch 129, loss: 1.987234\n",
      "Epoch 130, loss: 1.982947\n",
      "Epoch 131, loss: 1.983534\n",
      "Epoch 132, loss: 1.984004\n",
      "Epoch 133, loss: 1.980334\n",
      "Epoch 134, loss: 1.980419\n",
      "Epoch 135, loss: 1.982587\n",
      "Epoch 136, loss: 1.979855\n",
      "Epoch 137, loss: 1.978634\n",
      "Epoch 138, loss: 1.979754\n",
      "Epoch 139, loss: 1.978765\n",
      "Epoch 140, loss: 1.977694\n",
      "Epoch 141, loss: 1.978237\n",
      "Epoch 142, loss: 1.973026\n",
      "Epoch 143, loss: 1.976544\n",
      "Epoch 144, loss: 1.982082\n",
      "Epoch 145, loss: 1.973208\n",
      "Epoch 146, loss: 1.981638\n",
      "Epoch 147, loss: 1.977209\n",
      "Epoch 148, loss: 1.975165\n",
      "Epoch 149, loss: 1.974055\n",
      "Epoch 150, loss: 1.969636\n",
      "Epoch 151, loss: 1.975084\n",
      "Epoch 152, loss: 1.971722\n",
      "Epoch 153, loss: 1.971753\n",
      "Epoch 154, loss: 1.970066\n",
      "Epoch 155, loss: 1.972224\n",
      "Epoch 156, loss: 1.971209\n",
      "Epoch 157, loss: 1.971011\n",
      "Epoch 158, loss: 1.974047\n",
      "Epoch 159, loss: 1.968800\n",
      "Epoch 160, loss: 1.970451\n",
      "Epoch 161, loss: 1.963449\n",
      "Epoch 162, loss: 1.965878\n",
      "Epoch 163, loss: 1.967471\n",
      "Epoch 164, loss: 1.963821\n",
      "Epoch 165, loss: 1.962227\n",
      "Epoch 166, loss: 1.967896\n",
      "Epoch 167, loss: 1.967603\n",
      "Epoch 168, loss: 1.966877\n",
      "Epoch 169, loss: 1.966332\n",
      "Epoch 170, loss: 1.962329\n",
      "Epoch 171, loss: 1.960173\n",
      "Epoch 172, loss: 1.960962\n",
      "Epoch 173, loss: 1.961702\n",
      "Epoch 174, loss: 1.968485\n",
      "Epoch 175, loss: 1.957544\n",
      "Epoch 176, loss: 1.959312\n",
      "Epoch 177, loss: 1.962646\n",
      "Epoch 178, loss: 1.960970\n",
      "Epoch 179, loss: 1.956777\n",
      "Epoch 180, loss: 1.957930\n",
      "Epoch 181, loss: 1.960790\n",
      "Epoch 182, loss: 1.960954\n",
      "Epoch 183, loss: 1.956953\n",
      "Epoch 184, loss: 1.958925\n",
      "Epoch 185, loss: 1.954324\n",
      "Epoch 186, loss: 1.953218\n",
      "Epoch 187, loss: 1.956212\n",
      "Epoch 188, loss: 1.956869\n",
      "Epoch 189, loss: 1.951934\n",
      "Epoch 190, loss: 1.954168\n",
      "Epoch 191, loss: 1.956354\n",
      "Epoch 192, loss: 1.951822\n",
      "Epoch 193, loss: 1.953482\n",
      "Epoch 194, loss: 1.951225\n",
      "Epoch 195, loss: 1.952325\n",
      "Epoch 196, loss: 1.952608\n",
      "Epoch 197, loss: 1.951487\n",
      "Epoch 198, loss: 1.956358\n",
      "Epoch 199, loss: 1.952239\n",
      "lr: 0.01, rs: 1e-05, accuracy 200 epochs: 0.229\n",
      "Epoch 0, loss: 2.319654\n",
      "Epoch 1, loss: 2.264824\n",
      "Epoch 2, loss: 2.235153\n",
      "Epoch 3, loss: 2.215285\n",
      "Epoch 4, loss: 2.208934\n",
      "Epoch 5, loss: 2.197817\n",
      "Epoch 6, loss: 2.188322\n",
      "Epoch 7, loss: 2.179514\n",
      "Epoch 8, loss: 2.173607\n",
      "Epoch 9, loss: 2.166481\n",
      "Epoch 10, loss: 2.159760\n",
      "Epoch 11, loss: 2.158932\n",
      "Epoch 12, loss: 2.152592\n",
      "Epoch 13, loss: 2.149543\n",
      "Epoch 14, loss: 2.138053\n",
      "Epoch 15, loss: 2.136894\n",
      "Epoch 16, loss: 2.133422\n",
      "Epoch 17, loss: 2.132109\n",
      "Epoch 18, loss: 2.123716\n",
      "Epoch 19, loss: 2.120902\n",
      "Epoch 20, loss: 2.123007\n",
      "Epoch 21, loss: 2.118141\n",
      "Epoch 22, loss: 2.117529\n",
      "Epoch 23, loss: 2.108295\n",
      "Epoch 24, loss: 2.106203\n",
      "Epoch 25, loss: 2.103325\n",
      "Epoch 26, loss: 2.097866\n",
      "Epoch 27, loss: 2.094424\n",
      "Epoch 28, loss: 2.098658\n",
      "Epoch 29, loss: 2.090003\n",
      "Epoch 30, loss: 2.089840\n",
      "Epoch 31, loss: 2.092155\n",
      "Epoch 32, loss: 2.085020\n",
      "Epoch 33, loss: 2.079117\n",
      "Epoch 34, loss: 2.082841\n",
      "Epoch 35, loss: 2.077161\n",
      "Epoch 36, loss: 2.075243\n",
      "Epoch 37, loss: 2.080050\n",
      "Epoch 38, loss: 2.068315\n",
      "Epoch 39, loss: 2.071842\n",
      "Epoch 40, loss: 2.068958\n",
      "Epoch 41, loss: 2.068407\n",
      "Epoch 42, loss: 2.065280\n",
      "Epoch 43, loss: 2.061436\n",
      "Epoch 44, loss: 2.063049\n",
      "Epoch 45, loss: 2.060875\n",
      "Epoch 46, loss: 2.050509\n",
      "Epoch 47, loss: 2.057042\n",
      "Epoch 48, loss: 2.058178\n",
      "Epoch 49, loss: 2.053406\n",
      "Epoch 50, loss: 2.051741\n",
      "Epoch 51, loss: 2.047580\n",
      "Epoch 52, loss: 2.049103\n",
      "Epoch 53, loss: 2.045013\n",
      "Epoch 54, loss: 2.044502\n",
      "Epoch 55, loss: 2.045778\n",
      "Epoch 56, loss: 2.041445\n",
      "Epoch 57, loss: 2.042943\n",
      "Epoch 58, loss: 2.038589\n",
      "Epoch 59, loss: 2.038907\n",
      "Epoch 60, loss: 2.029194\n",
      "Epoch 61, loss: 2.040527\n",
      "Epoch 62, loss: 2.033062\n",
      "Epoch 63, loss: 2.033866\n",
      "Epoch 64, loss: 2.031621\n",
      "Epoch 65, loss: 2.026057\n",
      "Epoch 66, loss: 2.027253\n",
      "Epoch 67, loss: 2.024925\n",
      "Epoch 68, loss: 2.027284\n",
      "Epoch 69, loss: 2.026581\n",
      "Epoch 70, loss: 2.024638\n",
      "Epoch 71, loss: 2.019479\n",
      "Epoch 72, loss: 2.020263\n",
      "Epoch 73, loss: 2.019349\n",
      "Epoch 74, loss: 2.017129\n",
      "Epoch 75, loss: 2.013487\n",
      "Epoch 76, loss: 2.017363\n",
      "Epoch 77, loss: 2.016711\n",
      "Epoch 78, loss: 2.009059\n",
      "Epoch 79, loss: 2.012282\n",
      "Epoch 80, loss: 2.013808\n",
      "Epoch 81, loss: 2.012903\n",
      "Epoch 82, loss: 2.009992\n",
      "Epoch 83, loss: 2.005844\n",
      "Epoch 84, loss: 2.006357\n",
      "Epoch 85, loss: 2.010920\n",
      "Epoch 86, loss: 2.006902\n",
      "Epoch 87, loss: 2.006453\n",
      "Epoch 88, loss: 2.003634\n",
      "Epoch 89, loss: 2.002536\n",
      "Epoch 90, loss: 2.000816\n",
      "Epoch 91, loss: 1.999039\n",
      "Epoch 92, loss: 1.999305\n",
      "Epoch 93, loss: 2.001449\n",
      "Epoch 94, loss: 1.997338\n",
      "Epoch 95, loss: 1.994094\n",
      "Epoch 96, loss: 1.993091\n",
      "Epoch 97, loss: 1.994508\n",
      "Epoch 98, loss: 1.990122\n",
      "Epoch 99, loss: 1.992449\n",
      "Epoch 100, loss: 1.992599\n",
      "Epoch 101, loss: 1.988622\n",
      "Epoch 102, loss: 1.988074\n",
      "Epoch 103, loss: 1.990661\n",
      "Epoch 104, loss: 1.988954\n",
      "Epoch 105, loss: 1.984073\n",
      "Epoch 106, loss: 1.983864\n",
      "Epoch 107, loss: 1.986139\n",
      "Epoch 108, loss: 1.984317\n",
      "Epoch 109, loss: 1.979290\n",
      "Epoch 110, loss: 1.984257\n",
      "Epoch 111, loss: 1.986639\n",
      "Epoch 112, loss: 1.982255\n",
      "Epoch 113, loss: 1.978797\n",
      "Epoch 114, loss: 1.983017\n",
      "Epoch 115, loss: 1.985681\n",
      "Epoch 116, loss: 1.975615\n",
      "Epoch 117, loss: 1.981356\n",
      "Epoch 118, loss: 1.976747\n",
      "Epoch 119, loss: 1.977267\n",
      "Epoch 120, loss: 1.975381\n",
      "Epoch 121, loss: 1.974684\n",
      "Epoch 122, loss: 1.977826\n",
      "Epoch 123, loss: 1.973941\n",
      "Epoch 124, loss: 1.974746\n",
      "Epoch 125, loss: 1.968575\n",
      "Epoch 126, loss: 1.976870\n",
      "Epoch 127, loss: 1.969015\n",
      "Epoch 128, loss: 1.968246\n",
      "Epoch 129, loss: 1.967913\n",
      "Epoch 130, loss: 1.964626\n",
      "Epoch 131, loss: 1.963049\n",
      "Epoch 132, loss: 1.966753\n",
      "Epoch 133, loss: 1.968864\n",
      "Epoch 134, loss: 1.963849\n",
      "Epoch 135, loss: 1.965481\n",
      "Epoch 136, loss: 1.962712\n",
      "Epoch 137, loss: 1.963427\n",
      "Epoch 138, loss: 1.960365\n",
      "Epoch 139, loss: 1.964257\n",
      "Epoch 140, loss: 1.962205\n",
      "Epoch 141, loss: 1.960567\n",
      "Epoch 142, loss: 1.962718\n",
      "Epoch 143, loss: 1.959308\n",
      "Epoch 144, loss: 1.956527\n",
      "Epoch 145, loss: 1.956968\n",
      "Epoch 146, loss: 1.959083\n",
      "Epoch 147, loss: 1.958448\n",
      "Epoch 148, loss: 1.957840\n",
      "Epoch 149, loss: 1.952467\n",
      "Epoch 150, loss: 1.954211\n",
      "Epoch 151, loss: 1.953137\n",
      "Epoch 152, loss: 1.953379\n",
      "Epoch 153, loss: 1.950161\n",
      "Epoch 154, loss: 1.950391\n",
      "Epoch 155, loss: 1.948948\n",
      "Epoch 156, loss: 1.954083\n",
      "Epoch 157, loss: 1.948848\n",
      "Epoch 158, loss: 1.948595\n",
      "Epoch 159, loss: 1.947274\n",
      "Epoch 160, loss: 1.946894\n",
      "Epoch 161, loss: 1.945863\n",
      "Epoch 162, loss: 1.947020\n",
      "Epoch 163, loss: 1.946442\n",
      "Epoch 164, loss: 1.942154\n",
      "Epoch 165, loss: 1.945124\n",
      "Epoch 166, loss: 1.945144\n",
      "Epoch 167, loss: 1.940227\n",
      "Epoch 168, loss: 1.939434\n",
      "Epoch 169, loss: 1.940675\n",
      "Epoch 170, loss: 1.942165\n",
      "Epoch 171, loss: 1.943646\n",
      "Epoch 172, loss: 1.936664\n",
      "Epoch 173, loss: 1.936985\n",
      "Epoch 174, loss: 1.937015\n",
      "Epoch 175, loss: 1.942329\n",
      "Epoch 176, loss: 1.936695\n",
      "Epoch 177, loss: 1.940949\n",
      "Epoch 178, loss: 1.936187\n",
      "Epoch 179, loss: 1.938430\n",
      "Epoch 180, loss: 1.937742\n",
      "Epoch 181, loss: 1.932512\n",
      "Epoch 182, loss: 1.933616\n",
      "Epoch 183, loss: 1.935817\n",
      "Epoch 184, loss: 1.930651\n",
      "Epoch 185, loss: 1.934518\n",
      "Epoch 186, loss: 1.932960\n",
      "Epoch 187, loss: 1.930564\n",
      "Epoch 188, loss: 1.933001\n",
      "Epoch 189, loss: 1.925436\n",
      "Epoch 190, loss: 1.931747\n",
      "Epoch 191, loss: 1.928957\n",
      "Epoch 192, loss: 1.926837\n",
      "Epoch 193, loss: 1.934747\n",
      "Epoch 194, loss: 1.934412\n",
      "Epoch 195, loss: 1.921740\n",
      "Epoch 196, loss: 1.929242\n",
      "Epoch 197, loss: 1.930395\n",
      "Epoch 198, loss: 1.919479\n",
      "Epoch 199, loss: 1.927186\n",
      "lr: 0.01, rs: 1e-06, accuracy 200 epochs: 0.219\n",
      "Epoch 0, loss: 2.289170\n",
      "Epoch 1, loss: 2.272119\n",
      "Epoch 2, loss: 2.271629\n",
      "Epoch 3, loss: 2.271220\n",
      "Epoch 4, loss: 2.272316\n",
      "Epoch 5, loss: 2.269822\n",
      "Epoch 6, loss: 2.271384\n",
      "Epoch 7, loss: 2.270835\n",
      "Epoch 8, loss: 2.271623\n",
      "Epoch 9, loss: 2.271558\n",
      "Epoch 10, loss: 2.270543\n",
      "Epoch 11, loss: 2.271815\n",
      "Epoch 12, loss: 2.270671\n",
      "Epoch 13, loss: 2.271184\n",
      "Epoch 14, loss: 2.271763\n",
      "Epoch 15, loss: 2.270438\n",
      "Epoch 16, loss: 2.270975\n",
      "Epoch 17, loss: 2.270952\n",
      "Epoch 18, loss: 2.270941\n",
      "Epoch 19, loss: 2.272256\n",
      "Epoch 20, loss: 2.271300\n",
      "Epoch 21, loss: 2.270337\n",
      "Epoch 22, loss: 2.271288\n",
      "Epoch 23, loss: 2.270593\n",
      "Epoch 24, loss: 2.271949\n",
      "Epoch 25, loss: 2.270802\n",
      "Epoch 26, loss: 2.270756\n",
      "Epoch 27, loss: 2.271290\n",
      "Epoch 28, loss: 2.270904\n",
      "Epoch 29, loss: 2.271663\n",
      "Epoch 30, loss: 2.271119\n",
      "Epoch 31, loss: 2.272158\n",
      "Epoch 32, loss: 2.271579\n",
      "Epoch 33, loss: 2.270894\n",
      "Epoch 34, loss: 2.271768\n",
      "Epoch 35, loss: 2.270414\n",
      "Epoch 36, loss: 2.272046\n",
      "Epoch 37, loss: 2.271280\n",
      "Epoch 38, loss: 2.271597\n",
      "Epoch 39, loss: 2.270999\n",
      "Epoch 40, loss: 2.270744\n",
      "Epoch 41, loss: 2.271215\n",
      "Epoch 42, loss: 2.270393\n",
      "Epoch 43, loss: 2.270668\n",
      "Epoch 44, loss: 2.270447\n",
      "Epoch 45, loss: 2.270131\n",
      "Epoch 46, loss: 2.271961\n",
      "Epoch 47, loss: 2.272207\n",
      "Epoch 48, loss: 2.270088\n",
      "Epoch 49, loss: 2.271249\n",
      "Epoch 50, loss: 2.270417\n",
      "Epoch 51, loss: 2.270353\n",
      "Epoch 52, loss: 2.271244\n",
      "Epoch 53, loss: 2.271955\n",
      "Epoch 54, loss: 2.271031\n",
      "Epoch 55, loss: 2.269300\n",
      "Epoch 56, loss: 2.271972\n",
      "Epoch 57, loss: 2.271662\n",
      "Epoch 58, loss: 2.270412\n",
      "Epoch 59, loss: 2.272190\n",
      "Epoch 60, loss: 2.271510\n",
      "Epoch 61, loss: 2.270991\n",
      "Epoch 62, loss: 2.272177\n",
      "Epoch 63, loss: 2.272220\n",
      "Epoch 64, loss: 2.270365\n",
      "Epoch 65, loss: 2.270071\n",
      "Epoch 66, loss: 2.270722\n",
      "Epoch 67, loss: 2.271357\n",
      "Epoch 68, loss: 2.270690\n",
      "Epoch 69, loss: 2.269968\n",
      "Epoch 70, loss: 2.271875\n",
      "Epoch 71, loss: 2.271849\n",
      "Epoch 72, loss: 2.270820\n",
      "Epoch 73, loss: 2.271478\n",
      "Epoch 74, loss: 2.271295\n",
      "Epoch 75, loss: 2.271723\n",
      "Epoch 76, loss: 2.271350\n",
      "Epoch 77, loss: 2.272123\n",
      "Epoch 78, loss: 2.271431\n",
      "Epoch 79, loss: 2.270690\n",
      "Epoch 80, loss: 2.270618\n",
      "Epoch 81, loss: 2.270525\n",
      "Epoch 82, loss: 2.270094\n",
      "Epoch 83, loss: 2.271869\n",
      "Epoch 84, loss: 2.271135\n",
      "Epoch 85, loss: 2.271988\n",
      "Epoch 86, loss: 2.271631\n",
      "Epoch 87, loss: 2.271806\n",
      "Epoch 88, loss: 2.270597\n",
      "Epoch 89, loss: 2.271186\n",
      "Epoch 90, loss: 2.271433\n",
      "Epoch 91, loss: 2.270779\n",
      "Epoch 92, loss: 2.272140\n",
      "Epoch 93, loss: 2.271472\n",
      "Epoch 94, loss: 2.269587\n",
      "Epoch 95, loss: 2.271194\n",
      "Epoch 96, loss: 2.270775\n",
      "Epoch 97, loss: 2.270312\n",
      "Epoch 98, loss: 2.272358\n",
      "Epoch 99, loss: 2.270180\n",
      "Epoch 100, loss: 2.271534\n",
      "Epoch 101, loss: 2.271436\n",
      "Epoch 102, loss: 2.270653\n",
      "Epoch 103, loss: 2.269764\n",
      "Epoch 104, loss: 2.270380\n",
      "Epoch 105, loss: 2.270125\n",
      "Epoch 106, loss: 2.271505\n",
      "Epoch 107, loss: 2.271852\n",
      "Epoch 108, loss: 2.270503\n",
      "Epoch 109, loss: 2.270417\n",
      "Epoch 110, loss: 2.270150\n",
      "Epoch 111, loss: 2.272505\n",
      "Epoch 112, loss: 2.271006\n",
      "Epoch 113, loss: 2.270811\n",
      "Epoch 114, loss: 2.269965\n",
      "Epoch 115, loss: 2.270755\n",
      "Epoch 116, loss: 2.271042\n",
      "Epoch 117, loss: 2.271506\n",
      "Epoch 118, loss: 2.271671\n",
      "Epoch 119, loss: 2.270926\n",
      "Epoch 120, loss: 2.269948\n",
      "Epoch 121, loss: 2.270821\n",
      "Epoch 122, loss: 2.271011\n",
      "Epoch 123, loss: 2.271235\n",
      "Epoch 124, loss: 2.271530\n",
      "Epoch 125, loss: 2.271284\n",
      "Epoch 126, loss: 2.270710\n",
      "Epoch 127, loss: 2.269921\n",
      "Epoch 128, loss: 2.269332\n",
      "Epoch 129, loss: 2.270514\n",
      "Epoch 130, loss: 2.272100\n",
      "Epoch 131, loss: 2.270023\n",
      "Epoch 132, loss: 2.271371\n",
      "Epoch 133, loss: 2.270389\n",
      "Epoch 134, loss: 2.271251\n",
      "Epoch 135, loss: 2.270883\n",
      "Epoch 136, loss: 2.271105\n",
      "Epoch 137, loss: 2.271126\n",
      "Epoch 138, loss: 2.271050\n",
      "Epoch 139, loss: 2.270836\n",
      "Epoch 140, loss: 2.270524\n",
      "Epoch 141, loss: 2.271313\n",
      "Epoch 142, loss: 2.269874\n",
      "Epoch 143, loss: 2.269699\n",
      "Epoch 144, loss: 2.271807\n",
      "Epoch 145, loss: 2.270937\n",
      "Epoch 146, loss: 2.271175\n",
      "Epoch 147, loss: 2.270925\n",
      "Epoch 148, loss: 2.271313\n",
      "Epoch 149, loss: 2.272171\n",
      "Epoch 150, loss: 2.270586\n",
      "Epoch 151, loss: 2.271054\n",
      "Epoch 152, loss: 2.270194\n",
      "Epoch 153, loss: 2.270669\n",
      "Epoch 154, loss: 2.270591\n",
      "Epoch 155, loss: 2.270468\n",
      "Epoch 156, loss: 2.271049\n",
      "Epoch 157, loss: 2.269996\n",
      "Epoch 158, loss: 2.271854\n",
      "Epoch 159, loss: 2.268888\n",
      "Epoch 160, loss: 2.272966\n",
      "Epoch 161, loss: 2.270037\n",
      "Epoch 162, loss: 2.271522\n",
      "Epoch 163, loss: 2.270962\n",
      "Epoch 164, loss: 2.271529\n",
      "Epoch 165, loss: 2.271326\n",
      "Epoch 166, loss: 2.270987\n",
      "Epoch 167, loss: 2.270845\n",
      "Epoch 168, loss: 2.270595\n",
      "Epoch 169, loss: 2.270711\n",
      "Epoch 170, loss: 2.269896\n",
      "Epoch 171, loss: 2.271222\n",
      "Epoch 172, loss: 2.270992\n",
      "Epoch 173, loss: 2.272874\n",
      "Epoch 174, loss: 2.271060\n",
      "Epoch 175, loss: 2.271153\n",
      "Epoch 176, loss: 2.270155\n",
      "Epoch 177, loss: 2.270886\n",
      "Epoch 178, loss: 2.270622\n",
      "Epoch 179, loss: 2.271025\n",
      "Epoch 180, loss: 2.270657\n",
      "Epoch 181, loss: 2.271850\n",
      "Epoch 182, loss: 2.269781\n",
      "Epoch 183, loss: 2.271351\n",
      "Epoch 184, loss: 2.271477\n",
      "Epoch 185, loss: 2.270766\n",
      "Epoch 186, loss: 2.270477\n",
      "Epoch 187, loss: 2.271861\n",
      "Epoch 188, loss: 2.272300\n",
      "Epoch 189, loss: 2.271223\n",
      "Epoch 190, loss: 2.271282\n",
      "Epoch 191, loss: 2.270780\n",
      "Epoch 192, loss: 2.270582\n",
      "Epoch 193, loss: 2.270919\n",
      "Epoch 194, loss: 2.271670\n",
      "Epoch 195, loss: 2.271031\n",
      "Epoch 196, loss: 2.271513\n",
      "Epoch 197, loss: 2.271413\n",
      "Epoch 198, loss: 2.271573\n",
      "Epoch 199, loss: 2.271566\n",
      "lr: 0.001, rs: 0.1, accuracy 200 epochs: 0.201\n",
      "Epoch 0, loss: 2.273113\n",
      "Epoch 1, loss: 2.224941\n",
      "Epoch 2, loss: 2.205866\n",
      "Epoch 3, loss: 2.196808\n",
      "Epoch 4, loss: 2.190673\n",
      "Epoch 5, loss: 2.186835\n",
      "Epoch 6, loss: 2.184526\n",
      "Epoch 7, loss: 2.183243\n",
      "Epoch 8, loss: 2.181377\n",
      "Epoch 9, loss: 2.181069\n",
      "Epoch 10, loss: 2.180226\n",
      "Epoch 11, loss: 2.178488\n",
      "Epoch 12, loss: 2.178768\n",
      "Epoch 13, loss: 2.178729\n",
      "Epoch 14, loss: 2.178616\n",
      "Epoch 15, loss: 2.178374\n",
      "Epoch 16, loss: 2.178544\n",
      "Epoch 17, loss: 2.178112\n",
      "Epoch 18, loss: 2.177125\n",
      "Epoch 19, loss: 2.178533\n",
      "Epoch 20, loss: 2.177754\n",
      "Epoch 21, loss: 2.177874\n",
      "Epoch 22, loss: 2.177818\n",
      "Epoch 23, loss: 2.178049\n",
      "Epoch 24, loss: 2.177802\n",
      "Epoch 25, loss: 2.177775\n",
      "Epoch 26, loss: 2.177177\n",
      "Epoch 27, loss: 2.178679\n",
      "Epoch 28, loss: 2.177417\n",
      "Epoch 29, loss: 2.177877\n",
      "Epoch 30, loss: 2.177328\n",
      "Epoch 31, loss: 2.178722\n",
      "Epoch 32, loss: 2.177696\n",
      "Epoch 33, loss: 2.178904\n",
      "Epoch 34, loss: 2.177138\n",
      "Epoch 35, loss: 2.177045\n",
      "Epoch 36, loss: 2.177906\n",
      "Epoch 37, loss: 2.177935\n",
      "Epoch 38, loss: 2.176827\n",
      "Epoch 39, loss: 2.177796\n",
      "Epoch 40, loss: 2.178152\n",
      "Epoch 41, loss: 2.178007\n",
      "Epoch 42, loss: 2.176958\n",
      "Epoch 43, loss: 2.178633\n",
      "Epoch 44, loss: 2.178557\n",
      "Epoch 45, loss: 2.176958\n",
      "Epoch 46, loss: 2.177588\n",
      "Epoch 47, loss: 2.177964\n",
      "Epoch 48, loss: 2.177307\n",
      "Epoch 49, loss: 2.178667\n",
      "Epoch 50, loss: 2.179068\n",
      "Epoch 51, loss: 2.177882\n",
      "Epoch 52, loss: 2.178301\n",
      "Epoch 53, loss: 2.178015\n",
      "Epoch 54, loss: 2.177440\n",
      "Epoch 55, loss: 2.178148\n",
      "Epoch 56, loss: 2.178288\n",
      "Epoch 57, loss: 2.178878\n",
      "Epoch 58, loss: 2.178208\n",
      "Epoch 59, loss: 2.178958\n",
      "Epoch 60, loss: 2.177681\n",
      "Epoch 61, loss: 2.177255\n",
      "Epoch 62, loss: 2.177898\n",
      "Epoch 63, loss: 2.178338\n",
      "Epoch 64, loss: 2.176603\n",
      "Epoch 65, loss: 2.177619\n",
      "Epoch 66, loss: 2.177580\n",
      "Epoch 67, loss: 2.176825\n",
      "Epoch 68, loss: 2.178569\n",
      "Epoch 69, loss: 2.176861\n",
      "Epoch 70, loss: 2.177356\n",
      "Epoch 71, loss: 2.177660\n",
      "Epoch 72, loss: 2.177293\n",
      "Epoch 73, loss: 2.178034\n",
      "Epoch 74, loss: 2.177640\n",
      "Epoch 75, loss: 2.178331\n",
      "Epoch 76, loss: 2.178373\n",
      "Epoch 77, loss: 2.177870\n",
      "Epoch 78, loss: 2.178359\n",
      "Epoch 79, loss: 2.178752\n",
      "Epoch 80, loss: 2.177861\n",
      "Epoch 81, loss: 2.177589\n",
      "Epoch 82, loss: 2.177864\n",
      "Epoch 83, loss: 2.176583\n",
      "Epoch 84, loss: 2.177962\n",
      "Epoch 85, loss: 2.178567\n",
      "Epoch 86, loss: 2.178029\n",
      "Epoch 87, loss: 2.176754\n",
      "Epoch 88, loss: 2.179386\n",
      "Epoch 89, loss: 2.179586\n",
      "Epoch 90, loss: 2.178067\n",
      "Epoch 91, loss: 2.178292\n",
      "Epoch 92, loss: 2.175496\n",
      "Epoch 93, loss: 2.176783\n",
      "Epoch 94, loss: 2.178129\n",
      "Epoch 95, loss: 2.178450\n",
      "Epoch 96, loss: 2.178236\n",
      "Epoch 97, loss: 2.177868\n",
      "Epoch 98, loss: 2.177696\n",
      "Epoch 99, loss: 2.178476\n",
      "Epoch 100, loss: 2.178515\n",
      "Epoch 101, loss: 2.177589\n",
      "Epoch 102, loss: 2.179252\n",
      "Epoch 103, loss: 2.177142\n",
      "Epoch 104, loss: 2.177542\n",
      "Epoch 105, loss: 2.178139\n",
      "Epoch 106, loss: 2.177334\n",
      "Epoch 107, loss: 2.177685\n",
      "Epoch 108, loss: 2.178356\n",
      "Epoch 109, loss: 2.176935\n",
      "Epoch 110, loss: 2.177899\n",
      "Epoch 111, loss: 2.178301\n",
      "Epoch 112, loss: 2.176808\n",
      "Epoch 113, loss: 2.177519\n",
      "Epoch 114, loss: 2.176878\n",
      "Epoch 115, loss: 2.177575\n",
      "Epoch 116, loss: 2.177760\n",
      "Epoch 117, loss: 2.177575\n",
      "Epoch 118, loss: 2.177503\n",
      "Epoch 119, loss: 2.177868\n",
      "Epoch 120, loss: 2.177514\n",
      "Epoch 121, loss: 2.176680\n",
      "Epoch 122, loss: 2.176315\n",
      "Epoch 123, loss: 2.178444\n",
      "Epoch 124, loss: 2.177145\n",
      "Epoch 125, loss: 2.177729\n",
      "Epoch 126, loss: 2.178286\n",
      "Epoch 127, loss: 2.178216\n",
      "Epoch 128, loss: 2.179361\n",
      "Epoch 129, loss: 2.178247\n",
      "Epoch 130, loss: 2.178364\n",
      "Epoch 131, loss: 2.177393\n",
      "Epoch 132, loss: 2.178255\n",
      "Epoch 133, loss: 2.177896\n",
      "Epoch 134, loss: 2.176513\n",
      "Epoch 135, loss: 2.178233\n",
      "Epoch 136, loss: 2.177263\n",
      "Epoch 137, loss: 2.177462\n",
      "Epoch 138, loss: 2.176038\n",
      "Epoch 139, loss: 2.178473\n",
      "Epoch 140, loss: 2.177574\n",
      "Epoch 141, loss: 2.178443\n",
      "Epoch 142, loss: 2.176824\n",
      "Epoch 143, loss: 2.178261\n",
      "Epoch 144, loss: 2.177166\n",
      "Epoch 145, loss: 2.176829\n",
      "Epoch 146, loss: 2.178891\n",
      "Epoch 147, loss: 2.177977\n",
      "Epoch 148, loss: 2.177697\n",
      "Epoch 149, loss: 2.176930\n",
      "Epoch 150, loss: 2.178225\n",
      "Epoch 151, loss: 2.178162\n",
      "Epoch 152, loss: 2.177072\n",
      "Epoch 153, loss: 2.177822\n",
      "Epoch 154, loss: 2.177300\n",
      "Epoch 155, loss: 2.177734\n",
      "Epoch 156, loss: 2.178093\n",
      "Epoch 157, loss: 2.178659\n",
      "Epoch 158, loss: 2.177776\n",
      "Epoch 159, loss: 2.177561\n",
      "Epoch 160, loss: 2.178477\n",
      "Epoch 161, loss: 2.177351\n",
      "Epoch 162, loss: 2.178445\n",
      "Epoch 163, loss: 2.177774\n",
      "Epoch 164, loss: 2.178645\n",
      "Epoch 165, loss: 2.176815\n",
      "Epoch 166, loss: 2.178483\n",
      "Epoch 167, loss: 2.178334\n",
      "Epoch 168, loss: 2.177499\n",
      "Epoch 169, loss: 2.178066\n",
      "Epoch 170, loss: 2.178662\n",
      "Epoch 171, loss: 2.178087\n",
      "Epoch 172, loss: 2.179387\n",
      "Epoch 173, loss: 2.178147\n",
      "Epoch 174, loss: 2.177024\n",
      "Epoch 175, loss: 2.177683\n",
      "Epoch 176, loss: 2.176693\n",
      "Epoch 177, loss: 2.178633\n",
      "Epoch 178, loss: 2.178648\n",
      "Epoch 179, loss: 2.176088\n",
      "Epoch 180, loss: 2.178694\n",
      "Epoch 181, loss: 2.177003\n",
      "Epoch 182, loss: 2.176320\n",
      "Epoch 183, loss: 2.178343\n",
      "Epoch 184, loss: 2.176718\n",
      "Epoch 185, loss: 2.178002\n",
      "Epoch 186, loss: 2.175886\n",
      "Epoch 187, loss: 2.177768\n",
      "Epoch 188, loss: 2.178736\n",
      "Epoch 189, loss: 2.178189\n",
      "Epoch 190, loss: 2.178367\n",
      "Epoch 191, loss: 2.178399\n",
      "Epoch 192, loss: 2.178568\n",
      "Epoch 193, loss: 2.176405\n",
      "Epoch 194, loss: 2.178945\n",
      "Epoch 195, loss: 2.178062\n",
      "Epoch 196, loss: 2.178218\n",
      "Epoch 197, loss: 2.176870\n",
      "Epoch 198, loss: 2.177609\n",
      "Epoch 199, loss: 2.177130\n",
      "lr: 0.001, rs: 0.01, accuracy 200 epochs: 0.248\n",
      "Epoch 0, loss: 2.271318\n",
      "Epoch 1, loss: 2.214761\n",
      "Epoch 2, loss: 2.189025\n",
      "Epoch 3, loss: 2.173463\n",
      "Epoch 4, loss: 2.163931\n",
      "Epoch 5, loss: 2.156934\n",
      "Epoch 6, loss: 2.149908\n",
      "Epoch 7, loss: 2.145330\n",
      "Epoch 8, loss: 2.140555\n",
      "Epoch 9, loss: 2.135921\n",
      "Epoch 10, loss: 2.133370\n",
      "Epoch 11, loss: 2.130588\n",
      "Epoch 12, loss: 2.127263\n",
      "Epoch 13, loss: 2.123998\n",
      "Epoch 14, loss: 2.122985\n",
      "Epoch 15, loss: 2.120571\n",
      "Epoch 16, loss: 2.120080\n",
      "Epoch 17, loss: 2.116878\n",
      "Epoch 18, loss: 2.116120\n",
      "Epoch 19, loss: 2.115332\n",
      "Epoch 20, loss: 2.113217\n",
      "Epoch 21, loss: 2.112394\n",
      "Epoch 22, loss: 2.110370\n",
      "Epoch 23, loss: 2.109074\n",
      "Epoch 24, loss: 2.107357\n",
      "Epoch 25, loss: 2.106211\n",
      "Epoch 26, loss: 2.105604\n",
      "Epoch 27, loss: 2.105415\n",
      "Epoch 28, loss: 2.104555\n",
      "Epoch 29, loss: 2.102345\n",
      "Epoch 30, loss: 2.102903\n",
      "Epoch 31, loss: 2.102316\n",
      "Epoch 32, loss: 2.100730\n",
      "Epoch 33, loss: 2.100611\n",
      "Epoch 34, loss: 2.099325\n",
      "Epoch 35, loss: 2.098503\n",
      "Epoch 36, loss: 2.098220\n",
      "Epoch 37, loss: 2.097653\n",
      "Epoch 38, loss: 2.097002\n",
      "Epoch 39, loss: 2.095784\n",
      "Epoch 40, loss: 2.096771\n",
      "Epoch 41, loss: 2.094954\n",
      "Epoch 42, loss: 2.095015\n",
      "Epoch 43, loss: 2.094254\n",
      "Epoch 44, loss: 2.093580\n",
      "Epoch 45, loss: 2.093387\n",
      "Epoch 46, loss: 2.091970\n",
      "Epoch 47, loss: 2.093224\n",
      "Epoch 48, loss: 2.092067\n",
      "Epoch 49, loss: 2.092145\n",
      "Epoch 50, loss: 2.090843\n",
      "Epoch 51, loss: 2.091189\n",
      "Epoch 52, loss: 2.091178\n",
      "Epoch 53, loss: 2.089555\n",
      "Epoch 54, loss: 2.089667\n",
      "Epoch 55, loss: 2.090614\n",
      "Epoch 56, loss: 2.089833\n",
      "Epoch 57, loss: 2.089183\n",
      "Epoch 58, loss: 2.088589\n",
      "Epoch 59, loss: 2.087617\n",
      "Epoch 60, loss: 2.088027\n",
      "Epoch 61, loss: 2.087914\n",
      "Epoch 62, loss: 2.086986\n",
      "Epoch 63, loss: 2.087984\n",
      "Epoch 64, loss: 2.087701\n",
      "Epoch 65, loss: 2.086251\n",
      "Epoch 66, loss: 2.087517\n",
      "Epoch 67, loss: 2.087291\n",
      "Epoch 68, loss: 2.086021\n",
      "Epoch 69, loss: 2.086048\n",
      "Epoch 70, loss: 2.086107\n",
      "Epoch 71, loss: 2.086053\n",
      "Epoch 72, loss: 2.084403\n",
      "Epoch 73, loss: 2.085979\n",
      "Epoch 74, loss: 2.084646\n",
      "Epoch 75, loss: 2.085678\n",
      "Epoch 76, loss: 2.085024\n",
      "Epoch 77, loss: 2.084915\n",
      "Epoch 78, loss: 2.084597\n",
      "Epoch 79, loss: 2.084023\n",
      "Epoch 80, loss: 2.083749\n",
      "Epoch 81, loss: 2.083299\n",
      "Epoch 82, loss: 2.083045\n",
      "Epoch 83, loss: 2.083472\n",
      "Epoch 84, loss: 2.082994\n",
      "Epoch 85, loss: 2.083172\n",
      "Epoch 86, loss: 2.082686\n",
      "Epoch 87, loss: 2.083311\n",
      "Epoch 88, loss: 2.082691\n",
      "Epoch 89, loss: 2.083442\n",
      "Epoch 90, loss: 2.082333\n",
      "Epoch 91, loss: 2.082195\n",
      "Epoch 92, loss: 2.082445\n",
      "Epoch 93, loss: 2.082657\n",
      "Epoch 94, loss: 2.081181\n",
      "Epoch 95, loss: 2.082352\n",
      "Epoch 96, loss: 2.081760\n",
      "Epoch 97, loss: 2.081917\n",
      "Epoch 98, loss: 2.082015\n",
      "Epoch 99, loss: 2.082445\n",
      "Epoch 100, loss: 2.081915\n",
      "Epoch 101, loss: 2.081389\n",
      "Epoch 102, loss: 2.081654\n",
      "Epoch 103, loss: 2.080717\n",
      "Epoch 104, loss: 2.082255\n",
      "Epoch 105, loss: 2.081926\n",
      "Epoch 106, loss: 2.080601\n",
      "Epoch 107, loss: 2.081446\n",
      "Epoch 108, loss: 2.081164\n",
      "Epoch 109, loss: 2.081627\n",
      "Epoch 110, loss: 2.081422\n",
      "Epoch 111, loss: 2.081538\n",
      "Epoch 112, loss: 2.080476\n",
      "Epoch 113, loss: 2.080556\n",
      "Epoch 114, loss: 2.080102\n",
      "Epoch 115, loss: 2.080695\n",
      "Epoch 116, loss: 2.080227\n",
      "Epoch 117, loss: 2.079146\n",
      "Epoch 118, loss: 2.080654\n",
      "Epoch 119, loss: 2.080535\n",
      "Epoch 120, loss: 2.080110\n",
      "Epoch 121, loss: 2.080001\n",
      "Epoch 122, loss: 2.079269\n",
      "Epoch 123, loss: 2.080985\n",
      "Epoch 124, loss: 2.080930\n",
      "Epoch 125, loss: 2.080673\n",
      "Epoch 126, loss: 2.080400\n",
      "Epoch 127, loss: 2.079076\n",
      "Epoch 128, loss: 2.079235\n",
      "Epoch 129, loss: 2.079393\n",
      "Epoch 130, loss: 2.080149\n",
      "Epoch 131, loss: 2.080000\n",
      "Epoch 132, loss: 2.079400\n",
      "Epoch 133, loss: 2.080641\n",
      "Epoch 134, loss: 2.078142\n",
      "Epoch 135, loss: 2.079633\n",
      "Epoch 136, loss: 2.079544\n",
      "Epoch 137, loss: 2.079172\n",
      "Epoch 138, loss: 2.080637\n",
      "Epoch 139, loss: 2.079461\n",
      "Epoch 140, loss: 2.079924\n",
      "Epoch 141, loss: 2.079541\n",
      "Epoch 142, loss: 2.078952\n",
      "Epoch 143, loss: 2.079473\n",
      "Epoch 144, loss: 2.079853\n",
      "Epoch 145, loss: 2.079175\n",
      "Epoch 146, loss: 2.079904\n",
      "Epoch 147, loss: 2.078991\n",
      "Epoch 148, loss: 2.079403\n",
      "Epoch 149, loss: 2.079413\n",
      "Epoch 150, loss: 2.079603\n",
      "Epoch 151, loss: 2.078555\n",
      "Epoch 152, loss: 2.080158\n",
      "Epoch 153, loss: 2.079572\n",
      "Epoch 154, loss: 2.079926\n",
      "Epoch 155, loss: 2.077275\n",
      "Epoch 156, loss: 2.079293\n",
      "Epoch 157, loss: 2.079369\n",
      "Epoch 158, loss: 2.079243\n",
      "Epoch 159, loss: 2.078696\n",
      "Epoch 160, loss: 2.078846\n",
      "Epoch 161, loss: 2.079703\n",
      "Epoch 162, loss: 2.077674\n",
      "Epoch 163, loss: 2.078643\n",
      "Epoch 164, loss: 2.078350\n",
      "Epoch 165, loss: 2.079455\n",
      "Epoch 166, loss: 2.077932\n",
      "Epoch 167, loss: 2.079372\n",
      "Epoch 168, loss: 2.078023\n",
      "Epoch 169, loss: 2.079023\n",
      "Epoch 170, loss: 2.078493\n",
      "Epoch 171, loss: 2.078202\n",
      "Epoch 172, loss: 2.079639\n",
      "Epoch 173, loss: 2.079443\n",
      "Epoch 174, loss: 2.077339\n",
      "Epoch 175, loss: 2.079867\n",
      "Epoch 176, loss: 2.076245\n",
      "Epoch 177, loss: 2.078227\n",
      "Epoch 178, loss: 2.079916\n",
      "Epoch 179, loss: 2.077497\n",
      "Epoch 180, loss: 2.078373\n",
      "Epoch 181, loss: 2.078810\n",
      "Epoch 182, loss: 2.078599\n",
      "Epoch 183, loss: 2.078628\n",
      "Epoch 184, loss: 2.076421\n",
      "Epoch 185, loss: 2.078279\n",
      "Epoch 186, loss: 2.076564\n",
      "Epoch 187, loss: 2.077398\n",
      "Epoch 188, loss: 2.078718\n",
      "Epoch 189, loss: 2.079066\n",
      "Epoch 190, loss: 2.078953\n",
      "Epoch 191, loss: 2.078846\n",
      "Epoch 192, loss: 2.078523\n",
      "Epoch 193, loss: 2.077953\n",
      "Epoch 194, loss: 2.078076\n",
      "Epoch 195, loss: 2.077789\n",
      "Epoch 196, loss: 2.078598\n",
      "Epoch 197, loss: 2.078811\n",
      "Epoch 198, loss: 2.077532\n",
      "Epoch 199, loss: 2.079571\n",
      "lr: 0.001, rs: 0.001, accuracy 200 epochs: 0.253\n",
      "Epoch 0, loss: 2.270151\n",
      "Epoch 1, loss: 2.214098\n",
      "Epoch 2, loss: 2.187040\n",
      "Epoch 3, loss: 2.172330\n",
      "Epoch 4, loss: 2.160596\n",
      "Epoch 5, loss: 2.151875\n",
      "Epoch 6, loss: 2.146017\n",
      "Epoch 7, loss: 2.140080\n",
      "Epoch 8, loss: 2.133835\n",
      "Epoch 9, loss: 2.128772\n",
      "Epoch 10, loss: 2.126148\n",
      "Epoch 11, loss: 2.122817\n",
      "Epoch 12, loss: 2.119172\n",
      "Epoch 13, loss: 2.115647\n",
      "Epoch 14, loss: 2.114518\n",
      "Epoch 15, loss: 2.111523\n",
      "Epoch 16, loss: 2.109314\n",
      "Epoch 17, loss: 2.105158\n",
      "Epoch 18, loss: 2.105461\n",
      "Epoch 19, loss: 2.101711\n",
      "Epoch 20, loss: 2.100981\n",
      "Epoch 21, loss: 2.097956\n",
      "Epoch 22, loss: 2.096093\n",
      "Epoch 23, loss: 2.093552\n",
      "Epoch 24, loss: 2.092303\n",
      "Epoch 25, loss: 2.092545\n",
      "Epoch 26, loss: 2.089837\n",
      "Epoch 27, loss: 2.089263\n",
      "Epoch 28, loss: 2.087350\n",
      "Epoch 29, loss: 2.085750\n",
      "Epoch 30, loss: 2.083575\n",
      "Epoch 31, loss: 2.083449\n",
      "Epoch 32, loss: 2.082163\n",
      "Epoch 33, loss: 2.079686\n",
      "Epoch 34, loss: 2.079243\n",
      "Epoch 35, loss: 2.077750\n",
      "Epoch 36, loss: 2.076662\n",
      "Epoch 37, loss: 2.076078\n",
      "Epoch 38, loss: 2.075592\n",
      "Epoch 39, loss: 2.074090\n",
      "Epoch 40, loss: 2.073077\n",
      "Epoch 41, loss: 2.071530\n",
      "Epoch 42, loss: 2.070679\n",
      "Epoch 43, loss: 2.069447\n",
      "Epoch 44, loss: 2.068539\n",
      "Epoch 45, loss: 2.068426\n",
      "Epoch 46, loss: 2.068097\n",
      "Epoch 47, loss: 2.066231\n",
      "Epoch 48, loss: 2.065730\n",
      "Epoch 49, loss: 2.064432\n",
      "Epoch 50, loss: 2.063177\n",
      "Epoch 51, loss: 2.062897\n",
      "Epoch 52, loss: 2.062963\n",
      "Epoch 53, loss: 2.061349\n",
      "Epoch 54, loss: 2.060297\n",
      "Epoch 55, loss: 2.059188\n",
      "Epoch 56, loss: 2.059020\n",
      "Epoch 57, loss: 2.059091\n",
      "Epoch 58, loss: 2.057539\n",
      "Epoch 59, loss: 2.055386\n",
      "Epoch 60, loss: 2.057107\n",
      "Epoch 61, loss: 2.054834\n",
      "Epoch 62, loss: 2.053111\n",
      "Epoch 63, loss: 2.053771\n",
      "Epoch 64, loss: 2.053552\n",
      "Epoch 65, loss: 2.053232\n",
      "Epoch 66, loss: 2.050994\n",
      "Epoch 67, loss: 2.050846\n",
      "Epoch 68, loss: 2.049388\n",
      "Epoch 69, loss: 2.048842\n",
      "Epoch 70, loss: 2.049364\n",
      "Epoch 71, loss: 2.049306\n",
      "Epoch 72, loss: 2.045932\n",
      "Epoch 73, loss: 2.047838\n",
      "Epoch 74, loss: 2.047096\n",
      "Epoch 75, loss: 2.044964\n",
      "Epoch 76, loss: 2.045032\n",
      "Epoch 77, loss: 2.045321\n",
      "Epoch 78, loss: 2.044392\n",
      "Epoch 79, loss: 2.043104\n",
      "Epoch 80, loss: 2.043520\n",
      "Epoch 81, loss: 2.041000\n",
      "Epoch 82, loss: 2.042243\n",
      "Epoch 83, loss: 2.041049\n",
      "Epoch 84, loss: 2.040483\n",
      "Epoch 85, loss: 2.040325\n",
      "Epoch 86, loss: 2.038882\n",
      "Epoch 87, loss: 2.038455\n",
      "Epoch 88, loss: 2.039075\n",
      "Epoch 89, loss: 2.037002\n",
      "Epoch 90, loss: 2.037948\n",
      "Epoch 91, loss: 2.037263\n",
      "Epoch 92, loss: 2.035968\n",
      "Epoch 93, loss: 2.036516\n",
      "Epoch 94, loss: 2.035139\n",
      "Epoch 95, loss: 2.035877\n",
      "Epoch 96, loss: 2.034293\n",
      "Epoch 97, loss: 2.034128\n",
      "Epoch 98, loss: 2.031494\n",
      "Epoch 99, loss: 2.033471\n",
      "Epoch 100, loss: 2.032465\n",
      "Epoch 101, loss: 2.032929\n",
      "Epoch 102, loss: 2.032661\n",
      "Epoch 103, loss: 2.030172\n",
      "Epoch 104, loss: 2.030068\n",
      "Epoch 105, loss: 2.030810\n",
      "Epoch 106, loss: 2.029821\n",
      "Epoch 107, loss: 2.029363\n",
      "Epoch 108, loss: 2.028899\n",
      "Epoch 109, loss: 2.029220\n",
      "Epoch 110, loss: 2.029593\n",
      "Epoch 111, loss: 2.027455\n",
      "Epoch 112, loss: 2.027250\n",
      "Epoch 113, loss: 2.026776\n",
      "Epoch 114, loss: 2.026427\n",
      "Epoch 115, loss: 2.025550\n",
      "Epoch 116, loss: 2.025533\n",
      "Epoch 117, loss: 2.026125\n",
      "Epoch 118, loss: 2.024894\n",
      "Epoch 119, loss: 2.024502\n",
      "Epoch 120, loss: 2.024926\n",
      "Epoch 121, loss: 2.023664\n",
      "Epoch 122, loss: 2.022909\n",
      "Epoch 123, loss: 2.023665\n",
      "Epoch 124, loss: 2.023592\n",
      "Epoch 125, loss: 2.022359\n",
      "Epoch 126, loss: 2.022441\n",
      "Epoch 127, loss: 2.021644\n",
      "Epoch 128, loss: 2.019938\n",
      "Epoch 129, loss: 2.020727\n",
      "Epoch 130, loss: 2.019951\n",
      "Epoch 131, loss: 2.020570\n",
      "Epoch 132, loss: 2.020453\n",
      "Epoch 133, loss: 2.018803\n",
      "Epoch 134, loss: 2.019390\n",
      "Epoch 135, loss: 2.018777\n",
      "Epoch 136, loss: 2.018096\n",
      "Epoch 137, loss: 2.018106\n",
      "Epoch 138, loss: 2.018050\n",
      "Epoch 139, loss: 2.017624\n",
      "Epoch 140, loss: 2.017726\n",
      "Epoch 141, loss: 2.016269\n",
      "Epoch 142, loss: 2.016792\n",
      "Epoch 143, loss: 2.015213\n",
      "Epoch 144, loss: 2.016332\n",
      "Epoch 145, loss: 2.015269\n",
      "Epoch 146, loss: 2.015035\n",
      "Epoch 147, loss: 2.014627\n",
      "Epoch 148, loss: 2.014646\n",
      "Epoch 149, loss: 2.014076\n",
      "Epoch 150, loss: 2.013833\n",
      "Epoch 151, loss: 2.012962\n",
      "Epoch 152, loss: 2.013875\n",
      "Epoch 153, loss: 2.013536\n",
      "Epoch 154, loss: 2.012537\n",
      "Epoch 155, loss: 2.012193\n",
      "Epoch 156, loss: 2.012136\n",
      "Epoch 157, loss: 2.012474\n",
      "Epoch 158, loss: 2.010506\n",
      "Epoch 159, loss: 2.012479\n",
      "Epoch 160, loss: 2.010579\n",
      "Epoch 161, loss: 2.009617\n",
      "Epoch 162, loss: 2.011120\n",
      "Epoch 163, loss: 2.009981\n",
      "Epoch 164, loss: 2.010519\n",
      "Epoch 165, loss: 2.009622\n",
      "Epoch 166, loss: 2.008961\n",
      "Epoch 167, loss: 2.009763\n",
      "Epoch 168, loss: 2.008200\n",
      "Epoch 169, loss: 2.008223\n",
      "Epoch 170, loss: 2.008007\n",
      "Epoch 171, loss: 2.007484\n",
      "Epoch 172, loss: 2.007639\n",
      "Epoch 173, loss: 2.007825\n",
      "Epoch 174, loss: 2.007072\n",
      "Epoch 175, loss: 2.007776\n",
      "Epoch 176, loss: 2.004950\n",
      "Epoch 177, loss: 2.004596\n",
      "Epoch 178, loss: 2.006021\n",
      "Epoch 179, loss: 2.005968\n",
      "Epoch 180, loss: 2.004967\n",
      "Epoch 181, loss: 2.005348\n",
      "Epoch 182, loss: 2.005738\n",
      "Epoch 183, loss: 2.004505\n",
      "Epoch 184, loss: 2.005433\n",
      "Epoch 185, loss: 2.004680\n",
      "Epoch 186, loss: 2.003664\n",
      "Epoch 187, loss: 2.002841\n",
      "Epoch 188, loss: 2.004600\n",
      "Epoch 189, loss: 2.003769\n",
      "Epoch 190, loss: 2.003113\n",
      "Epoch 191, loss: 2.003158\n",
      "Epoch 192, loss: 2.004288\n",
      "Epoch 193, loss: 2.002799\n",
      "Epoch 194, loss: 2.003375\n",
      "Epoch 195, loss: 2.002041\n",
      "Epoch 196, loss: 2.001172\n",
      "Epoch 197, loss: 2.000983\n",
      "Epoch 198, loss: 1.998623\n",
      "Epoch 199, loss: 2.000447\n",
      "lr: 0.001, rs: 0.0001, accuracy 200 epochs: 0.242\n",
      "Epoch 0, loss: 2.270742\n",
      "Epoch 1, loss: 2.215361\n",
      "Epoch 2, loss: 2.187710\n",
      "Epoch 3, loss: 2.171490\n",
      "Epoch 4, loss: 2.160348\n",
      "Epoch 5, loss: 2.152229\n",
      "Epoch 6, loss: 2.144897\n",
      "Epoch 7, loss: 2.137814\n",
      "Epoch 8, loss: 2.134476\n",
      "Epoch 9, loss: 2.130436\n",
      "Epoch 10, loss: 2.125314\n",
      "Epoch 11, loss: 2.121612\n",
      "Epoch 12, loss: 2.118823\n",
      "Epoch 13, loss: 2.115150\n",
      "Epoch 14, loss: 2.112415\n",
      "Epoch 15, loss: 2.109651\n",
      "Epoch 16, loss: 2.108118\n",
      "Epoch 17, loss: 2.105174\n",
      "Epoch 18, loss: 2.103013\n",
      "Epoch 19, loss: 2.100544\n",
      "Epoch 20, loss: 2.099342\n",
      "Epoch 21, loss: 2.097087\n",
      "Epoch 22, loss: 2.095627\n",
      "Epoch 23, loss: 2.093789\n",
      "Epoch 24, loss: 2.091669\n",
      "Epoch 25, loss: 2.088588\n",
      "Epoch 26, loss: 2.089192\n",
      "Epoch 27, loss: 2.087160\n",
      "Epoch 28, loss: 2.084308\n",
      "Epoch 29, loss: 2.084190\n",
      "Epoch 30, loss: 2.082282\n",
      "Epoch 31, loss: 2.080392\n",
      "Epoch 32, loss: 2.081055\n",
      "Epoch 33, loss: 2.078196\n",
      "Epoch 34, loss: 2.076627\n",
      "Epoch 35, loss: 2.076636\n",
      "Epoch 36, loss: 2.075455\n",
      "Epoch 37, loss: 2.073789\n",
      "Epoch 38, loss: 2.071591\n",
      "Epoch 39, loss: 2.071702\n",
      "Epoch 40, loss: 2.069957\n",
      "Epoch 41, loss: 2.070171\n",
      "Epoch 42, loss: 2.067338\n",
      "Epoch 43, loss: 2.067752\n",
      "Epoch 44, loss: 2.065657\n",
      "Epoch 45, loss: 2.065489\n",
      "Epoch 46, loss: 2.064262\n",
      "Epoch 47, loss: 2.062385\n",
      "Epoch 48, loss: 2.062633\n",
      "Epoch 49, loss: 2.061221\n",
      "Epoch 50, loss: 2.060423\n",
      "Epoch 51, loss: 2.060039\n",
      "Epoch 52, loss: 2.057901\n",
      "Epoch 53, loss: 2.058115\n",
      "Epoch 54, loss: 2.054885\n",
      "Epoch 55, loss: 2.055380\n",
      "Epoch 56, loss: 2.054719\n",
      "Epoch 57, loss: 2.053784\n",
      "Epoch 58, loss: 2.053776\n",
      "Epoch 59, loss: 2.052745\n",
      "Epoch 60, loss: 2.052213\n",
      "Epoch 61, loss: 2.049972\n",
      "Epoch 62, loss: 2.051160\n",
      "Epoch 63, loss: 2.048756\n",
      "Epoch 64, loss: 2.049218\n",
      "Epoch 65, loss: 2.046762\n",
      "Epoch 66, loss: 2.047205\n",
      "Epoch 67, loss: 2.044573\n",
      "Epoch 68, loss: 2.045744\n",
      "Epoch 69, loss: 2.043646\n",
      "Epoch 70, loss: 2.044201\n",
      "Epoch 71, loss: 2.043040\n",
      "Epoch 72, loss: 2.042625\n",
      "Epoch 73, loss: 2.042210\n",
      "Epoch 74, loss: 2.041333\n",
      "Epoch 75, loss: 2.039640\n",
      "Epoch 76, loss: 2.039707\n",
      "Epoch 77, loss: 2.038836\n",
      "Epoch 78, loss: 2.039038\n",
      "Epoch 79, loss: 2.038135\n",
      "Epoch 80, loss: 2.037188\n",
      "Epoch 81, loss: 2.036303\n",
      "Epoch 82, loss: 2.035898\n",
      "Epoch 83, loss: 2.036032\n",
      "Epoch 84, loss: 2.035401\n",
      "Epoch 85, loss: 2.033970\n",
      "Epoch 86, loss: 2.033244\n",
      "Epoch 87, loss: 2.032782\n",
      "Epoch 88, loss: 2.032782\n",
      "Epoch 89, loss: 2.030728\n",
      "Epoch 90, loss: 2.031137\n",
      "Epoch 91, loss: 2.030875\n",
      "Epoch 92, loss: 2.029770\n",
      "Epoch 93, loss: 2.028961\n",
      "Epoch 94, loss: 2.029296\n",
      "Epoch 95, loss: 2.028625\n",
      "Epoch 96, loss: 2.028055\n",
      "Epoch 97, loss: 2.026338\n",
      "Epoch 98, loss: 2.026562\n",
      "Epoch 99, loss: 2.026347\n",
      "Epoch 100, loss: 2.024072\n",
      "Epoch 101, loss: 2.024551\n",
      "Epoch 102, loss: 2.023720\n",
      "Epoch 103, loss: 2.023234\n",
      "Epoch 104, loss: 2.023111\n",
      "Epoch 105, loss: 2.023631\n",
      "Epoch 106, loss: 2.022447\n",
      "Epoch 107, loss: 2.022013\n",
      "Epoch 108, loss: 2.021463\n",
      "Epoch 109, loss: 2.020050\n",
      "Epoch 110, loss: 2.020682\n",
      "Epoch 111, loss: 2.019319\n",
      "Epoch 112, loss: 2.019722\n",
      "Epoch 113, loss: 2.018686\n",
      "Epoch 114, loss: 2.018521\n",
      "Epoch 115, loss: 2.017788\n",
      "Epoch 116, loss: 2.016447\n",
      "Epoch 117, loss: 2.017254\n",
      "Epoch 118, loss: 2.016884\n",
      "Epoch 119, loss: 2.015359\n",
      "Epoch 120, loss: 2.015148\n",
      "Epoch 121, loss: 2.015278\n",
      "Epoch 122, loss: 2.014228\n",
      "Epoch 123, loss: 2.014657\n",
      "Epoch 124, loss: 2.012601\n",
      "Epoch 125, loss: 2.011066\n",
      "Epoch 126, loss: 2.012015\n",
      "Epoch 127, loss: 2.012079\n",
      "Epoch 128, loss: 2.011703\n",
      "Epoch 129, loss: 2.011861\n",
      "Epoch 130, loss: 2.010476\n",
      "Epoch 131, loss: 2.010621\n",
      "Epoch 132, loss: 2.009090\n",
      "Epoch 133, loss: 2.010134\n",
      "Epoch 134, loss: 2.009531\n",
      "Epoch 135, loss: 2.008725\n",
      "Epoch 136, loss: 2.008416\n",
      "Epoch 137, loss: 2.007512\n",
      "Epoch 138, loss: 2.007738\n",
      "Epoch 139, loss: 2.007840\n",
      "Epoch 140, loss: 2.006871\n",
      "Epoch 141, loss: 2.005306\n",
      "Epoch 142, loss: 2.006292\n",
      "Epoch 143, loss: 2.004736\n",
      "Epoch 144, loss: 2.004146\n",
      "Epoch 145, loss: 2.005317\n",
      "Epoch 146, loss: 2.004084\n",
      "Epoch 147, loss: 2.003586\n",
      "Epoch 148, loss: 2.002599\n",
      "Epoch 149, loss: 2.001144\n",
      "Epoch 150, loss: 2.001637\n",
      "Epoch 151, loss: 2.002510\n",
      "Epoch 152, loss: 2.001499\n",
      "Epoch 153, loss: 2.002050\n",
      "Epoch 154, loss: 2.001053\n",
      "Epoch 155, loss: 2.000513\n",
      "Epoch 156, loss: 1.999544\n",
      "Epoch 157, loss: 1.999168\n",
      "Epoch 158, loss: 1.997905\n",
      "Epoch 159, loss: 1.999451\n",
      "Epoch 160, loss: 1.997821\n",
      "Epoch 161, loss: 1.998075\n",
      "Epoch 162, loss: 1.997805\n",
      "Epoch 163, loss: 1.997380\n",
      "Epoch 164, loss: 1.996952\n",
      "Epoch 165, loss: 1.997145\n",
      "Epoch 166, loss: 1.995750\n",
      "Epoch 167, loss: 1.996473\n",
      "Epoch 168, loss: 1.995849\n",
      "Epoch 169, loss: 1.995560\n",
      "Epoch 170, loss: 1.994033\n",
      "Epoch 171, loss: 1.993981\n",
      "Epoch 172, loss: 1.994147\n",
      "Epoch 173, loss: 1.993922\n",
      "Epoch 174, loss: 1.993821\n",
      "Epoch 175, loss: 1.992227\n",
      "Epoch 176, loss: 1.992471\n",
      "Epoch 177, loss: 1.993210\n",
      "Epoch 178, loss: 1.992404\n",
      "Epoch 179, loss: 1.992450\n",
      "Epoch 180, loss: 1.991174\n",
      "Epoch 181, loss: 1.991472\n",
      "Epoch 182, loss: 1.989687\n",
      "Epoch 183, loss: 1.990615\n",
      "Epoch 184, loss: 1.990821\n",
      "Epoch 185, loss: 1.988194\n",
      "Epoch 186, loss: 1.989807\n",
      "Epoch 187, loss: 1.988672\n",
      "Epoch 188, loss: 1.989521\n",
      "Epoch 189, loss: 1.989882\n",
      "Epoch 190, loss: 1.988710\n",
      "Epoch 191, loss: 1.987945\n",
      "Epoch 192, loss: 1.988277\n",
      "Epoch 193, loss: 1.987393\n",
      "Epoch 194, loss: 1.988348\n",
      "Epoch 195, loss: 1.985365\n",
      "Epoch 196, loss: 1.986394\n",
      "Epoch 197, loss: 1.985581\n",
      "Epoch 198, loss: 1.985561\n",
      "Epoch 199, loss: 1.984795\n",
      "lr: 0.001, rs: 1e-05, accuracy 200 epochs: 0.24\n",
      "Epoch 0, loss: 2.270792\n",
      "Epoch 1, loss: 2.214962\n",
      "Epoch 2, loss: 2.187493\n",
      "Epoch 3, loss: 2.171911\n",
      "Epoch 4, loss: 2.160563\n",
      "Epoch 5, loss: 2.150681\n",
      "Epoch 6, loss: 2.145108\n",
      "Epoch 7, loss: 2.138218\n",
      "Epoch 8, loss: 2.133412\n",
      "Epoch 9, loss: 2.129910\n",
      "Epoch 10, loss: 2.125241\n",
      "Epoch 11, loss: 2.121420\n",
      "Epoch 12, loss: 2.118827\n",
      "Epoch 13, loss: 2.114760\n",
      "Epoch 14, loss: 2.111785\n",
      "Epoch 15, loss: 2.110569\n",
      "Epoch 16, loss: 2.107991\n",
      "Epoch 17, loss: 2.105878\n",
      "Epoch 18, loss: 2.103400\n",
      "Epoch 19, loss: 2.100943\n",
      "Epoch 20, loss: 2.099051\n",
      "Epoch 21, loss: 2.095921\n",
      "Epoch 22, loss: 2.095781\n",
      "Epoch 23, loss: 2.092930\n",
      "Epoch 24, loss: 2.089776\n",
      "Epoch 25, loss: 2.089703\n",
      "Epoch 26, loss: 2.087950\n",
      "Epoch 27, loss: 2.086030\n",
      "Epoch 28, loss: 2.085912\n",
      "Epoch 29, loss: 2.083473\n",
      "Epoch 30, loss: 2.081779\n",
      "Epoch 31, loss: 2.080092\n",
      "Epoch 32, loss: 2.080008\n",
      "Epoch 33, loss: 2.077612\n",
      "Epoch 34, loss: 2.078058\n",
      "Epoch 35, loss: 2.076303\n",
      "Epoch 36, loss: 2.075047\n",
      "Epoch 37, loss: 2.072767\n",
      "Epoch 38, loss: 2.071986\n",
      "Epoch 39, loss: 2.071820\n",
      "Epoch 40, loss: 2.068266\n",
      "Epoch 41, loss: 2.068694\n",
      "Epoch 42, loss: 2.067610\n",
      "Epoch 43, loss: 2.066078\n",
      "Epoch 44, loss: 2.066722\n",
      "Epoch 45, loss: 2.063638\n",
      "Epoch 46, loss: 2.062121\n",
      "Epoch 47, loss: 2.062334\n",
      "Epoch 48, loss: 2.061476\n",
      "Epoch 49, loss: 2.060568\n",
      "Epoch 50, loss: 2.059204\n",
      "Epoch 51, loss: 2.059592\n",
      "Epoch 52, loss: 2.057455\n",
      "Epoch 53, loss: 2.056355\n",
      "Epoch 54, loss: 2.056461\n",
      "Epoch 55, loss: 2.055778\n",
      "Epoch 56, loss: 2.054894\n",
      "Epoch 57, loss: 2.053401\n",
      "Epoch 58, loss: 2.052576\n",
      "Epoch 59, loss: 2.051407\n",
      "Epoch 60, loss: 2.050195\n",
      "Epoch 61, loss: 2.049141\n",
      "Epoch 62, loss: 2.049495\n",
      "Epoch 63, loss: 2.049934\n",
      "Epoch 64, loss: 2.046523\n",
      "Epoch 65, loss: 2.046866\n",
      "Epoch 66, loss: 2.046702\n",
      "Epoch 67, loss: 2.047094\n",
      "Epoch 68, loss: 2.045238\n",
      "Epoch 69, loss: 2.044234\n",
      "Epoch 70, loss: 2.042965\n",
      "Epoch 71, loss: 2.042642\n",
      "Epoch 72, loss: 2.042419\n",
      "Epoch 73, loss: 2.042144\n",
      "Epoch 74, loss: 2.040144\n",
      "Epoch 75, loss: 2.039943\n",
      "Epoch 76, loss: 2.040185\n",
      "Epoch 77, loss: 2.039292\n",
      "Epoch 78, loss: 2.037160\n",
      "Epoch 79, loss: 2.036241\n",
      "Epoch 80, loss: 2.036044\n",
      "Epoch 81, loss: 2.037014\n",
      "Epoch 82, loss: 2.035679\n",
      "Epoch 83, loss: 2.034240\n",
      "Epoch 84, loss: 2.033940\n",
      "Epoch 85, loss: 2.033444\n",
      "Epoch 86, loss: 2.031805\n",
      "Epoch 87, loss: 2.031924\n",
      "Epoch 88, loss: 2.031414\n",
      "Epoch 89, loss: 2.030560\n",
      "Epoch 90, loss: 2.030498\n",
      "Epoch 91, loss: 2.029273\n",
      "Epoch 92, loss: 2.028577\n",
      "Epoch 93, loss: 2.028325\n",
      "Epoch 94, loss: 2.028379\n",
      "Epoch 95, loss: 2.028044\n",
      "Epoch 96, loss: 2.027117\n",
      "Epoch 97, loss: 2.026942\n",
      "Epoch 98, loss: 2.025587\n",
      "Epoch 99, loss: 2.024069\n",
      "Epoch 100, loss: 2.025310\n",
      "Epoch 101, loss: 2.023233\n",
      "Epoch 102, loss: 2.023024\n",
      "Epoch 103, loss: 2.021183\n",
      "Epoch 104, loss: 2.024208\n",
      "Epoch 105, loss: 2.021398\n",
      "Epoch 106, loss: 2.021803\n",
      "Epoch 107, loss: 2.021137\n",
      "Epoch 108, loss: 2.020380\n",
      "Epoch 109, loss: 2.019830\n",
      "Epoch 110, loss: 2.019276\n",
      "Epoch 111, loss: 2.017873\n",
      "Epoch 112, loss: 2.019283\n",
      "Epoch 113, loss: 2.018128\n",
      "Epoch 114, loss: 2.017289\n",
      "Epoch 115, loss: 2.016220\n",
      "Epoch 116, loss: 2.016387\n",
      "Epoch 117, loss: 2.016989\n",
      "Epoch 118, loss: 2.014766\n",
      "Epoch 119, loss: 2.014696\n",
      "Epoch 120, loss: 2.015031\n",
      "Epoch 121, loss: 2.015224\n",
      "Epoch 122, loss: 2.014710\n",
      "Epoch 123, loss: 2.012666\n",
      "Epoch 124, loss: 2.012326\n",
      "Epoch 125, loss: 2.011919\n",
      "Epoch 126, loss: 2.011512\n",
      "Epoch 127, loss: 2.009210\n",
      "Epoch 128, loss: 2.011770\n",
      "Epoch 129, loss: 2.009954\n",
      "Epoch 130, loss: 2.009226\n",
      "Epoch 131, loss: 2.009741\n",
      "Epoch 132, loss: 2.008737\n",
      "Epoch 133, loss: 2.008469\n",
      "Epoch 134, loss: 2.008074\n",
      "Epoch 135, loss: 2.008236\n",
      "Epoch 136, loss: 2.006967\n",
      "Epoch 137, loss: 2.005239\n",
      "Epoch 138, loss: 2.007154\n",
      "Epoch 139, loss: 2.005820\n",
      "Epoch 140, loss: 2.005189\n",
      "Epoch 141, loss: 2.004848\n",
      "Epoch 142, loss: 2.003845\n",
      "Epoch 143, loss: 2.004567\n",
      "Epoch 144, loss: 2.004896\n",
      "Epoch 145, loss: 2.001070\n",
      "Epoch 146, loss: 2.002987\n",
      "Epoch 147, loss: 2.001982\n",
      "Epoch 148, loss: 2.003164\n",
      "Epoch 149, loss: 2.001962\n",
      "Epoch 150, loss: 2.001377\n",
      "Epoch 151, loss: 2.000547\n",
      "Epoch 152, loss: 2.000802\n",
      "Epoch 153, loss: 1.999609\n",
      "Epoch 154, loss: 1.999526\n",
      "Epoch 155, loss: 1.998439\n",
      "Epoch 156, loss: 1.998122\n",
      "Epoch 157, loss: 1.996544\n",
      "Epoch 158, loss: 1.997932\n",
      "Epoch 159, loss: 1.997288\n",
      "Epoch 160, loss: 1.997294\n",
      "Epoch 161, loss: 1.997017\n",
      "Epoch 162, loss: 1.995701\n",
      "Epoch 163, loss: 1.996474\n",
      "Epoch 164, loss: 1.994627\n",
      "Epoch 165, loss: 1.996174\n",
      "Epoch 166, loss: 1.994895\n",
      "Epoch 167, loss: 1.994864\n",
      "Epoch 168, loss: 1.994690\n",
      "Epoch 169, loss: 1.993862\n",
      "Epoch 170, loss: 1.994229\n",
      "Epoch 171, loss: 1.993000\n",
      "Epoch 172, loss: 1.993140\n",
      "Epoch 173, loss: 1.993833\n",
      "Epoch 174, loss: 1.990632\n",
      "Epoch 175, loss: 1.992133\n",
      "Epoch 176, loss: 1.989899\n",
      "Epoch 177, loss: 1.990646\n",
      "Epoch 178, loss: 1.990988\n",
      "Epoch 179, loss: 1.991049\n",
      "Epoch 180, loss: 1.989967\n",
      "Epoch 181, loss: 1.988663\n",
      "Epoch 182, loss: 1.989691\n",
      "Epoch 183, loss: 1.987825\n",
      "Epoch 184, loss: 1.989022\n",
      "Epoch 185, loss: 1.987827\n",
      "Epoch 186, loss: 1.987835\n",
      "Epoch 187, loss: 1.987530\n",
      "Epoch 188, loss: 1.986376\n",
      "Epoch 189, loss: 1.986863\n",
      "Epoch 190, loss: 1.987044\n",
      "Epoch 191, loss: 1.985331\n",
      "Epoch 192, loss: 1.985816\n",
      "Epoch 193, loss: 1.985226\n",
      "Epoch 194, loss: 1.984527\n",
      "Epoch 195, loss: 1.984800\n",
      "Epoch 196, loss: 1.985209\n",
      "Epoch 197, loss: 1.985376\n",
      "Epoch 198, loss: 1.983108\n",
      "Epoch 199, loss: 1.984436\n",
      "lr: 0.001, rs: 1e-06, accuracy 200 epochs: 0.25\n",
      "Epoch 0, loss: 2.300772\n",
      "Epoch 1, loss: 2.290164\n",
      "Epoch 2, loss: 2.282109\n",
      "Epoch 3, loss: 2.276076\n",
      "Epoch 4, loss: 2.271536\n",
      "Epoch 5, loss: 2.268096\n",
      "Epoch 6, loss: 2.265306\n",
      "Epoch 7, loss: 2.263383\n",
      "Epoch 8, loss: 2.261490\n",
      "Epoch 9, loss: 2.260393\n",
      "Epoch 10, loss: 2.259621\n",
      "Epoch 11, loss: 2.258627\n",
      "Epoch 12, loss: 2.258184\n",
      "Epoch 13, loss: 2.257691\n",
      "Epoch 14, loss: 2.257269\n",
      "Epoch 15, loss: 2.257021\n",
      "Epoch 16, loss: 2.256635\n",
      "Epoch 17, loss: 2.256607\n",
      "Epoch 18, loss: 2.256565\n",
      "Epoch 19, loss: 2.256211\n",
      "Epoch 20, loss: 2.256204\n",
      "Epoch 21, loss: 2.256112\n",
      "Epoch 22, loss: 2.256041\n",
      "Epoch 23, loss: 2.255893\n",
      "Epoch 24, loss: 2.255914\n",
      "Epoch 25, loss: 2.256026\n",
      "Epoch 26, loss: 2.255934\n",
      "Epoch 27, loss: 2.256118\n",
      "Epoch 28, loss: 2.255565\n",
      "Epoch 29, loss: 2.256056\n",
      "Epoch 30, loss: 2.255839\n",
      "Epoch 31, loss: 2.256076\n",
      "Epoch 32, loss: 2.255844\n",
      "Epoch 33, loss: 2.255799\n",
      "Epoch 34, loss: 2.255599\n",
      "Epoch 35, loss: 2.255578\n",
      "Epoch 36, loss: 2.255998\n",
      "Epoch 37, loss: 2.255830\n",
      "Epoch 38, loss: 2.255811\n",
      "Epoch 39, loss: 2.255924\n",
      "Epoch 40, loss: 2.255971\n",
      "Epoch 41, loss: 2.255811\n",
      "Epoch 42, loss: 2.255733\n",
      "Epoch 43, loss: 2.255850\n",
      "Epoch 44, loss: 2.255850\n",
      "Epoch 45, loss: 2.255619\n",
      "Epoch 46, loss: 2.255800\n",
      "Epoch 47, loss: 2.255886\n",
      "Epoch 48, loss: 2.255875\n",
      "Epoch 49, loss: 2.255634\n",
      "Epoch 50, loss: 2.256008\n",
      "Epoch 51, loss: 2.255889\n",
      "Epoch 52, loss: 2.255916\n",
      "Epoch 53, loss: 2.255818\n",
      "Epoch 54, loss: 2.255981\n",
      "Epoch 55, loss: 2.255870\n",
      "Epoch 56, loss: 2.255827\n",
      "Epoch 57, loss: 2.255566\n",
      "Epoch 58, loss: 2.255922\n",
      "Epoch 59, loss: 2.255570\n",
      "Epoch 60, loss: 2.256057\n",
      "Epoch 61, loss: 2.255961\n",
      "Epoch 62, loss: 2.255874\n",
      "Epoch 63, loss: 2.255560\n",
      "Epoch 64, loss: 2.255769\n",
      "Epoch 65, loss: 2.256011\n",
      "Epoch 66, loss: 2.255699\n",
      "Epoch 67, loss: 2.255950\n",
      "Epoch 68, loss: 2.256066\n",
      "Epoch 69, loss: 2.255989\n",
      "Epoch 70, loss: 2.255799\n",
      "Epoch 71, loss: 2.255973\n",
      "Epoch 72, loss: 2.255734\n",
      "Epoch 73, loss: 2.255923\n",
      "Epoch 74, loss: 2.255915\n",
      "Epoch 75, loss: 2.255820\n",
      "Epoch 76, loss: 2.255899\n",
      "Epoch 77, loss: 2.255980\n",
      "Epoch 78, loss: 2.255986\n",
      "Epoch 79, loss: 2.256021\n",
      "Epoch 80, loss: 2.255958\n",
      "Epoch 81, loss: 2.255921\n",
      "Epoch 82, loss: 2.255777\n",
      "Epoch 83, loss: 2.255817\n",
      "Epoch 84, loss: 2.255927\n",
      "Epoch 85, loss: 2.256000\n",
      "Epoch 86, loss: 2.255916\n",
      "Epoch 87, loss: 2.255724\n",
      "Epoch 88, loss: 2.255546\n",
      "Epoch 89, loss: 2.255941\n",
      "Epoch 90, loss: 2.255984\n",
      "Epoch 91, loss: 2.255959\n",
      "Epoch 92, loss: 2.255568\n",
      "Epoch 93, loss: 2.256004\n",
      "Epoch 94, loss: 2.255905\n",
      "Epoch 95, loss: 2.255550\n",
      "Epoch 96, loss: 2.256096\n",
      "Epoch 97, loss: 2.255788\n",
      "Epoch 98, loss: 2.255671\n",
      "Epoch 99, loss: 2.255813\n",
      "Epoch 100, loss: 2.256140\n",
      "Epoch 101, loss: 2.255877\n",
      "Epoch 102, loss: 2.255430\n",
      "Epoch 103, loss: 2.256081\n",
      "Epoch 104, loss: 2.255829\n",
      "Epoch 105, loss: 2.255667\n",
      "Epoch 106, loss: 2.255880\n",
      "Epoch 107, loss: 2.255941\n",
      "Epoch 108, loss: 2.255920\n",
      "Epoch 109, loss: 2.255766\n",
      "Epoch 110, loss: 2.255856\n",
      "Epoch 111, loss: 2.255967\n",
      "Epoch 112, loss: 2.255803\n",
      "Epoch 113, loss: 2.256009\n",
      "Epoch 114, loss: 2.255852\n",
      "Epoch 115, loss: 2.255631\n",
      "Epoch 116, loss: 2.255793\n",
      "Epoch 117, loss: 2.255621\n",
      "Epoch 118, loss: 2.256087\n",
      "Epoch 119, loss: 2.255832\n",
      "Epoch 120, loss: 2.255743\n",
      "Epoch 121, loss: 2.255939\n",
      "Epoch 122, loss: 2.255570\n",
      "Epoch 123, loss: 2.255960\n",
      "Epoch 124, loss: 2.255954\n",
      "Epoch 125, loss: 2.255839\n",
      "Epoch 126, loss: 2.255857\n",
      "Epoch 127, loss: 2.255964\n",
      "Epoch 128, loss: 2.255656\n",
      "Epoch 129, loss: 2.255863\n",
      "Epoch 130, loss: 2.255770\n",
      "Epoch 131, loss: 2.255936\n",
      "Epoch 132, loss: 2.255576\n",
      "Epoch 133, loss: 2.255656\n",
      "Epoch 134, loss: 2.256006\n",
      "Epoch 135, loss: 2.255897\n",
      "Epoch 136, loss: 2.255801\n",
      "Epoch 137, loss: 2.255819\n",
      "Epoch 138, loss: 2.256002\n",
      "Epoch 139, loss: 2.255893\n",
      "Epoch 140, loss: 2.255893\n",
      "Epoch 141, loss: 2.255670\n",
      "Epoch 142, loss: 2.256075\n",
      "Epoch 143, loss: 2.255696\n",
      "Epoch 144, loss: 2.255797\n",
      "Epoch 145, loss: 2.256026\n",
      "Epoch 146, loss: 2.255670\n",
      "Epoch 147, loss: 2.255621\n",
      "Epoch 148, loss: 2.255969\n",
      "Epoch 149, loss: 2.256006\n",
      "Epoch 150, loss: 2.255890\n",
      "Epoch 151, loss: 2.255976\n",
      "Epoch 152, loss: 2.255752\n",
      "Epoch 153, loss: 2.255897\n",
      "Epoch 154, loss: 2.255766\n",
      "Epoch 155, loss: 2.255644\n",
      "Epoch 156, loss: 2.255829\n",
      "Epoch 157, loss: 2.255948\n",
      "Epoch 158, loss: 2.255889\n",
      "Epoch 159, loss: 2.255688\n",
      "Epoch 160, loss: 2.255894\n",
      "Epoch 161, loss: 2.255757\n",
      "Epoch 162, loss: 2.255865\n",
      "Epoch 163, loss: 2.255886\n",
      "Epoch 164, loss: 2.256009\n",
      "Epoch 165, loss: 2.255802\n",
      "Epoch 166, loss: 2.255652\n",
      "Epoch 167, loss: 2.255916\n",
      "Epoch 168, loss: 2.255950\n",
      "Epoch 169, loss: 2.255825\n",
      "Epoch 170, loss: 2.255800\n",
      "Epoch 171, loss: 2.255785\n",
      "Epoch 172, loss: 2.255956\n",
      "Epoch 173, loss: 2.255799\n",
      "Epoch 174, loss: 2.255878\n",
      "Epoch 175, loss: 2.255959\n",
      "Epoch 176, loss: 2.255785\n",
      "Epoch 177, loss: 2.255776\n",
      "Epoch 178, loss: 2.255956\n",
      "Epoch 179, loss: 2.255837\n",
      "Epoch 180, loss: 2.255954\n",
      "Epoch 181, loss: 2.255779\n",
      "Epoch 182, loss: 2.255832\n",
      "Epoch 183, loss: 2.255840\n",
      "Epoch 184, loss: 2.255976\n",
      "Epoch 185, loss: 2.255892\n",
      "Epoch 186, loss: 2.255901\n",
      "Epoch 187, loss: 2.255924\n",
      "Epoch 188, loss: 2.256014\n",
      "Epoch 189, loss: 2.255741\n",
      "Epoch 190, loss: 2.255862\n",
      "Epoch 191, loss: 2.255884\n",
      "Epoch 192, loss: 2.255841\n",
      "Epoch 193, loss: 2.255811\n",
      "Epoch 194, loss: 2.255891\n",
      "Epoch 195, loss: 2.255822\n",
      "Epoch 196, loss: 2.255919\n",
      "Epoch 197, loss: 2.255816\n",
      "Epoch 198, loss: 2.255711\n",
      "Epoch 199, loss: 2.255727\n",
      "lr: 0.0001, rs: 0.1, accuracy 200 epochs: 0.238\n",
      "Epoch 0, loss: 2.298204\n",
      "Epoch 1, loss: 2.286483\n",
      "Epoch 2, loss: 2.275990\n",
      "Epoch 3, loss: 2.266613\n",
      "Epoch 4, loss: 2.258319\n",
      "Epoch 5, loss: 2.251056\n",
      "Epoch 6, loss: 2.244451\n",
      "Epoch 7, loss: 2.238538\n",
      "Epoch 8, loss: 2.232939\n",
      "Epoch 9, loss: 2.228290\n",
      "Epoch 10, loss: 2.223776\n",
      "Epoch 11, loss: 2.219803\n",
      "Epoch 12, loss: 2.215976\n",
      "Epoch 13, loss: 2.212386\n",
      "Epoch 14, loss: 2.209914\n",
      "Epoch 15, loss: 2.206949\n",
      "Epoch 16, loss: 2.204474\n",
      "Epoch 17, loss: 2.202124\n",
      "Epoch 18, loss: 2.200043\n",
      "Epoch 19, loss: 2.198141\n",
      "Epoch 20, loss: 2.196225\n",
      "Epoch 21, loss: 2.194596\n",
      "Epoch 22, loss: 2.192996\n",
      "Epoch 23, loss: 2.191290\n",
      "Epoch 24, loss: 2.190273\n",
      "Epoch 25, loss: 2.188802\n",
      "Epoch 26, loss: 2.187715\n",
      "Epoch 27, loss: 2.186623\n",
      "Epoch 28, loss: 2.185634\n",
      "Epoch 29, loss: 2.184478\n",
      "Epoch 30, loss: 2.183785\n",
      "Epoch 31, loss: 2.182715\n",
      "Epoch 32, loss: 2.181729\n",
      "Epoch 33, loss: 2.181454\n",
      "Epoch 34, loss: 2.180513\n",
      "Epoch 35, loss: 2.179678\n",
      "Epoch 36, loss: 2.179368\n",
      "Epoch 37, loss: 2.178606\n",
      "Epoch 38, loss: 2.177998\n",
      "Epoch 39, loss: 2.177365\n",
      "Epoch 40, loss: 2.177032\n",
      "Epoch 41, loss: 2.176363\n",
      "Epoch 42, loss: 2.175881\n",
      "Epoch 43, loss: 2.175272\n",
      "Epoch 44, loss: 2.175140\n",
      "Epoch 45, loss: 2.174575\n",
      "Epoch 46, loss: 2.174113\n",
      "Epoch 47, loss: 2.173670\n",
      "Epoch 48, loss: 2.173662\n",
      "Epoch 49, loss: 2.173072\n",
      "Epoch 50, loss: 2.172612\n",
      "Epoch 51, loss: 2.172464\n",
      "Epoch 52, loss: 2.172079\n",
      "Epoch 53, loss: 2.171661\n",
      "Epoch 54, loss: 2.171292\n",
      "Epoch 55, loss: 2.171398\n",
      "Epoch 56, loss: 2.170471\n",
      "Epoch 57, loss: 2.170719\n",
      "Epoch 58, loss: 2.170521\n",
      "Epoch 59, loss: 2.170145\n",
      "Epoch 60, loss: 2.169897\n",
      "Epoch 61, loss: 2.169822\n",
      "Epoch 62, loss: 2.169688\n",
      "Epoch 63, loss: 2.169078\n",
      "Epoch 64, loss: 2.169257\n",
      "Epoch 65, loss: 2.168941\n",
      "Epoch 66, loss: 2.168723\n",
      "Epoch 67, loss: 2.168651\n",
      "Epoch 68, loss: 2.168327\n",
      "Epoch 69, loss: 2.168399\n",
      "Epoch 70, loss: 2.167970\n",
      "Epoch 71, loss: 2.167956\n",
      "Epoch 72, loss: 2.167696\n",
      "Epoch 73, loss: 2.167706\n",
      "Epoch 74, loss: 2.167503\n",
      "Epoch 75, loss: 2.167331\n",
      "Epoch 76, loss: 2.167155\n",
      "Epoch 77, loss: 2.166931\n",
      "Epoch 78, loss: 2.167051\n",
      "Epoch 79, loss: 2.166515\n",
      "Epoch 80, loss: 2.166756\n",
      "Epoch 81, loss: 2.166719\n",
      "Epoch 82, loss: 2.166489\n",
      "Epoch 83, loss: 2.166248\n",
      "Epoch 84, loss: 2.166164\n",
      "Epoch 85, loss: 2.166223\n",
      "Epoch 86, loss: 2.166241\n",
      "Epoch 87, loss: 2.165885\n",
      "Epoch 88, loss: 2.165830\n",
      "Epoch 89, loss: 2.165788\n",
      "Epoch 90, loss: 2.165803\n",
      "Epoch 91, loss: 2.165806\n",
      "Epoch 92, loss: 2.165424\n",
      "Epoch 93, loss: 2.165290\n",
      "Epoch 94, loss: 2.165350\n",
      "Epoch 95, loss: 2.165226\n",
      "Epoch 96, loss: 2.165241\n",
      "Epoch 97, loss: 2.165105\n",
      "Epoch 98, loss: 2.165057\n",
      "Epoch 99, loss: 2.165137\n",
      "Epoch 100, loss: 2.165146\n",
      "Epoch 101, loss: 2.164982\n",
      "Epoch 102, loss: 2.164783\n",
      "Epoch 103, loss: 2.164513\n",
      "Epoch 104, loss: 2.164734\n",
      "Epoch 105, loss: 2.164694\n",
      "Epoch 106, loss: 2.164550\n",
      "Epoch 107, loss: 2.164762\n",
      "Epoch 108, loss: 2.164453\n",
      "Epoch 109, loss: 2.164530\n",
      "Epoch 110, loss: 2.164387\n",
      "Epoch 111, loss: 2.164333\n",
      "Epoch 112, loss: 2.164236\n",
      "Epoch 113, loss: 2.164446\n",
      "Epoch 114, loss: 2.164341\n",
      "Epoch 115, loss: 2.164167\n",
      "Epoch 116, loss: 2.164191\n",
      "Epoch 117, loss: 2.164122\n",
      "Epoch 118, loss: 2.164252\n",
      "Epoch 119, loss: 2.163565\n",
      "Epoch 120, loss: 2.164193\n",
      "Epoch 121, loss: 2.164025\n",
      "Epoch 122, loss: 2.163775\n",
      "Epoch 123, loss: 2.163973\n",
      "Epoch 124, loss: 2.163826\n",
      "Epoch 125, loss: 2.163866\n",
      "Epoch 126, loss: 2.163804\n",
      "Epoch 127, loss: 2.163921\n",
      "Epoch 128, loss: 2.163576\n",
      "Epoch 129, loss: 2.163899\n",
      "Epoch 130, loss: 2.163693\n",
      "Epoch 131, loss: 2.163760\n",
      "Epoch 132, loss: 2.163643\n",
      "Epoch 133, loss: 2.163592\n",
      "Epoch 134, loss: 2.163652\n",
      "Epoch 135, loss: 2.163550\n",
      "Epoch 136, loss: 2.163582\n",
      "Epoch 137, loss: 2.163568\n",
      "Epoch 138, loss: 2.163356\n",
      "Epoch 139, loss: 2.163536\n",
      "Epoch 140, loss: 2.163272\n",
      "Epoch 141, loss: 2.163540\n",
      "Epoch 142, loss: 2.163275\n",
      "Epoch 143, loss: 2.163323\n",
      "Epoch 144, loss: 2.163497\n",
      "Epoch 145, loss: 2.163339\n",
      "Epoch 146, loss: 2.163117\n",
      "Epoch 147, loss: 2.163331\n",
      "Epoch 148, loss: 2.163253\n",
      "Epoch 149, loss: 2.163009\n",
      "Epoch 150, loss: 2.163107\n",
      "Epoch 151, loss: 2.163242\n",
      "Epoch 152, loss: 2.163216\n",
      "Epoch 153, loss: 2.162981\n",
      "Epoch 154, loss: 2.163241\n",
      "Epoch 155, loss: 2.163185\n",
      "Epoch 156, loss: 2.162893\n",
      "Epoch 157, loss: 2.163291\n",
      "Epoch 158, loss: 2.162975\n",
      "Epoch 159, loss: 2.162997\n",
      "Epoch 160, loss: 2.163100\n",
      "Epoch 161, loss: 2.163121\n",
      "Epoch 162, loss: 2.162948\n",
      "Epoch 163, loss: 2.162964\n",
      "Epoch 164, loss: 2.163031\n",
      "Epoch 165, loss: 2.162985\n",
      "Epoch 166, loss: 2.163040\n",
      "Epoch 167, loss: 2.162882\n",
      "Epoch 168, loss: 2.162965\n",
      "Epoch 169, loss: 2.162753\n",
      "Epoch 170, loss: 2.163086\n",
      "Epoch 171, loss: 2.162884\n",
      "Epoch 172, loss: 2.162879\n",
      "Epoch 173, loss: 2.162886\n",
      "Epoch 174, loss: 2.162862\n",
      "Epoch 175, loss: 2.162603\n",
      "Epoch 176, loss: 2.162913\n",
      "Epoch 177, loss: 2.162809\n",
      "Epoch 178, loss: 2.162847\n",
      "Epoch 179, loss: 2.162515\n",
      "Epoch 180, loss: 2.162970\n",
      "Epoch 181, loss: 2.162766\n",
      "Epoch 182, loss: 2.162501\n",
      "Epoch 183, loss: 2.162889\n",
      "Epoch 184, loss: 2.162709\n",
      "Epoch 185, loss: 2.162862\n",
      "Epoch 186, loss: 2.162932\n",
      "Epoch 187, loss: 2.162841\n",
      "Epoch 188, loss: 2.162722\n",
      "Epoch 189, loss: 2.162715\n",
      "Epoch 190, loss: 2.162658\n",
      "Epoch 191, loss: 2.162841\n",
      "Epoch 192, loss: 2.162779\n",
      "Epoch 193, loss: 2.162739\n",
      "Epoch 194, loss: 2.162746\n",
      "Epoch 195, loss: 2.162835\n",
      "Epoch 196, loss: 2.162793\n",
      "Epoch 197, loss: 2.162685\n",
      "Epoch 198, loss: 2.162844\n",
      "Epoch 199, loss: 2.162503\n",
      "lr: 0.0001, rs: 0.01, accuracy 200 epochs: 0.242\n",
      "Epoch 0, loss: 2.297660\n",
      "Epoch 1, loss: 2.285634\n",
      "Epoch 2, loss: 2.274493\n",
      "Epoch 3, loss: 2.264935\n",
      "Epoch 4, loss: 2.256505\n",
      "Epoch 5, loss: 2.248167\n",
      "Epoch 6, loss: 2.240886\n",
      "Epoch 7, loss: 2.234442\n",
      "Epoch 8, loss: 2.228087\n",
      "Epoch 9, loss: 2.222860\n",
      "Epoch 10, loss: 2.217375\n",
      "Epoch 11, loss: 2.212691\n",
      "Epoch 12, loss: 2.208439\n",
      "Epoch 13, loss: 2.204222\n",
      "Epoch 14, loss: 2.200384\n",
      "Epoch 15, loss: 2.196816\n",
      "Epoch 16, loss: 2.193831\n",
      "Epoch 17, loss: 2.190712\n",
      "Epoch 18, loss: 2.187865\n",
      "Epoch 19, loss: 2.185167\n",
      "Epoch 20, loss: 2.182431\n",
      "Epoch 21, loss: 2.180165\n",
      "Epoch 22, loss: 2.178148\n",
      "Epoch 23, loss: 2.176067\n",
      "Epoch 24, loss: 2.174187\n",
      "Epoch 25, loss: 2.172232\n",
      "Epoch 26, loss: 2.170346\n",
      "Epoch 27, loss: 2.168435\n",
      "Epoch 28, loss: 2.167031\n",
      "Epoch 29, loss: 2.165375\n",
      "Epoch 30, loss: 2.164032\n",
      "Epoch 31, loss: 2.162668\n",
      "Epoch 32, loss: 2.161262\n",
      "Epoch 33, loss: 2.160055\n",
      "Epoch 34, loss: 2.158776\n",
      "Epoch 35, loss: 2.157561\n",
      "Epoch 36, loss: 2.156560\n",
      "Epoch 37, loss: 2.155215\n",
      "Epoch 38, loss: 2.154466\n",
      "Epoch 39, loss: 2.153077\n",
      "Epoch 40, loss: 2.152311\n",
      "Epoch 41, loss: 2.150935\n",
      "Epoch 42, loss: 2.150503\n",
      "Epoch 43, loss: 2.149370\n",
      "Epoch 44, loss: 2.148516\n",
      "Epoch 45, loss: 2.147662\n",
      "Epoch 46, loss: 2.146889\n",
      "Epoch 47, loss: 2.145926\n",
      "Epoch 48, loss: 2.145207\n",
      "Epoch 49, loss: 2.144342\n",
      "Epoch 50, loss: 2.143739\n",
      "Epoch 51, loss: 2.142794\n",
      "Epoch 52, loss: 2.142041\n",
      "Epoch 53, loss: 2.141533\n",
      "Epoch 54, loss: 2.140603\n",
      "Epoch 55, loss: 2.140125\n",
      "Epoch 56, loss: 2.139377\n",
      "Epoch 57, loss: 2.138871\n",
      "Epoch 58, loss: 2.138062\n",
      "Epoch 59, loss: 2.137649\n",
      "Epoch 60, loss: 2.136660\n",
      "Epoch 61, loss: 2.136340\n",
      "Epoch 62, loss: 2.135660\n",
      "Epoch 63, loss: 2.135100\n",
      "Epoch 64, loss: 2.134515\n",
      "Epoch 65, loss: 2.134076\n",
      "Epoch 66, loss: 2.133517\n",
      "Epoch 67, loss: 2.132529\n",
      "Epoch 68, loss: 2.132484\n",
      "Epoch 69, loss: 2.131667\n",
      "Epoch 70, loss: 2.131290\n",
      "Epoch 71, loss: 2.130769\n",
      "Epoch 72, loss: 2.130483\n",
      "Epoch 73, loss: 2.129760\n",
      "Epoch 74, loss: 2.129454\n",
      "Epoch 75, loss: 2.129025\n",
      "Epoch 76, loss: 2.128453\n",
      "Epoch 77, loss: 2.128056\n",
      "Epoch 78, loss: 2.127638\n",
      "Epoch 79, loss: 2.126954\n",
      "Epoch 80, loss: 2.126600\n",
      "Epoch 81, loss: 2.126305\n",
      "Epoch 82, loss: 2.126034\n",
      "Epoch 83, loss: 2.125425\n",
      "Epoch 84, loss: 2.124863\n",
      "Epoch 85, loss: 2.124699\n",
      "Epoch 86, loss: 2.124190\n",
      "Epoch 87, loss: 2.123771\n",
      "Epoch 88, loss: 2.123400\n",
      "Epoch 89, loss: 2.123146\n",
      "Epoch 90, loss: 2.122771\n",
      "Epoch 91, loss: 2.122419\n",
      "Epoch 92, loss: 2.122042\n",
      "Epoch 93, loss: 2.121533\n",
      "Epoch 94, loss: 2.121222\n",
      "Epoch 95, loss: 2.120862\n",
      "Epoch 96, loss: 2.120569\n",
      "Epoch 97, loss: 2.120120\n",
      "Epoch 98, loss: 2.119814\n",
      "Epoch 99, loss: 2.119665\n",
      "Epoch 100, loss: 2.119236\n",
      "Epoch 101, loss: 2.118940\n",
      "Epoch 102, loss: 2.118581\n",
      "Epoch 103, loss: 2.118197\n",
      "Epoch 104, loss: 2.117979\n",
      "Epoch 105, loss: 2.117719\n",
      "Epoch 106, loss: 2.117205\n",
      "Epoch 107, loss: 2.116845\n",
      "Epoch 108, loss: 2.116505\n",
      "Epoch 109, loss: 2.116432\n",
      "Epoch 110, loss: 2.116084\n",
      "Epoch 111, loss: 2.115822\n",
      "Epoch 112, loss: 2.115716\n",
      "Epoch 113, loss: 2.115338\n",
      "Epoch 114, loss: 2.114978\n",
      "Epoch 115, loss: 2.114502\n",
      "Epoch 116, loss: 2.114543\n",
      "Epoch 117, loss: 2.114249\n",
      "Epoch 118, loss: 2.113732\n",
      "Epoch 119, loss: 2.113527\n",
      "Epoch 120, loss: 2.113523\n",
      "Epoch 121, loss: 2.113081\n",
      "Epoch 122, loss: 2.113023\n",
      "Epoch 123, loss: 2.112584\n",
      "Epoch 124, loss: 2.112136\n",
      "Epoch 125, loss: 2.112333\n",
      "Epoch 126, loss: 2.111836\n",
      "Epoch 127, loss: 2.111728\n",
      "Epoch 128, loss: 2.111369\n",
      "Epoch 129, loss: 2.111205\n",
      "Epoch 130, loss: 2.110759\n",
      "Epoch 131, loss: 2.110689\n",
      "Epoch 132, loss: 2.110409\n",
      "Epoch 133, loss: 2.110195\n",
      "Epoch 134, loss: 2.110083\n",
      "Epoch 135, loss: 2.109770\n",
      "Epoch 136, loss: 2.109351\n",
      "Epoch 137, loss: 2.109133\n",
      "Epoch 138, loss: 2.109045\n",
      "Epoch 139, loss: 2.108810\n",
      "Epoch 140, loss: 2.108603\n",
      "Epoch 141, loss: 2.108625\n",
      "Epoch 142, loss: 2.108075\n",
      "Epoch 143, loss: 2.107971\n",
      "Epoch 144, loss: 2.107679\n",
      "Epoch 145, loss: 2.107512\n",
      "Epoch 146, loss: 2.107234\n",
      "Epoch 147, loss: 2.107230\n",
      "Epoch 148, loss: 2.106913\n",
      "Epoch 149, loss: 2.106723\n",
      "Epoch 150, loss: 2.106515\n",
      "Epoch 151, loss: 2.106451\n",
      "Epoch 152, loss: 2.106088\n",
      "Epoch 153, loss: 2.105931\n",
      "Epoch 154, loss: 2.105611\n",
      "Epoch 155, loss: 2.105501\n",
      "Epoch 156, loss: 2.105392\n",
      "Epoch 157, loss: 2.105110\n",
      "Epoch 158, loss: 2.104862\n",
      "Epoch 159, loss: 2.104940\n",
      "Epoch 160, loss: 2.104742\n",
      "Epoch 161, loss: 2.104387\n",
      "Epoch 162, loss: 2.104153\n",
      "Epoch 163, loss: 2.104221\n",
      "Epoch 164, loss: 2.103864\n",
      "Epoch 165, loss: 2.103790\n",
      "Epoch 166, loss: 2.103626\n",
      "Epoch 167, loss: 2.103306\n",
      "Epoch 168, loss: 2.103127\n",
      "Epoch 169, loss: 2.102977\n",
      "Epoch 170, loss: 2.102882\n",
      "Epoch 171, loss: 2.102625\n",
      "Epoch 172, loss: 2.102256\n",
      "Epoch 173, loss: 2.102304\n",
      "Epoch 174, loss: 2.102246\n",
      "Epoch 175, loss: 2.102053\n",
      "Epoch 176, loss: 2.101821\n",
      "Epoch 177, loss: 2.101737\n",
      "Epoch 178, loss: 2.101603\n",
      "Epoch 179, loss: 2.101391\n",
      "Epoch 180, loss: 2.101143\n",
      "Epoch 181, loss: 2.101149\n",
      "Epoch 182, loss: 2.100819\n",
      "Epoch 183, loss: 2.100634\n",
      "Epoch 184, loss: 2.100576\n",
      "Epoch 185, loss: 2.100335\n",
      "Epoch 186, loss: 2.099956\n",
      "Epoch 187, loss: 2.100023\n",
      "Epoch 188, loss: 2.100136\n",
      "Epoch 189, loss: 2.099707\n",
      "Epoch 190, loss: 2.099621\n",
      "Epoch 191, loss: 2.099590\n",
      "Epoch 192, loss: 2.099318\n",
      "Epoch 193, loss: 2.099269\n",
      "Epoch 194, loss: 2.099164\n",
      "Epoch 195, loss: 2.098874\n",
      "Epoch 196, loss: 2.098965\n",
      "Epoch 197, loss: 2.098700\n",
      "Epoch 198, loss: 2.098545\n",
      "Epoch 199, loss: 2.098346\n",
      "lr: 0.0001, rs: 0.001, accuracy 200 epochs: 0.243\n",
      "Epoch 0, loss: 2.298025\n",
      "Epoch 1, loss: 2.285432\n",
      "Epoch 2, loss: 2.274877\n",
      "Epoch 3, loss: 2.265171\n",
      "Epoch 4, loss: 2.255905\n",
      "Epoch 5, loss: 2.248409\n",
      "Epoch 6, loss: 2.240987\n",
      "Epoch 7, loss: 2.234088\n",
      "Epoch 8, loss: 2.227821\n",
      "Epoch 9, loss: 2.222281\n",
      "Epoch 10, loss: 2.217046\n",
      "Epoch 11, loss: 2.211989\n",
      "Epoch 12, loss: 2.207580\n",
      "Epoch 13, loss: 2.203441\n",
      "Epoch 14, loss: 2.199691\n",
      "Epoch 15, loss: 2.196019\n",
      "Epoch 16, loss: 2.192560\n",
      "Epoch 17, loss: 2.189378\n",
      "Epoch 18, loss: 2.186809\n",
      "Epoch 19, loss: 2.183749\n",
      "Epoch 20, loss: 2.181257\n",
      "Epoch 21, loss: 2.178562\n",
      "Epoch 22, loss: 2.176470\n",
      "Epoch 23, loss: 2.174502\n",
      "Epoch 24, loss: 2.172296\n",
      "Epoch 25, loss: 2.170421\n",
      "Epoch 26, loss: 2.168651\n",
      "Epoch 27, loss: 2.166633\n",
      "Epoch 28, loss: 2.165249\n",
      "Epoch 29, loss: 2.163407\n",
      "Epoch 30, loss: 2.161692\n",
      "Epoch 31, loss: 2.160339\n",
      "Epoch 32, loss: 2.159071\n",
      "Epoch 33, loss: 2.157601\n",
      "Epoch 34, loss: 2.156418\n",
      "Epoch 35, loss: 2.155054\n",
      "Epoch 36, loss: 2.154043\n",
      "Epoch 37, loss: 2.152766\n",
      "Epoch 38, loss: 2.151415\n",
      "Epoch 39, loss: 2.150492\n",
      "Epoch 40, loss: 2.149363\n",
      "Epoch 41, loss: 2.148188\n",
      "Epoch 42, loss: 2.147319\n",
      "Epoch 43, loss: 2.146383\n",
      "Epoch 44, loss: 2.145316\n",
      "Epoch 45, loss: 2.144354\n",
      "Epoch 46, loss: 2.143550\n",
      "Epoch 47, loss: 2.142431\n",
      "Epoch 48, loss: 2.141628\n",
      "Epoch 49, loss: 2.140763\n",
      "Epoch 50, loss: 2.139947\n",
      "Epoch 51, loss: 2.139266\n",
      "Epoch 52, loss: 2.138395\n",
      "Epoch 53, loss: 2.137784\n",
      "Epoch 54, loss: 2.136896\n",
      "Epoch 55, loss: 2.136232\n",
      "Epoch 56, loss: 2.135490\n",
      "Epoch 57, loss: 2.134694\n",
      "Epoch 58, loss: 2.134014\n",
      "Epoch 59, loss: 2.133381\n",
      "Epoch 60, loss: 2.132692\n",
      "Epoch 61, loss: 2.132218\n",
      "Epoch 62, loss: 2.131439\n",
      "Epoch 63, loss: 2.130651\n",
      "Epoch 64, loss: 2.130135\n",
      "Epoch 65, loss: 2.129351\n",
      "Epoch 66, loss: 2.128958\n",
      "Epoch 67, loss: 2.128123\n",
      "Epoch 68, loss: 2.127551\n",
      "Epoch 69, loss: 2.126917\n",
      "Epoch 70, loss: 2.126620\n",
      "Epoch 71, loss: 2.125914\n",
      "Epoch 72, loss: 2.125524\n",
      "Epoch 73, loss: 2.124981\n",
      "Epoch 74, loss: 2.123868\n",
      "Epoch 75, loss: 2.123867\n",
      "Epoch 76, loss: 2.123121\n",
      "Epoch 77, loss: 2.122753\n",
      "Epoch 78, loss: 2.122205\n",
      "Epoch 79, loss: 2.121589\n",
      "Epoch 80, loss: 2.121221\n",
      "Epoch 81, loss: 2.120720\n",
      "Epoch 82, loss: 2.120216\n",
      "Epoch 83, loss: 2.119945\n",
      "Epoch 84, loss: 2.119433\n",
      "Epoch 85, loss: 2.118922\n",
      "Epoch 86, loss: 2.118568\n",
      "Epoch 87, loss: 2.117929\n",
      "Epoch 88, loss: 2.117523\n",
      "Epoch 89, loss: 2.117241\n",
      "Epoch 90, loss: 2.116701\n",
      "Epoch 91, loss: 2.116265\n",
      "Epoch 92, loss: 2.115908\n",
      "Epoch 93, loss: 2.115382\n",
      "Epoch 94, loss: 2.114938\n",
      "Epoch 95, loss: 2.114568\n",
      "Epoch 96, loss: 2.114139\n",
      "Epoch 97, loss: 2.113617\n",
      "Epoch 98, loss: 2.112929\n",
      "Epoch 99, loss: 2.112695\n",
      "Epoch 100, loss: 2.112651\n",
      "Epoch 101, loss: 2.112124\n",
      "Epoch 102, loss: 2.111731\n",
      "Epoch 103, loss: 2.111507\n",
      "Epoch 104, loss: 2.110846\n",
      "Epoch 105, loss: 2.110752\n",
      "Epoch 106, loss: 2.110429\n",
      "Epoch 107, loss: 2.109833\n",
      "Epoch 108, loss: 2.109686\n",
      "Epoch 109, loss: 2.109172\n",
      "Epoch 110, loss: 2.108690\n",
      "Epoch 111, loss: 2.108627\n",
      "Epoch 112, loss: 2.107980\n",
      "Epoch 113, loss: 2.107963\n",
      "Epoch 114, loss: 2.107667\n",
      "Epoch 115, loss: 2.107125\n",
      "Epoch 116, loss: 2.106730\n",
      "Epoch 117, loss: 2.106600\n",
      "Epoch 118, loss: 2.106221\n",
      "Epoch 119, loss: 2.105887\n",
      "Epoch 120, loss: 2.105604\n",
      "Epoch 121, loss: 2.105314\n",
      "Epoch 122, loss: 2.104912\n",
      "Epoch 123, loss: 2.104620\n",
      "Epoch 124, loss: 2.104325\n",
      "Epoch 125, loss: 2.104120\n",
      "Epoch 126, loss: 2.103569\n",
      "Epoch 127, loss: 2.103578\n",
      "Epoch 128, loss: 2.102812\n",
      "Epoch 129, loss: 2.102881\n",
      "Epoch 130, loss: 2.102420\n",
      "Epoch 131, loss: 2.102280\n",
      "Epoch 132, loss: 2.101637\n",
      "Epoch 133, loss: 2.101804\n",
      "Epoch 134, loss: 2.101296\n",
      "Epoch 135, loss: 2.101042\n",
      "Epoch 136, loss: 2.100746\n",
      "Epoch 137, loss: 2.100413\n",
      "Epoch 138, loss: 2.100201\n",
      "Epoch 139, loss: 2.099881\n",
      "Epoch 140, loss: 2.099539\n",
      "Epoch 141, loss: 2.099277\n",
      "Epoch 142, loss: 2.098831\n",
      "Epoch 143, loss: 2.098682\n",
      "Epoch 144, loss: 2.098711\n",
      "Epoch 145, loss: 2.098304\n",
      "Epoch 146, loss: 2.097949\n",
      "Epoch 147, loss: 2.097545\n",
      "Epoch 148, loss: 2.097692\n",
      "Epoch 149, loss: 2.097301\n",
      "Epoch 150, loss: 2.096972\n",
      "Epoch 151, loss: 2.096608\n",
      "Epoch 152, loss: 2.096443\n",
      "Epoch 153, loss: 2.096135\n",
      "Epoch 154, loss: 2.095900\n",
      "Epoch 155, loss: 2.095639\n",
      "Epoch 156, loss: 2.095528\n",
      "Epoch 157, loss: 2.095289\n",
      "Epoch 158, loss: 2.094906\n",
      "Epoch 159, loss: 2.094820\n",
      "Epoch 160, loss: 2.094432\n",
      "Epoch 161, loss: 2.094150\n",
      "Epoch 162, loss: 2.094020\n",
      "Epoch 163, loss: 2.093714\n",
      "Epoch 164, loss: 2.093619\n",
      "Epoch 165, loss: 2.093405\n",
      "Epoch 166, loss: 2.093065\n",
      "Epoch 167, loss: 2.092932\n",
      "Epoch 168, loss: 2.092764\n",
      "Epoch 169, loss: 2.092230\n",
      "Epoch 170, loss: 2.092201\n",
      "Epoch 171, loss: 2.091984\n",
      "Epoch 172, loss: 2.091823\n",
      "Epoch 173, loss: 2.091556\n",
      "Epoch 174, loss: 2.091451\n",
      "Epoch 175, loss: 2.091045\n",
      "Epoch 176, loss: 2.090992\n",
      "Epoch 177, loss: 2.090671\n",
      "Epoch 178, loss: 2.090612\n",
      "Epoch 179, loss: 2.090265\n",
      "Epoch 180, loss: 2.090077\n",
      "Epoch 181, loss: 2.089718\n",
      "Epoch 182, loss: 2.089647\n",
      "Epoch 183, loss: 2.089472\n",
      "Epoch 184, loss: 2.089173\n",
      "Epoch 185, loss: 2.089025\n",
      "Epoch 186, loss: 2.088697\n",
      "Epoch 187, loss: 2.088466\n",
      "Epoch 188, loss: 2.088320\n",
      "Epoch 189, loss: 2.088343\n",
      "Epoch 190, loss: 2.087916\n",
      "Epoch 191, loss: 2.087812\n",
      "Epoch 192, loss: 2.087500\n",
      "Epoch 193, loss: 2.087479\n",
      "Epoch 194, loss: 2.087072\n",
      "Epoch 195, loss: 2.087140\n",
      "Epoch 196, loss: 2.086737\n",
      "Epoch 197, loss: 2.086557\n",
      "Epoch 198, loss: 2.086470\n",
      "Epoch 199, loss: 2.085895\n",
      "lr: 0.0001, rs: 0.0001, accuracy 200 epochs: 0.245\n",
      "Epoch 0, loss: 2.297323\n",
      "Epoch 1, loss: 2.285378\n",
      "Epoch 2, loss: 2.274780\n",
      "Epoch 3, loss: 2.264630\n",
      "Epoch 4, loss: 2.255958\n",
      "Epoch 5, loss: 2.248156\n",
      "Epoch 6, loss: 2.240554\n",
      "Epoch 7, loss: 2.234039\n",
      "Epoch 8, loss: 2.227815\n",
      "Epoch 9, loss: 2.221933\n",
      "Epoch 10, loss: 2.216675\n",
      "Epoch 11, loss: 2.211831\n",
      "Epoch 12, loss: 2.207401\n",
      "Epoch 13, loss: 2.203255\n",
      "Epoch 14, loss: 2.199267\n",
      "Epoch 15, loss: 2.195763\n",
      "Epoch 16, loss: 2.192527\n",
      "Epoch 17, loss: 2.189151\n",
      "Epoch 18, loss: 2.186128\n",
      "Epoch 19, loss: 2.183734\n",
      "Epoch 20, loss: 2.180859\n",
      "Epoch 21, loss: 2.178605\n",
      "Epoch 22, loss: 2.176323\n",
      "Epoch 23, loss: 2.173991\n",
      "Epoch 24, loss: 2.171900\n",
      "Epoch 25, loss: 2.170171\n",
      "Epoch 26, loss: 2.168105\n",
      "Epoch 27, loss: 2.166550\n",
      "Epoch 28, loss: 2.164846\n",
      "Epoch 29, loss: 2.163136\n",
      "Epoch 30, loss: 2.161581\n",
      "Epoch 31, loss: 2.160042\n",
      "Epoch 32, loss: 2.158899\n",
      "Epoch 33, loss: 2.157420\n",
      "Epoch 34, loss: 2.155948\n",
      "Epoch 35, loss: 2.154787\n",
      "Epoch 36, loss: 2.153531\n",
      "Epoch 37, loss: 2.152431\n",
      "Epoch 38, loss: 2.151085\n",
      "Epoch 39, loss: 2.150013\n",
      "Epoch 40, loss: 2.149170\n",
      "Epoch 41, loss: 2.147966\n",
      "Epoch 42, loss: 2.147094\n",
      "Epoch 43, loss: 2.145957\n",
      "Epoch 44, loss: 2.145004\n",
      "Epoch 45, loss: 2.143906\n",
      "Epoch 46, loss: 2.143137\n",
      "Epoch 47, loss: 2.142341\n",
      "Epoch 48, loss: 2.141330\n",
      "Epoch 49, loss: 2.140528\n",
      "Epoch 50, loss: 2.139627\n",
      "Epoch 51, loss: 2.138659\n",
      "Epoch 52, loss: 2.137974\n",
      "Epoch 53, loss: 2.137263\n",
      "Epoch 54, loss: 2.136426\n",
      "Epoch 55, loss: 2.135658\n",
      "Epoch 56, loss: 2.135044\n",
      "Epoch 57, loss: 2.134306\n",
      "Epoch 58, loss: 2.133722\n",
      "Epoch 59, loss: 2.132658\n",
      "Epoch 60, loss: 2.132178\n",
      "Epoch 61, loss: 2.131586\n",
      "Epoch 62, loss: 2.130960\n",
      "Epoch 63, loss: 2.130280\n",
      "Epoch 64, loss: 2.129598\n",
      "Epoch 65, loss: 2.129032\n",
      "Epoch 66, loss: 2.128296\n",
      "Epoch 67, loss: 2.127713\n",
      "Epoch 68, loss: 2.126917\n",
      "Epoch 69, loss: 2.126705\n",
      "Epoch 70, loss: 2.126095\n",
      "Epoch 71, loss: 2.125407\n",
      "Epoch 72, loss: 2.124836\n",
      "Epoch 73, loss: 2.124363\n",
      "Epoch 74, loss: 2.123760\n",
      "Epoch 75, loss: 2.123330\n",
      "Epoch 76, loss: 2.122599\n",
      "Epoch 77, loss: 2.122193\n",
      "Epoch 78, loss: 2.121793\n",
      "Epoch 79, loss: 2.121110\n",
      "Epoch 80, loss: 2.120418\n",
      "Epoch 81, loss: 2.120278\n",
      "Epoch 82, loss: 2.119657\n",
      "Epoch 83, loss: 2.119231\n",
      "Epoch 84, loss: 2.118621\n",
      "Epoch 85, loss: 2.118060\n",
      "Epoch 86, loss: 2.117904\n",
      "Epoch 87, loss: 2.117275\n",
      "Epoch 88, loss: 2.116852\n",
      "Epoch 89, loss: 2.116385\n",
      "Epoch 90, loss: 2.116266\n",
      "Epoch 91, loss: 2.115748\n",
      "Epoch 92, loss: 2.115123\n",
      "Epoch 93, loss: 2.114685\n",
      "Epoch 94, loss: 2.114215\n",
      "Epoch 95, loss: 2.113779\n",
      "Epoch 96, loss: 2.113464\n",
      "Epoch 97, loss: 2.112909\n",
      "Epoch 98, loss: 2.112681\n",
      "Epoch 99, loss: 2.112292\n",
      "Epoch 100, loss: 2.111747\n",
      "Epoch 101, loss: 2.111354\n",
      "Epoch 102, loss: 2.111035\n",
      "Epoch 103, loss: 2.110591\n",
      "Epoch 104, loss: 2.110291\n",
      "Epoch 105, loss: 2.109977\n",
      "Epoch 106, loss: 2.109460\n",
      "Epoch 107, loss: 2.109282\n",
      "Epoch 108, loss: 2.108801\n",
      "Epoch 109, loss: 2.108307\n",
      "Epoch 110, loss: 2.108293\n",
      "Epoch 111, loss: 2.107650\n",
      "Epoch 112, loss: 2.107264\n",
      "Epoch 113, loss: 2.107180\n",
      "Epoch 114, loss: 2.106831\n",
      "Epoch 115, loss: 2.106427\n",
      "Epoch 116, loss: 2.106097\n",
      "Epoch 117, loss: 2.105763\n",
      "Epoch 118, loss: 2.105465\n",
      "Epoch 119, loss: 2.104997\n",
      "Epoch 120, loss: 2.104635\n",
      "Epoch 121, loss: 2.104536\n",
      "Epoch 122, loss: 2.104049\n",
      "Epoch 123, loss: 2.103771\n",
      "Epoch 124, loss: 2.103468\n",
      "Epoch 125, loss: 2.103045\n",
      "Epoch 126, loss: 2.102714\n",
      "Epoch 127, loss: 2.102719\n",
      "Epoch 128, loss: 2.101641\n",
      "Epoch 129, loss: 2.102101\n",
      "Epoch 130, loss: 2.101672\n",
      "Epoch 131, loss: 2.101291\n",
      "Epoch 132, loss: 2.100950\n",
      "Epoch 133, loss: 2.100788\n",
      "Epoch 134, loss: 2.100358\n",
      "Epoch 135, loss: 2.100076\n",
      "Epoch 136, loss: 2.099747\n",
      "Epoch 137, loss: 2.099552\n",
      "Epoch 138, loss: 2.098787\n",
      "Epoch 139, loss: 2.099212\n",
      "Epoch 140, loss: 2.098547\n",
      "Epoch 141, loss: 2.098426\n",
      "Epoch 142, loss: 2.098129\n",
      "Epoch 143, loss: 2.097835\n",
      "Epoch 144, loss: 2.097487\n",
      "Epoch 145, loss: 2.097467\n",
      "Epoch 146, loss: 2.096973\n",
      "Epoch 147, loss: 2.096672\n",
      "Epoch 148, loss: 2.096618\n",
      "Epoch 149, loss: 2.096375\n",
      "Epoch 150, loss: 2.096039\n",
      "Epoch 151, loss: 2.095527\n",
      "Epoch 152, loss: 2.095392\n",
      "Epoch 153, loss: 2.095151\n",
      "Epoch 154, loss: 2.094906\n",
      "Epoch 155, loss: 2.094740\n",
      "Epoch 156, loss: 2.094515\n",
      "Epoch 157, loss: 2.094051\n",
      "Epoch 158, loss: 2.093854\n",
      "Epoch 159, loss: 2.093707\n",
      "Epoch 160, loss: 2.093548\n",
      "Epoch 161, loss: 2.093165\n",
      "Epoch 162, loss: 2.093029\n",
      "Epoch 163, loss: 2.092817\n",
      "Epoch 164, loss: 2.092411\n",
      "Epoch 165, loss: 2.092172\n",
      "Epoch 166, loss: 2.092143\n",
      "Epoch 167, loss: 2.091623\n",
      "Epoch 168, loss: 2.091598\n",
      "Epoch 169, loss: 2.091111\n",
      "Epoch 170, loss: 2.091153\n",
      "Epoch 171, loss: 2.090731\n",
      "Epoch 172, loss: 2.090582\n",
      "Epoch 173, loss: 2.090378\n",
      "Epoch 174, loss: 2.090217\n",
      "Epoch 175, loss: 2.089997\n",
      "Epoch 176, loss: 2.089649\n",
      "Epoch 177, loss: 2.089461\n",
      "Epoch 178, loss: 2.089211\n",
      "Epoch 179, loss: 2.089109\n",
      "Epoch 180, loss: 2.088856\n",
      "Epoch 181, loss: 2.088573\n",
      "Epoch 182, loss: 2.088426\n",
      "Epoch 183, loss: 2.088244\n",
      "Epoch 184, loss: 2.087823\n",
      "Epoch 185, loss: 2.087794\n",
      "Epoch 186, loss: 2.087478\n",
      "Epoch 187, loss: 2.087503\n",
      "Epoch 188, loss: 2.086861\n",
      "Epoch 189, loss: 2.086957\n",
      "Epoch 190, loss: 2.086636\n",
      "Epoch 191, loss: 2.086545\n",
      "Epoch 192, loss: 2.086257\n",
      "Epoch 193, loss: 2.085834\n",
      "Epoch 194, loss: 2.085986\n",
      "Epoch 195, loss: 2.085606\n",
      "Epoch 196, loss: 2.085381\n",
      "Epoch 197, loss: 2.085082\n",
      "Epoch 198, loss: 2.085230\n",
      "Epoch 199, loss: 2.084908\n",
      "lr: 0.0001, rs: 1e-05, accuracy 200 epochs: 0.247\n",
      "Epoch 0, loss: 2.298107\n",
      "Epoch 1, loss: 2.285899\n",
      "Epoch 2, loss: 2.274925\n",
      "Epoch 3, loss: 2.264945\n",
      "Epoch 4, loss: 2.256338\n",
      "Epoch 5, loss: 2.248162\n",
      "Epoch 6, loss: 2.241010\n",
      "Epoch 7, loss: 2.233949\n",
      "Epoch 8, loss: 2.228003\n",
      "Epoch 9, loss: 2.222241\n",
      "Epoch 10, loss: 2.216854\n",
      "Epoch 11, loss: 2.211962\n",
      "Epoch 12, loss: 2.207370\n",
      "Epoch 13, loss: 2.202657\n",
      "Epoch 14, loss: 2.199708\n",
      "Epoch 15, loss: 2.195774\n",
      "Epoch 16, loss: 2.192358\n",
      "Epoch 17, loss: 2.189026\n",
      "Epoch 18, loss: 2.186428\n",
      "Epoch 19, loss: 2.183718\n",
      "Epoch 20, loss: 2.181150\n",
      "Epoch 21, loss: 2.178710\n",
      "Epoch 22, loss: 2.176432\n",
      "Epoch 23, loss: 2.174037\n",
      "Epoch 24, loss: 2.172031\n",
      "Epoch 25, loss: 2.170232\n",
      "Epoch 26, loss: 2.168258\n",
      "Epoch 27, loss: 2.166522\n",
      "Epoch 28, loss: 2.164764\n",
      "Epoch 29, loss: 2.163259\n",
      "Epoch 30, loss: 2.161624\n",
      "Epoch 31, loss: 2.160172\n",
      "Epoch 32, loss: 2.158715\n",
      "Epoch 33, loss: 2.157390\n",
      "Epoch 34, loss: 2.155981\n",
      "Epoch 35, loss: 2.154796\n",
      "Epoch 36, loss: 2.153446\n",
      "Epoch 37, loss: 2.152191\n",
      "Epoch 38, loss: 2.151393\n",
      "Epoch 39, loss: 2.149993\n",
      "Epoch 40, loss: 2.148936\n",
      "Epoch 41, loss: 2.147801\n",
      "Epoch 42, loss: 2.147013\n",
      "Epoch 43, loss: 2.145879\n",
      "Epoch 44, loss: 2.145003\n",
      "Epoch 45, loss: 2.144056\n",
      "Epoch 46, loss: 2.142964\n",
      "Epoch 47, loss: 2.142253\n",
      "Epoch 48, loss: 2.141466\n",
      "Epoch 49, loss: 2.140411\n",
      "Epoch 50, loss: 2.139783\n",
      "Epoch 51, loss: 2.138631\n",
      "Epoch 52, loss: 2.138109\n",
      "Epoch 53, loss: 2.137131\n",
      "Epoch 54, loss: 2.136485\n",
      "Epoch 55, loss: 2.135336\n",
      "Epoch 56, loss: 2.135251\n",
      "Epoch 57, loss: 2.134222\n",
      "Epoch 58, loss: 2.133710\n",
      "Epoch 59, loss: 2.132803\n",
      "Epoch 60, loss: 2.132102\n",
      "Epoch 61, loss: 2.131577\n",
      "Epoch 62, loss: 2.130951\n",
      "Epoch 63, loss: 2.130291\n",
      "Epoch 64, loss: 2.129528\n",
      "Epoch 65, loss: 2.128935\n",
      "Epoch 66, loss: 2.128169\n",
      "Epoch 67, loss: 2.127862\n",
      "Epoch 68, loss: 2.127055\n",
      "Epoch 69, loss: 2.126548\n",
      "Epoch 70, loss: 2.125981\n",
      "Epoch 71, loss: 2.125407\n",
      "Epoch 72, loss: 2.124631\n",
      "Epoch 73, loss: 2.124438\n",
      "Epoch 74, loss: 2.123814\n",
      "Epoch 75, loss: 2.123221\n",
      "Epoch 76, loss: 2.122823\n",
      "Epoch 77, loss: 2.122188\n",
      "Epoch 78, loss: 2.121672\n",
      "Epoch 79, loss: 2.121247\n",
      "Epoch 80, loss: 2.120497\n",
      "Epoch 81, loss: 2.120070\n",
      "Epoch 82, loss: 2.119572\n",
      "Epoch 83, loss: 2.118918\n",
      "Epoch 84, loss: 2.118954\n",
      "Epoch 85, loss: 2.118041\n",
      "Epoch 86, loss: 2.117598\n",
      "Epoch 87, loss: 2.117314\n",
      "Epoch 88, loss: 2.117036\n",
      "Epoch 89, loss: 2.116505\n",
      "Epoch 90, loss: 2.116076\n",
      "Epoch 91, loss: 2.115349\n",
      "Epoch 92, loss: 2.115108\n",
      "Epoch 93, loss: 2.114635\n",
      "Epoch 94, loss: 2.114251\n",
      "Epoch 95, loss: 2.114031\n",
      "Epoch 96, loss: 2.113427\n",
      "Epoch 97, loss: 2.113026\n",
      "Epoch 98, loss: 2.112529\n",
      "Epoch 99, loss: 2.112371\n",
      "Epoch 100, loss: 2.111855\n",
      "Epoch 101, loss: 2.111176\n",
      "Epoch 102, loss: 2.110804\n",
      "Epoch 103, loss: 2.110486\n",
      "Epoch 104, loss: 2.110323\n",
      "Epoch 105, loss: 2.109802\n",
      "Epoch 106, loss: 2.109526\n",
      "Epoch 107, loss: 2.109020\n",
      "Epoch 108, loss: 2.108863\n",
      "Epoch 109, loss: 2.108555\n",
      "Epoch 110, loss: 2.108096\n",
      "Epoch 111, loss: 2.107624\n",
      "Epoch 112, loss: 2.107279\n",
      "Epoch 113, loss: 2.107077\n",
      "Epoch 114, loss: 2.106658\n",
      "Epoch 115, loss: 2.106303\n",
      "Epoch 116, loss: 2.106230\n",
      "Epoch 117, loss: 2.105726\n",
      "Epoch 118, loss: 2.105316\n",
      "Epoch 119, loss: 2.104734\n",
      "Epoch 120, loss: 2.104686\n",
      "Epoch 121, loss: 2.104368\n",
      "Epoch 122, loss: 2.103997\n",
      "Epoch 123, loss: 2.103758\n",
      "Epoch 124, loss: 2.103167\n",
      "Epoch 125, loss: 2.102998\n",
      "Epoch 126, loss: 2.102811\n",
      "Epoch 127, loss: 2.102138\n",
      "Epoch 128, loss: 2.102054\n",
      "Epoch 129, loss: 2.101967\n",
      "Epoch 130, loss: 2.101354\n",
      "Epoch 131, loss: 2.101275\n",
      "Epoch 132, loss: 2.100832\n",
      "Epoch 133, loss: 2.100607\n",
      "Epoch 134, loss: 2.100257\n",
      "Epoch 135, loss: 2.100128\n",
      "Epoch 136, loss: 2.099675\n",
      "Epoch 137, loss: 2.099676\n",
      "Epoch 138, loss: 2.099221\n",
      "Epoch 139, loss: 2.098979\n",
      "Epoch 140, loss: 2.098671\n",
      "Epoch 141, loss: 2.098240\n",
      "Epoch 142, loss: 2.098134\n",
      "Epoch 143, loss: 2.097756\n",
      "Epoch 144, loss: 2.097594\n",
      "Epoch 145, loss: 2.097262\n",
      "Epoch 146, loss: 2.096803\n",
      "Epoch 147, loss: 2.096744\n",
      "Epoch 148, loss: 2.096390\n",
      "Epoch 149, loss: 2.096114\n",
      "Epoch 150, loss: 2.095840\n",
      "Epoch 151, loss: 2.095715\n",
      "Epoch 152, loss: 2.095469\n",
      "Epoch 153, loss: 2.095098\n",
      "Epoch 154, loss: 2.094903\n",
      "Epoch 155, loss: 2.094630\n",
      "Epoch 156, loss: 2.094295\n",
      "Epoch 157, loss: 2.094151\n",
      "Epoch 158, loss: 2.093798\n",
      "Epoch 159, loss: 2.093490\n",
      "Epoch 160, loss: 2.093390\n",
      "Epoch 161, loss: 2.092978\n",
      "Epoch 162, loss: 2.092788\n",
      "Epoch 163, loss: 2.092654\n",
      "Epoch 164, loss: 2.092375\n",
      "Epoch 165, loss: 2.091893\n",
      "Epoch 166, loss: 2.091863\n",
      "Epoch 167, loss: 2.091634\n",
      "Epoch 168, loss: 2.091370\n",
      "Epoch 169, loss: 2.091352\n",
      "Epoch 170, loss: 2.091053\n",
      "Epoch 171, loss: 2.090880\n",
      "Epoch 172, loss: 2.090418\n",
      "Epoch 173, loss: 2.090029\n",
      "Epoch 174, loss: 2.090320\n",
      "Epoch 175, loss: 2.089854\n",
      "Epoch 176, loss: 2.089644\n",
      "Epoch 177, loss: 2.089448\n",
      "Epoch 178, loss: 2.089104\n",
      "Epoch 179, loss: 2.088990\n",
      "Epoch 180, loss: 2.088848\n",
      "Epoch 181, loss: 2.088416\n",
      "Epoch 182, loss: 2.088213\n",
      "Epoch 183, loss: 2.087971\n",
      "Epoch 184, loss: 2.087887\n",
      "Epoch 185, loss: 2.087362\n",
      "Epoch 186, loss: 2.087596\n",
      "Epoch 187, loss: 2.087302\n",
      "Epoch 188, loss: 2.086851\n",
      "Epoch 189, loss: 2.086822\n",
      "Epoch 190, loss: 2.086625\n",
      "Epoch 191, loss: 2.086461\n",
      "Epoch 192, loss: 2.086236\n",
      "Epoch 193, loss: 2.085789\n",
      "Epoch 194, loss: 2.085917\n",
      "Epoch 195, loss: 2.085428\n",
      "Epoch 196, loss: 2.085341\n",
      "Epoch 197, loss: 2.085087\n",
      "Epoch 198, loss: 2.084889\n",
      "Epoch 199, loss: 2.084493\n",
      "lr: 0.0001, rs: 1e-06, accuracy 200 epochs: 0.246\n",
      "Epoch 0, loss: 2.305259\n",
      "Epoch 1, loss: 2.303678\n",
      "Epoch 2, loss: 2.302241\n",
      "Epoch 3, loss: 2.300879\n",
      "Epoch 4, loss: 2.299577\n",
      "Epoch 5, loss: 2.298330\n",
      "Epoch 6, loss: 2.297126\n",
      "Epoch 7, loss: 2.295956\n",
      "Epoch 8, loss: 2.294833\n",
      "Epoch 9, loss: 2.293737\n",
      "Epoch 10, loss: 2.292676\n",
      "Epoch 11, loss: 2.291638\n",
      "Epoch 12, loss: 2.290646\n",
      "Epoch 13, loss: 2.289664\n",
      "Epoch 14, loss: 2.288727\n",
      "Epoch 15, loss: 2.287809\n",
      "Epoch 16, loss: 2.286921\n",
      "Epoch 17, loss: 2.286054\n",
      "Epoch 18, loss: 2.285215\n",
      "Epoch 19, loss: 2.284397\n",
      "Epoch 20, loss: 2.283596\n",
      "Epoch 21, loss: 2.282829\n",
      "Epoch 22, loss: 2.282084\n",
      "Epoch 23, loss: 2.281353\n",
      "Epoch 24, loss: 2.280643\n",
      "Epoch 25, loss: 2.279953\n",
      "Epoch 26, loss: 2.279281\n",
      "Epoch 27, loss: 2.278627\n",
      "Epoch 28, loss: 2.277997\n",
      "Epoch 29, loss: 2.277377\n",
      "Epoch 30, loss: 2.276776\n",
      "Epoch 31, loss: 2.276190\n",
      "Epoch 32, loss: 2.275622\n",
      "Epoch 33, loss: 2.275066\n",
      "Epoch 34, loss: 2.274531\n",
      "Epoch 35, loss: 2.274004\n",
      "Epoch 36, loss: 2.273492\n",
      "Epoch 37, loss: 2.272997\n",
      "Epoch 38, loss: 2.272512\n",
      "Epoch 39, loss: 2.272039\n",
      "Epoch 40, loss: 2.271581\n",
      "Epoch 41, loss: 2.271140\n",
      "Epoch 42, loss: 2.270695\n",
      "Epoch 43, loss: 2.270286\n",
      "Epoch 44, loss: 2.269870\n",
      "Epoch 45, loss: 2.269468\n",
      "Epoch 46, loss: 2.269079\n",
      "Epoch 47, loss: 2.268693\n",
      "Epoch 48, loss: 2.268334\n",
      "Epoch 49, loss: 2.267970\n",
      "Epoch 50, loss: 2.267618\n",
      "Epoch 51, loss: 2.267275\n",
      "Epoch 52, loss: 2.266940\n",
      "Epoch 53, loss: 2.266615\n",
      "Epoch 54, loss: 2.266297\n",
      "Epoch 55, loss: 2.265986\n",
      "Epoch 56, loss: 2.265690\n",
      "Epoch 57, loss: 2.265396\n",
      "Epoch 58, loss: 2.265110\n",
      "Epoch 59, loss: 2.264837\n",
      "Epoch 60, loss: 2.264569\n",
      "Epoch 61, loss: 2.264300\n",
      "Epoch 62, loss: 2.264048\n",
      "Epoch 63, loss: 2.263796\n",
      "Epoch 64, loss: 2.263540\n",
      "Epoch 65, loss: 2.263310\n",
      "Epoch 66, loss: 2.263084\n",
      "Epoch 67, loss: 2.262852\n",
      "Epoch 68, loss: 2.262639\n",
      "Epoch 69, loss: 2.262425\n",
      "Epoch 70, loss: 2.262211\n",
      "Epoch 71, loss: 2.262013\n",
      "Epoch 72, loss: 2.261806\n",
      "Epoch 73, loss: 2.261620\n",
      "Epoch 74, loss: 2.261432\n",
      "Epoch 75, loss: 2.261241\n",
      "Epoch 76, loss: 2.261066\n",
      "Epoch 77, loss: 2.260886\n",
      "Epoch 78, loss: 2.260720\n",
      "Epoch 79, loss: 2.260557\n",
      "Epoch 80, loss: 2.260394\n",
      "Epoch 81, loss: 2.260239\n",
      "Epoch 82, loss: 2.260082\n",
      "Epoch 83, loss: 2.259933\n",
      "Epoch 84, loss: 2.259788\n",
      "Epoch 85, loss: 2.259642\n",
      "Epoch 86, loss: 2.259504\n",
      "Epoch 87, loss: 2.259369\n",
      "Epoch 88, loss: 2.259238\n",
      "Epoch 89, loss: 2.259111\n",
      "Epoch 90, loss: 2.258988\n",
      "Epoch 91, loss: 2.258863\n",
      "Epoch 92, loss: 2.258740\n",
      "Epoch 93, loss: 2.258629\n",
      "Epoch 94, loss: 2.258509\n",
      "Epoch 95, loss: 2.258404\n",
      "Epoch 96, loss: 2.258299\n",
      "Epoch 97, loss: 2.258188\n",
      "Epoch 98, loss: 2.258087\n",
      "Epoch 99, loss: 2.257987\n",
      "Epoch 100, loss: 2.257889\n",
      "Epoch 101, loss: 2.257794\n",
      "Epoch 102, loss: 2.257702\n",
      "Epoch 103, loss: 2.257607\n",
      "Epoch 104, loss: 2.257522\n",
      "Epoch 105, loss: 2.257439\n",
      "Epoch 106, loss: 2.257351\n",
      "Epoch 107, loss: 2.257268\n",
      "Epoch 108, loss: 2.257191\n",
      "Epoch 109, loss: 2.257116\n",
      "Epoch 110, loss: 2.257031\n",
      "Epoch 111, loss: 2.256959\n",
      "Epoch 112, loss: 2.256885\n",
      "Epoch 113, loss: 2.256821\n",
      "Epoch 114, loss: 2.256752\n",
      "Epoch 115, loss: 2.256686\n",
      "Epoch 116, loss: 2.256614\n",
      "Epoch 117, loss: 2.256553\n",
      "Epoch 118, loss: 2.256487\n",
      "Epoch 119, loss: 2.256427\n",
      "Epoch 120, loss: 2.256370\n",
      "Epoch 121, loss: 2.256311\n",
      "Epoch 122, loss: 2.256239\n",
      "Epoch 123, loss: 2.256206\n",
      "Epoch 124, loss: 2.256144\n",
      "Epoch 125, loss: 2.256094\n",
      "Epoch 126, loss: 2.256044\n",
      "Epoch 127, loss: 2.255995\n",
      "Epoch 128, loss: 2.255941\n",
      "Epoch 129, loss: 2.255898\n",
      "Epoch 130, loss: 2.255849\n",
      "Epoch 131, loss: 2.255805\n",
      "Epoch 132, loss: 2.255759\n",
      "Epoch 133, loss: 2.255718\n",
      "Epoch 134, loss: 2.255676\n",
      "Epoch 135, loss: 2.255635\n",
      "Epoch 136, loss: 2.255594\n",
      "Epoch 137, loss: 2.255557\n",
      "Epoch 138, loss: 2.255512\n",
      "Epoch 139, loss: 2.255478\n",
      "Epoch 140, loss: 2.255440\n",
      "Epoch 141, loss: 2.255405\n",
      "Epoch 142, loss: 2.255364\n",
      "Epoch 143, loss: 2.255339\n",
      "Epoch 144, loss: 2.255303\n",
      "Epoch 145, loss: 2.255274\n",
      "Epoch 146, loss: 2.255244\n",
      "Epoch 147, loss: 2.255213\n",
      "Epoch 148, loss: 2.255176\n",
      "Epoch 149, loss: 2.255154\n",
      "Epoch 150, loss: 2.255122\n",
      "Epoch 151, loss: 2.255096\n",
      "Epoch 152, loss: 2.255068\n",
      "Epoch 153, loss: 2.255042\n",
      "Epoch 154, loss: 2.255012\n",
      "Epoch 155, loss: 2.254987\n",
      "Epoch 156, loss: 2.254965\n",
      "Epoch 157, loss: 2.254939\n",
      "Epoch 158, loss: 2.254909\n",
      "Epoch 159, loss: 2.254893\n",
      "Epoch 160, loss: 2.254870\n",
      "Epoch 161, loss: 2.254853\n",
      "Epoch 162, loss: 2.254827\n",
      "Epoch 163, loss: 2.254805\n",
      "Epoch 164, loss: 2.254784\n",
      "Epoch 165, loss: 2.254767\n",
      "Epoch 166, loss: 2.254747\n",
      "Epoch 167, loss: 2.254721\n",
      "Epoch 168, loss: 2.254708\n",
      "Epoch 169, loss: 2.254688\n",
      "Epoch 170, loss: 2.254675\n",
      "Epoch 171, loss: 2.254657\n",
      "Epoch 172, loss: 2.254639\n",
      "Epoch 173, loss: 2.254621\n",
      "Epoch 174, loss: 2.254604\n",
      "Epoch 175, loss: 2.254588\n",
      "Epoch 176, loss: 2.254572\n",
      "Epoch 177, loss: 2.254559\n",
      "Epoch 178, loss: 2.254539\n",
      "Epoch 179, loss: 2.254531\n",
      "Epoch 180, loss: 2.254513\n",
      "Epoch 181, loss: 2.254503\n",
      "Epoch 182, loss: 2.254485\n",
      "Epoch 183, loss: 2.254478\n",
      "Epoch 184, loss: 2.254461\n",
      "Epoch 185, loss: 2.254446\n",
      "Epoch 186, loss: 2.254435\n",
      "Epoch 187, loss: 2.254426\n",
      "Epoch 188, loss: 2.254416\n",
      "Epoch 189, loss: 2.254397\n",
      "Epoch 190, loss: 2.254391\n",
      "Epoch 191, loss: 2.254381\n",
      "Epoch 192, loss: 2.254368\n",
      "Epoch 193, loss: 2.254361\n",
      "Epoch 194, loss: 2.254348\n",
      "Epoch 195, loss: 2.254333\n",
      "Epoch 196, loss: 2.254325\n",
      "Epoch 197, loss: 2.254323\n",
      "Epoch 198, loss: 2.254310\n",
      "Epoch 199, loss: 2.254293\n",
      "lr: 1e-05, rs: 0.1, accuracy 200 epochs: 0.229\n",
      "Epoch 0, loss: 2.302231\n",
      "Epoch 1, loss: 2.300721\n",
      "Epoch 2, loss: 2.299307\n",
      "Epoch 3, loss: 2.297945\n",
      "Epoch 4, loss: 2.296636\n",
      "Epoch 5, loss: 2.295340\n",
      "Epoch 6, loss: 2.294084\n",
      "Epoch 7, loss: 2.292840\n",
      "Epoch 8, loss: 2.291614\n",
      "Epoch 9, loss: 2.290411\n",
      "Epoch 10, loss: 2.289225\n",
      "Epoch 11, loss: 2.288052\n",
      "Epoch 12, loss: 2.286900\n",
      "Epoch 13, loss: 2.285761\n",
      "Epoch 14, loss: 2.284629\n",
      "Epoch 15, loss: 2.283527\n",
      "Epoch 16, loss: 2.282433\n",
      "Epoch 17, loss: 2.281350\n",
      "Epoch 18, loss: 2.280283\n",
      "Epoch 19, loss: 2.279232\n",
      "Epoch 20, loss: 2.278190\n",
      "Epoch 21, loss: 2.277163\n",
      "Epoch 22, loss: 2.276145\n",
      "Epoch 23, loss: 2.275144\n",
      "Epoch 24, loss: 2.274156\n",
      "Epoch 25, loss: 2.273182\n",
      "Epoch 26, loss: 2.272214\n",
      "Epoch 27, loss: 2.271261\n",
      "Epoch 28, loss: 2.270314\n",
      "Epoch 29, loss: 2.269382\n",
      "Epoch 30, loss: 2.268466\n",
      "Epoch 31, loss: 2.267549\n",
      "Epoch 32, loss: 2.266655\n",
      "Epoch 33, loss: 2.265767\n",
      "Epoch 34, loss: 2.264887\n",
      "Epoch 35, loss: 2.264010\n",
      "Epoch 36, loss: 2.263159\n",
      "Epoch 37, loss: 2.262312\n",
      "Epoch 38, loss: 2.261471\n",
      "Epoch 39, loss: 2.260639\n",
      "Epoch 40, loss: 2.259817\n",
      "Epoch 41, loss: 2.259008\n",
      "Epoch 42, loss: 2.258198\n",
      "Epoch 43, loss: 2.257412\n",
      "Epoch 44, loss: 2.256620\n",
      "Epoch 45, loss: 2.255850\n",
      "Epoch 46, loss: 2.255081\n",
      "Epoch 47, loss: 2.254321\n",
      "Epoch 48, loss: 2.253566\n",
      "Epoch 49, loss: 2.252826\n",
      "Epoch 50, loss: 2.252086\n",
      "Epoch 51, loss: 2.251361\n",
      "Epoch 52, loss: 2.250637\n",
      "Epoch 53, loss: 2.249928\n",
      "Epoch 54, loss: 2.249224\n",
      "Epoch 55, loss: 2.248532\n",
      "Epoch 56, loss: 2.247841\n",
      "Epoch 57, loss: 2.247148\n",
      "Epoch 58, loss: 2.246479\n",
      "Epoch 59, loss: 2.245811\n",
      "Epoch 60, loss: 2.245149\n",
      "Epoch 61, loss: 2.244491\n",
      "Epoch 62, loss: 2.243851\n",
      "Epoch 63, loss: 2.243206\n",
      "Epoch 64, loss: 2.242576\n",
      "Epoch 65, loss: 2.241945\n",
      "Epoch 66, loss: 2.241325\n",
      "Epoch 67, loss: 2.240708\n",
      "Epoch 68, loss: 2.240104\n",
      "Epoch 69, loss: 2.239503\n",
      "Epoch 70, loss: 2.238902\n",
      "Epoch 71, loss: 2.238313\n",
      "Epoch 72, loss: 2.237727\n",
      "Epoch 73, loss: 2.237153\n",
      "Epoch 74, loss: 2.236576\n",
      "Epoch 75, loss: 2.236013\n",
      "Epoch 76, loss: 2.235451\n",
      "Epoch 77, loss: 2.234901\n",
      "Epoch 78, loss: 2.234350\n",
      "Epoch 79, loss: 2.233809\n",
      "Epoch 80, loss: 2.233270\n",
      "Epoch 81, loss: 2.232738\n",
      "Epoch 82, loss: 2.232211\n",
      "Epoch 83, loss: 2.231689\n",
      "Epoch 84, loss: 2.231169\n",
      "Epoch 85, loss: 2.230654\n",
      "Epoch 86, loss: 2.230151\n",
      "Epoch 87, loss: 2.229649\n",
      "Epoch 88, loss: 2.229153\n",
      "Epoch 89, loss: 2.228665\n",
      "Epoch 90, loss: 2.228174\n",
      "Epoch 91, loss: 2.227693\n",
      "Epoch 92, loss: 2.227219\n",
      "Epoch 93, loss: 2.226744\n",
      "Epoch 94, loss: 2.226278\n",
      "Epoch 95, loss: 2.225816\n",
      "Epoch 96, loss: 2.225359\n",
      "Epoch 97, loss: 2.224901\n",
      "Epoch 98, loss: 2.224454\n",
      "Epoch 99, loss: 2.224006\n",
      "Epoch 100, loss: 2.223568\n",
      "Epoch 101, loss: 2.223129\n",
      "Epoch 102, loss: 2.222698\n",
      "Epoch 103, loss: 2.222269\n",
      "Epoch 104, loss: 2.221840\n",
      "Epoch 105, loss: 2.221427\n",
      "Epoch 106, loss: 2.221010\n",
      "Epoch 107, loss: 2.220599\n",
      "Epoch 108, loss: 2.220188\n",
      "Epoch 109, loss: 2.219789\n",
      "Epoch 110, loss: 2.219387\n",
      "Epoch 111, loss: 2.218989\n",
      "Epoch 112, loss: 2.218599\n",
      "Epoch 113, loss: 2.218207\n",
      "Epoch 114, loss: 2.217825\n",
      "Epoch 115, loss: 2.217443\n",
      "Epoch 116, loss: 2.217063\n",
      "Epoch 117, loss: 2.216688\n",
      "Epoch 118, loss: 2.216319\n",
      "Epoch 119, loss: 2.215952\n",
      "Epoch 120, loss: 2.215586\n",
      "Epoch 121, loss: 2.215227\n",
      "Epoch 122, loss: 2.214873\n",
      "Epoch 123, loss: 2.214516\n",
      "Epoch 124, loss: 2.214170\n",
      "Epoch 125, loss: 2.213818\n",
      "Epoch 126, loss: 2.213479\n",
      "Epoch 127, loss: 2.213130\n",
      "Epoch 128, loss: 2.212780\n",
      "Epoch 129, loss: 2.212467\n",
      "Epoch 130, loss: 2.212133\n",
      "Epoch 131, loss: 2.211801\n",
      "Epoch 132, loss: 2.211480\n",
      "Epoch 133, loss: 2.211154\n",
      "Epoch 134, loss: 2.210841\n",
      "Epoch 135, loss: 2.210523\n",
      "Epoch 136, loss: 2.210213\n",
      "Epoch 137, loss: 2.209900\n",
      "Epoch 138, loss: 2.209586\n",
      "Epoch 139, loss: 2.209288\n",
      "Epoch 140, loss: 2.208988\n",
      "Epoch 141, loss: 2.208686\n",
      "Epoch 142, loss: 2.208384\n",
      "Epoch 143, loss: 2.208095\n",
      "Epoch 144, loss: 2.207804\n",
      "Epoch 145, loss: 2.207517\n",
      "Epoch 146, loss: 2.207230\n",
      "Epoch 147, loss: 2.206945\n",
      "Epoch 148, loss: 2.206662\n",
      "Epoch 149, loss: 2.206380\n",
      "Epoch 150, loss: 2.206113\n",
      "Epoch 151, loss: 2.205835\n",
      "Epoch 152, loss: 2.205566\n",
      "Epoch 153, loss: 2.205295\n",
      "Epoch 154, loss: 2.205030\n",
      "Epoch 155, loss: 2.204764\n",
      "Epoch 156, loss: 2.204503\n",
      "Epoch 157, loss: 2.204245\n",
      "Epoch 158, loss: 2.203985\n",
      "Epoch 159, loss: 2.203731\n",
      "Epoch 160, loss: 2.203481\n",
      "Epoch 161, loss: 2.203230\n",
      "Epoch 162, loss: 2.202979\n",
      "Epoch 163, loss: 2.202731\n",
      "Epoch 164, loss: 2.202489\n",
      "Epoch 165, loss: 2.202242\n",
      "Epoch 166, loss: 2.202009\n",
      "Epoch 167, loss: 2.201770\n",
      "Epoch 168, loss: 2.201535\n",
      "Epoch 169, loss: 2.201301\n",
      "Epoch 170, loss: 2.201065\n",
      "Epoch 171, loss: 2.200835\n",
      "Epoch 172, loss: 2.200606\n",
      "Epoch 173, loss: 2.200387\n",
      "Epoch 174, loss: 2.200158\n",
      "Epoch 175, loss: 2.199937\n",
      "Epoch 176, loss: 2.199713\n",
      "Epoch 177, loss: 2.199500\n",
      "Epoch 178, loss: 2.199280\n",
      "Epoch 179, loss: 2.199070\n",
      "Epoch 180, loss: 2.198854\n",
      "Epoch 181, loss: 2.198641\n",
      "Epoch 182, loss: 2.198434\n",
      "Epoch 183, loss: 2.198219\n",
      "Epoch 184, loss: 2.198019\n",
      "Epoch 185, loss: 2.197817\n",
      "Epoch 186, loss: 2.197610\n",
      "Epoch 187, loss: 2.197410\n",
      "Epoch 188, loss: 2.197204\n",
      "Epoch 189, loss: 2.197011\n",
      "Epoch 190, loss: 2.196809\n",
      "Epoch 191, loss: 2.196622\n",
      "Epoch 192, loss: 2.196430\n",
      "Epoch 193, loss: 2.196235\n",
      "Epoch 194, loss: 2.196044\n",
      "Epoch 195, loss: 2.195854\n",
      "Epoch 196, loss: 2.195668\n",
      "Epoch 197, loss: 2.195477\n",
      "Epoch 198, loss: 2.195298\n",
      "Epoch 199, loss: 2.195115\n",
      "lr: 1e-05, rs: 0.01, accuracy 200 epochs: 0.228\n",
      "Epoch 0, loss: 2.302129\n",
      "Epoch 1, loss: 2.300615\n",
      "Epoch 2, loss: 2.299188\n",
      "Epoch 3, loss: 2.297828\n",
      "Epoch 4, loss: 2.296503\n",
      "Epoch 5, loss: 2.295198\n",
      "Epoch 6, loss: 2.293927\n",
      "Epoch 7, loss: 2.292672\n",
      "Epoch 8, loss: 2.291436\n",
      "Epoch 9, loss: 2.290209\n",
      "Epoch 10, loss: 2.289000\n",
      "Epoch 11, loss: 2.287806\n",
      "Epoch 12, loss: 2.286625\n",
      "Epoch 13, loss: 2.285463\n",
      "Epoch 14, loss: 2.284317\n",
      "Epoch 15, loss: 2.283177\n",
      "Epoch 16, loss: 2.282050\n",
      "Epoch 17, loss: 2.280941\n",
      "Epoch 18, loss: 2.279840\n",
      "Epoch 19, loss: 2.278753\n",
      "Epoch 20, loss: 2.277681\n",
      "Epoch 21, loss: 2.276617\n",
      "Epoch 22, loss: 2.275556\n",
      "Epoch 23, loss: 2.274516\n",
      "Epoch 24, loss: 2.273490\n",
      "Epoch 25, loss: 2.272471\n",
      "Epoch 26, loss: 2.271469\n",
      "Epoch 27, loss: 2.270466\n",
      "Epoch 28, loss: 2.269475\n",
      "Epoch 29, loss: 2.268504\n",
      "Epoch 30, loss: 2.267536\n",
      "Epoch 31, loss: 2.266572\n",
      "Epoch 32, loss: 2.265628\n",
      "Epoch 33, loss: 2.264684\n",
      "Epoch 34, loss: 2.263758\n",
      "Epoch 35, loss: 2.262840\n",
      "Epoch 36, loss: 2.261933\n",
      "Epoch 37, loss: 2.261024\n",
      "Epoch 38, loss: 2.260130\n",
      "Epoch 39, loss: 2.259245\n",
      "Epoch 40, loss: 2.258369\n",
      "Epoch 41, loss: 2.257503\n",
      "Epoch 42, loss: 2.256639\n",
      "Epoch 43, loss: 2.255788\n",
      "Epoch 44, loss: 2.254946\n",
      "Epoch 45, loss: 2.254107\n",
      "Epoch 46, loss: 2.253285\n",
      "Epoch 47, loss: 2.252466\n",
      "Epoch 48, loss: 2.251651\n",
      "Epoch 49, loss: 2.250842\n",
      "Epoch 50, loss: 2.250042\n",
      "Epoch 51, loss: 2.249257\n",
      "Epoch 52, loss: 2.248468\n",
      "Epoch 53, loss: 2.247692\n",
      "Epoch 54, loss: 2.246925\n",
      "Epoch 55, loss: 2.246163\n",
      "Epoch 56, loss: 2.245406\n",
      "Epoch 57, loss: 2.244657\n",
      "Epoch 58, loss: 2.243920\n",
      "Epoch 59, loss: 2.243182\n",
      "Epoch 60, loss: 2.242449\n",
      "Epoch 61, loss: 2.241725\n",
      "Epoch 62, loss: 2.241003\n",
      "Epoch 63, loss: 2.240306\n",
      "Epoch 64, loss: 2.239599\n",
      "Epoch 65, loss: 2.238901\n",
      "Epoch 66, loss: 2.238208\n",
      "Epoch 67, loss: 2.237531\n",
      "Epoch 68, loss: 2.236849\n",
      "Epoch 69, loss: 2.236179\n",
      "Epoch 70, loss: 2.235502\n",
      "Epoch 71, loss: 2.234848\n",
      "Epoch 72, loss: 2.234186\n",
      "Epoch 73, loss: 2.233537\n",
      "Epoch 74, loss: 2.232897\n",
      "Epoch 75, loss: 2.232252\n",
      "Epoch 76, loss: 2.231622\n",
      "Epoch 77, loss: 2.230992\n",
      "Epoch 78, loss: 2.230374\n",
      "Epoch 79, loss: 2.229755\n",
      "Epoch 80, loss: 2.229144\n",
      "Epoch 81, loss: 2.228536\n",
      "Epoch 82, loss: 2.227931\n",
      "Epoch 83, loss: 2.227337\n",
      "Epoch 84, loss: 2.226740\n",
      "Epoch 85, loss: 2.226159\n",
      "Epoch 86, loss: 2.225573\n",
      "Epoch 87, loss: 2.225000\n",
      "Epoch 88, loss: 2.224421\n",
      "Epoch 89, loss: 2.223853\n",
      "Epoch 90, loss: 2.223303\n",
      "Epoch 91, loss: 2.222740\n",
      "Epoch 92, loss: 2.222185\n",
      "Epoch 93, loss: 2.221637\n",
      "Epoch 94, loss: 2.221093\n",
      "Epoch 95, loss: 2.220552\n",
      "Epoch 96, loss: 2.220018\n",
      "Epoch 97, loss: 2.219488\n",
      "Epoch 98, loss: 2.218962\n",
      "Epoch 99, loss: 2.218440\n",
      "Epoch 100, loss: 2.217910\n",
      "Epoch 101, loss: 2.217413\n",
      "Epoch 102, loss: 2.216904\n",
      "Epoch 103, loss: 2.216396\n",
      "Epoch 104, loss: 2.215897\n",
      "Epoch 105, loss: 2.215396\n",
      "Epoch 106, loss: 2.214905\n",
      "Epoch 107, loss: 2.214414\n",
      "Epoch 108, loss: 2.213925\n",
      "Epoch 109, loss: 2.213451\n",
      "Epoch 110, loss: 2.212972\n",
      "Epoch 111, loss: 2.212498\n",
      "Epoch 112, loss: 2.212030\n",
      "Epoch 113, loss: 2.211560\n",
      "Epoch 114, loss: 2.211102\n",
      "Epoch 115, loss: 2.210642\n",
      "Epoch 116, loss: 2.210188\n",
      "Epoch 117, loss: 2.209735\n",
      "Epoch 118, loss: 2.209292\n",
      "Epoch 119, loss: 2.208848\n",
      "Epoch 120, loss: 2.208404\n",
      "Epoch 121, loss: 2.207969\n",
      "Epoch 122, loss: 2.207530\n",
      "Epoch 123, loss: 2.207105\n",
      "Epoch 124, loss: 2.206676\n",
      "Epoch 125, loss: 2.206254\n",
      "Epoch 126, loss: 2.205832\n",
      "Epoch 127, loss: 2.205417\n",
      "Epoch 128, loss: 2.205003\n",
      "Epoch 129, loss: 2.204592\n",
      "Epoch 130, loss: 2.204179\n",
      "Epoch 131, loss: 2.203771\n",
      "Epoch 132, loss: 2.203376\n",
      "Epoch 133, loss: 2.202977\n",
      "Epoch 134, loss: 2.202580\n",
      "Epoch 135, loss: 2.202191\n",
      "Epoch 136, loss: 2.201809\n",
      "Epoch 137, loss: 2.201416\n",
      "Epoch 138, loss: 2.201036\n",
      "Epoch 139, loss: 2.200646\n",
      "Epoch 140, loss: 2.200276\n",
      "Epoch 141, loss: 2.199903\n",
      "Epoch 142, loss: 2.199529\n",
      "Epoch 143, loss: 2.199156\n",
      "Epoch 144, loss: 2.198789\n",
      "Epoch 145, loss: 2.198429\n",
      "Epoch 146, loss: 2.198068\n",
      "Epoch 147, loss: 2.197708\n",
      "Epoch 148, loss: 2.197355\n",
      "Epoch 149, loss: 2.196999\n",
      "Epoch 150, loss: 2.196652\n",
      "Epoch 151, loss: 2.196297\n",
      "Epoch 152, loss: 2.195955\n",
      "Epoch 153, loss: 2.195610\n",
      "Epoch 154, loss: 2.195274\n",
      "Epoch 155, loss: 2.194933\n",
      "Epoch 156, loss: 2.194599\n",
      "Epoch 157, loss: 2.194262\n",
      "Epoch 158, loss: 2.193930\n",
      "Epoch 159, loss: 2.193604\n",
      "Epoch 160, loss: 2.193279\n",
      "Epoch 161, loss: 2.192957\n",
      "Epoch 162, loss: 2.192633\n",
      "Epoch 163, loss: 2.192317\n",
      "Epoch 164, loss: 2.191992\n",
      "Epoch 165, loss: 2.191673\n",
      "Epoch 166, loss: 2.191372\n",
      "Epoch 167, loss: 2.191058\n",
      "Epoch 168, loss: 2.190756\n",
      "Epoch 169, loss: 2.190444\n",
      "Epoch 170, loss: 2.190139\n",
      "Epoch 171, loss: 2.189843\n",
      "Epoch 172, loss: 2.189539\n",
      "Epoch 173, loss: 2.189245\n",
      "Epoch 174, loss: 2.188947\n",
      "Epoch 175, loss: 2.188652\n",
      "Epoch 176, loss: 2.188355\n",
      "Epoch 177, loss: 2.188072\n",
      "Epoch 178, loss: 2.187779\n",
      "Epoch 179, loss: 2.187495\n",
      "Epoch 180, loss: 2.187211\n",
      "Epoch 181, loss: 2.186930\n",
      "Epoch 182, loss: 2.186651\n",
      "Epoch 183, loss: 2.186371\n",
      "Epoch 184, loss: 2.186093\n",
      "Epoch 185, loss: 2.185817\n",
      "Epoch 186, loss: 2.185548\n",
      "Epoch 187, loss: 2.185273\n",
      "Epoch 188, loss: 2.185008\n",
      "Epoch 189, loss: 2.184741\n",
      "Epoch 190, loss: 2.184469\n",
      "Epoch 191, loss: 2.184214\n",
      "Epoch 192, loss: 2.183949\n",
      "Epoch 193, loss: 2.183689\n",
      "Epoch 194, loss: 2.183426\n",
      "Epoch 195, loss: 2.183166\n",
      "Epoch 196, loss: 2.182917\n",
      "Epoch 197, loss: 2.182655\n",
      "Epoch 198, loss: 2.182405\n",
      "Epoch 199, loss: 2.182157\n",
      "lr: 1e-05, rs: 0.001, accuracy 200 epochs: 0.224\n",
      "Epoch 0, loss: 2.302115\n",
      "Epoch 1, loss: 2.300615\n",
      "Epoch 2, loss: 2.299206\n",
      "Epoch 3, loss: 2.297848\n",
      "Epoch 4, loss: 2.296519\n",
      "Epoch 5, loss: 2.295223\n",
      "Epoch 6, loss: 2.293943\n",
      "Epoch 7, loss: 2.292688\n",
      "Epoch 8, loss: 2.291440\n",
      "Epoch 9, loss: 2.290216\n",
      "Epoch 10, loss: 2.288997\n",
      "Epoch 11, loss: 2.287807\n",
      "Epoch 12, loss: 2.286624\n",
      "Epoch 13, loss: 2.285455\n",
      "Epoch 14, loss: 2.284299\n",
      "Epoch 15, loss: 2.283156\n",
      "Epoch 16, loss: 2.282029\n",
      "Epoch 17, loss: 2.280916\n",
      "Epoch 18, loss: 2.279806\n",
      "Epoch 19, loss: 2.278719\n",
      "Epoch 20, loss: 2.277636\n",
      "Epoch 21, loss: 2.276568\n",
      "Epoch 22, loss: 2.275512\n",
      "Epoch 23, loss: 2.274467\n",
      "Epoch 24, loss: 2.273435\n",
      "Epoch 25, loss: 2.272404\n",
      "Epoch 26, loss: 2.271394\n",
      "Epoch 27, loss: 2.270395\n",
      "Epoch 28, loss: 2.269398\n",
      "Epoch 29, loss: 2.268417\n",
      "Epoch 30, loss: 2.267441\n",
      "Epoch 31, loss: 2.266482\n",
      "Epoch 32, loss: 2.265529\n",
      "Epoch 33, loss: 2.264580\n",
      "Epoch 34, loss: 2.263652\n",
      "Epoch 35, loss: 2.262724\n",
      "Epoch 36, loss: 2.261809\n",
      "Epoch 37, loss: 2.260900\n",
      "Epoch 38, loss: 2.259999\n",
      "Epoch 39, loss: 2.259107\n",
      "Epoch 40, loss: 2.258225\n",
      "Epoch 41, loss: 2.257353\n",
      "Epoch 42, loss: 2.256485\n",
      "Epoch 43, loss: 2.255629\n",
      "Epoch 44, loss: 2.254774\n",
      "Epoch 45, loss: 2.253925\n",
      "Epoch 46, loss: 2.253101\n",
      "Epoch 47, loss: 2.252268\n",
      "Epoch 48, loss: 2.251456\n",
      "Epoch 49, loss: 2.250643\n",
      "Epoch 50, loss: 2.249836\n",
      "Epoch 51, loss: 2.249040\n",
      "Epoch 52, loss: 2.248243\n",
      "Epoch 53, loss: 2.247461\n",
      "Epoch 54, loss: 2.246693\n",
      "Epoch 55, loss: 2.245926\n",
      "Epoch 56, loss: 2.245156\n",
      "Epoch 57, loss: 2.244401\n",
      "Epoch 58, loss: 2.243655\n",
      "Epoch 59, loss: 2.242909\n",
      "Epoch 60, loss: 2.242172\n",
      "Epoch 61, loss: 2.241438\n",
      "Epoch 62, loss: 2.240717\n",
      "Epoch 63, loss: 2.239998\n",
      "Epoch 64, loss: 2.239291\n",
      "Epoch 65, loss: 2.238588\n",
      "Epoch 66, loss: 2.237891\n",
      "Epoch 67, loss: 2.237199\n",
      "Epoch 68, loss: 2.236507\n",
      "Epoch 69, loss: 2.235832\n",
      "Epoch 70, loss: 2.235146\n",
      "Epoch 71, loss: 2.234488\n",
      "Epoch 72, loss: 2.233817\n",
      "Epoch 73, loss: 2.233163\n",
      "Epoch 74, loss: 2.232508\n",
      "Epoch 75, loss: 2.231868\n",
      "Epoch 76, loss: 2.231226\n",
      "Epoch 77, loss: 2.230588\n",
      "Epoch 78, loss: 2.229957\n",
      "Epoch 79, loss: 2.229335\n",
      "Epoch 80, loss: 2.228707\n",
      "Epoch 81, loss: 2.228091\n",
      "Epoch 82, loss: 2.227485\n",
      "Epoch 83, loss: 2.226882\n",
      "Epoch 84, loss: 2.226282\n",
      "Epoch 85, loss: 2.225686\n",
      "Epoch 86, loss: 2.225097\n",
      "Epoch 87, loss: 2.224513\n",
      "Epoch 88, loss: 2.223932\n",
      "Epoch 89, loss: 2.223359\n",
      "Epoch 90, loss: 2.222783\n",
      "Epoch 91, loss: 2.222216\n",
      "Epoch 92, loss: 2.221658\n",
      "Epoch 93, loss: 2.221096\n",
      "Epoch 94, loss: 2.220546\n",
      "Epoch 95, loss: 2.220001\n",
      "Epoch 96, loss: 2.219459\n",
      "Epoch 97, loss: 2.218920\n",
      "Epoch 98, loss: 2.218386\n",
      "Epoch 99, loss: 2.217854\n",
      "Epoch 100, loss: 2.217330\n",
      "Epoch 101, loss: 2.216804\n",
      "Epoch 102, loss: 2.216292\n",
      "Epoch 103, loss: 2.215776\n",
      "Epoch 104, loss: 2.215267\n",
      "Epoch 105, loss: 2.214758\n",
      "Epoch 106, loss: 2.214261\n",
      "Epoch 107, loss: 2.213760\n",
      "Epoch 108, loss: 2.213271\n",
      "Epoch 109, loss: 2.212776\n",
      "Epoch 110, loss: 2.212293\n",
      "Epoch 111, loss: 2.211811\n",
      "Epoch 112, loss: 2.211334\n",
      "Epoch 113, loss: 2.210860\n",
      "Epoch 114, loss: 2.210388\n",
      "Epoch 115, loss: 2.209921\n",
      "Epoch 116, loss: 2.209454\n",
      "Epoch 117, loss: 2.208994\n",
      "Epoch 118, loss: 2.208538\n",
      "Epoch 119, loss: 2.208088\n",
      "Epoch 120, loss: 2.207639\n",
      "Epoch 121, loss: 2.207189\n",
      "Epoch 122, loss: 2.206748\n",
      "Epoch 123, loss: 2.206309\n",
      "Epoch 124, loss: 2.205875\n",
      "Epoch 125, loss: 2.205446\n",
      "Epoch 126, loss: 2.205015\n",
      "Epoch 127, loss: 2.204591\n",
      "Epoch 128, loss: 2.204166\n",
      "Epoch 129, loss: 2.203746\n",
      "Epoch 130, loss: 2.203334\n",
      "Epoch 131, loss: 2.202918\n",
      "Epoch 132, loss: 2.202506\n",
      "Epoch 133, loss: 2.202105\n",
      "Epoch 134, loss: 2.201689\n",
      "Epoch 135, loss: 2.201299\n",
      "Epoch 136, loss: 2.200902\n",
      "Epoch 137, loss: 2.200506\n",
      "Epoch 138, loss: 2.200116\n",
      "Epoch 139, loss: 2.199726\n",
      "Epoch 140, loss: 2.199334\n",
      "Epoch 141, loss: 2.198950\n",
      "Epoch 142, loss: 2.198572\n",
      "Epoch 143, loss: 2.198194\n",
      "Epoch 144, loss: 2.197815\n",
      "Epoch 145, loss: 2.197443\n",
      "Epoch 146, loss: 2.197076\n",
      "Epoch 147, loss: 2.196709\n",
      "Epoch 148, loss: 2.196345\n",
      "Epoch 149, loss: 2.195977\n",
      "Epoch 150, loss: 2.195626\n",
      "Epoch 151, loss: 2.195272\n",
      "Epoch 152, loss: 2.194911\n",
      "Epoch 153, loss: 2.194563\n",
      "Epoch 154, loss: 2.194216\n",
      "Epoch 155, loss: 2.193862\n",
      "Epoch 156, loss: 2.193523\n",
      "Epoch 157, loss: 2.193184\n",
      "Epoch 158, loss: 2.192840\n",
      "Epoch 159, loss: 2.192499\n",
      "Epoch 160, loss: 2.192172\n",
      "Epoch 161, loss: 2.191834\n",
      "Epoch 162, loss: 2.191505\n",
      "Epoch 163, loss: 2.191178\n",
      "Epoch 164, loss: 2.190850\n",
      "Epoch 165, loss: 2.190534\n",
      "Epoch 166, loss: 2.190209\n",
      "Epoch 167, loss: 2.189892\n",
      "Epoch 168, loss: 2.189570\n",
      "Epoch 169, loss: 2.189257\n",
      "Epoch 170, loss: 2.188947\n",
      "Epoch 171, loss: 2.188633\n",
      "Epoch 172, loss: 2.188327\n",
      "Epoch 173, loss: 2.188027\n",
      "Epoch 174, loss: 2.187720\n",
      "Epoch 175, loss: 2.187417\n",
      "Epoch 176, loss: 2.187100\n",
      "Epoch 177, loss: 2.186818\n",
      "Epoch 178, loss: 2.186519\n",
      "Epoch 179, loss: 2.186229\n",
      "Epoch 180, loss: 2.185938\n",
      "Epoch 181, loss: 2.185648\n",
      "Epoch 182, loss: 2.185353\n",
      "Epoch 183, loss: 2.185074\n",
      "Epoch 184, loss: 2.184786\n",
      "Epoch 185, loss: 2.184502\n",
      "Epoch 186, loss: 2.184216\n",
      "Epoch 187, loss: 2.183941\n",
      "Epoch 188, loss: 2.183657\n",
      "Epoch 189, loss: 2.183389\n",
      "Epoch 190, loss: 2.183111\n",
      "Epoch 191, loss: 2.182843\n",
      "Epoch 192, loss: 2.182568\n",
      "Epoch 193, loss: 2.182305\n",
      "Epoch 194, loss: 2.182036\n",
      "Epoch 195, loss: 2.181766\n",
      "Epoch 196, loss: 2.181507\n",
      "Epoch 197, loss: 2.181238\n",
      "Epoch 198, loss: 2.180980\n",
      "Epoch 199, loss: 2.180723\n",
      "lr: 1e-05, rs: 0.0001, accuracy 200 epochs: 0.224\n",
      "Epoch 0, loss: 2.302064\n",
      "Epoch 1, loss: 2.300575\n",
      "Epoch 2, loss: 2.299167\n",
      "Epoch 3, loss: 2.297804\n",
      "Epoch 4, loss: 2.296477\n",
      "Epoch 5, loss: 2.295178\n",
      "Epoch 6, loss: 2.293889\n",
      "Epoch 7, loss: 2.292634\n",
      "Epoch 8, loss: 2.291389\n",
      "Epoch 9, loss: 2.290161\n",
      "Epoch 10, loss: 2.288951\n",
      "Epoch 11, loss: 2.287753\n",
      "Epoch 12, loss: 2.286567\n",
      "Epoch 13, loss: 2.285400\n",
      "Epoch 14, loss: 2.284246\n",
      "Epoch 15, loss: 2.283099\n",
      "Epoch 16, loss: 2.281969\n",
      "Epoch 17, loss: 2.280848\n",
      "Epoch 18, loss: 2.279746\n",
      "Epoch 19, loss: 2.278648\n",
      "Epoch 20, loss: 2.277573\n",
      "Epoch 21, loss: 2.276511\n",
      "Epoch 22, loss: 2.275452\n",
      "Epoch 23, loss: 2.274404\n",
      "Epoch 24, loss: 2.273372\n",
      "Epoch 25, loss: 2.272347\n",
      "Epoch 26, loss: 2.271334\n",
      "Epoch 27, loss: 2.270331\n",
      "Epoch 28, loss: 2.269342\n",
      "Epoch 29, loss: 2.268349\n",
      "Epoch 30, loss: 2.267378\n",
      "Epoch 31, loss: 2.266423\n",
      "Epoch 32, loss: 2.265464\n",
      "Epoch 33, loss: 2.264522\n",
      "Epoch 34, loss: 2.263587\n",
      "Epoch 35, loss: 2.262657\n",
      "Epoch 36, loss: 2.261742\n",
      "Epoch 37, loss: 2.260834\n",
      "Epoch 38, loss: 2.259933\n",
      "Epoch 39, loss: 2.259039\n",
      "Epoch 40, loss: 2.258160\n",
      "Epoch 41, loss: 2.257287\n",
      "Epoch 42, loss: 2.256426\n",
      "Epoch 43, loss: 2.255552\n",
      "Epoch 44, loss: 2.254710\n",
      "Epoch 45, loss: 2.253874\n",
      "Epoch 46, loss: 2.253035\n",
      "Epoch 47, loss: 2.252205\n",
      "Epoch 48, loss: 2.251377\n",
      "Epoch 49, loss: 2.250579\n",
      "Epoch 50, loss: 2.249771\n",
      "Epoch 51, loss: 2.248971\n",
      "Epoch 52, loss: 2.248184\n",
      "Epoch 53, loss: 2.247402\n",
      "Epoch 54, loss: 2.246623\n",
      "Epoch 55, loss: 2.245854\n",
      "Epoch 56, loss: 2.245094\n",
      "Epoch 57, loss: 2.244336\n",
      "Epoch 58, loss: 2.243588\n",
      "Epoch 59, loss: 2.242844\n",
      "Epoch 60, loss: 2.242108\n",
      "Epoch 61, loss: 2.241376\n",
      "Epoch 62, loss: 2.240656\n",
      "Epoch 63, loss: 2.239937\n",
      "Epoch 64, loss: 2.239223\n",
      "Epoch 65, loss: 2.238523\n",
      "Epoch 66, loss: 2.237822\n",
      "Epoch 67, loss: 2.237127\n",
      "Epoch 68, loss: 2.236442\n",
      "Epoch 69, loss: 2.235765\n",
      "Epoch 70, loss: 2.235087\n",
      "Epoch 71, loss: 2.234415\n",
      "Epoch 72, loss: 2.233755\n",
      "Epoch 73, loss: 2.233097\n",
      "Epoch 74, loss: 2.232441\n",
      "Epoch 75, loss: 2.231794\n",
      "Epoch 76, loss: 2.231151\n",
      "Epoch 77, loss: 2.230518\n",
      "Epoch 78, loss: 2.229888\n",
      "Epoch 79, loss: 2.229262\n",
      "Epoch 80, loss: 2.228641\n",
      "Epoch 81, loss: 2.228024\n",
      "Epoch 82, loss: 2.227415\n",
      "Epoch 83, loss: 2.226807\n",
      "Epoch 84, loss: 2.226212\n",
      "Epoch 85, loss: 2.225617\n",
      "Epoch 86, loss: 2.225019\n",
      "Epoch 87, loss: 2.224441\n",
      "Epoch 88, loss: 2.223861\n",
      "Epoch 89, loss: 2.223281\n",
      "Epoch 90, loss: 2.222710\n",
      "Epoch 91, loss: 2.222143\n",
      "Epoch 92, loss: 2.221588\n",
      "Epoch 93, loss: 2.221028\n",
      "Epoch 94, loss: 2.220474\n",
      "Epoch 95, loss: 2.219924\n",
      "Epoch 96, loss: 2.219377\n",
      "Epoch 97, loss: 2.218834\n",
      "Epoch 98, loss: 2.218306\n",
      "Epoch 99, loss: 2.217775\n",
      "Epoch 100, loss: 2.217247\n",
      "Epoch 101, loss: 2.216729\n",
      "Epoch 102, loss: 2.216211\n",
      "Epoch 103, loss: 2.215694\n",
      "Epoch 104, loss: 2.215172\n",
      "Epoch 105, loss: 2.214678\n",
      "Epoch 106, loss: 2.214180\n",
      "Epoch 107, loss: 2.213680\n",
      "Epoch 108, loss: 2.213185\n",
      "Epoch 109, loss: 2.212697\n",
      "Epoch 110, loss: 2.212205\n",
      "Epoch 111, loss: 2.211727\n",
      "Epoch 112, loss: 2.211250\n",
      "Epoch 113, loss: 2.210768\n",
      "Epoch 114, loss: 2.210306\n",
      "Epoch 115, loss: 2.209832\n",
      "Epoch 116, loss: 2.209371\n",
      "Epoch 117, loss: 2.208914\n",
      "Epoch 118, loss: 2.208452\n",
      "Epoch 119, loss: 2.208003\n",
      "Epoch 120, loss: 2.207549\n",
      "Epoch 121, loss: 2.207105\n",
      "Epoch 122, loss: 2.206660\n",
      "Epoch 123, loss: 2.206227\n",
      "Epoch 124, loss: 2.205789\n",
      "Epoch 125, loss: 2.205353\n",
      "Epoch 126, loss: 2.204927\n",
      "Epoch 127, loss: 2.204500\n",
      "Epoch 128, loss: 2.204079\n",
      "Epoch 129, loss: 2.203657\n",
      "Epoch 130, loss: 2.203242\n",
      "Epoch 131, loss: 2.202824\n",
      "Epoch 132, loss: 2.202411\n",
      "Epoch 133, loss: 2.202009\n",
      "Epoch 134, loss: 2.201604\n",
      "Epoch 135, loss: 2.201197\n",
      "Epoch 136, loss: 2.200805\n",
      "Epoch 137, loss: 2.200407\n",
      "Epoch 138, loss: 2.200011\n",
      "Epoch 139, loss: 2.199624\n",
      "Epoch 140, loss: 2.199230\n",
      "Epoch 141, loss: 2.198852\n",
      "Epoch 142, loss: 2.198479\n",
      "Epoch 143, loss: 2.198097\n",
      "Epoch 144, loss: 2.197717\n",
      "Epoch 145, loss: 2.197340\n",
      "Epoch 146, loss: 2.196977\n",
      "Epoch 147, loss: 2.196611\n",
      "Epoch 148, loss: 2.196245\n",
      "Epoch 149, loss: 2.195882\n",
      "Epoch 150, loss: 2.195518\n",
      "Epoch 151, loss: 2.195167\n",
      "Epoch 152, loss: 2.194807\n",
      "Epoch 153, loss: 2.194459\n",
      "Epoch 154, loss: 2.194107\n",
      "Epoch 155, loss: 2.193763\n",
      "Epoch 156, loss: 2.193410\n",
      "Epoch 157, loss: 2.193072\n",
      "Epoch 158, loss: 2.192737\n",
      "Epoch 159, loss: 2.192397\n",
      "Epoch 160, loss: 2.192064\n",
      "Epoch 161, loss: 2.191731\n",
      "Epoch 162, loss: 2.191400\n",
      "Epoch 163, loss: 2.191071\n",
      "Epoch 164, loss: 2.190747\n",
      "Epoch 165, loss: 2.190418\n",
      "Epoch 166, loss: 2.190097\n",
      "Epoch 167, loss: 2.189778\n",
      "Epoch 168, loss: 2.189463\n",
      "Epoch 169, loss: 2.189138\n",
      "Epoch 170, loss: 2.188824\n",
      "Epoch 171, loss: 2.188522\n",
      "Epoch 172, loss: 2.188216\n",
      "Epoch 173, loss: 2.187910\n",
      "Epoch 174, loss: 2.187603\n",
      "Epoch 175, loss: 2.187296\n",
      "Epoch 176, loss: 2.186997\n",
      "Epoch 177, loss: 2.186700\n",
      "Epoch 178, loss: 2.186402\n",
      "Epoch 179, loss: 2.186104\n",
      "Epoch 180, loss: 2.185816\n",
      "Epoch 181, loss: 2.185523\n",
      "Epoch 182, loss: 2.185231\n",
      "Epoch 183, loss: 2.184945\n",
      "Epoch 184, loss: 2.184655\n",
      "Epoch 185, loss: 2.184370\n",
      "Epoch 186, loss: 2.184094\n",
      "Epoch 187, loss: 2.183816\n",
      "Epoch 188, loss: 2.183539\n",
      "Epoch 189, loss: 2.183261\n",
      "Epoch 190, loss: 2.182989\n",
      "Epoch 191, loss: 2.182717\n",
      "Epoch 192, loss: 2.182439\n",
      "Epoch 193, loss: 2.182173\n",
      "Epoch 194, loss: 2.181904\n",
      "Epoch 195, loss: 2.181638\n",
      "Epoch 196, loss: 2.181377\n",
      "Epoch 197, loss: 2.181111\n",
      "Epoch 198, loss: 2.180848\n",
      "Epoch 199, loss: 2.180591\n",
      "lr: 1e-05, rs: 1e-05, accuracy 200 epochs: 0.223\n",
      "Epoch 0, loss: 2.302275\n",
      "Epoch 1, loss: 2.300713\n",
      "Epoch 2, loss: 2.299273\n",
      "Epoch 3, loss: 2.297894\n",
      "Epoch 4, loss: 2.296553\n",
      "Epoch 5, loss: 2.295252\n",
      "Epoch 6, loss: 2.293971\n",
      "Epoch 7, loss: 2.292706\n",
      "Epoch 8, loss: 2.291464\n",
      "Epoch 9, loss: 2.290233\n",
      "Epoch 10, loss: 2.289026\n",
      "Epoch 11, loss: 2.287824\n",
      "Epoch 12, loss: 2.286638\n",
      "Epoch 13, loss: 2.285474\n",
      "Epoch 14, loss: 2.284317\n",
      "Epoch 15, loss: 2.283178\n",
      "Epoch 16, loss: 2.282049\n",
      "Epoch 17, loss: 2.280928\n",
      "Epoch 18, loss: 2.279825\n",
      "Epoch 19, loss: 2.278733\n",
      "Epoch 20, loss: 2.277650\n",
      "Epoch 21, loss: 2.276583\n",
      "Epoch 22, loss: 2.275525\n",
      "Epoch 23, loss: 2.274477\n",
      "Epoch 24, loss: 2.273445\n",
      "Epoch 25, loss: 2.272419\n",
      "Epoch 26, loss: 2.271405\n",
      "Epoch 27, loss: 2.270403\n",
      "Epoch 28, loss: 2.269408\n",
      "Epoch 29, loss: 2.268424\n",
      "Epoch 30, loss: 2.267449\n",
      "Epoch 31, loss: 2.266485\n",
      "Epoch 32, loss: 2.265529\n",
      "Epoch 33, loss: 2.264584\n",
      "Epoch 34, loss: 2.263649\n",
      "Epoch 35, loss: 2.262721\n",
      "Epoch 36, loss: 2.261810\n",
      "Epoch 37, loss: 2.260890\n",
      "Epoch 38, loss: 2.259996\n",
      "Epoch 39, loss: 2.259097\n",
      "Epoch 40, loss: 2.258225\n",
      "Epoch 41, loss: 2.257347\n",
      "Epoch 42, loss: 2.256477\n",
      "Epoch 43, loss: 2.255616\n",
      "Epoch 44, loss: 2.254764\n",
      "Epoch 45, loss: 2.253926\n",
      "Epoch 46, loss: 2.253089\n",
      "Epoch 47, loss: 2.252259\n",
      "Epoch 48, loss: 2.251441\n",
      "Epoch 49, loss: 2.250630\n",
      "Epoch 50, loss: 2.249812\n",
      "Epoch 51, loss: 2.249022\n",
      "Epoch 52, loss: 2.248231\n",
      "Epoch 53, loss: 2.247447\n",
      "Epoch 54, loss: 2.246670\n",
      "Epoch 55, loss: 2.245901\n",
      "Epoch 56, loss: 2.245139\n",
      "Epoch 57, loss: 2.244378\n",
      "Epoch 58, loss: 2.243624\n",
      "Epoch 59, loss: 2.242880\n",
      "Epoch 60, loss: 2.242151\n",
      "Epoch 61, loss: 2.241422\n",
      "Epoch 62, loss: 2.240698\n",
      "Epoch 63, loss: 2.239978\n",
      "Epoch 64, loss: 2.239262\n",
      "Epoch 65, loss: 2.238559\n",
      "Epoch 66, loss: 2.237857\n",
      "Epoch 67, loss: 2.237169\n",
      "Epoch 68, loss: 2.236478\n",
      "Epoch 69, loss: 2.235796\n",
      "Epoch 70, loss: 2.235107\n",
      "Epoch 71, loss: 2.234452\n",
      "Epoch 72, loss: 2.233789\n",
      "Epoch 73, loss: 2.233127\n",
      "Epoch 74, loss: 2.232475\n",
      "Epoch 75, loss: 2.231822\n",
      "Epoch 76, loss: 2.231187\n",
      "Epoch 77, loss: 2.230548\n",
      "Epoch 78, loss: 2.229915\n",
      "Epoch 79, loss: 2.229287\n",
      "Epoch 80, loss: 2.228668\n",
      "Epoch 81, loss: 2.228048\n",
      "Epoch 82, loss: 2.227439\n",
      "Epoch 83, loss: 2.226832\n",
      "Epoch 84, loss: 2.226235\n",
      "Epoch 85, loss: 2.225636\n",
      "Epoch 86, loss: 2.225048\n",
      "Epoch 87, loss: 2.224461\n",
      "Epoch 88, loss: 2.223878\n",
      "Epoch 89, loss: 2.223305\n",
      "Epoch 90, loss: 2.222723\n",
      "Epoch 91, loss: 2.222164\n",
      "Epoch 92, loss: 2.221601\n",
      "Epoch 93, loss: 2.221043\n",
      "Epoch 94, loss: 2.220488\n",
      "Epoch 95, loss: 2.219936\n",
      "Epoch 96, loss: 2.219400\n",
      "Epoch 97, loss: 2.218851\n",
      "Epoch 98, loss: 2.218320\n",
      "Epoch 99, loss: 2.217788\n",
      "Epoch 100, loss: 2.217265\n",
      "Epoch 101, loss: 2.216741\n",
      "Epoch 102, loss: 2.216225\n",
      "Epoch 103, loss: 2.215706\n",
      "Epoch 104, loss: 2.215194\n",
      "Epoch 105, loss: 2.214688\n",
      "Epoch 106, loss: 2.214189\n",
      "Epoch 107, loss: 2.213690\n",
      "Epoch 108, loss: 2.213197\n",
      "Epoch 109, loss: 2.212705\n",
      "Epoch 110, loss: 2.212219\n",
      "Epoch 111, loss: 2.211730\n",
      "Epoch 112, loss: 2.211252\n",
      "Epoch 113, loss: 2.210781\n",
      "Epoch 114, loss: 2.210310\n",
      "Epoch 115, loss: 2.209837\n",
      "Epoch 116, loss: 2.209377\n",
      "Epoch 117, loss: 2.208908\n",
      "Epoch 118, loss: 2.208455\n",
      "Epoch 119, loss: 2.208003\n",
      "Epoch 120, loss: 2.207550\n",
      "Epoch 121, loss: 2.207108\n",
      "Epoch 122, loss: 2.206665\n",
      "Epoch 123, loss: 2.206222\n",
      "Epoch 124, loss: 2.205787\n",
      "Epoch 125, loss: 2.205349\n",
      "Epoch 126, loss: 2.204920\n",
      "Epoch 127, loss: 2.204499\n",
      "Epoch 128, loss: 2.204075\n",
      "Epoch 129, loss: 2.203650\n",
      "Epoch 130, loss: 2.203237\n",
      "Epoch 131, loss: 2.202822\n",
      "Epoch 132, loss: 2.202408\n",
      "Epoch 133, loss: 2.202002\n",
      "Epoch 134, loss: 2.201599\n",
      "Epoch 135, loss: 2.201195\n",
      "Epoch 136, loss: 2.200796\n",
      "Epoch 137, loss: 2.200404\n",
      "Epoch 138, loss: 2.200005\n",
      "Epoch 139, loss: 2.199617\n",
      "Epoch 140, loss: 2.199233\n",
      "Epoch 141, loss: 2.198850\n",
      "Epoch 142, loss: 2.198467\n",
      "Epoch 143, loss: 2.198083\n",
      "Epoch 144, loss: 2.197709\n",
      "Epoch 145, loss: 2.197337\n",
      "Epoch 146, loss: 2.196963\n",
      "Epoch 147, loss: 2.196598\n",
      "Epoch 148, loss: 2.196231\n",
      "Epoch 149, loss: 2.195870\n",
      "Epoch 150, loss: 2.195510\n",
      "Epoch 151, loss: 2.195139\n",
      "Epoch 152, loss: 2.194795\n",
      "Epoch 153, loss: 2.194444\n",
      "Epoch 154, loss: 2.194095\n",
      "Epoch 155, loss: 2.193748\n",
      "Epoch 156, loss: 2.193401\n",
      "Epoch 157, loss: 2.193060\n",
      "Epoch 158, loss: 2.192720\n",
      "Epoch 159, loss: 2.192380\n",
      "Epoch 160, loss: 2.192040\n",
      "Epoch 161, loss: 2.191706\n",
      "Epoch 162, loss: 2.191383\n",
      "Epoch 163, loss: 2.191048\n",
      "Epoch 164, loss: 2.190726\n",
      "Epoch 165, loss: 2.190402\n",
      "Epoch 166, loss: 2.190080\n",
      "Epoch 167, loss: 2.189761\n",
      "Epoch 168, loss: 2.189435\n",
      "Epoch 169, loss: 2.189124\n",
      "Epoch 170, loss: 2.188811\n",
      "Epoch 171, loss: 2.188497\n",
      "Epoch 172, loss: 2.188192\n",
      "Epoch 173, loss: 2.187886\n",
      "Epoch 174, loss: 2.187583\n",
      "Epoch 175, loss: 2.187278\n",
      "Epoch 176, loss: 2.186968\n",
      "Epoch 177, loss: 2.186675\n",
      "Epoch 178, loss: 2.186379\n",
      "Epoch 179, loss: 2.186080\n",
      "Epoch 180, loss: 2.185789\n",
      "Epoch 181, loss: 2.185499\n",
      "Epoch 182, loss: 2.185210\n",
      "Epoch 183, loss: 2.184919\n",
      "Epoch 184, loss: 2.184638\n",
      "Epoch 185, loss: 2.184353\n",
      "Epoch 186, loss: 2.184070\n",
      "Epoch 187, loss: 2.183786\n",
      "Epoch 188, loss: 2.183500\n",
      "Epoch 189, loss: 2.183234\n",
      "Epoch 190, loss: 2.182959\n",
      "Epoch 191, loss: 2.182686\n",
      "Epoch 192, loss: 2.182414\n",
      "Epoch 193, loss: 2.182142\n",
      "Epoch 194, loss: 2.181876\n",
      "Epoch 195, loss: 2.181610\n",
      "Epoch 196, loss: 2.181344\n",
      "Epoch 197, loss: 2.181079\n",
      "Epoch 198, loss: 2.180822\n",
      "Epoch 199, loss: 2.180556\n",
      "lr: 1e-05, rs: 1e-06, accuracy 200 epochs: 0.224\n",
      "best validation accuracy achieved: 0.253000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "# TODO use validation set to find the best hyperparameters\n",
    "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
    "# than provided initially\n",
    "scores = []\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strengths:\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        loss_history = classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=lr, batch_size=batch_size, reg=rs)\n",
    "        pred = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        if accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            best_classifier = classifier\n",
    "        print(f\"lr: {lr}, rs: {rs}, accuracy 200 epochs: {accuracy}\")\n",
    "        scores.append((lr, rs, accuracy))\n",
    "        \n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7EtKeq697WA",
    "outputId": "5e5de7c3-ad07-4d10-e605-5059c245fa1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: lr = 0.001, rs = 0.001, accuracy = 0.253\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: lr = %.3f, rs = %.3f, accuracy = %.3f' % sorted(scores, key=lambda x: x[2], reverse=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTkMtNXV97WD"
   },
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5qeGU3s97WI",
    "outputId": "1d3d3834-9cfa-4c6d-bb3b-811409a362db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.195000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Linear classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
